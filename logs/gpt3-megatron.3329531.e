Error: SMPI environment generator script not found at:
Path : /gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/bin/alias.pl
Error: No such file or directory
Warning. Failed to setup the Spectrum MPI environment.
Continuing to launch. Beware, the Spectrum MPI environment may not be completely setup.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
/bin/sh: line 0: type: git: not found
Detected CUDA files, patching ldflags
Emitting ninja build file /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/fused_kernels/build/build.ninja...
Building extension module scaled_upper_triang_masked_softmax_cuda...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module scaled_upper_triang_masked_softmax_cuda...
Detected CUDA files, patching ldflags
Emitting ninja build file /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/fused_kernels/build/build.ninja...
Building extension module scaled_masked_softmax_cuda...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module scaled_masked_softmax_cuda...
Detected CUDA files, patching ldflags
Emitting ninja build file /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/fused_kernels/build/build.ninja...
Building extension module scaled_softmax_cuda...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module scaled_softmax_cuda...
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model = get_model(model_provider_func, model_type)
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model = get_model(model_provider_func, model_type)
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    model = get_model(model_provider_func, model_type)
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    model = get_model(model_provider_func, model_type)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    self.language_model, self._language_model_key = get_language_model(
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    model = get_model(model_provider_func, model_type)
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    model = get_model(model_provider_func, model_type)
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
    self.layers.append(build_layer(layer_num, n_e))
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model = get_model(model_provider_func, model_type)
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    self.layers.append(build_layer(layer_num, n_e))
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model = get_model(model_provider_func, model_type)
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    model = get_model(model_provider_func, model_type)
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
    model = get_model(model_provider_func, model_type)
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    model = get_model(model_provider_func, model_type)
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model = get_model(model_provider_func, model_type)
    self.layers.append(build_layer(layer_num, n_e))
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.layers.append(build_layer(layer_num, n_e))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.layers.append(build_layer(layer_num, n_e))
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    model = get_model(model_provider_func, model_type)
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    model = get_model(model_provider_func, model_type)
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    model = get_model(model_provider_func, model_type)
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    model = get_model(model_provider_func, model_type)
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    self.num_attention_heads_per_partition = core.utils.divide(
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    ensure_divisibility(numerator, denominator)
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    ensure_divisibility(numerator, denominator)
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    self.num_attention_heads_per_partition = core.utils.divide(
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    ensure_divisibility(numerator, denominator)
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    ensure_divisibility(numerator, denominator)
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    model = get_model(model_provider_func, model_type)
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model = get_model(model_provider_func, model_type)
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model = get_model(model_provider_func, model_type)
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
    self.encoder = ParallelTransformer(
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    model = get_model(model_provider_func, model_type)
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
    model = get_model(model_provider_func, model_type)
    self.layers.append(build_layer(layer_num, n_e))
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
    self.layers.append(build_layer(layer_num, n_e))
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.layers.append(build_layer(layer_num, n_e))
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    self.language_model, self._language_model_key = get_language_model(
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    self.layers.append(build_layer(layer_num, n_e))
    self.layers.append(build_layer(layer_num, n_e))
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.layers.append(build_layer(layer_num, n_e))
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model = get_model(model_provider_func, model_type)
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    model = get_model(model_provider_func, model_type)
    model = get_model(model_provider_func, model_type)
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    model = get_model(model_provider_func, model_type)
    model = get_model(model_provider_func, model_type)
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    model = get_model(model_provider_func, model_type)
    model = get_model(model_provider_func, model_type)
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.num_attention_heads_per_partition = core.utils.divide(
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    model = get_model(model_provider_func, model_type)
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    model = GPTModel(
            ^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    ensure_divisibility(numerator, denominator)
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    ensure_divisibility(numerator, denominator)
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    self.self_attention = ParallelAttention(
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    model = GPTModel(
            ^^^^^^^^^
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    self.num_attention_heads_per_partition = core.utils.divide(
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    model = get_model(model_provider_func, model_type)
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    self.encoder = ParallelTransformer(
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    model = get_model(model_provider_func, model_type)
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    model = get_model(model_provider_func, model_type)
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model = get_model(model_provider_func, model_type)
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model = get_model(model_provider_func, model_type)
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    self.layers.append(build_layer(layer_num, n_e))
    model = get_model(model_provider_func, model_type)
    self.layers.append(build_layer(layer_num, n_e))
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.layers.append(build_layer(layer_num, n_e))
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model = get_model(model_provider_func, model_type)
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model = get_model(model_provider_func, model_type)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.layers.append(build_layer(layer_num, n_e))
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    model = get_model(model_provider_func, model_type)
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    model = get_model(model_provider_func, model_type)
    model = get_model(model_provider_func, model_type)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.layers.append(build_layer(layer_num, n_e))
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    model = get_model(model_provider_func, model_type)
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.layers.append(build_layer(layer_num, n_e))
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    model = get_model(model_provider_func, model_type)
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.layers.append(build_layer(layer_num, n_e))
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
Traceback (most recent call last):
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 356, in <module>
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    model = get_model(model_provider_func, model_type)
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    model = get_model(model_provider_func, model_type)
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.layers.append(build_layer(layer_num, n_e))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    self.num_attention_heads_per_partition = core.utils.divide(
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.layers.append(build_layer(layer_num, n_e))
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    model = GPTModel(
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    model = get_model(model_provider_func, model_type)
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    self.layers.append(build_layer(layer_num, n_e))
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    model = get_model(model_provider_func, model_type)
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.num_attention_heads_per_partition = core.utils.divide(
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    ensure_divisibility(numerator, denominator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
    self.language_model, self._language_model_key = get_language_model(
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    self.layers.append(build_layer(layer_num, n_e))
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
AssertionError: 32 is not divisible by 6
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    self.num_attention_heads_per_partition = core.utils.divide(
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    self.num_attention_heads_per_partition = core.utils.divide(
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    ensure_divisibility(numerator, denominator)
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    self.num_attention_heads_per_partition = core.utils.divide(
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.layers.append(build_layer(layer_num, n_e))
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    ensure_divisibility(numerator, denominator)
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    self.layers.append(build_layer(layer_num, n_e))
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    self.layers.append(build_layer(layer_num, n_e))
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    self.layers.append(build_layer(layer_num, n_e))
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.layers.append(build_layer(layer_num, n_e))
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    self.layers.append(build_layer(layer_num, n_e))
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    self.layers.append(build_layer(layer_num, n_e))
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    pretrain(train_valid_test_datasets_provider,
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 165, in pretrain
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.layers.append(build_layer(layer_num, n_e))
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.layers.append(build_layer(layer_num, n_e))
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.layers.append(build_layer(layer_num, n_e))
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    self.layers.append(build_layer(layer_num, n_e))
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.layers.append(build_layer(layer_num, n_e))
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.num_attention_heads_per_partition = core.utils.divide(
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    ensure_divisibility(numerator, denominator)
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    ensure_divisibility(numerator, denominator)
    ensure_divisibility(numerator, denominator)
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    model = get_model(model_provider_func, model_type)
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 527, in setup_model_and_optimizer
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    model = get_model(model_provider_func, model_type)
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    model = get_model(model_provider_func, model_type)
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    model = get_model(model_provider_func, model_type)
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    model = get_model(model_provider_func, model_type)
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    model = get_model(model_provider_func, model_type)
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    model = get_model(model_provider_func, model_type)
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    model = get_model(model_provider_func, model_type)
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    model = get_model(model_provider_func, model_type)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    model = get_model(model_provider_func, model_type)
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    model = get_model(model_provider_func, model_type)
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/training.py", line 366, in get_model
    self.num_attention_heads_per_partition = core.utils.divide(
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.num_attention_heads_per_partition = core.utils.divide(
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    ensure_divisibility(numerator, denominator)
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    model = model_provider_func(
            ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/pretrain_gpt.py", line 82, in model_provider
    ensure_divisibility(numerator, denominator)
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    model = GPTModel(
            ^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 85, in __init__
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    self.language_model, self._language_model_key = get_language_model(
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    ensure_divisibility(numerator, denominator)
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    self.language_model, self._language_model_key = get_language_model(
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
                                                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 67, in get_language_model
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    language_model = TransformerLanguageModel(
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    self.layers.append(build_layer(layer_num, n_e))
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    self.layers.append(build_layer(layer_num, n_e))
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
    self.layers.append(build_layer(layer_num, n_e))
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    self.layers.append(build_layer(layer_num, n_e))
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
    language_model = TransformerLanguageModel(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/language_model.py", line 441, in __init__
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.layers.append(build_layer(layer_num, n_e))
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.layers.append(build_layer(layer_num, n_e))
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.layers.append(build_layer(layer_num, n_e))
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.layers.append(build_layer(layer_num, n_e))
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    self.layers.append(build_layer(layer_num, n_e))
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.encoder = ParallelTransformer(
                   ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1677, in __init__
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    self.layers.append(build_layer(layer_num, n_e))
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    self.layers.append(build_layer(layer_num, n_e))
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    self.layers.append(build_layer(layer_num, n_e))
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.layers.append(build_layer(layer_num, n_e))
    self.layers.append(build_layer(layer_num, n_e))
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.layers.append(build_layer(layer_num, n_e))
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.layers.append(build_layer(layer_num, n_e))
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    ensure_divisibility(numerator, denominator)
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
    self.layers.append(build_layer(layer_num, n_e))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 1580, in build_layer
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    ensure_divisibility(numerator, denominator)
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    self.num_attention_heads_per_partition = core.utils.divide(
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
AssertionError: 32 is not divisible by 6
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    return ParallelTransformerLayer(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 899, in __init__
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    ensure_divisibility(numerator, denominator)
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
    self.self_attention = ParallelAttention(
                          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/model/transformer.py", line 527, in __init__
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    ensure_divisibility(numerator, denominator)
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    ensure_divisibility(numerator, denominator)
    self.num_attention_heads_per_partition = core.utils.divide(
                                             ^^^^^^^^^^^^^^^^^^
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 26, in divide
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    ensure_divisibility(numerator, denominator)
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    ensure_divisibility(numerator, denominator)
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
  File "/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/core/utils.py", line 18, in ensure_divisibility
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6
    assert numerator % denominator == 0, "{} is not divisible by {}".format(
AssertionError: 32 is not divisible by 6

real	0m59.785s
user	0m0.344s
sys	0m0.159s
