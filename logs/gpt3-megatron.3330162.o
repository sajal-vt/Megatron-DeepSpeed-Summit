d09n07
10.134.8.171
[2024-03-04 16:46:05,493] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,493] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,493] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,493] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,493] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,493] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,499] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,499] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,504] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,508] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,508] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,508] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,509] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,510] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,510] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,510] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,510] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,510] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,512] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,512] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,512] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,512] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,513] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,513] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,513] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,514] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,515] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,515] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,515] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,515] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,521] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,522] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,522] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,522] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,522] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,523] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,524] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,524] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,524] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,524] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,524] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,524] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,532] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,532] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,532] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,532] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,532] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,532] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,633] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,633] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,634] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,635] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,635] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,635] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,650] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,650] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,651] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,653] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,655] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:05,655] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,872] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,872] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,872] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,872] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,872] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,872] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,874] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,874] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,874] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,874] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,874] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,875] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,874] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,875] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,874] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,875] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,875] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,875] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,876] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,876] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,876] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,876] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,876] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,876] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,948] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,948] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,948] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,948] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,948] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,948] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,971] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,971] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,971] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,971] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,971] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 16:46:07,971] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 83
MA = 10.134.8.171
World view:  83 96 10.134.8.171
[2024-03-04 16:46:08,907] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:08,908] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 82
MA = 10.134.8.171
World view:  82 96 10.134.8.171
[2024-03-04 16:46:08,907] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:08,908] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 81
MA = 10.134.8.171
World view:  81 96 10.134.8.171
[2024-03-04 16:46:08,908] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:08,908] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 78
MA = 10.134.8.171
World view:  78 96 10.134.8.171
[2024-03-04 16:46:08,910] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 80
MA = 10.134.8.171
World view:  80 96 10.134.8.171
[2024-03-04 16:46:08,910] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:08,910] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 79
MA = 10.134.8.171
World view:  79 96 10.134.8.171
[2024-03-04 16:46:08,910] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:08,910] [INFO] [comm.py:616:init_distributed] cdb=None
[2024-03-04 16:46:08,910] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 72
MA = 10.134.8.171
World view:  72 96 10.134.8.171
[2024-03-04 16:46:08,919] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 73
MA = 10.134.8.171
World view:  73 96 10.134.8.171
[2024-03-04 16:46:08,919] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:08,919] [INFO] [comm.py:616:init_distributed] cdb=None
[2024-03-04 16:46:08,919] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 74
MA = 10.134.8.171
World view:  74 96 10.134.8.171
[2024-03-04 16:46:08,919] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:08,919] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 16
MA = 10.134.8.171
World view:  16 96 10.134.8.171
[2024-03-04 16:46:08,921] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 17
MA = 10.134.8.171
World view:  17 96 10.134.8.171
[2024-03-04 16:46:08,921] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:08,921] [INFO] [comm.py:616:init_distributed] cdb=None
[2024-03-04 16:46:08,921] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 13
MA = 10.134.8.171
World view:  13 96 10.134.8.171
[2024-03-04 16:46:08,921] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 14
MA = 10.134.8.171
World view:  14 96 10.134.8.171
[2024-03-04 16:46:08,921] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:08,921] [INFO] [comm.py:616:init_distributed] cdb=None
[2024-03-04 16:46:08,921] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 12
MA = 10.134.8.171
World view:  12 96 10.134.8.171
[2024-03-04 16:46:08,923] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:08,924] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 77
MA = 10.134.8.171
World view:  77 96 10.134.8.171
[2024-03-04 16:46:08,923] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 75
MA = 10.134.8.171
World view:  75 96 10.134.8.171
[2024-03-04 16:46:08,924] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:08,924] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 15
MA = 10.134.8.171
World view:  15 96 10.134.8.171
[2024-03-04 16:46:08,924] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:08,924] [INFO] [comm.py:616:init_distributed] cdb=None
[2024-03-04 16:46:08,924] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 68
MA = 10.134.8.171
World view:  68 96 10.134.8.171
[2024-03-04 16:46:08,924] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:08,924] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 76
MA = 10.134.8.171
World view:  76 96 10.134.8.171
[2024-03-04 16:46:08,924] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 67
MA = 10.134.8.171
World view:  67 96 10.134.8.171
[2024-03-04 16:46:08,924] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:08,924] [INFO] [comm.py:616:init_distributed] cdb=None
[2024-03-04 16:46:08,925] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 66
MA = 10.134.8.171
World view:  66 96 10.134.8.171
[2024-03-04 16:46:08,926] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:08,926] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 69
MA = 10.134.8.171
World view:  69 96 10.134.8.171
[2024-03-04 16:46:08,926] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 70
MA = 10.134.8.171
World view:  70 96 10.134.8.171
[2024-03-04 16:46:08,926] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:08,926] [INFO] [comm.py:616:init_distributed] cdb=None
[2024-03-04 16:46:08,926] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 71
MA = 10.134.8.171
World view:  71 96 10.134.8.171
[2024-03-04 16:46:08,930] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:08,930] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 92
MA = 10.134.8.171
World view:  92 96 10.134.8.171
[2024-03-04 16:46:08,942] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 94
MA = 10.134.8.171
World view:  94 96 10.134.8.171
[2024-03-04 16:46:08,942] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:08,942] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 91
MA = 10.134.8.171
World view:  91 96 10.134.8.171
[2024-03-04 16:46:08,942] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:08,942] [INFO] [comm.py:616:init_distributed] cdb=None
[2024-03-04 16:46:08,942] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 90
MA = 10.134.8.171
World view:  90 96 10.134.8.171
[2024-03-04 16:46:08,943] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:08,943] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 93
MA = 10.134.8.171
World view:  93 96 10.134.8.171
[2024-03-04 16:46:08,943] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:08,943] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 86
MA = 10.134.8.171
World view:  86 96 10.134.8.171
[2024-03-04 16:46:08,952] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:08,952] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 89
MA = 10.134.8.171
World view:  89 96 10.134.8.171
[2024-03-04 16:46:08,952] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:08,952] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 84
MA = 10.134.8.171
World view:  84 96 10.134.8.171
[2024-03-04 16:46:08,952] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:08,952] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 85
MA = 10.134.8.171
World view:  85 96 10.134.8.171
[2024-03-04 16:46:08,953] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:08,953] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 88
MA = 10.134.8.171
World view:  88 96 10.134.8.171
[2024-03-04 16:46:08,953] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:08,953] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 87
MA = 10.134.8.171
World view:  87 96 10.134.8.171
[2024-03-04 16:46:08,953] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:08,953] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 19
MA = 10.134.8.171
World view:  19 96 10.134.8.171
[2024-03-04 16:46:08,999] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:08,999] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 20
MA = 10.134.8.171
World view:  20 96 10.134.8.171
[2024-03-04 16:46:09,000] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:09,000] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 18
MA = 10.134.8.171
World view:  18 96 10.134.8.171
[2024-03-04 16:46:09,001] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:09,001] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 22
MA = 10.134.8.171
World view:  22 96 10.134.8.171
[2024-03-04 16:46:09,001] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:09,001] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 21
MA = 10.134.8.171
World view:  21 96 10.134.8.171
[2024-03-04 16:46:09,001] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:09,001] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 23
MA = 10.134.8.171
World view:  23 96 10.134.8.171
[2024-03-04 16:46:09,002] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:09,002] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 0
MA = 10.134.8.171
World view:  0 96 10.134.8.171
using world size: 96, data-parallel-size: 12, sequence-parallel size: 1, tensor-model-parallel size: 8, pipeline-model-parallel size: 1 
using torch.float16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. False
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.95
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  aml_data_download_path .......................... None
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ False
  bias_dropout_fusion ............................. True
  bias_gelu_fusion ................................ True
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  checkpoint_activations .......................... True
  checkpoint_in_cpu ............................... False
  checkpoint_num_layers ........................... 1
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  compression_training ............................ False
  consumed_train_samples .......................... 0
  consumed_train_tokens ........................... 0
  consumed_valid_samples .......................... 0
  contigious_checkpointing ........................ False
  cpu_optimizer ................................... False
  cpu_torch_adam .................................. False
  create_moe_param_group .......................... False
  curriculum_learning_legacy ...................... False
  data_cache_path ................................. None
  data_efficiency_curriculum_learning ............. False
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 12
  data_path ....................................... ['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  deepscale ....................................... False
  deepscale_config ................................ None
  deepspeed ....................................... True
  deepspeed_activation_checkpointing .............. True
  deepspeed_config ................................ ds_config_gpt_gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1.json
  deepspeed_mpi ................................... False
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_checkpointed_activations ............. False
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  ds_fused_adam ................................... False
  ds_inference .................................... False
  ds_pipeline_enabled ............................. True
  ds_sequence_parallel_size ....................... 1
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  enable_expert_tensor_parallelism ................ False
  encoder_num_layers .............................. 32
  encoder_seq_length .............................. 2048
  end_weight_decay ................................ 0.1
  eod_mask_loss ................................... False
  eval_interval ................................... 100
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... 30000000
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  expert_interval ................................. 2
  ffn_hidden_size ................................. 16384
  finetune ........................................ False
  force_ds_sequence_parallel ...................... False
  fp16 ............................................ True
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 24
  gradient_accumulation_fusion .................... True
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 4096
  hidden_size_teacher ............................. None
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference ....................................... False
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.014
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  kd .............................................. False
  kd_alpha_ce ..................................... 1
  kd_beta_ce ...................................... 1
  kd_temp ......................................... 1.0
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1
  load_tag ........................................ None
  load_teacher .................................... None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... True
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_optimizer_states_to_tensorboard ............. False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... True
  log_validation_ppl_to_tensorboard ............... True
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00012
  lr_decay_iters .................................. None
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_decay_tokens ................................. 300000000000
  lr_warmup_fraction .............................. None
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  lr_warmup_tokens ................................ 375000000
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... True
  max_position_embeddings ......................... 2048
  max_tokens_to_oom ............................... 12000
  mem_efficient_ln ................................ True
  memory_centric_tiled_linear ..................... False
  merge_file ...................................... gpt2-merges.txt
  micro_batch_size ................................ 1
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-06
  mlp_type ........................................ standard
  mmap_warmup ..................................... False
  moe_eval_capacity_factor ........................ 1.0
  moe_expert_parallel_size ........................ 1
  moe_loss_coeff .................................. 0.01
  moe_min_capacity ................................ 4
  moe_token_dropping .............................. True
  moe_train_capacity_factor ....................... 1.0
  mos ............................................. False
  no_load_lr_state ................................ False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_pipeline_parallel ............................ False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  normalization ................................... layernorm
  num_attention_heads ............................. 32
  num_attention_heads_teacher ..................... None
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... [1]
  num_experts_switch .............................. None
  num_experts_teacher ............................. [1]
  num_key_value_heads ............................. 32
  num_layers ...................................... 32
  num_layers_per_virtual_pipeline_stage ........... None
  num_layers_teacher .............................. None
  num_workers ..................................... 0
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... True
  params_dtype .................................... torch.float16
  partition_activations ........................... False
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 1
  pipeline_model_parallel_split_rank .............. None
  profile_backward ................................ False
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  random_ltd ...................................... False
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  remote_device ................................... none
  repeated_dataloader ............................. False
  reset_attention_mask ............................ False
  reset_iteration ................................. False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  return_data_index ............................... False
  rope_theta ...................................... 10000
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1
  save_interval ................................... 10000
  scatter_gather_tensors_in_pipeline .............. True
  scattered_embeddings ............................ False
  seed ............................................ 1234
  seq_length ...................................... 2048
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  skip_train ...................................... False
  split ........................................... 98,2,0
  split_transformers .............................. False
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.1
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  synchronize_each_layer .......................... False
  tensor_model_parallel_size ...................... 8
  tensorboard_dir ................................. /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1
  test_data_path .................................. None
  tile_factor ..................................... 1
  timing_log_level ................................ 0
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  topk ............................................ 1
  train_data_exact_num_epochs ..................... None
  train_data_path ................................. None
  train_desc_path ................................. None
  train_doc_idx_path .............................. None
  train_idx_path .................................. None
  train_iters ..................................... 18310546
  train_sample_idx_path ........................... None
  train_samples ................................... None
  train_shuffle_idx_path .......................... None
  train_tokens .................................... 300000000000
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 1
  universal_checkpoint ............................ False
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_dataset_only ................................ False
  use_distributed_optimizer ....................... False
  use_flash_attn .................................. False
  use_flash_attn_triton ........................... False
  use_flash_attn_v1 ............................... False
  use_flash_attn_v2 ............................... False
  use_one_sent_docs ............................... False
  use_pin_memory .................................. False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  use_tutel ....................................... False
  valid_data_path ................................. None
  variable_seq_lengths ............................ False
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... gpt2-vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.1
  weight_decay_incr_style ......................... constant
  world_size ...................................... 96
  zero_allgather_bucket_size ...................... 0.0
  zero_contigious_gradients ....................... False
  zero_reduce_bucket_size ......................... 0.0
  zero_reduce_scatter ............................. False
  zero_stage ...................................... 1.0
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 2
> building GPT2BPETokenizer tokenizer ...
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 61
MA = 10.134.8.171
World view:  61 96 10.134.8.171
[2024-03-04 16:46:09,053] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:09,053] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 60
MA = 10.134.8.171
World view:  60 96 10.134.8.171
[2024-03-04 16:46:09,053] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:09,053] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 64
MA = 10.134.8.171
World view:  64 96 10.134.8.171
[2024-03-04 16:46:09,053] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:09,054] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 62
MA = 10.134.8.171
World view:  62 96 10.134.8.171
[2024-03-04 16:46:09,054] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:09,054] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 65
MA = 10.134.8.171
World view:  65 96 10.134.8.171
[2024-03-04 16:46:09,055] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:09,055] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 63
MA = 10.134.8.171
World view:  63 96 10.134.8.171
[2024-03-04 16:46:09,055] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:09,055] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 10
MA = 10.134.8.171
World view:  10 96 10.134.8.171
[2024-03-04 16:46:09,059] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:09,059] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 8
MA = 10.134.8.171
World view:  8 96 10.134.8.171
[2024-03-04 16:46:09,059] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:09,059] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 9
MA = 10.134.8.171
World view:  9 96 10.134.8.171
[2024-03-04 16:46:09,059] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:09,060] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 11
MA = 10.134.8.171
World view:  11 96 10.134.8.171
[2024-03-04 16:46:09,059] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:09,060] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 6
MA = 10.134.8.171
World view:  6 96 10.134.8.171
[2024-03-04 16:46:09,059] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:09,060] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 7
MA = 10.134.8.171
World view:  7 96 10.134.8.171
[2024-03-04 16:46:09,060] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:09,060] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 1
MA = 10.134.8.171
World view:  1 96 10.134.8.171
[2024-03-04 16:46:09,095] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:09,095] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 2
MA = 10.134.8.171
World view:  2 96 10.134.8.171
[2024-03-04 16:46:09,095] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:09,095] [INFO] [comm.py:616:init_distributed] cdb=None
 > padded vocab (size: 50257) with 943 dummy tokens (new size: 51200)
> initializing torch distributed ...
[2024-03-04 16:46:09,096] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:09,096] [INFO] [comm.py:616:init_distributed] cdb=None
[2024-03-04 16:46:09,096] [INFO] [comm.py:643:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 4
MA = 10.134.8.171
World view:  4 96 10.134.8.171
[2024-03-04 16:46:09,096] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 3
MA = 10.134.8.171
World view:  3 96 10.134.8.171
[2024-03-04 16:46:09,096] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:09,097] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 5
MA = 10.134.8.171
World view:  5 96 10.134.8.171
[2024-03-04 16:46:09,097] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:09,097] [INFO] [comm.py:616:init_distributed] cdb=None
[2024-03-04 16:46:09,097] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 30
MA = 10.134.8.171
World view:  30 96 10.134.8.171
[2024-03-04 16:46:13,637] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:13,637] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 32
MA = 10.134.8.171
World view:  32 96 10.134.8.171
[2024-03-04 16:46:13,637] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:13,637] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 31
MA = 10.134.8.171
World view:  31 96 10.134.8.171
[2024-03-04 16:46:13,637] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:13,637] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 33
MA = 10.134.8.171
World view:  33 96 10.134.8.171
[2024-03-04 16:46:13,637] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:13,638] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 34
MA = 10.134.8.171
World view:  34 96 10.134.8.171
[2024-03-04 16:46:13,637] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:13,638] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 35
MA = 10.134.8.171
World view:  35 96 10.134.8.171
[2024-03-04 16:46:13,638] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:13,638] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 37
MA = 10.134.8.171
World view:  37 96 10.134.8.171
[2024-03-04 16:46:13,643] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 41
MA = 10.134.8.171
World view:  41 96 10.134.8.171
[2024-03-04 16:46:13,643] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:13,643] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 40
MA = 10.134.8.171
World view:  40 96 10.134.8.171
[2024-03-04 16:46:13,643] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:13,643] [INFO] [comm.py:616:init_distributed] cdb=None
[2024-03-04 16:46:13,643] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 38
MA = 10.134.8.171
World view:  38 96 10.134.8.171
[2024-03-04 16:46:13,643] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:13,644] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 36
MA = 10.134.8.171
World view:  36 96 10.134.8.171
[2024-03-04 16:46:13,644] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 39
MA = 10.134.8.171
World view:  39 96 10.134.8.171
[2024-03-04 16:46:13,644] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:13,644] [INFO] [comm.py:616:init_distributed] cdb=None
[2024-03-04 16:46:13,644] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 24
MA = 10.134.8.171
World view:  24 96 10.134.8.171
[2024-03-04 16:46:13,645] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 29
MA = 10.134.8.171
World view:  29 96 10.134.8.171
[2024-03-04 16:46:13,645] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:13,645] [INFO] [comm.py:616:init_distributed] cdb=None
[2024-03-04 16:46:13,645] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 26
MA = 10.134.8.171
World view:  26 96 10.134.8.171
[2024-03-04 16:46:13,645] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:13,645] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 27
MA = 10.134.8.171
World view:  27 96 10.134.8.171
[2024-03-04 16:46:13,645] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:13,645] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 28
MA = 10.134.8.171
World view:  28 96 10.134.8.171
[2024-03-04 16:46:13,645] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:13,645] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 25
MA = 10.134.8.171
World view:  25 96 10.134.8.171
[2024-03-04 16:46:13,645] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:13,645] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 45
MA = 10.134.8.171
World view:  45 96 10.134.8.171
[2024-03-04 16:46:13,652] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:13,652] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 44
MA = 10.134.8.171
World view:  44 96 10.134.8.171
[2024-03-04 16:46:13,652] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 43
MA = 10.134.8.171
World view:  43 96 10.134.8.171
[2024-03-04 16:46:13,652] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:13,652] [INFO] [comm.py:616:init_distributed] cdb=None
[2024-03-04 16:46:13,652] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 46
MA = 10.134.8.171
World view:  46 96 10.134.8.171
[2024-03-04 16:46:13,652] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:13,653] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 42
MA = 10.134.8.171
World view:  42 96 10.134.8.171
[2024-03-04 16:46:13,653] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 47
MA = 10.134.8.171
World view:  47 96 10.134.8.171
[2024-03-04 16:46:13,653] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:13,653] [INFO] [comm.py:616:init_distributed] cdb=None
[2024-03-04 16:46:13,653] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 95
MA = 10.134.8.171
World view:  95 96 10.134.8.171
> setting tensorboard ...
[2024-03-04 16:46:13,744] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:13,744] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 48
MA = 10.134.8.171
World view:  48 96 10.134.8.171
[2024-03-04 16:46:13,799] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:13,799] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 52
MA = 10.134.8.171
World view:  52 96 10.134.8.171
[2024-03-04 16:46:13,800] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 53
MA = 10.134.8.171
World view:  53 96 10.134.8.171
[2024-03-04 16:46:13,800] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:13,800] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 49
MA = 10.134.8.171
World view:  49 96 10.134.8.171
[2024-03-04 16:46:13,800] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:13,800] [INFO] [comm.py:616:init_distributed] cdb=None
[2024-03-04 16:46:13,800] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 51
MA = 10.134.8.171
World view:  51 96 10.134.8.171
[2024-03-04 16:46:13,800] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:13,800] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 50
MA = 10.134.8.171
World view:  50 96 10.134.8.171
[2024-03-04 16:46:13,800] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:13,800] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 55
MA = 10.134.8.171
World view:  55 96 10.134.8.171
[2024-03-04 16:46:13,811] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:13,811] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 54
MA = 10.134.8.171
World view:  54 96 10.134.8.171
[2024-03-04 16:46:13,811] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:13,811] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 56
MA = 10.134.8.171
World view:  56 96 10.134.8.171
[2024-03-04 16:46:13,811] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:13,811] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 59
MA = 10.134.8.171
World view:  59 96 10.134.8.171
[2024-03-04 16:46:13,812] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:13,812] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 57
MA = 10.134.8.171
World view:  57 96 10.134.8.171
[2024-03-04 16:46:13,812] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:13,812] [INFO] [comm.py:616:init_distributed] cdb=None
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [91m[FAIL][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [93m[NO][0m ....... [93m[NO][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/torch']
torch version .................... 2.0.1
deepspeed install path ........... ['/gpfs/alpine2/stf218/world-shared/sajal/moe-env-311/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+f5c834a6e, f5c834a6e, HEAD
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.0, cuda 12.2
**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
world vision: 96 58
MA = 10.134.8.171
World view:  58 96 10.134.8.171
[2024-03-04 16:46:13,813] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-03-04 16:46:13,813] [INFO] [comm.py:616:init_distributed] cdb=None
> initialized tensor model parallel with size 8
> initialized pipeline model parallel with size 1
> setting random seeds to 1234 ...
[2024-03-04 16:46:18,184] [INFO] [checkpointing.py:226:model_parallel_cuda_manual_seed] > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234
make: Entering directory '/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/megatron/data'
> compiling dataset index builder ...
>>> done with dataset index builder. Compilation time: 0.080 seconds
> compiling and loading fused kernels ...
ninja: no work to do.
ninja: no work to do.
ninja: no work to do.
d09n07:1063016:1063016 [0] NCCL INFO Bootstrap : Using ib0:10.41.8.171<0>
d09n07:1063016:1063016 [0] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d09n07:1063016:1063016 [0] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d09n07:1063016:1063016 [0] NCCL INFO cudaDriverVersion 12020
NCCL version 2.18.3+cuda11.8
>>> done with compiling and loading fused kernels. Compilation time: 2.716 seconds
time to initialize megatron (seconds): 14.243
[after megatron is initialized] datetime: 2024-03-04 16:46:22 
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=0, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=0, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
building GPT model ...
[2024-03-04 16:46:22,853] [INFO] [utils.py:785:see_memory_usage] Before Building Model
[2024-03-04 16:46:22,855] [INFO] [utils.py:786:see_memory_usage] MA 0.0 GB         Max_MA 0.13 GB         CA 0.0 GB         Max_CA 0 GB 
[2024-03-04 16:46:22,856] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 48.74 GB, percent = 8.2%
SEED_LAYERS=False BASE_SEED=1234 SEED_FN=None
Using topology: {ProcessCoord(pipe=0, data=0, model=0): 0, ProcessCoord(pipe=0, data=0, model=1): 1, ProcessCoord(pipe=0, data=0, model=2): 2, ProcessCoord(pipe=0, data=0, model=3): 3, ProcessCoord(pipe=0, data=0, model=4): 4, ProcessCoord(pipe=0, data=0, model=5): 5, ProcessCoord(pipe=0, data=0, model=6): 6, ProcessCoord(pipe=0, data=0, model=7): 7, ProcessCoord(pipe=0, data=1, model=0): 8, ProcessCoord(pipe=0, data=1, model=1): 9, ProcessCoord(pipe=0, data=1, model=2): 10, ProcessCoord(pipe=0, data=1, model=3): 11, ProcessCoord(pipe=0, data=1, model=4): 12, ProcessCoord(pipe=0, data=1, model=5): 13, ProcessCoord(pipe=0, data=1, model=6): 14, ProcessCoord(pipe=0, data=1, model=7): 15, ProcessCoord(pipe=0, data=2, model=0): 16, ProcessCoord(pipe=0, data=2, model=1): 17, ProcessCoord(pipe=0, data=2, model=2): 18, ProcessCoord(pipe=0, data=2, model=3): 19, ProcessCoord(pipe=0, data=2, model=4): 20, ProcessCoord(pipe=0, data=2, model=5): 21, ProcessCoord(pipe=0, data=2, model=6): 22, ProcessCoord(pipe=0, data=2, model=7): 23, ProcessCoord(pipe=0, data=3, model=0): 24, ProcessCoord(pipe=0, data=3, model=1): 25, ProcessCoord(pipe=0, data=3, model=2): 26, ProcessCoord(pipe=0, data=3, model=3): 27, ProcessCoord(pipe=0, data=3, model=4): 28, ProcessCoord(pipe=0, data=3, model=5): 29, ProcessCoord(pipe=0, data=3, model=6): 30, ProcessCoord(pipe=0, data=3, model=7): 31, ProcessCoord(pipe=0, data=4, model=0): 32, ProcessCoord(pipe=0, data=4, model=1): 33, ProcessCoord(pipe=0, data=4, model=2): 34, ProcessCoord(pipe=0, data=4, model=3): 35, ProcessCoord(pipe=0, data=4, model=4): 36, ProcessCoord(pipe=0, data=4, model=5): 37, ProcessCoord(pipe=0, data=4, model=6): 38, ProcessCoord(pipe=0, data=4, model=7): 39, ProcessCoord(pipe=0, data=5, model=0): 40, ProcessCoord(pipe=0, data=5, model=1): 41, ProcessCoord(pipe=0, data=5, model=2): 42, ProcessCoord(pipe=0, data=5, model=3): 43, ProcessCoord(pipe=0, data=5, model=4): 44, ProcessCoord(pipe=0, data=5, model=5): 45, ProcessCoord(pipe=0, data=5, model=6): 46, ProcessCoord(pipe=0, data=5, model=7): 47, ProcessCoord(pipe=0, data=6, model=0): 48, ProcessCoord(pipe=0, data=6, model=1): 49, ProcessCoord(pipe=0, data=6, model=2): 50, ProcessCoord(pipe=0, data=6, model=3): 51, ProcessCoord(pipe=0, data=6, model=4): 52, ProcessCoord(pipe=0, data=6, model=5): 53, ProcessCoord(pipe=0, data=6, model=6): 54, ProcessCoord(pipe=0, data=6, model=7): 55, ProcessCoord(pipe=0, data=7, model=0): 56, ProcessCoord(pipe=0, data=7, model=1): 57, ProcessCoord(pipe=0, data=7, model=2): 58, ProcessCoord(pipe=0, data=7, model=3): 59, ProcessCoord(pipe=0, data=7, model=4): 60, ProcessCoord(pipe=0, data=7, model=5): 61, ProcessCoord(pipe=0, data=7, model=6): 62, ProcessCoord(pipe=0, data=7, model=7): 63, ProcessCoord(pipe=0, data=8, model=0): 64, ProcessCoord(pipe=0, data=8, model=1): 65, ProcessCoord(pipe=0, data=8, model=2): 66, ProcessCoord(pipe=0, data=8, model=3): 67, ProcessCoord(pipe=0, data=8, model=4): 68, ProcessCoord(pipe=0, data=8, model=5): 69, ProcessCoord(pipe=0, data=8, model=6): 70, ProcessCoord(pipe=0, data=8, model=7): 71, ProcessCoord(pipe=0, data=9, model=0): 72, ProcessCoord(pipe=0, data=9, model=1): 73, ProcessCoord(pipe=0, data=9, model=2): 74, ProcessCoord(pipe=0, data=9, model=3): 75, ProcessCoord(pipe=0, data=9, model=4): 76, ProcessCoord(pipe=0, data=9, model=5): 77, ProcessCoord(pipe=0, data=9, model=6): 78, ProcessCoord(pipe=0, data=9, model=7): 79, ProcessCoord(pipe=0, data=10, model=0): 80, ProcessCoord(pipe=0, data=10, model=1): 81, ProcessCoord(pipe=0, data=10, model=2): 82, ProcessCoord(pipe=0, data=10, model=3): 83, ProcessCoord(pipe=0, data=10, model=4): 84, ProcessCoord(pipe=0, data=10, model=5): 85, ProcessCoord(pipe=0, data=10, model=6): 86, ProcessCoord(pipe=0, data=10, model=7): 87, ProcessCoord(pipe=0, data=11, model=0): 88, ProcessCoord(pipe=0, data=11, model=1): 89, ProcessCoord(pipe=0, data=11, model=2): 90, ProcessCoord(pipe=0, data=11, model=3): 91, ProcessCoord(pipe=0, data=11, model=4): 92, ProcessCoord(pipe=0, data=11, model=5): 93, ProcessCoord(pipe=0, data=11, model=6): 94, ProcessCoord(pipe=0, data=11, model=7): 95}
[2024-03-04 16:46:24,208] [INFO] [module.py:358:_partition_layers] Partitioning pipeline stages with method type:transformer
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=1, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=2, lazy_mpu_init=None, use_cpu_initiald11n16:1130269:1130269 [1] NCCL INFO cudaDriverVersion 12020
d11n16:1130269:1130269 [1] NCCL INFO Bootstrap : Using ib0:10.41.8.216<0>
d11n16:1130269:1130269 [1] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d11n16:1130269:1130269 [1] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d11n16:1130269:1130490 [1] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.8.216<0>
d11n16:1130269:1130490 [1] NCCL INFO Using network IB
d11n16:1130269:1130490 [1] NCCL INFO comm 0x1345e3750 rank 13 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init START
d11n16:1130269:1130490 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d11n16:1130269:1130490 [1] NCCL INFO Trees [0] 14/6/-1->13->12 [1] 12/-1/-1->13->17 [2] 14/-1/-1->13->12 [3] 12/-1/-1->13->17
d11n16:1130269:1130490 [1] NCCL INFO P2P Chunksize set to 131072
d11n16:1130269:1130490 [1] NCCL INFO Channel 00/0 : 13[1] -> 14[2] via P2P/IPC
d11n16:1130269:1130490 [1] NCCL INFO Channel 02/0 : 13[1] -> 14[2] via P2P/IPC
d11n16:1130269:1130490 [1] NCCL INFO Channel 01/0 : 13[1] -> 12[0] via P2P/IPC
d11n16:1130269:1130490 [1] NCCL INFO Channel 03/0 : 13[1] -> 12[0] via P2P/IPC
d11n16:1130269:1130490 [1] NCCL INFO Connected all rings
d11n16:1130269:1130490 [1] NCCL INFO Channel 01/0 : 13[1] -> 17[5] via P2P/IPC
d11n16:1130269:1130490 [1] NCCL INFO Channel 03/0 : 13[1] -> 17[5] via P2P/IPC
d11n16:1130269:1130490 [1] NCCL INFO Channel 00/0 : 6[0] -> 13[1] [receive] via NET/IB/0
d11n16:1130269:1130490 [1] NCCL INFO Channel 00/0 : 13[1] -> 6[0] [send] via NET/IB/0
d11n16:1130269:1130490 [1] NCCL INFO Channel 00/0 : 13[1] -> 12[0] via P2P/IPC
d11n16:1130269:1130490 [1] NCCL INFO Channel 02/0 : 13[1] -> 12[0] via P2P/IPC
d11n16:1130269:1130490 [1] NCCL INFO Connected all trees
d11n16:1130269:1130490 [1] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d11n16:1130269:1130490 [1] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d11n16:1130269:1130490 [1] NCCL INFO comm 0x1345e3750 rank 13 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init COMPLETE
f18n05:1008223:1008223 [4] NCCL INFO cudaDriverVersion 12020
f18n05:1008223:1008223 [4] NCCL INFO Bootstrap : Using ib0:10.41.14.109<0>
f18n05:1008223:1008223 [4] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f18n05:1008223:1008223 [4] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f18n05:1008223:1008439 [4] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.109<0>
f18n05:1008223:1008439 [4] NCCL INFO Using network IB
f18n05:1008223:1008439 [4] NCCL INFO comm 0x17b0b3ab0 rank 94 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init START
f18n05:1008223:1008439 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
f18n05:1008223:1008439 [4] NCCL INFO Trees [0] 95/-1/-1->94->93 [1] 93/-1/-1->94->88 [2] 95/-1/-1->94->93 [3] 93/46/-1->94->-1
f18n05:1008223:1008439 [4] NCCL INFO P2P Chunksize set to 131072
f18n05:1008223:1008439 [4] NCCL INFO Channel 00/0 : 94[4] -> 95[5] via P2P/IPC
f18n05:1008223:1008439 [4] NCCL INFO Channel 01/0 : 94[4] -> 95[5] via P2P/IPC
f18n05:1008223:1008439 [4] NCCL INFO Channel 02/0 : 94[4] -> 95[5] via P2P/IPC
f18n05:1008223:1008439 [4] NCCL INFO Channel 03/0 : 94[4] -> 95[5] via P2P/IPC
f18n05:1008223:1008439 [4] NCCL INFO Connected all rings
f18n05:1008223:1008439 [4] NCCL INFO Channel 01/0 : 88[4] -> 94[4] [receive] via NET/IB/3
f18n05:1008223:1008439 [4] NCCL INFO Channel 03/0 : 46[4] -> 94[4] [receive] via NET/IB/3
f18n05:1008223:1008439 [4] NCCL INFO Channel 03/0 : 94[4] -> 46[4] [send] via NET/IB/3
f18n05:1008223:1008439 [4] NCCL INFO Channel 01/0 : 94[4] -> 88[4] [send] via NET/IB/3
f18n05:1008223:1008439 [4] NCCL INFO Channel 00/0 : 94[4] -> 93[3] via P2P/IPC
f18n05:1008223:1008439 [4] NCCL INFO Channel 01/0 : 94[4] -> 93[3] via P2P/IPC
f18n05:1008223:1008439 [4] NCCL INFO Channel 02/0 : 94[4] -> 93[3] via P2P/IPC
f18n05:1008223:1008439 [4] NCCL INFO Channel 03/0 : 94[4] -> 93[3] via P2P/IPC
f18n05:1008223:1008439 [4] NCCL INFO Connected all trees
f18n05:1008223:1008439 [4] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f18n05:1008223:1008439 [4] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f18n05:1008223:1008439 [4] NCCL INFO comm 0x17b0b3ab0 rank 94 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init COMPLETE
ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=2, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_sArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=4, lazy_mpu_init=None, use_cpu_initialf18n05:1008222:1008222 [3] NCCL INFO cudaDriverVersion 12020
f18n05:1008222:1008222 [3] NCCL INFO Bootstrap : Using ib0:10.41.14.109<0>
f18n05:1008222:1008222 [3] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f18n05:1008222:1008222 [3] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f18n05:1008222:1008438 [3] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.109<0>
f18n05:1008222:1008438 [3] NCCL INFO Using network IB
f18n05:1008222:1008438 [3] NCCL INFO comm 0x14f703b60 rank 93 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init START
f18n05:1008222:1008438 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
f18n05:1008222:1008438 [3] NCCL INFO Trees [0] 94/-1/-1->93->92 [1] 95/-1/-1->93->94 [2] 94/-1/-1->93->92 [3] 95/-1/-1->93->94
f18n05:1008222:1008438 [3] NCCL INFO P2P Chunksize set to 131072
f18n05:1008222:1008438 [3] NCCL INFO Channel 00/0 : 93[3] -> 94[4] via P2P/IPC
f18n05:1008222:1008438 [3] NCCL INFO Channel 01/0 : 93[3] -> 94[4] via P2P/IPC
f18n05:1008222:1008438 [3] NCCL INFO Channel 02/0 : 93[3] -> 94[4] via P2P/IPC
f18n05:1008222:1008438 [3] NCCL INFO Channel 03/0 : 93[3] -> 94[4] via P2P/IPC
f18n05:1008222:1008438 [3] NCCL INFO Channel 01/0 : 84[0] -> 93[3] [receive] via NET/IB/3
f18n05:1008222:1008438 [3] NCCL INFO Channel 03/0 : 84[0] -> 93[3] [receive] via NET/IB/3
f18n05:1008222:1008438 [3] NCCL INFO Connected all rings
f18n05:1008222:1008438 [3] NCCL INFO Channel 01/0 : 93[3] -> 95[5] via P2P/IPC
f18n05:1008222:1008438 [3] NCCL INFO Channel 03/0 : 93[3] -> 95[5] via P2P/IPC
f18n05:1008222:1008438 [3] NCCL INFO Channel 00/0 : 93[3] -> 92[2] via P2P/IPC
f18n05:1008222:1008438 [3] NCCL INFO Channel 02/0 : 93[3] -> 92[2] via P2P/IPC
f18n05:1008222:1008438 [3] NCCL INFO Connected all trees
f18n05:1008222:1008438 [3] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f18n05:1008222:1008438 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f18n05:1008222:1008438 [3] NCCL INFO comm 0x14f703b60 rank 93 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init COMPLETE
ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=1, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_sf18n05:1008220:1008220 [1] NCCL INFO cudaDriverVersion 12020
f18n05:1008220:1008220 [1] NCCL INFO Bootstrap : Using ib0:10.41.14.109<0>
f18n05:1008220:1008220 [1] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f18n05:1008220:1008220 [1] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f18n05:1008220:1008441 [1] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.109<0>
f18n05:1008220:1008441 [1] NCCL INFO Using network IB
f18n05:1008220:1008441 [1] NCCL INFO comm 0x165933510 rank 91 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init START
f18n05:1008220:1008441 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
f18n05:1008220:1008441 [1] NCCL INFO Trees [0] 92/-1/-1->91->90 [1] 90/-1/-1->91->95 [2] 92/-1/-1->91->90 [3] 90/-1/-1->91->95
f18n05:1008220:1008441 [1] NCCL INFO P2P Chunksize set to 131072
f18n05:1008220:1008441 [1] NCCL INFO Channel 00/0 : 91[1] -> 92[2] via P2P/IPC
f18n05:1008220:1008441 [1] NCCL INFO Channel 02/0 : 91[1] -> 92[2] via P2P/IPC
f18n05:1008220:1008441 [1] NCCL INFO Channel 01/0 : 91[1] -> 90[0] via P2P/IPC
f18n05:1008220:1008441 [1] NCCL INFO Channel 03/0 : 91[1] -> 90[0] via P2P/IPC
f18n05:1008220:1008441 [1] NCCL INFO Connected all rings
f18n05:1008220:1008441 [1] NCCL INFO Channel 01/0 : 91[1] -> 95[5] via P2P/IPC
f18n05:1008220:1008441 [1] NCCL INFO Channel 03/0 : 91[1] -> 95[5] via P2P/IPC
f18n05:1008220:1008441 [1] NCCL INFO Channel 00/0 : 91[1] -> 90[0] via P2P/IPC
f18n05:1008220:1008441 [1] NCCL INFO Channel 02/0 : 91[1] -> 90[0] via P2P/IPC
f18n05:1008220:1008441 [1] NCCL INFO Connected all trees
f18n05:1008220:1008441 [1] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f18n05:1008220:1008441 [1] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f18n05:1008220:1008441 [1] NCCL INFO comm 0x165933510 rank 91 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init COMPLETE
f18n05:1008221:1008221 [2] NCCL INFO cudaDriverVersion 12020
f18n05:1008221:1008221 [2] NCCL INFO Bootstrap : Using ib0:10.41.14.109<0>
f18n05:1008221:1008221 [2] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f18n05:1008221:1008221 [2] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f18n05:1008221:1008440 [2] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.109<0>
f18n05:1008221:1008440 [2] NCCL INFO Using network IB
f18n05:1008221:1008440 [2] NCCL INFO comm 0x160bb38b0 rank 92 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init START
f18n05:1008221:1008440 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
f18n05:1008221:1008440 [2] NCCL INFO Trees [0] 93/-1/-1->92->91 [1] -1/-1/-1->92->90 [2] 93/-1/-1->92->91 [3] -1/-1/-1->92->90
f18n05:1008221:1008440 [2] NCCL INFO P2P Chunksize set to 131072
f18n05:1008221:1008440 [2] NCCL INFO Channel 00/0 : 92[2] -> 93[3] via P2P/IPC
f18n05:1008221:1008440 [2] NCCL INFO Channel 02/0 : 92[2] -> 93[3] via P2P/IPC
f18n05:1008221:1008440 [2] NCCL INFO Channel 01/0 : 92[2] -> 91[1] via P2P/IPC
f18n05:1008221:1008440 [2] NCCL INFO Channel 03/0 : 92[2] -> 91[1] via P2P/IPC
f18n05:1008221:1008440 [2] NCCL INFO Connected all rings
f18n05:1008221:1008440 [2] NCCL INFO Channel 01/0 : 92[2] -> 90[0] via P2P/IPC
f18n05:1008221:1008440 [2] NCCL INFO Channel 03/0 : 92[2] -> 90[0] via P2P/IPC
f18n05:1008221:1008440 [2] NCCL INFO Channel 00/0 : 92[2] -> 91[1] via P2P/IPC
f18n05:1008221:1008440 [2] NCCL INFO Channel 02/0 : 92[2] -> 91[1] via P2P/IPC
f18n05:1008221:1008440 [2] NCCL INFO Connected all trees
f18n05:1008221:1008440 [2] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f18n05:1008221:1008440 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f18n05:1008221:1008440 [2] NCCL INFO comm 0x160bb38b0 rank 92 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init COMPLETE
f18n05:1008219:1008219 [0] NCCL INFO cudaDriverVersion 12020
f18n05:1008219:1008219 [0] NCCL INFO Bootstrap : Using ib0:10.41.14.109<0>
f18n05:1008219:1008219 [0] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f18n05:1008219:1008219 [0] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f18n05:1008219:1008442 [0] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.109<0>
f18n05:1008219:1008442 [0] NCCL INFO Using network IB
f18n05:1008219:1008442 [0] NCCL INFO comm 0x156623ba0 rank 90 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init START
f18n05:1008219:1008442 [0] NCCL INFO Setting affinity for GPU 0 to 0f
f18n05:1008219:1008442 [0] NCCL INFO Trees [0] 91/-1/-1->90->84 [1] 92/-1/-1->90->91 [2] 91/42/-1->90->-1 [3] 92/-1/-1->90->91
f18n05:1008219:1008442 [0] NCCL INFO P2P Chunksize set to 131072
f18n05:1008219:1008442 [0] NCCL INFO Channel 00/0 : 89[5] -> 90[0] [receive] via NET/IB/0
f18n05:1008219:1008442 [0] NCCL INFO Channel 02/0 : 89[5] -> 90[0] [receive] via NET/IB/0
f18n05:1008219:1008442 [0] NCCL INFO Channel 00/0 : 90[0] -> 91[1] via P2P/IPC
f18n05:1008219:1008442 [0] NCCL INFO Channel 02/0 : 90[0] -> 91[1] via P2P/IPC
f18n05:1008219:1008442 [0] NCCL INFO Channel 01/0 : 90[0] -> 3[3] [send] via NET/IB/2
f18n05:1008219:1008442 [0] NCCL INFO Channel 03/0 : 90[0] -> 3[3] [send] via NET/IB/2
f18n05:1008219:1008442 [0] NCCL INFO Connected all rings
f18n05:1008219:1008442 [0] NCCL INFO Channel 01/0 : 90[0] -> 91[1] via P2P/IPC
f18n05:1008219:1008442 [0] NCCL INFO Channel 03/0 : 90[0] -> 91[1] via P2P/IPC
f18n05:1008219:1008442 [0] NCCL INFO Channel 01/0 : 90[0] -> 92[2] via P2P/IPC
f18n05:1008219:1008442 [0] NCCL INFO Channel 03/0 : 90[0] -> 92[2] via P2P/IPC
f18n05:1008219:1008442 [0] NCCL INFO Channel 00/0 : 84[0] -> 90[0] [receive] via NET/IB/0
f18n05:1008219:1008442 [0] NCCL INFO Channel 02/0 : 42[0] -> 90[0] [receive] via NET/IB/0
f18n05:1008219:1008442 [0] NCCL INFO Channel 02/0 : 90[0] -> 42[0] [send] via NET/IB/0
f18n05:1008219:1008442 [0] NCCL INFO Channel 00/0 : 90[0] -> 84[0] [send] via NET/IB/0
f18n05:1008219:1008442 [0] NCCL INFO Connected all trees
f18n05:1008219:1008442 [0] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f18n05:1008219:1008442 [0] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f18n05:1008219:1008442 [0] NCCL INFO comm 0x156623ba0 rank 90 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init COMPLETE
d11n16:1130270:1130270 [2] NCCL INFO cudaDriverVersion 12020
d11n16:1130270:1130270 [2] NCCL INFO Bootstrap : Using ib0:10.41.8.216<0>
d11n16:1130270:1130270 [2] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d11n16:1130270:1130270 [2] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d11n16:1130270:1130489 [2] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.8.216<0>
d11n16:1130270:1130489 [2] NCCL INFO Using network IB
d11n16:1130270:1130489 [2] NCCL INFO comm 0x1472e3aa0 rank 14 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init START
d11n16:1130270:1130489 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d11n16:1130270:1130489 [2] NCCL INFO Trees [0] 15/-1/-1->14->13 [1] -1/-1/-1->14->12 [2] 15/-1/-1->14->13 [3] -1/-1/-1->14->12
d11n16:1130270:1130489 [2] NCCL INFO P2P Chunksize set to 131072
d11n16:1130270:1130489 [2] NCCL INFO Channel 00/0 : 14[2] -> 15[3] via P2P/IPC
d11n16:1130270:1130489 [2] NCCL INFO Channel 02/0 : 14[2] -> 15[3] via P2P/IPC
d11n16:1130270:1130489 [2] NCCL INFO Channel 01/0 : 14[2] -> 13[1] via P2P/IPC
d11n16:1130270:1130489 [2] NCCL INFO Channel 03/0 : 14[2] -> 13[1] via P2P/IPC
d11n16:1130270:1130489 [2] NCCL INFO Connected all rings
d11n16:1130270:1130489 [2] NCCL INFO Channel 01/0 : 14[2] -> 12[0] via P2P/IPC
d11n16:1130270:1130489 [2] NCCL INFO Channel 03/0 : 14[2] -> 12[0] via P2P/IPC
d11n16:1130270:1130489 [2] NCCL INFO Channel 00/0 : 14[2] -> 13[1] via P2P/IPC
d11n16:1130270:1130489 [2] NCCL INFO Channel 02/0 : 14[2] -> 13[1] via P2P/IPC
d11n16:1130270:1130489 [2] NCCL INFO Connected all trees
d11n16:1130270:1130489 [2] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d11n16:1130270:1130489 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d11n16:1130270:1130489 [2] NCCL INFO comm 0x1472e3aa0 rank 14 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init COMPLETE
f16n18:1091870:1091870 [4] NCCL INFO cudaDriverVersion 12020
f16n18:1091870:1091870 [4] NCCL INFO Bootstrap : Using ib0:10.41.14.86<0>
f16n18:1091870:1091870 [4] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f16n18:1091870:1091870 [4] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f16n18:1091870:1092091 [4] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.86<0>
f16n18:1091870:1092091 [4] NCCL INFO Using network IB
f16n18:1091870:1092091 [4] NCCL INFO comm 0x16d0b38e0 rank 76 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init START
f16n18:1091870:1092091 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
f16n18:1091870:1092091 [4] NCCL INFO Trees [0] 77/-1/-1->76->75 [1] 75/88/-1->76->52 [2] 77/-1/-1->76->75 [3] 75/-1/-1->76->82
f16n18:1091870:1092091 [4] NCCL INFO P2P Chunksize set to 131072
f16n18:1091870:1092091 [4] NCCL INFO Channel 00/0 : 76[4] -> 77[5] via P2P/IPC
f16n18:1091870:1092091 [4] NCCL INFO Channel 01/0 : 76[4] -> 77[5] via P2P/IPC
f16n18:1091870:1092091 [4] NCCL INFO Channel 02/0 : 76[4] -> 77[5] via P2P/IPC
f16n18:1091870:1092091 [4] NCCL INFO Channel 03/0 : 76[4] -> 77[5] via P2P/IPC
f16n18:1091870:1092091 [4] NCCL INFO Connected all rings
f16n18:1091870:1092091 [4] NCCL INFO Channel 03/0 : 76[4] -> 82[4] [send] via NET/IB/3
f16n18:1091870:1092091 [4] NCCL INFO Channel 01/0 : 76[4] -> 88[4] [send] via NET/IB/3
f16n18:1091870:1092091 [4] NCCL INFO Channel 01/0 : 52[4] -> 76[4] [receive] via NET/IB/3
f16n18:1091870:1092091 [4] NCCL INFO Channel 01/0 : 76[4] -> 52[4] [send] via NET/IB/3
f16n18:1091870:1092091 [4] NCCL INFO Channel 01/0 : 88[4] -> 76[4] [receive] via NET/IB/3
f16n18:1091870:1092091 [4] NCCL INFO Channel 03/0 : 82[4] -> 76[4] [receive] via NET/IB/3
f16n18:1091870:1092091 [4] NCCL INFO Channel 00/0 : 76[4] -> 75[3] via P2P/IPC
f16n18:1091870:1092091 [4] NCCL INFO Channel 01/0 : 76[4] -> 75[3] via P2P/IPC
f16n18:1091870:1092091 [4] NCCL INFO Channel 02/0 : 76[4] -> 75[3] via P2P/IPC
f16n18:1091870:1092091 [4] NCCL INFO Channel 03/0 : 76[4] -> 75[3] via P2P/IPC
f16n18:1091870:1092091 [4] NCCL INFO Connected all trees
f16n18:1091870:1092091 [4] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f16n18:1091870:1092091 [4] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f16n18:1091870:1092091 [4] NCCL INFO comm 0x16d0b38e0 rank 76 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init COMPLETE
amples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
 > number of parameters on (tensor, pipeline) model parallel rank (1, 0): 840818688
f18n05:1008224:1008224 [5] NCCL INFO cudaDriverVersion 12020
f18n05:1008224:1008224 [5] NCCL INFO Bootstrap : Using ib0:10.41.14.109<0>
f18n05:1008224:1008224 [5] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f18n05:1008224:1008224 [5] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f18n05:1008224:1008437 [5] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.109<0>
f18n05:1008224:1008437 [5] NCCL INFO Using network IB
f18n05:1008224:1008437 [5] NCCL INFO comm 0x14bbdc0d0 rank 95 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init START
f18n05:1008224:1008437 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
f18n05:1008224:1008437 [5] NCCL INFO Trees [0] -1/-1/-1->95->94 [1] 91/-1/-1->95->93 [2] -1/-1/-1->95->94 [3] 91/-1/-1->95->93
f18n05:1008224:1008437 [5] NCCL INFO P2P Chunksize set to 131072
f18n05:1008224:1008437 [5] NCCL INFO Channel 00/0 : 95[5] -> 0[0] [send] via NET/IB/1
f18n05:1008224:1008437 [5] NCCL INFO Channel 02/0 : 95[5] -> 0[0] [send] via NET/IB/1
f18n05:1008224:1008437 [5] NCCL INFO Channel 01/0 : 95[5] -> 92[2] via P2P/IPC
f18n05:1008224:1008437 [5] NCCL INFO Channel 03/0 : 95[5] -> 92[2] via P2P/IPC
f18n05:1008224:1008437 [5] NCCL INFO Connected all rings
f18n05:1008224:1008437 [5] NCCL INFO Channel 01/0 : 95[5] -> 91[1] via P2P/IPC
f18n05:1008224:1008437 [5] NCCL INFO Channel 03/0 : 95[5] -> 91[1] via P2P/IPC
f18n05:1008224:1008437 [5] NCCL INFO Channel 01/0 : 95[5] -> 93[3] via P2P/IPC
f18n05:1008224:1008437 [5] NCCL INFO Channel 03/0 : 95[5] -> 93[3] via P2P/IPC
f18n05:1008224:1008437 [5] NCCL INFO Channel 00/0 : 95[5] -> 94[4] via P2P/IPC
f18n05:1008224:1008437 [5] NCCL INFO Channel 02/0 : 95[5] -> 94[4] via P2P/IPC
f18n05:1008224:1008437 [5] NCCL INFO Connected all trees
f18n05:1008224:1008437 [5] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f18n05:1008224:1008437 [5] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f18n05:1008224:1008437 [5] NCCL INFO comm 0x14bbdc0d0 rank 95 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init COMPLETE
d11n16:1130268:1130268 [0] NCCL INFO cudaDriverVersion 12020
d11n16:1130268:1130268 [0] NCCL INFO Bootstrap : Using ib0:10.41.8.216<0>
d11n16:1130268:1130268 [0] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d11n16:1130268:1130268 [0] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d11n16:1130268:1130491 [0] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.8.216<0>
d11n16:1130268:1130491 [0] NCCL INFO Using network IB
d11n16:1130268:1130491 [0] NCCL INFO comm 0x153cf3370 rank 12 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init START
d11n16:1130268:1130491 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d11n16:1130268:1130491 [0] NCCL INFO Trees [0] 13/18/-1->12->25 [1] 14/-1/-1->12->13 [2] 13/-1/-1->12->7 [3] 14/-1/-1->12->13
d11n16:1130268:1130491 [0] NCCL INFO P2P Chunksize set to 131072
d11n16:1130268:1130491 [0] NCCL INFO Channel 00/0 : 11[5] -> 12[0] [receive] via NET/IB/0
d11n16:1130268:1130491 [0] NCCL INFO Channel 02/0 : 11[5] -> 12[0] [receive] via NET/IB/0
d11n16:1130268:1130491 [0] NCCL INFO Channel 00/0 : 12[0] -> 13[1] via P2P/IPC
d11n16:1130268:1130491 [0] NCCL INFO Channel 02/0 : 12[0] -> 13[1] via P2P/IPC
d11n16:1130268:1130491 [0] NCCL INFO Channel 01/0 : 12[0] -> 21[3] [send] via NET/IB/2
d11n16:1130268:1130491 [0] NCCL INFO Channel 03/0 : 12[0] -> 21[3] [send] via NET/IB/2
d11n16:1130268:1130491 [0] NCCL INFO Connected all rings
d11n16:1130268:1130491 [0] NCCL INFO Channel 01/0 : 12[0] -> 13[1] via P2P/IPC
d11n16:1130268:1130491 [0] NCCL INFO Channel 03/0 : 12[0] -> 13[1] via P2P/IPC
d11n16:1130268:1130491 [0] NCCL INFO Channel 01/0 : 12[0] -> 14[2] via P2P/IPC
d11n16:1130268:1130491 [0] NCCL INFO Channel 03/0 : 12[0] -> 14[2] via P2P/IPC
d11n16:1130268:1130491 [0] NCCL INFO Channel 02/0 : 7[1] -> 12[0] [receive] via NET/IB/0
d11n16:1130268:1130491 [0] NCCL INFO Channel 00/0 : 12[0] -> 18[0] [send] via NET/IB/0
d11n16:1130268:1130491 [0] NCCL INFO Channel 00/0 : 12[0] -> 25[1] [send] via NET/IB/0
d11n16:1130268:1130491 [0] NCCL INFO Channel 00/0 : 25[1] -> 12[0] [receive] via NET/IB/0
d11n16:1130268:1130491 [0] NCCL INFO Channel 00/0 : 18[0] -> 12[0] [receive] via NET/IB/0
d11n16:1130268:1130491 [0] NCCL INFO Channel 02/0 : 12[0] -> 7[1] [send] via NET/IB/0
d11n16:1130268:1130491 [0] NCCL INFO Connected all trees
d11n16:1130268:1130491 [0] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d11n16:1130268:1130491 [0] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d11n16:1130268:1130491 [0] NCCL INFO comm 0x153cf3370 rank 12 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init COMPLETE
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=5, lazy_mpu_init=None, use_cpu_initiald11n16:1130272:1130272 [4] NCCL INFO cudaDriverVersion 12020
d11n16:1130272:1130272 [4] NCCL INFO Bootstrap : Using ib0:10.41.8.216<0>
d11n16:1130272:1130272 [4] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d11n16:1130272:1130272 [4] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d11n16:1130272:1130488 [4] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.8.216<0>
d11n16:1130272:1130488 [4] NCCL INFO Using network IB
d11n16:1130272:1130488 [4] NCCL INFO comm 0x121a53790 rank 16 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init START
d11n16:1130272:1130488 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d11n16:1130272:1130488 [4] NCCL INFO Trees [0] 17/-1/-1->16->15 [1] 15/22/-1->16->27 [2] 17/-1/-1->16->15 [3] 15/-1/-1->16->9
d11n16:1130272:1130488 [4] NCCL INFO P2P Chunksize set to 131072
d11n16:1130272:1130488 [4] NCCL INFO Channel 00/0 : 16[4] -> 17[5] via P2P/IPC
d11n16:1130272:1130488 [4] NCCL INFO Channel 01/0 : 16[4] -> 17[5] via P2P/IPC
d11n16:1130272:1130488 [4] NCCL INFO Channel 02/0 : 16[4] -> 17[5] via P2P/IPC
d11n16:1130272:1130488 [4] NCCL INFO Channel 03/0 : 16[4] -> 17[5] via P2P/IPC
d11n16:1130272:1130488 [4] NCCL INFO Connected all rings
d11n16:1130272:1130488 [4] NCCL INFO Channel 01/0 : 16[4] -> 22[4] [send] via NET/IB/3
d11n16:1130272:1130488 [4] NCCL INFO Channel 03/0 : 9[3] -> 16[4] [receive] via NET/IB/3
d11n16:1130272:1130488 [4] NCCL INFO Channel 01/0 : 16[4] -> 27[3] [send] via NET/IB/3
d11n16:1130272:1130488 [4] NCCL INFO Channel 01/0 : 27[3] -> 16[4] [receive] via NET/IB/3
d11n16:1130272:1130488 [4] NCCL INFO Channel 03/0 : 16[4] -> 9[3] [send] via NET/IB/3
d11n16:1130272:1130488 [4] NCCL INFO Channel 01/0 : 22[4] -> 16[4] [receive] via NET/IB/3
d11n16:1130272:1130488 [4] NCCL INFO Channel 00/0 : 16[4] -> 15[3] via P2P/IPC
d11n16:1130272:1130488 [4] NCCL INFO Channel 01/0 : 16[4] -> 15[3] via P2P/IPC
d11n16:1130272:1130488 [4] NCCL INFO Channel 02/0 : 16[4] -> 15[3] via P2P/IPC
d11n16:1130272:1130488 [4] NCCL INFO Channel 03/0 : 16[4] -> 15[3] via P2P/IPC
d11n16:1130272:1130488 [4] NCCL INFO Connected all trees
d11n16:1130272:1130488 [4] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d11n16:1130272:1130488 [4] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d11n16:1130272:1130488 [4] NCCL INFO comm 0x121a53790 rank 16 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init COMPLETE
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=3, lazy_mpu_init=None, use_cpu_initiald11n16:1130273:1130273 [5] NCCL INFO cudaDriverVersion 12020
d11n16:1130273:1130273 [5] NCCL INFO Bootstrap : Using ib0:10.41.8.216<0>
d11n16:1130273:1130273 [5] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d11n16:1130273:1130273 [5] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d11n16:1130273:1130486 [5] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.8.216<0>
d11n16:1130273:1130486 [5] NCCL INFO Using network IB
d11n16:1130273:1130486 [5] NCCL INFO comm 0x14d5132f0 rank 17 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init START
d11n16:1130273:1130486 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d11n16:1130273:1130486 [5] NCCL INFO Trees [0] -1/-1/-1->17->16 [1] 13/-1/-1->17->15 [2] -1/-1/-1->17->16 [3] 13/-1/-1->17->15
d11n16:1130273:1130486 [5] NCCL INFO P2P Chunksize set to 131072
d11n16:1130273:1130486 [5] NCCL INFO Channel 00/0 : 17[5] -> 18[0] [send] via NET/IB/1
d11n16:1130273:1130486 [5] NCCL INFO Channel 02/0 : 17[5] -> 18[0] [send] via NET/IB/1
d11n16:1130273:1130486 [5] NCCL INFO Channel 01/0 : 17[5] -> 14[2] via P2P/IPC
d11n16:1130273:1130486 [5] NCCL INFO Channel 03/0 : 17[5] -> 14[2] via P2P/IPC
d11n16:1130273:1130486 [5] NCCL INFO Connected all rings
d11n16:1130273:1130486 [5] NCCL INFO Channel 01/0 : 17[5] -> 13[1] via P2P/IPC
d11n16:1130273:1130486 [5] NCCL INFO Channel 03/0 : 17[5] -> 13[1] via P2P/IPC
d11n16:1130273:1130486 [5] NCCL INFO Channel 01/0 : 17[5] -> 15[3] via P2P/IPC
d11n16:1130273:1130486 [5] NCCL INFO Channel 03/0 : 17[5] -> 15[3] via P2P/IPC
d11n16:1130273:1130486 [5] NCCL INFO Channel 00/0 : 17[5] -> 16[4] via P2P/IPC
d11n16:1130273:1130486 [5] NCCL INFO Channel 02/0 : 17[5] -> 16[4] via P2P/IPC
d11n16:1130273:1130486 [5] NCCL INFO Connected all trees
d11n16:1130273:1130486 [5] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d11n16:1130273:1130486 [5] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d11n16:1130273:1130486 [5] NCCL INFO comm 0x14d5132f0 rank 17 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init COMPLETE
amples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
 > number of parameters on (tensor, pipeline) model parallel rank (2, 0): 840818688
d11n16:1130271:1130271 [3] NCCL INFO cudaDriverVersion 12020
d11n16:1130271:1130271 [3] NCCL INFO Bootstrap : Using ib0:10.41.8.216<0>
d11n16:1130271:1130271 [3] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d11n16:1130271:1130271 [3] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d11n16:1130271:1130487 [3] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.8.216<0>
d11n16:1130271:1130487 [3] NCCL INFO Using network IB
d11n16:1130271:1130487 [3] NCCL INFO comm 0x169ad3810 rank 15 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init START
d11n16:1130271:1130487 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d11n16:1130271:1130487 [3] NCCL INFO Trees [0] 16/-1/-1->15->14 [1] 17/10/-1->15->16 [2] 16/-1/-1->15->14 [3] 17/-1/-1->15->16
d11n16:1130271:1130487 [3] NCCL INFO P2P Chunksize set to 131072
d11n16:1130271:1130487 [3] NCCL INFO Channel 00/0 : 15[3] -> 16[4] via P2P/IPC
d11n16:1130271:1130487 [3] NCCL INFO Channel 01/0 : 15[3] -> 16[4] via P2P/IPC
d11n16:1130271:1130487 [3] NCCL INFO Channel 02/0 : 15[3] -> 16[4] via P2P/IPC
d11n16:1130271:1130487 [3] NCCL INFO Channel 03/0 : 15[3] -> 16[4] via P2P/IPC
d11n16:1130271:1130487 [3] NCCL INFO Channel 01/0 : 6[0] -> 15[3] [receive] via NET/IB/3
d11n16:1130271:1130487 [3] NCCL INFO Channel 03/0 : 6[0] -> 15[3] [receive] via NET/IB/3
d11n16:1130271:1130487 [3] NCCL INFO Connected all rings
d11n16:1130271:1130487 [3] NCCL INFO Channel 01/0 : 15[3] -> 17[5] via P2P/IPC
d11n16:1130271:1130487 [3] NCCL INFO Channel 03/0 : 15[3] -> 17[5] via P2P/IPC
d11n16:1130271:1130487 [3] NCCL INFO Channel 01/0 : 10[4] -> 15[3] [receive] via NET/IB/3
d11n16:1130271:1130487 [3] NCCL INFO Channel 01/0 : 15[3] -> 10[4] [send] via NET/IB/3
d11n16:1130271:1130487 [3] NCCL INFO Channel 00/0 : 15[3] -> 14[2] via P2P/IPC
d11n16:1130271:1130487 [3] NCCL INFO Channel 02/0 : 15[3] -> 14[2] via P2P/IPC
d11n16:1130271:1130487 [3] NCCL INFO Connected all trees
d11n16:1130271:1130487 [3] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d11n16:1130271:1130487 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d11n16:1130271:1130487 [3] NCCL INFO comm 0x169ad3810 rank 15 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init COMPLETE
ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=4, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_sization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=3, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_sization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=5, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
 > number of parameters on (tensor, pipeline) model parallel rank (4, 0): 840818688
amples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
 > number of parameters on (tensor, pipeline) model parallel rank (3, 0): 840818688
amples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
 > number of parameters on (tensor, pipeline) model parallel rank (5, 0): 840818688
d14n10:565683:565683 [2] NCCL INFO cudaDriverVersion 12020
d14n10:565683:565683 [2] NCCL INFO Bootstrap : Using ib0:10.41.9.11<0>
d14n10:565683:565683 [2] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d14n10:565683:565683 [2] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d14n10:565683:565909 [2] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.11<0>
d14n10:565683:565909 [2] NCCL INFO Using network IB
d14n10:565683:565909 [2] NCCL INFO comm 0x1298432e0 rank 38 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init START
d14n10:565683:565909 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d14n10:565683:565909 [2] NCCL INFO Trees [0] 39/-1/-1->38->37 [1] -1/-1/-1->38->36 [2] 39/-1/-1->38->37 [3] -1/-1/-1->38->36
d14n10:565683:565909 [2] NCCL INFO P2P Chunksize set to 131072
d14n10:565683:565909 [2] NCCL INFO Channel 00/0 : 38[2] -> 39[3] via P2P/IPC
d14n10:565683:565909 [2] NCCL INFO Channel 02/0 : 38[2] -> 39[3] via P2P/IPC
d14n10:565683:565909 [2] NCCL INFO Channel 01/0 : 38[2] -> 37[1] via P2P/IPC
d14n10:565683:565909 [2] NCCL INFO Channel 03/0 : 38[2] -> 37[1] via P2P/IPC
d14n10:565683:565909 [2] NCCL INFO Connected all rings
d14n10:565683:565909 [2] NCCL INFO Channel 01/0 : 38[2] -> 36[0] via P2P/IPC
d14n10:565683:565909 [2] NCCL INFO Channel 03/0 : 38[2] -> 36[0] via P2P/IPC
d14n10:565683:565909 [2] NCCL INFO Channel 00/0 : 38[2] -> 37[1] via P2P/IPC
d14n10:565683:565909 [2] NCCL INFO Channel 02/0 : 38[2] -> 37[1] via P2P/IPC
d14n10:565683:565909 [2] NCCL INFO Connected all trees
d14n10:565683:565909 [2] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d14n10:565683:565909 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n10:565683:565909 [2] NCCL INFO comm 0x1298432e0 rank 38 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init COMPLETE
d17n07:1212411:1212411 [1] NCCL INFO cudaDriverVersion 12020
d17n07:1212411:1212411 [1] NCCL INFO Bootstrap : Using ib0:10.41.9.62<0>
d17n07:1212411:1212411 [1] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d17n07:1212411:1212411 [1] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d17n07:1212411:1212641 [1] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.62<0>
d17n07:1212411:1212641 [1] NCCL INFO Using network IB
d17n07:1212411:1212641 [1] NCCL INFO comm 0x177773660 rank 55 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init START
d17n07:1212411:1212641 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d17n07:1212411:1212641 [1] NCCL INFO Trees [0] 56/-1/-1->55->54 [1] 54/-1/-1->55->59 [2] 56/60/-1->55->54 [3] 54/-1/-1->55->59
d17n07:1212411:1212641 [1] NCCL INFO P2P Chunksize set to 131072
d17n07:1212411:1212641 [1] NCCL INFO Channel 00/0 : 55[1] -> 56[2] via P2P/IPC
d17n07:1212411:1212641 [1] NCCL INFO Channel 02/0 : 55[1] -> 56[2] via P2P/IPC
d17n07:1212411:1212641 [1] NCCL INFO Channel 01/0 : 55[1] -> 54[0] via P2P/IPC
d17n07:1212411:1212641 [1] NCCL INFO Channel 03/0 : 55[1] -> 54[0] via P2P/IPC
d17n07:1212411:1212641 [1] NCCL INFO Connected all rings
d17n07:1212411:1212641 [1] NCCL INFO Channel 01/0 : 55[1] -> 59[5] via P2P/IPC
d17n07:1212411:1212641 [1] NCCL INFO Channel 03/0 : 55[1] -> 59[5] via P2P/IPC
d17n07:1212411:1212641 [1] NCCL INFO Channel 02/0 : 55[1] -> 60[0] [send] via NET/IB/0
d17n07:1212411:1212641 [1] NCCL INFO Channel 02/0 : 60[0] -> 55[1] [receive] via NET/IB/0
d17n07:1212411:1212641 [1] NCCL INFO Channel 00/0 : 55[1] -> 54[0] via P2P/IPC
d17n07:1212411:1212641 [1] NCCL INFO Channel 02/0 : 55[1] -> 54[0] via P2P/IPC
d17n07:1212411:1212641 [1] NCCL INFO Connected all trees
d17n07:1212411:1212641 [1] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d17n07:1212411:1212641 [1] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d17n07:1212411:1212641 [1] NCCL INFO comm 0x177773660 rank 55 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init COMPLETE
d17n07:1212412:1212412 [2] NCCL INFO cudaDriverVersion 12020
d17n07:1212412:1212412 [2] NCCL INFO Bootstrap : Using ib0:10.41.9.62<0>
d17n07:1212412:1212412 [2] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d17n07:1212412:1212412 [2] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d17n07:1212412:1212642 [2] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.62<0>
d17n07:1212412:1212642 [2] NCCL INFO Using network IB
d17n07:1212412:1212642 [2] NCCL INFO comm 0x12a683f10 rank 56 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init START
d17n07:1212412:1212642 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d17n07:1212412:1212642 [2] NCCL INFO Trees [0] 57/-1/-1->56->55 [1] -1/-1/-1->56->54 [2] 57/-1/-1->56->55 [3] -1/-1/-1->56->54
d17n07:1212412:1212642 [2] NCCL INFO P2P Chunksize set to 131072
d17n07:1212412:1212642 [2] NCCL INFO Channel 00/0 : 56[2] -> 57[3] via P2P/IPC
d17n07:1212412:1212642 [2] NCCL INFO Channel 02/0 : 56[2] -> 57[3] via P2P/IPC
d17n07:1212412:1212642 [2] NCCL INFO Channel 01/0 : 56[2] -> 55[1] via P2P/IPC
d17n07:1212412:1212642 [2] NCCL INFO Channel 03/0 : 56[2] -> 55[1] via P2P/IPC
d17n07:1212412:1212642 [2] NCCL INFO Connected all rings
d17n07:1212412:1212642 [2] NCCL INFO Channel 01/0 : 56[2] -> 54[0] via P2P/IPC
d17n07:1212412:1212642 [2] NCCL INFO Channel 03/0 : 56[2] -> 54[0] via P2P/IPC
d17n07:1212412:1212642 [2] NCCL INFO Channel 00/0 : 56[2] -> 55[1] via P2P/IPC
d17n07:1212412:1212642 [2] NCCL INFO Channel 02/0 : 56[2] -> 55[1] via P2P/IPC
d17n07:1212412:1212642 [2] NCCL INFO Connected all trees
d17n07:1212412:1212642 [2] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d17n07:1212412:1212642 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d17n07:1212412:1212642 [2] NCCL INFO comm 0x12a683f10 rank 56 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init COMPLETE
d17n07:1212410:1212410 [0] NCCL INFO cudaDriverVersion 12020
d17n07:1212410:1212410 [0] NCCL INFO Bootstrap : Using ib0:10.41.9.62<0>
d17n07:1212410:1212410 [0] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d17n07:1212410:1212410 [0] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d17n07:1212410:1212644 [0] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.62<0>
d17n07:1212410:1212644 [0] NCCL INFO Using network IB
d17n07:1212410:1212644 [0] NCCL INFO comm 0x16e5a3360 rank 54 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init START
d17n07:1212410:1212644 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d17n07:1212410:1212644 [0] NCCL INFO Trees [0] 55/-1/-1->54->61 [1] 56/-1/-1->54->55 [2] 55/48/-1->54->66 [3] 56/-1/-1->54->55
d17n07:1212410:1212644 [0] NCCL INFO P2P Chunksize set to 131072
d17n07:1212410:1212644 [0] NCCL INFO Channel 00/0 : 53[5] -> 54[0] [receive] via NET/IB/0
d17n07:1212410:1212644 [0] NCCL INFO Channel 02/0 : 53[5] -> 54[0] [receive] via NET/IB/0
d17n07:1212410:1212644 [0] NCCL INFO Channel 00/0 : 54[0] -> 55[1] via P2P/IPC
d17n07:1212410:1212644 [0] NCCL INFO Channel 02/0 : 54[0] -> 55[1] via P2P/IPC
d17n07:1212410:1212644 [0] NCCL INFO Channel 01/0 : 54[0] -> 63[3] [send] via NET/IB/2
d17n07:1212410:1212644 [0] NCCL INFO Channel 03/0 : 54[0] -> 63[3] [send] via NET/IB/2
d17n07:1212410:1212644 [0] NCCL INFO Connected all rings
d17n07:1212410:1212644 [0] NCCL INFO Channel 01/0 : 54[0] -> 55[1] via P2P/IPC
d17n07:1212410:1212644 [0] NCCL INFO Channel 03/0 : 54[0] -> 55[1] via P2P/IPC
d17n07:1212410:1212644 [0] NCCL INFO Channel 01/0 : 54[0] -> 56[2] via P2P/IPC
d17n07:1212410:1212644 [0] NCCL INFO Channel 03/0 : 54[0] -> 56[2] via P2P/IPC
d17n07:1212410:1212644 [0] NCCL INFO Channel 02/0 : 48[0] -> 54[0] [receive] via NET/IB/0
d17n07:1212410:1212644 [0] NCCL INFO Channel 00/0 : 54[0] -> 61[1] [send] via NET/IB/0
d17n07:1212410:1212644 [0] NCCL INFO Channel 02/0 : 54[0] -> 66[0] [send] via NET/IB/0
d17n07:1212410:1212644 [0] NCCL INFO Channel 02/0 : 66[0] -> 54[0] [receive] via NET/IB/0
d17n07:1212410:1212644 [0] NCCL INFO Channel 00/0 : 61[1] -> 54[0] [receive] via NET/IB/0
d17n07:1212410:1212644 [0] NCCL INFO Channel 02/0 : 54[0] -> 48[0] [send] via NET/IB/0
d17n07:1212410:1212644 [0] NCCL INFO Connected all trees
d17n07:1212410:1212644 [0] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d17n07:1212410:1212644 [0] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d17n07:1212410:1212644 [0] NCCL INFO comm 0x16e5a3360 rank 54 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init COMPLETE
d17n07:1212413:1212413 [3] NCCL INFO cudaDriverVersion 12020
d17n07:1212413:1212413 [3] NCCL INFO Bootstrap : Using ib0:10.41.9.62<0>
d17n07:1212413:1212413 [3] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d17n07:1212413:1212413 [3] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d17n07:1212413:1212643 [3] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.62<0>
d17n07:1212413:1212643 [3] NCCL INFO Using network IB
d17n07:1212413:1212643 [3] NCCL INFO comm 0x1330336f0 rank 57 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init START
d17n07:1212413:1212643 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d17n07:1212413:1212643 [3] NCCL INFO Trees [0] 58/-1/-1->57->56 [1] 59/-1/-1->57->58 [2] 58/-1/-1->57->56 [3] 59/64/-1->57->58
d17n07:1212413:1212643 [3] NCCL INFO P2P Chunksize set to 131072
d17n07:1212413:1212643 [3] NCCL INFO Channel 00/0 : 57[3] -> 58[4] via P2P/IPC
d17n07:1212413:1212643 [3] NCCL INFO Channel 01/0 : 57[3] -> 58[4] via P2P/IPC
d17n07:1212413:1212643 [3] NCCL INFO Channel 02/0 : 57[3] -> 58[4] via P2P/IPC
d17n07:1212413:1212643 [3] NCCL INFO Channel 03/0 : 57[3] -> 58[4] via P2P/IPC
d17n07:1212413:1212643 [3] NCCL INFO Channel 01/0 : 48[0] -> 57[3] [receive] via NET/IB/3
d17n07:1212413:1212643 [3] NCCL INFO Channel 03/0 : 48[0] -> 57[3] [receive] via NET/IB/3
d17n07:1212413:1212643 [3] NCCL INFO Connected all rings
d17n07:1212413:1212643 [3] NCCL INFO Channel 01/0 : 57[3] -> 59[5] via P2P/IPC
d17n07:1212413:1212643 [3] NCCL INFO Channel 03/0 : 57[3] -> 59[5] via P2P/IPC
d17n07:1212413:1212643 [3] NCCL INFO Channel 03/0 : 57[3] -> 64[4] [send] via NET/IB/3
d17n07:1212413:1212643 [3] NCCL INFO Channel 03/0 : 64[4] -> 57[3] [receive] via NET/IB/3
d17n07:1212413:1212643 [3] NCCL INFO Channel 00/0 : 57[3] -> 56[2] via P2P/IPC
d17n07:1212413:1212643 [3] NCCL INFO Channel 02/0 : 57[3] -> 56[2] via P2P/IPC
d17n07:1212413:1212643 [3] NCCL INFO Connected all trees
d17n07:1212413:1212643 [3] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d17n07:1212413:1212643 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d17n07:1212413:1212643 [3] NCCL INFO comm 0x1330336f0 rank 57 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init COMPLETE
d14n10:565682:565682 [1] NCCL INFO cudaDriverVersion 12020
d14n10:565682:565682 [1] NCCL INFO Bootstrap : Using ib0:10.41.9.11<0>
d14n10:565682:565682 [1] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d14n10:565682:565682 [1] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d14n10:565682:565908 [1] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.11<0>
d14n10:565682:565908 [1] NCCL INFO Using network IB
d14n10:565682:565908 [1] NCCL INFO comm 0x1763d3430 rank 37 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init START
d14n10:565682:565908 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d14n10:565682:565908 [1] NCCL INFO Trees [0] 38/30/-1->37->36 [1] 36/-1/-1->37->41 [2] 38/-1/-1->37->36 [3] 36/-1/-1->37->41
d14n10:565682:565908 [1] NCCL INFO P2P Chunksize set to 131072
d14n10:565682:565908 [1] NCCL INFO Channel 00/0 : 37[1] -> 38[2] via P2P/IPC
d14n10:565682:565908 [1] NCCL INFO Channel 02/0 : 37[1] -> 38[2] via P2P/IPC
d14n10:565682:565908 [1] NCCL INFO Channel 01/0 : 37[1] -> 36[0] via P2P/IPC
d14n10:565682:565908 [1] NCCL INFO Channel 03/0 : 37[1] -> 36[0] via P2P/IPC
d14n10:565682:565908 [1] NCCL INFO Connected all rings
d14n10:565682:565908 [1] NCCL INFO Channel 01/0 : 37[1] -> 41[5] via P2P/IPC
d14n10:565682:565908 [1] NCCL INFO Channel 03/0 : 37[1] -> 41[5] via P2P/IPC
d14n10:565682:565908 [1] NCCL INFO Channel 00/0 : 30[0] -> 37[1] [receive] via NET/IB/0
d14n10:565682:565908 [1] NCCL INFO Channel 00/0 : 37[1] -> 30[0] [send] via NET/IB/0
d14n10:565682:565908 [1] NCCL INFO Channel 00/0 : 37[1] -> 36[0] via P2P/IPC
d14n10:565682:565908 [1] NCCL INFO Channel 02/0 : 37[1] -> 36[0] via P2P/IPC
d14n10:565682:565908 [1] NCCL INFO Connected all trees
d14n10:565682:565908 [1] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d14n10:565682:565908 [1] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n10:565682:565908 [1] NCCL INFO comm 0x1763d3430 rank 37 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init COMPLETE
f17n02:1076280:1076280 [1] NCCL INFO cudaDriverVersion 12020
f17n02:1076280:1076280 [1] NCCL INFO Bootstrap : Using ib0:10.41.14.88<0>
f17n02:1076280:1076280 [1] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f17n02:1076280:1076280 [1] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f17n02:1076280:1076498 [1] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.88<0>
f17n02:1076280:1076498 [1] NCCL INFO Using network IB
f17n02:1076280:1076498 [1] NCCL INFO comm 0x141ce4000 rank 85 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init START
f17n02:1076280:1076498 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
f17n02:1076280:1076498 [1] NCCL INFO Trees [0] 86/78/-1->85->84 [1] 84/-1/-1->85->89 [2] 86/-1/-1->85->84 [3] 84/-1/-1->85->89
f17n02:1076280:1076498 [1] NCCL INFO P2P Chunksize set to 131072
f17n02:1076280:1076498 [1] NCCL INFO Channel 00/0 : 85[1] -> 86[2] via P2P/IPC
f17n02:1076280:1076498 [1] NCCL INFO Channel 02/0 : 85[1] -> 86[2] via P2P/IPC
f17n02:1076280:1076498 [1] NCCL INFO Channel 01/0 : 85[1] -> 84[0] via P2P/IPC
f17n02:1076280:1076498 [1] NCCL INFO Channel 03/0 : 85[1] -> 84[0] via P2P/IPC
f17n02:1076280:1076498 [1] NCCL INFO Connected all rings
f17n02:1076280:1076498 [1] NCCL INFO Channel 01/0 : 85[1] -> 89[5] via P2P/IPC
f17n02:1076280:1076498 [1] NCCL INFO Channel 03/0 : 85[1] -> 89[5] via P2P/IPC
f17n02:1076280:1076498 [1] NCCL INFO Channel 00/0 : 78[0] -> 85[1] [receive] via NET/IB/0
f17n02:1076280:1076498 [1] NCCL INFO Channel 00/0 : 85[1] -> 78[0] [send] via NET/IB/0
f17n02:1076280:1076498 [1] NCCL INFO Channel 00/0 : 85[1] -> 84[0] via P2P/IPC
f17n02:1076280:1076498 [1] NCCL INFO Channel 02/0 : 85[1] -> 84[0] via P2P/IPC
f17n02:1076280:1076498 [1] NCCL INFO Connected all trees
f17n02:1076280:1076498 [1] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f17n02:1076280:1076498 [1] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f17n02:1076280:1076498 [1] NCCL INFO comm 0x141ce4000 rank 85 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init COMPLETE
d14n10:565681:565681 [0] NCCL INFO cudaDriverVersion 12020
d14n10:565681:565681 [0] NCCL INFO Bootstrap : Using ib0:10.41.9.11<0>
d14n10:565681:565681 [0] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d14n10:565681:565681 [0] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d14n10:565681:565910 [0] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.11<0>
d14n10:565681:565910 [0] NCCL INFO Using network IB
d14n10:565681:565910 [0] NCCL INFO comm 0x162a83930 rank 36 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init START
d14n10:565681:565910 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d14n10:565681:565910 [0] NCCL INFO Trees [0] 37/42/-1->36->24 [1] 38/-1/-1->36->37 [2] 37/-1/-1->36->31 [3] 38/-1/-1->36->37
d14n10:565681:565910 [0] NCCL INFO P2P Chunksize set to 131072
d14n10:565681:565910 [0] NCCL INFO Channel 00/0 : 35[5] -> 36[0] [receive] via NET/IB/0
d14n10:565681:565910 [0] NCCL INFO Channel 02/0 : 35[5] -> 36[0] [receive] via NET/IB/0
d14n10:565681:565910 [0] NCCL INFO Channel 00/0 : 36[0] -> 37[1] via P2P/IPC
d14n10:565681:565910 [0] NCCL INFO Channel 02/0 : 36[0] -> 37[1] via P2P/IPC
d14n10:565681:565910 [0] NCCL INFO Channel 01/0 : 36[0] -> 45[3] [send] via NET/IB/2
d14n10:565681:565910 [0] NCCL INFO Channel 03/0 : 36[0] -> 45[3] [send] via NET/IB/2
d14n10:565681:565910 [0] NCCL INFO Connected all rings
d14n10:565681:565910 [0] NCCL INFO Channel 01/0 : 36[0] -> 37[1] via P2P/IPC
d14n10:565681:565910 [0] NCCL INFO Channel 03/0 : 36[0] -> 37[1] via P2P/IPC
d14n10:565681:565910 [0] NCCL INFO Channel 01/0 : 36[0] -> 38[2] via P2P/IPC
d14n10:565681:565910 [0] NCCL INFO Channel 03/0 : 36[0] -> 38[2] via P2P/IPC
d14n10:565681:565910 [0] NCCL INFO Channel 02/0 : 31[1] -> 36[0] [receive] via NET/IB/0
d14n10:565681:565910 [0] NCCL INFO Channel 00/0 : 36[0] -> 42[0] [send] via NET/IB/0
d14n10:565681:565910 [0] NCCL INFO Channel 00/0 : 24[0] -> 36[0] [receive] via NET/IB/0
d14n10:565681:565910 [0] NCCL INFO Channel 00/0 : 36[0] -> 24[0] [send] via NET/IB/0
d14n10:565681:565910 [0] NCCL INFO Channel 00/0 : 42[0] -> 36[0] [receive] via NET/IB/0
d14n10:565681:565910 [0] NCCL INFO Channel 02/0 : 36[0] -> 31[1] [send] via NET/IB/0
d14n10:565681:565910 [0] NCCL INFO Connected all trees
d14n10:565681:565910 [0] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d14n10:565681:565910 [0] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n10:565681:565910 [0] NCCL INFO comm 0x162a83930 rank 36 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init COMPLETE
f17n02:1076282:1076282 [3] NCCL INFO cudaDriverVersion 12020
f17n02:1076282:1076282 [3] NCCL INFO Bootstrap : Using ib0:10.41.14.88<0>
f17n02:1076282:1076282 [3] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f17n02:1076282:1076282 [3] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f17n02:1076282:1076501 [3] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.88<0>
f17n02:1076282:1076501 [3] NCCL INFO Using network IB
f17n02:1076282:1076501 [3] NCCL INFO comm 0x126912f90 rank 87 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init START
f17n02:1076282:1076501 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
f17n02:1076282:1076501 [3] NCCL INFO Trees [0] 88/-1/-1->87->86 [1] 89/82/-1->87->88 [2] 88/-1/-1->87->86 [3] 89/-1/-1->87->88
f17n02:1076282:1076501 [3] NCCL INFO P2P Chunksize set to 131072
f17n02:1076282:1076501 [3] NCCL INFO Channel 00/0 : 87[3] -> 88[4] via P2P/IPC
f17n02:1076282:1076501 [3] NCCL INFO Channel 01/0 : 87[3] -> 88[4] via P2P/IPC
f17n02:1076282:1076501 [3] NCCL INFO Channel 02/0 : 87[3] -> 88[4] via P2P/IPC
f17n02:1076282:1076501 [3] NCCL INFO Channel 03/0 : 87[3] -> 88[4] via P2P/IPC
f17n02:1076282:1076501 [3] NCCL INFO Channel 01/0 : 78[0] -> 87[3] [receive] via NET/IB/3
f17n02:1076282:1076501 [3] NCCL INFO Channel 03/0 : 78[0] -> 87[3] [receive] via NET/IB/3
f17n02:1076282:1076501 [3] NCCL INFO Connected all rings
f17n02:1076282:1076501 [3] NCCL INFO Channel 01/0 : 87[3] -> 89[5] via P2P/IPC
f17n02:1076282:1076501 [3] NCCL INFO Channel 03/0 : 87[3] -> 89[5] via P2P/IPC
f17n02:1076282:1076501 [3] NCCL INFO Channel 01/0 : 82[4] -> 87[3] [receive] via NET/IB/3
f17n02:1076282:1076501 [3] NCCL INFO Channel 01/0 : 87[3] -> 82[4] [send] via NET/IB/3
f17n02:1076282:1076501 [3] NCCL INFO Channel 00/0 : 87[3] -> 86[2] via P2P/IPC
f17n02:1076282:1076501 [3] NCCL INFO Channel 02/0 : 87[3] -> 86[2] via P2P/IPC
f17n02:1076282:1076501 [3] NCCL INFO Connected all trees
f17n02:1076282:1076501 [3] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f17n02:1076282:1076501 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f17n02:1076282:1076501 [3] NCCL INFO comm 0x126912f90 rank 87 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init COMPLETE
d14n10:565684:565684 [3] NCCL INFO cudaDriverVersion 12020
d14n10:565684:565684 [3] NCCL INFO Bootstrap : Using ib0:10.41.9.11<0>
d14n10:565684:565684 [3] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d14n10:565684:565684 [3] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d14n10:565684:565913 [3] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.11<0>
d14n10:565684:565913 [3] NCCL INFO Using network IB
d14n10:565684:565913 [3] NCCL INFO comm 0x129ce37b0 rank 39 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init START
d14n10:565684:565913 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d14n10:565684:565913 [3] NCCL INFO Trees [0] 40/-1/-1->39->38 [1] 41/34/-1->39->40 [2] 40/-1/-1->39->38 [3] 41/-1/-1->39->40
d14n10:565684:565913 [3] NCCL INFO P2P Chunksize set to 131072
d14n10:565684:565913 [3] NCCL INFO Channel 00/0 : 39[3] -> 40[4] via P2P/IPC
d14n10:565684:565913 [3] NCCL INFO Channel 01/0 : 39[3] -> 40[4] via P2P/IPC
d14n10:565684:565913 [3] NCCL INFO Channel 02/0 : 39[3] -> 40[4] via P2P/IPC
d14n10:565684:565913 [3] NCCL INFO Channel 03/0 : 39[3] -> 40[4] via P2P/IPC
d14n10:565684:565913 [3] NCCL INFO Channel 01/0 : 30[0] -> 39[3] [receive] via NET/IB/3
d14n10:565684:565913 [3] NCCL INFO Channel 03/0 : 30[0] -> 39[3] [receive] via NET/IB/3
d14n10:565684:565913 [3] NCCL INFO Connected all rings
d14n10:565684:565913 [3] NCCL INFO Channel 01/0 : 39[3] -> 41[5] via P2P/IPC
d14n10:565684:565913 [3] NCCL INFO Channel 03/0 : 39[3] -> 41[5] via P2P/IPC
d14n10:565684:565913 [3] NCCL INFO Channel 01/0 : 34[4] -> 39[3] [receive] via NET/IB/3
d14n10:565684:565913 [3] NCCL INFO Channel 01/0 : 39[3] -> 34[4] [send] via NET/IB/3
d14n10:565684:565913 [3] NCCL INFO Channel 00/0 : 39[3] -> 38[2] via P2P/IPC
d14n10:565684:565913 [3] NCCL INFO Channel 02/0 : 39[3] -> 38[2] via P2P/IPC
d14n10:565684:565913 [3] NCCL INFO Connected all trees
d14n10:565684:565913 [3] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d14n10:565684:565913 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n10:565684:565913 [3] NCCL INFO comm 0x129ce37b0 rank 39 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init COMPLETE
f17n02:1076284:1076284 [5] NCCL INFO cudaDriverVersion 12020
f17n02:1076284:1076284 [5] NCCL INFO Bootstrap : Using ib0:10.41.14.88<0>
f17n02:1076284:1076284 [5] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f17n02:1076284:1076284 [5] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f17n02:1076284:1076502 [5] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.88<0>
f17n02:1076284:1076502 [5] NCCL INFO Using network IB
f17n02:1076284:1076502 [5] NCCL INFO comm 0x1470d3090 rank 89 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init START
f17n02:1076284:1076502 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
f17n02:1076284:1076502 [5] NCCL INFO Trees [0] -1/-1/-1->89->88 [1] 85/-1/-1->89->87 [2] -1/-1/-1->89->88 [3] 85/-1/-1->89->87
f17n02:1076284:1076502 [5] NCCL INFO P2P Chunksize set to 131072
f17n02:1076284:1076502 [5] NCCL INFO Channel 00/0 : 89[5] -> 90[0] [send] via NET/IB/1
f17n02:1076284:1076502 [5] NCCL INFO Channel 02/0 : 89[5] -> 90[0] [send] via NET/IB/1
f17n02:1076284:1076502 [5] NCCL INFO Channel 01/0 : 89[5] -> 86[2] via P2P/IPC
f17n02:1076284:1076502 [5] NCCL INFO Channel 03/0 : 89[5] -> 86[2] via P2P/IPC
f17n02:1076284:1076502 [5] NCCL INFO Connected all rings
f17n02:1076284:1076502 [5] NCCL INFO Channel 01/0 : 89[5] -> 85[1] via P2P/IPC
f17n02:1076284:1076502 [5] NCCL INFO Channel 03/0 : 89[5] -> 85[1] via P2P/IPC
f17n02:1076284:1076502 [5] NCCL INFO Channel 01/0 : 89[5] -> 87[3] via P2P/IPC
f17n02:1076284:1076502 [5] NCCL INFO Channel 03/0 : 89[5] -> 87[3] via P2P/IPC
f17n02:1076284:1076502 [5] NCCL INFO Channel 00/0 : 89[5] -> 88[4] via P2P/IPC
f17n02:1076284:1076502 [5] NCCL INFO Channel 02/0 : 89[5] -> 88[4] via P2P/IPC
f17n02:1076284:1076502 [5] NCCL INFO Connected all trees
f17n02:1076284:1076502 [5] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f17n02:1076284:1076502 [5] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f17n02:1076284:1076502 [5] NCCL INFO comm 0x1470d3090 rank 89 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init COMPLETE
d14n10:565685:565685 [4] NCCL INFO cudaDriverVersion 12020
d14n10:565685:565685 [4] NCCL INFO Bootstrap : Using ib0:10.41.9.11<0>
d14n10:565685:565685 [4] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d14n10:565685:565685 [4] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d14n10:565685:565911 [4] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.11<0>
d14n10:565685:565911 [4] NCCL INFO Using network IB
d14n10:565685:565911 [4] NCCL INFO comm 0x15ea238f0 rank 40 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init START
d14n10:565685:565911 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d14n10:565685:565911 [4] NCCL INFO Trees [0] 41/-1/-1->40->39 [1] 39/46/-1->40->28 [2] 41/-1/-1->40->39 [3] 39/-1/-1->40->33
d14n10:565685:565911 [4] NCCL INFO P2P Chunksize set to 131072
d14n10:565685:565911 [4] NCCL INFO Channel 00/0 : 40[4] -> 41[5] via P2P/IPC
d14n10:565685:565911 [4] NCCL INFO Channel 01/0 : 40[4] -> 41[5] via P2P/IPC
d14n10:565685:565911 [4] NCCL INFO Channel 02/0 : 40[4] -> 41[5] via P2P/IPC
d14n10:565685:565911 [4] NCCL INFO Channel 03/0 : 40[4] -> 41[5] via P2P/IPC
d14n10:565685:565911 [4] NCCL INFO Connected all rings
d14n10:565685:565911 [4] NCCL INFO Channel 01/0 : 40[4] -> 46[4] [send] via NET/IB/3
d14n10:565685:565911 [4] NCCL INFO Channel 03/0 : 33[3] -> 40[4] [receive] via NET/IB/3
d14n10:565685:565911 [4] NCCL INFO Channel 01/0 : 28[4] -> 40[4] [receive] via NET/IB/3
d14n10:565685:565911 [4] NCCL INFO Channel 01/0 : 40[4] -> 28[4] [send] via NET/IB/3
d14n10:565685:565911 [4] NCCL INFO Channel 03/0 : 40[4] -> 33[3] [send] via NET/IB/3
d14n10:565685:565911 [4] NCCL INFO Channel 01/0 : 46[4] -> 40[4] [receive] via NET/IB/3
d14n10:565685:565911 [4] NCCL INFO Channel 00/0 : 40[4] -> 39[3] via P2P/IPC
d14n10:565685:565911 [4] NCCL INFO Channel 01/0 : 40[4] -> 39[3] via P2P/IPC
d14n10:565685:565911 [4] NCCL INFO Channel 02/0 : 40[4] -> 39[3] via P2P/IPC
d14n10:565685:565911 [4] NCCL INFO Channel 03/0 : 40[4] -> 39[3] via P2P/IPC
d14n10:565685:565911 [4] NCCL INFO Connected all trees
d14n10:565685:565911 [4] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d14n10:565685:565911 [4] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n10:565685:565911 [4] NCCL INFO comm 0x15ea238f0 rank 40 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init COMPLETE
f17n02:1076283:1076283 [4] NCCL INFO cudaDriverVersion 12020
f17n02:1076283:1076283 [4] NCCL INFO Bootstrap : Using ib0:10.41.14.88<0>
f17n02:1076283:1076283 [4] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f17n02:1076283:1076283 [4] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f17n02:1076283:1076500 [4] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.88<0>
f17n02:1076283:1076500 [4] NCCL INFO Using network IB
f17n02:1076283:1076500 [4] NCCL INFO comm 0x157293690 rank 88 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init START
f17n02:1076283:1076500 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
f17n02:1076283:1076500 [4] NCCL INFO Trees [0] 89/-1/-1->88->87 [1] 87/94/-1->88->76 [2] 89/-1/-1->88->87 [3] 87/-1/-1->88->81
f17n02:1076283:1076500 [4] NCCL INFO P2P Chunksize set to 131072
f17n02:1076283:1076500 [4] NCCL INFO Channel 00/0 : 88[4] -> 89[5] via P2P/IPC
f17n02:1076283:1076500 [4] NCCL INFO Channel 01/0 : 88[4] -> 89[5] via P2P/IPC
f17n02:1076283:1076500 [4] NCCL INFO Channel 02/0 : 88[4] -> 89[5] via P2P/IPC
f17n02:1076283:1076500 [4] NCCL INFO Channel 03/0 : 88[4] -> 89[5] via P2P/IPC
f17n02:1076283:1076500 [4] NCCL INFO Connected all rings
f17n02:1076283:1076500 [4] NCCL INFO Channel 01/0 : 88[4] -> 94[4] [send] via NET/IB/3
f17n02:1076283:1076500 [4] NCCL INFO Channel 03/0 : 81[3] -> 88[4] [receive] via NET/IB/3
f17n02:1076283:1076500 [4] NCCL INFO Channel 01/0 : 76[4] -> 88[4] [receive] via NET/IB/3
f17n02:1076283:1076500 [4] NCCL INFO Channel 01/0 : 88[4] -> 76[4] [send] via NET/IB/3
f17n02:1076283:1076500 [4] NCCL INFO Channel 03/0 : 88[4] -> 81[3] [send] via NET/IB/3
f17n02:1076283:1076500 [4] NCCL INFO Channel 01/0 : 94[4] -> 88[4] [receive] via NET/IB/3
f17n02:1076283:1076500 [4] NCCL INFO Channel 00/0 : 88[4] -> 87[3] via P2P/IPC
f17n02:1076283:1076500 [4] NCCL INFO Channel 01/0 : 88[4] -> 87[3] via P2P/IPC
f17n02:1076283:1076500 [4] NCCL INFO Channel 02/0 : 88[4] -> 87[3] via P2P/IPC
f17n02:1076283:1076500 [4] NCCL INFO Channel 03/0 : 88[4] -> 87[3] via P2P/IPC
f17n02:1076283:1076500 [4] NCCL INFO Connected all trees
f17n02:1076283:1076500 [4] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f17n02:1076283:1076500 [4] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f17n02:1076283:1076500 [4] NCCL INFO comm 0x157293690 rank 88 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init COMPLETE
d14n10:565686:565686 [5] NCCL INFO cudaDriverVersion 12020
d14n10:565686:565686 [5] NCCL INFO Bootstrap : Using ib0:10.41.9.11<0>
d14n10:565686:565686 [5] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d14n10:565686:565686 [5] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d14n10:565686:565912 [5] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.11<0>
d14n10:565686:565912 [5] NCCL INFO Using network IB
d14n10:565686:565912 [5] NCCL INFO comm 0x114953890 rank 41 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init START
d14n10:565686:565912 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d14n10:565686:565912 [5] NCCL INFO Trees [0] -1/-1/-1->41->40 [1] 37/-1/-1->41->39 [2] -1/-1/-1->41->40 [3] 37/-1/-1->41->39
d14n10:565686:565912 [5] NCCL INFO P2P Chunksize set to 131072
d14n10:565686:565912 [5] NCCL INFO Channel 00/0 : 41[5] -> 42[0] [send] via NET/IB/1
d14n10:565686:565912 [5] NCCL INFO Channel 02/0 : 41[5] -> 42[0] [send] via NET/IB/1
d14n10:565686:565912 [5] NCCL INFO Channel 01/0 : 41[5] -> 38[2] via P2P/IPC
d14n10:565686:565912 [5] NCCL INFO Channel 03/0 : 41[5] -> 38[2] via P2P/IPC
d14n10:565686:565912 [5] NCCL INFO Connected all rings
d14n10:565686:565912 [5] NCCL INFO Channel 01/0 : 41[5] -> 37[1] via P2P/IPC
d14n10:565686:565912 [5] NCCL INFO Channel 03/0 : 41[5] -> 37[1] via P2P/IPC
d14n10:565686:565912 [5] NCCL INFO Channel 01/0 : 41[5] -> 39[3] via P2P/IPC
d14n10:565686:565912 [5] NCCL INFO Channel 03/0 : 41[5] -> 39[3] via P2P/IPC
d14n10:565686:565912 [5] NCCL INFO Channel 00/0 : 41[5] -> 40[4] via P2P/IPC
d14n10:565686:565912 [5] NCCL INFO Channel 02/0 : 41[5] -> 40[4] via P2P/IPC
d14n10:565686:565912 [5] NCCL INFO Connected all trees
d14n10:565686:565912 [5] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d14n10:565686:565912 [5] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n10:565686:565912 [5] NCCL INFO comm 0x114953890 rank 41 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init COMPLETE
f17n02:1076281:1076281 [2] NCCL INFO cudaDriverVersion 12020
f17n02:1076281:1076281 [2] NCCL INFO Bootstrap : Using ib0:10.41.14.88<0>
f17n02:1076281:1076281 [2] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f17n02:1076281:1076281 [2] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f17n02:1076281:1076497 [2] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.88<0>
f17n02:1076281:1076497 [2] NCCL INFO Using network IB
f17n02:1076281:1076497 [2] NCCL INFO comm 0x178a63a80 rank 86 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init START
f17n02:1076281:1076497 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
f17n02:1076281:1076497 [2] NCCL INFO Trees [0] 87/-1/-1->86->85 [1] -1/-1/-1->86->84 [2] 87/-1/-1->86->85 [3] -1/-1/-1->86->84
f17n02:1076281:1076497 [2] NCCL INFO P2P Chunksize set to 131072
f17n02:1076281:1076497 [2] NCCL INFO Channel 00/0 : 86[2] -> 87[3] via P2P/IPC
f17n02:1076281:1076497 [2] NCCL INFO Channel 02/0 : 86[2] -> 87[3] via P2P/IPC
f17n02:1076281:1076497 [2] NCCL INFO Channel 01/0 : 86[2] -> 85[1] via P2P/IPC
f17n02:1076281:1076497 [2] NCCL INFO Channel 03/0 : 86[2] -> 85[1] via P2P/IPC
f17n02:1076281:1076497 [2] NCCL INFO Connected all rings
f17n02:1076281:1076497 [2] NCCL INFO Channel 01/0 : 86[2] -> 84[0] via P2P/IPC
f17n02:1076281:1076497 [2] NCCL INFO Channel 03/0 : 86[2] -> 84[0] via P2P/IPC
f17n02:1076281:1076497 [2] NCCL INFO Channel 00/0 : 86[2] -> 85[1] via P2P/IPC
f17n02:1076281:1076497 [2] NCCL INFO Channel 02/0 : 86[2] -> 85[1] via P2P/IPC
f17n02:1076281:1076497 [2] NCCL INFO Connected all trees
f17n02:1076281:1076497 [2] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f17n02:1076281:1076497 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f17n02:1076281:1076497 [2] NCCL INFO comm 0x178a63a80 rank 86 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init COMPLETE
f17n02:1076279:1076279 [0] NCCL INFO cudaDriverVersion 12020
f17n02:1076279:1076279 [0] NCCL INFO Bootstrap : Using ib0:10.41.14.88<0>
f17n02:1076279:1076279 [0] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f17n02:1076279:1076279 [0] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f17n02:1076279:1076499 [0] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.88<0>
f17n02:1076279:1076499 [0] NCCL INFO Using network IB
f17n02:1076279:1076499 [0] NCCL INFO comm 0x15ed931b0 rank 84 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init START
f17n02:1076279:1076499 [0] NCCL INFO Setting affinity for GPU 0 to 0f
f17n02:1076279:1076499 [0] NCCL INFO Trees [0] 85/90/-1->84->72 [1] 86/-1/-1->84->85 [2] 85/-1/-1->84->79 [3] 86/-1/-1->84->85
f17n02:1076279:1076499 [0] NCCL INFO P2P Chunksize set to 131072
f17n02:1076279:1076499 [0] NCCL INFO Channel 00/0 : 83[5] -> 84[0] [receive] via NET/IB/0
f17n02:1076279:1076499 [0] NCCL INFO Channel 02/0 : 83[5] -> 84[0] [receive] via NET/IB/0
f17n02:1076279:1076499 [0] NCCL INFO Channel 00/0 : 84[0] -> 85[1] via P2P/IPC
f17n02:1076279:1076499 [0] NCCL INFO Channel 02/0 : 84[0] -> 85[1] via P2P/IPC
f17n02:1076279:1076499 [0] NCCL INFO Channel 01/0 : 84[0] -> 93[3] [send] via NET/IB/2
f17n02:1076279:1076499 [0] NCCL INFO Channel 03/0 : 84[0] -> 93[3] [send] via NET/IB/2
f17n02:1076279:1076499 [0] NCCL INFO Connected all rings
f17n02:1076279:1076499 [0] NCCL INFO Channel 01/0 : 84[0] -> 85[1] via P2P/IPC
f17n02:1076279:1076499 [0] NCCL INFO Channel 03/0 : 84[0] -> 85[1] via P2P/IPC
f17n02:1076279:1076499 [0] NCCL INFO Channel 01/0 : 84[0] -> 86[2] via P2P/IPC
f17n02:1076279:1076499 [0] NCCL INFO Channel 03/0 : 84[0] -> 86[2] via P2P/IPC
f17n02:1076279:1076499 [0] NCCL INFO Channel 02/0 : 79[1] -> 84[0] [receive] via NET/IB/0
f17n02:1076279:1076499 [0] NCCL INFO Channel 00/0 : 84[0] -> 90[0] [send] via NET/IB/0
f17n02:1076279:1076499 [0] NCCL INFO Channel 00/0 : 72[0] -> 84[0] [receive] via NET/IB/0
f17n02:1076279:1076499 [0] NCCL INFO Channel 00/0 : 84[0] -> 72[0] [send] via NET/IB/0
f17n02:1076279:1076499 [0] NCCL INFO Channel 00/0 : 90[0] -> 84[0] [receive] via NET/IB/0
f17n02:1076279:1076499 [0] NCCL INFO Channel 02/0 : 84[0] -> 79[1] [send] via NET/IB/0
f17n02:1076279:1076499 [0] NCCL INFO Connected all trees
f17n02:1076279:1076499 [0] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f17n02:1076279:1076499 [0] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f17n02:1076279:1076499 [0] NCCL INFO comm 0x15ed931b0 rank 84 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init COMPLETE
d09n07:1063018:1063018 [1] NCCL INFO cudaDriverVersion 12020
d09n07:1063018:1063018 [1] NCCL INFO Bootstrap : Using ib0:10.41.8.171<0>
d09n07:1063018:1063018 [1] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d09n07:1063018:1063018 [1] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d09n07:1063018:1063305 [1] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.8.171<0>
d09n07:1063018:1063305 [1] NCCL INFO Using network IB
d09n07:1063018:1063305 [1] NCCL INFO comm 0x121df3470 rank 1 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init START
d09n07:1063018:1063305 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d09n07:1063018:1063305 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 0/-1/-1->1->5 [2] 2/-1/-1->1->0 [3] 0/-1/-1->1->5
d09n07:1063018:1063305 [1] NCCL INFO P2P Chunksize set to 131072
d09n07:1063018:1063305 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/IPC
d09n07:1063018:1063305 [1] NCCL INFO Channel 02/0 : 1[1] -> 2[2] via P2P/IPC
d09n07:1063018:1063305 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/IPC
d09n07:1063018:1063305 [1] NCCL INFO Channel 03/0 : 1[1] -> 0[0] via P2P/IPC
d09n07:1063018:1063305 [1] NCCL INFO Connected all rings
d09n07:1063018:1063305 [1] NCCL INFO Channel 01/0 : 1[1] -> 5[5] via P2P/IPC
d09n07:1063018:1063305 [1] NCCL INFO Channel 03/0 : 1[1] -> 5[5] via P2P/IPC
d09n07:1063018:1063305 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/IPC
d09n07:1063018:1063305 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/IPC
d09n07:1063018:1063305 [1] NCCL INFO Connected all trees
d09n07:1063018:1063305 [1] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d09n07:1063018:1063305 [1] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d09n07:1063018:1063305 [1] NCCL INFO comm 0x121df3470 rank 1 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init COMPLETE
d09n07:1063019:1063019 [2] NCCL INFO cudaDriverVersion 12020
d09n07:1063019:1063019 [2] NCCL INFO Bootstrap : Using ib0:10.41.8.171<0>
d09n07:1063019:1063019 [2] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d09n07:1063019:1063019 [2] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d09n07:1063019:1063304 [2] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.8.171<0>
d09n07:1063019:1063304 [2] NCCL INFO Using network IB
d09n07:1063019:1063304 [2] NCCL INFO comm 0x15f2b3bf0 rank 2 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init START
d09n07:1063019:1063304 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d09n07:1063019:1063304 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] -1/-1/-1->2->0 [2] 3/-1/-1->2->1 [3] -1/-1/-1->2->0
d09n07:1063019:1063304 [2] NCCL INFO P2P Chunksize set to 131072
d09n07:1063019:1063304 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/IPC
d09n07:1063019:1063304 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/IPC
d09n07:1063019:1063304 [2] NCCL INFO Channel 01/0 : 2[2] -> 1[1] via P2P/IPC
d09n07:1063019:1063304 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/IPC
d09n07:1063019:1063304 [2] NCCL INFO Connected all rings
d09n07:1063019:1063304 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/IPC
d09n07:1063019:1063304 [2] NCCL INFO Channel 03/0 : 2[2] -> 0[0] via P2P/IPC
d09n07:1063019:1063304 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/IPC
d09n07:1063019:1063304 [2] NCCL INFO Channel 02/0 : 2[2] -> 1[1] via P2P/IPC
d09n07:1063019:1063304 [2] NCCL INFO Connected all trees
d09n07:1063019:1063304 [2] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d09n07:1063019:1063304 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d09n07:1063019:1063304 [2] NCCL INFO comm 0x15f2b3bf0 rank 2 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init COMPLETE
d09n07:1063021:1063021 [4] NCCL INFO cudaDriverVersion 12020
d09n07:1063021:1063021 [4] NCCL INFO Bootstrap : Using ib0:10.41.8.171<0>
d09n07:1063021:1063021 [4] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d09n07:1063021:1063021 [4] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d09n07:1063021:1063307 [4] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.8.171<0>
d09n07:1063021:1063307 [4] NCCL INFO Using network IB
d09n07:1063021:1063307 [4] NCCL INFO comm 0x1774933e0 rank 4 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init START
d09n07:1063021:1063307 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d09n07:1063021:1063307 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 3/52/-1->4->-1 [2] 5/-1/-1->4->3 [3] 3/-1/-1->4->10
d09n07:1063021:1063307 [4] NCCL INFO P2P Chunksize set to 131072
d09n07:1063021:1063307 [4] NCCL INFO Channel 00/0 : 4[4] -> 5[5] via P2P/IPC
d09n07:1063021:1063307 [4] NCCL INFO Channel 01/0 : 4[4] -> 5[5] via P2P/IPC
d09n07:1063021:1063307 [4] NCCL INFO Channel 02/0 : 4[4] -> 5[5] via P2P/IPC
d09n07:1063021:1063307 [4] NCCL INFO Channel 03/0 : 4[4] -> 5[5] via P2P/IPC
d09n07:1063021:1063307 [4] NCCL INFO Connected all rings
d09n07:1063021:1063307 [4] NCCL INFO Channel 03/0 : 4[4] -> 10[4] [send] via NET/IB/3
d09n07:1063021:1063307 [4] NCCL INFO Channel 01/0 : 52[4] -> 4[4] [receive] via NET/IB/3
d09n07:1063021:1063307 [4] NCCL INFO Channel 01/0 : 4[4] -> 52[4] [send] via NET/IB/3
d09n07:1063021:1063307 [4] NCCL INFO Channel 03/0 : 10[4] -> 4[4] [receive] via NET/IB/3
d09n07:1063021:1063307 [4] NCCL INFO Channel 00/0 : 4[4] -> 3[3] via P2P/IPC
d09n07:1063021:1063307 [4] NCCL INFO Channel 01/0 : 4[4] -> 3[3] via P2P/IPC
d09n07:1063021:1063307 [4] NCCL INFO Channel 02/0 : 4[4] -> 3[3] via P2P/IPC
d09n07:1063021:1063307 [4] NCCL INFO Channel 03/0 : 4[4] -> 3[3] via P2P/IPC
d09n07:1063021:1063307 [4] NCCL INFO Connected all trees
d09n07:1063021:1063307 [4] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d09n07:1063021:1063307 [4] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d09n07:1063021:1063307 [4] NCCL INFO comm 0x1774933e0 rank 4 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init COMPLETE
d09n07:1063022:1063022 [5] NCCL INFO cudaDriverVersion 12020
d09n07:1063022:1063022 [5] NCCL INFO Bootstrap : Using ib0:10.41.8.171<0>
d09n07:1063022:1063022 [5] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d09n07:1063022:1063022 [5] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d09n07:1063022:1063306 [5] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.8.171<0>
d09n07:1063022:1063306 [5] NCCL INFO Using network IB
d09n07:1063022:1063306 [5] NCCL INFO comm 0x165873980 rank 5 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init START
d09n07:1063022:1063306 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d09n07:1063022:1063306 [5] NCCL INFO Trees [0] -1/-1/-1->5->4 [1] 1/-1/-1->5->3 [2] -1/-1/-1->5->4 [3] 1/-1/-1->5->3
d09n07:1063022:1063306 [5] NCCL INFO P2P Chunksize set to 131072
d09n07:1063022:1063306 [5] NCCL INFO Channel 00/0 : 5[5] -> 6[0] [send] via NET/IB/1
d09n07:1063022:1063306 [5] NCCL INFO Channel 02/0 : 5[5] -> 6[0] [send] via NET/IB/1
d09n07:1063022:1063306 [5] NCCL INFO Channel 01/0 : 5[5] -> 2[2] via P2P/IPC
d09n07:1063022:1063306 [5] NCCL INFO Channel 03/0 : 5[5] -> 2[2] via P2P/IPC
d09n07:1063022:1063306 [5] NCCL INFO Connected all rings
d09n07:1063022:1063306 [5] NCCL INFO Channel 01/0 : 5[5] -> 1[1] via P2P/IPC
d09n07:1063022:1063306 [5] NCCL INFO Channel 03/0 : 5[5] -> 1[1] via P2P/IPC
d09n07:1063022:1063306 [5] NCCL INFO Channel 01/0 : 5[5] -> 3[3] via P2P/IPC
d09n07:1063022:1063306 [5] NCCL INFO Channel 03/0 : 5[5] -> 3[3] via P2P/IPC
d09n07:1063022:1063306 [5] NCCL INFO Channel 00/0 : 5[5] -> 4[4] via P2P/IPC
d09n07:1063022:1063306 [5] NCCL INFO Channel 02/0 : 5[5] -> 4[4] via P2P/IPC
d09n07:1063022:1063306 [5] NCCL INFO Connected all trees
d09n07:1063022:1063306 [5] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d09n07:1063022:1063306 [5] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d09n07:1063022:1063306 [5] NCCL INFO comm 0x165873980 rank 5 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init COMPLETE
d09n07:1063020:1063020 [3] NCCL INFO cudaDriverVersion 12020
d09n07:1063020:1063020 [3] NCCL INFO Bootstrap : Using ib0:10.41.8.171<0>
d09n07:1063020:1063020 [3] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d09n07:1063020:1063020 [3] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d09n07:1063020:1063308 [3] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.8.171<0>
d09n07:1063020:1063308 [3] NCCL INFO Using network IB
d09n07:1063020:1063308 [3] NCCL INFO comm 0x11afd3980 rank 3 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init START
d09n07:1063020:1063308 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d09n07:1063020:1063308 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 5/-1/-1->3->4 [2] 4/-1/-1->3->2 [3] 5/-1/-1->3->4
d09n07:1063020:1063308 [3] NCCL INFO P2P Chunksize set to 131072
d09n07:1063020:1063308 [3] NCCL INFO Channel 00/0 : 3[3] -> 4[4] via P2P/IPC
d09n07:1063020:1063308 [3] NCCL INFO Channel 01/0 : 3[3] -> 4[4] via P2P/IPC
d09n07:1063020:1063308 [3] NCCL INFO Channel 02/0 : 3[3] -> 4[4] via P2P/IPC
d09n07:1063020:1063308 [3] NCCL INFO Channel 03/0 : 3[3] -> 4[4] via P2P/IPC
d09n07:1063020:1063308 [3] NCCL INFO Channel 01/0 : 90[0] -> 3[3] [receive] via NET/IB/3
d09n07:1063020:1063308 [3] NCCL INFO Channel 03/0 : 90[0] -> 3[3] [receive] via NET/IB/3
d09n07:1063020:1063308 [3] NCCL INFO Connected all rings
d09n07:1063020:1063308 [3] NCCL INFO Channel 01/0 : 3[3] -> 5[5] via P2P/IPC
d09n07:1063020:1063308 [3] NCCL INFO Channel 03/0 : 3[3] -> 5[5] via P2P/IPC
d09n07:1063020:1063308 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/IPC
d09n07:1063020:1063308 [3] NCCL INFO Channel 02/0 : 3[3] -> 2[2] via P2P/IPC
d09n07:1063020:1063308 [3] NCCL INFO Connected all trees
d09n07:1063020:1063308 [3] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d09n07:1063020:1063308 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d09n07:1063020:1063308 [3] NCCL INFO comm 0x11afd3980 rank 3 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init COMPLETE
d17n06:1216531:1216531 [1] NCCL INFO cudaDriverVersion 12020
d17n06:1216531:1216531 [1] NCCL INFO Bootstrap : Using ib0:10.41.9.61<0>
d17n06:1216531:1216531 [1] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d17n06:1216531:1216531 [1] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d17n06:1216531:1216762 [1] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.61<0>
d17n06:1216531:1216762 [1] NCCL INFO Using network IB
d17n06:1216531:1216762 [1] NCCL INFO comm 0x1201f3690 rank 49 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init START
d17n06:1216531:1216762 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d17n06:1216531:1216762 [1] NCCL INFO Trees [0] 50/24/-1->49->48 [1] 48/-1/-1->49->53 [2] 50/-1/-1->49->48 [3] 48/-1/-1->49->53
d17n06:1216531:1216762 [1] NCCL INFO P2P Chunksize set to 131072
d17n06:1216531:1216762 [1] NCCL INFO Channel 00/0 : 49[1] -> 50[2] via P2P/IPC
d17n06:1216531:1216762 [1] NCCL INFO Channel 02/0 : 49[1] -> 50[2] via P2P/IPC
d17n06:1216531:1216762 [1] NCCL INFO Channel 01/0 : 49[1] -> 48[0] via P2P/IPC
d17n06:1216531:1216762 [1] NCCL INFO Channel 03/0 : 49[1] -> 48[0] via P2P/IPC
d17n06:1216531:1216762 [1] NCCL INFO Connected all rings
d17n06:1216531:1216762 [1] NCCL INFO Channel 01/0 : 49[1] -> 53[5] via P2P/IPC
d17n06:1216531:1216762 [1] NCCL INFO Channel 03/0 : 49[1] -> 53[5] via P2P/IPC
d17n06:1216531:1216762 [1] NCCL INFO Channel 00/0 : 24[0] -> 49[1] [receive] via NET/IB/0
d17n06:1216531:1216762 [1] NCCL INFO Channel 00/0 : 49[1] -> 24[0] [send] via NET/IB/0
d17n06:1216531:1216762 [1] NCCL INFO Channel 00/0 : 49[1] -> 48[0] via P2P/IPC
d17n06:1216531:1216762 [1] NCCL INFO Channel 02/0 : 49[1] -> 48[0] via P2P/IPC
d17n06:1216531:1216762 [1] NCCL INFO Connected all trees
d17n06:1216531:1216762 [1] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d17n06:1216531:1216762 [1] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d17n06:1216531:1216762 [1] NCCL INFO comm 0x1201f3690 rank 49 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init COMPLETE
d17n06:1216532:1216532 [2] NCCL INFO cudaDriverVersion 12020
d17n06:1216532:1216532 [2] NCCL INFO Bootstrap : Using ib0:10.41.9.61<0>
d17n06:1216532:1216532 [2] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d17n06:1216532:1216532 [2] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d17n06:1216532:1216763 [2] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.61<0>
d17n06:1216532:1216763 [2] NCCL INFO Using network IB
d17n06:1216532:1216763 [2] NCCL INFO comm 0x12df03750 rank 50 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init START
d17n06:1216532:1216763 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d17n06:1216532:1216763 [2] NCCL INFO Trees [0] 51/-1/-1->50->49 [1] -1/-1/-1->50->48 [2] 51/-1/-1->50->49 [3] -1/-1/-1->50->48
d17n06:1216532:1216763 [2] NCCL INFO P2P Chunksize set to 131072
d17n06:1216532:1216763 [2] NCCL INFO Channel 00/0 : 50[2] -> 51[3] via P2P/IPC
d17n06:1216532:1216763 [2] NCCL INFO Channel 02/0 : 50[2] -> 51[3] via P2P/IPC
d17n06:1216532:1216763 [2] NCCL INFO Channel 01/0 : 50[2] -> 49[1] via P2P/IPC
d17n06:1216532:1216763 [2] NCCL INFO Channel 03/0 : 50[2] -> 49[1] via P2P/IPC
d17n06:1216532:1216763 [2] NCCL INFO Connected all rings
d17n06:1216532:1216763 [2] NCCL INFO Channel 01/0 : 50[2] -> 48[0] via P2P/IPC
d17n06:1216532:1216763 [2] NCCL INFO Channel 03/0 : 50[2] -> 48[0] via P2P/IPC
d17n06:1216532:1216763 [2] NCCL INFO Channel 00/0 : 50[2] -> 49[1] via P2P/IPC
d17n06:1216532:1216763 [2] NCCL INFO Channel 02/0 : 50[2] -> 49[1] via P2P/IPC
d17n06:1216532:1216763 [2] NCCL INFO Connected all trees
d17n06:1216532:1216763 [2] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d17n06:1216532:1216763 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d17n06:1216532:1216763 [2] NCCL INFO comm 0x12df03750 rank 50 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init COMPLETE
f16n18:1091867:1091867 [1] NCCL INFO cudaDriverVersion 12020
f16n18:1091867:1091867 [1] NCCL INFO Bootstrap : Using ib0:10.41.14.86<0>
f16n18:1091867:1091867 [1] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f16n18:1091867:1091867 [1] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f16n18:1091867:1092086 [1] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.86<0>
f16n18:1091867:1092086 [1] NCCL INFO Using network IB
f16n18:1091867:1092086 [1] NCCL INFO comm 0x1578e2ff0 rank 73 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init START
f16n18:1091867:1092086 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
f16n18:1091867:1092086 [1] NCCL INFO Trees [0] 74/60/-1->73->72 [1] 72/-1/-1->73->77 [2] 74/-1/-1->73->72 [3] 72/-1/-1->73->77
f16n18:1091867:1092086 [1] NCCL INFO P2P Chunksize set to 131072
f16n18:1091867:1092086 [1] NCCL INFO Channel 00/0 : 73[1] -> 74[2] via P2P/IPC
f16n18:1091867:1092086 [1] NCCL INFO Channel 02/0 : 73[1] -> 74[2] via P2P/IPC
f16n18:1091867:1092086 [1] NCCL INFO Channel 01/0 : 73[1] -> 72[0] via P2P/IPC
f16n18:1091867:1092086 [1] NCCL INFO Channel 03/0 : 73[1] -> 72[0] via P2P/IPC
f16n18:1091867:1092086 [1] NCCL INFO Connected all rings
f16n18:1091867:1092086 [1] NCCL INFO Channel 01/0 : 73[1] -> 77[5] via P2P/IPC
f16n18:1091867:1092086 [1] NCCL INFO Channel 03/0 : 73[1] -> 77[5] via P2P/IPC
f16n18:1091867:1092086 [1] NCCL INFO Channel 00/0 : 60[0] -> 73[1] [receive] via NET/IB/0
f16n18:1091867:1092086 [1] NCCL INFO Channel 00/0 : 73[1] -> 60[0] [send] via NET/IB/0
f16n18:1091867:1092086 [1] NCCL INFO Channel 00/0 : 73[1] -> 72[0] via P2P/IPC
f16n18:1091867:1092086 [1] NCCL INFO Channel 02/0 : 73[1] -> 72[0] via P2P/IPC
f16n18:1091867:1092086 [1] NCCL INFO Connected all trees
f16n18:1091867:1092086 [1] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f16n18:1091867:1092086 [1] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f16n18:1091867:1092086 [1] NCCL INFO comm 0x1578e2ff0 rank 73 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init COMPLETE
d17n06:1216534:1216534 [4] NCCL INFO cudaDriverVersion 12020
d17n06:1216534:1216534 [4] NCCL INFO Bootstrap : Using ib0:10.41.9.61<0>
d17n06:1216534:1216534 [4] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d17n06:1216534:1216534 [4] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d17n06:1216534:1216767 [4] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.61<0>
d17n06:1216534:1216767 [4] NCCL INFO Using network IB
d17n06:1216534:1216767 [4] NCCL INFO comm 0x127d73a20 rank 52 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init START
d17n06:1216534:1216767 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d17n06:1216534:1216767 [4] NCCL INFO Trees [0] 53/-1/-1->52->51 [1] 51/76/-1->52->4 [2] 53/-1/-1->52->51 [3] 51/-1/-1->52->58
d17n06:1216534:1216767 [4] NCCL INFO P2P Chunksize set to 131072
d17n06:1216534:1216767 [4] NCCL INFO Channel 00/0 : 52[4] -> 53[5] via P2P/IPC
d17n06:1216534:1216767 [4] NCCL INFO Channel 01/0 : 52[4] -> 53[5] via P2P/IPC
d17n06:1216534:1216767 [4] NCCL INFO Channel 02/0 : 52[4] -> 53[5] via P2P/IPC
d17n06:1216534:1216767 [4] NCCL INFO Channel 03/0 : 52[4] -> 53[5] via P2P/IPC
d17n06:1216534:1216767 [4] NCCL INFO Connected all rings
d17n06:1216534:1216767 [4] NCCL INFO Channel 03/0 : 52[4] -> 58[4] [send] via NET/IB/3
d17n06:1216534:1216767 [4] NCCL INFO Channel 01/0 : 52[4] -> 76[4] [send] via NET/IB/3
d17n06:1216534:1216767 [4] NCCL INFO Channel 01/0 : 4[4] -> 52[4] [receive] via NET/IB/3
d17n06:1216534:1216767 [4] NCCL INFO Channel 01/0 : 52[4] -> 4[4] [send] via NET/IB/3
d17n06:1216534:1216767 [4] NCCL INFO Channel 01/0 : 76[4] -> 52[4] [receive] via NET/IB/3
d17n06:1216534:1216767 [4] NCCL INFO Channel 03/0 : 58[4] -> 52[4] [receive] via NET/IB/3
d17n06:1216534:1216767 [4] NCCL INFO Channel 00/0 : 52[4] -> 51[3] via P2P/IPC
d17n06:1216534:1216767 [4] NCCL INFO Channel 01/0 : 52[4] -> 51[3] via P2P/IPC
d17n06:1216534:1216767 [4] NCCL INFO Channel 02/0 : 52[4] -> 51[3] via P2P/IPC
d17n06:1216534:1216767 [4] NCCL INFO Channel 03/0 : 52[4] -> 51[3] via P2P/IPC
d17n06:1216534:1216767 [4] NCCL INFO Connected all trees
d17n06:1216534:1216767 [4] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d17n06:1216534:1216767 [4] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d17n06:1216534:1216767 [4] NCCL INFO comm 0x127d73a20 rank 52 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init COMPLETE
d17n06:1216530:1216530 [0] NCCL INFO cudaDriverVersion 12020
d17n06:1216530:1216530 [0] NCCL INFO Bootstrap : Using ib0:10.41.9.61<0>
d17n06:1216530:1216530 [0] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d17n06:1216530:1216530 [0] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d17n06:1216530:1216765 [0] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.61<0>
d17n06:1216530:1216765 [0] NCCL INFO Using network IB
d17n06:1216530:1216765 [0] NCCL INFO comm 0x143883b20 rank 48 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init START
d17n06:1216530:1216765 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d17n06:1216530:1216765 [0] NCCL INFO Trees [0] 49/72/-1->48->0 [1] 50/-1/-1->48->49 [2] 49/-1/-1->48->54 [3] 50/-1/-1->48->49
d17n06:1216530:1216765 [0] NCCL INFO P2P Chunksize set to 131072
d17n06:1216530:1216765 [0] NCCL INFO Channel 00/0 : 47[5] -> 48[0] [receive] via NET/IB/0
d17n06:1216530:1216765 [0] NCCL INFO Channel 02/0 : 47[5] -> 48[0] [receive] via NET/IB/0
d17n06:1216530:1216765 [0] NCCL INFO Channel 00/0 : 48[0] -> 49[1] via P2P/IPC
d17n06:1216530:1216765 [0] NCCL INFO Channel 02/0 : 48[0] -> 49[1] via P2P/IPC
d17n06:1216530:1216765 [0] NCCL INFO Channel 01/0 : 48[0] -> 57[3] [send] via NET/IB/2
d17n06:1216530:1216765 [0] NCCL INFO Channel 03/0 : 48[0] -> 57[3] [send] via NET/IB/2
d17n06:1216530:1216765 [0] NCCL INFO Connected all rings
d17n06:1216530:1216765 [0] NCCL INFO Channel 01/0 : 48[0] -> 49[1] via P2P/IPC
d17n06:1216530:1216765 [0] NCCL INFO Channel 03/0 : 48[0] -> 49[1] via P2P/IPC
d17n06:1216530:1216765 [0] NCCL INFO Channel 01/0 : 48[0] -> 50[2] via P2P/IPC
d17n06:1216530:1216765 [0] NCCL INFO Channel 03/0 : 48[0] -> 50[2] via P2P/IPC
d17n06:1216530:1216765 [0] NCCL INFO Channel 02/0 : 48[0] -> 54[0] [send] via NET/IB/0
d17n06:1216530:1216765 [0] NCCL INFO Channel 00/0 : 48[0] -> 72[0] [send] via NET/IB/0
d17n06:1216530:1216765 [0] NCCL INFO Channel 00/0 : 0[0] -> 48[0] [receive] via NET/IB/0
d17n06:1216530:1216765 [0] NCCL INFO Channel 00/0 : 48[0] -> 0[0] [send] via NET/IB/0
d17n06:1216530:1216765 [0] NCCL INFO Channel 00/0 : 72[0] -> 48[0] [receive] via NET/IB/0
d17n06:1216530:1216765 [0] NCCL INFO Channel 02/0 : 54[0] -> 48[0] [receive] via NET/IB/0
d17n06:1216530:1216765 [0] NCCL INFO Connected all trees
d17n06:1216530:1216765 [0] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d17n06:1216530:1216765 [0] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d17n06:1216530:1216765 [0] NCCL INFO comm 0x143883b20 rank 48 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init COMPLETE
f16n18:1091866:1091866 [0] NCCL INFO cudaDriverVersion 12020
f16n18:1091866:1091866 [0] NCCL INFO Bootstrap : Using ib0:10.41.14.86<0>
f16n18:1091866:1091866 [0] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f16n18:1091866:1091866 [0] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f16n18:1091866:1092088 [0] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.86<0>
f16n18:1091866:1092088 [0] NCCL INFO Using network IB
f16n18:1091866:1092088 [0] NCCL INFO comm 0x118b033a0 rank 72 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init START
f16n18:1091866:1092088 [0] NCCL INFO Setting affinity for GPU 0 to 0f
f16n18:1091866:1092088 [0] NCCL INFO Trees [0] 73/84/-1->72->48 [1] 74/-1/-1->72->73 [2] 73/-1/-1->72->78 [3] 74/-1/-1->72->73
f16n18:1091866:1092088 [0] NCCL INFO P2P Chunksize set to 131072
f16n18:1091866:1092088 [0] NCCL INFO Channel 00/0 : 71[5] -> 72[0] [receive] via NET/IB/0
f16n18:1091866:1092088 [0] NCCL INFO Channel 02/0 : 71[5] -> 72[0] [receive] via NET/IB/0
f16n18:1091866:1092088 [0] NCCL INFO Channel 00/0 : 72[0] -> 73[1] via P2P/IPC
f16n18:1091866:1092088 [0] NCCL INFO Channel 02/0 : 72[0] -> 73[1] via P2P/IPC
f16n18:1091866:1092088 [0] NCCL INFO Channel 01/0 : 72[0] -> 81[3] [send] via NET/IB/2
f16n18:1091866:1092088 [0] NCCL INFO Channel 03/0 : 72[0] -> 81[3] [send] via NET/IB/2
f16n18:1091866:1092088 [0] NCCL INFO Connected all rings
f16n18:1091866:1092088 [0] NCCL INFO Channel 01/0 : 72[0] -> 73[1] via P2P/IPC
f16n18:1091866:1092088 [0] NCCL INFO Channel 03/0 : 72[0] -> 73[1] via P2P/IPC
f16n18:1091866:1092088 [0] NCCL INFO Channel 01/0 : 72[0] -> 74[2] via P2P/IPC
f16n18:1091866:1092088 [0] NCCL INFO Channel 03/0 : 72[0] -> 74[2] via P2P/IPC
f16n18:1091866:1092088 [0] NCCL INFO Channel 02/0 : 72[0] -> 78[0] [send] via NET/IB/0
f16n18:1091866:1092088 [0] NCCL INFO Channel 00/0 : 72[0] -> 84[0] [send] via NET/IB/0
f16n18:1091866:1092088 [0] NCCL INFO Channel 00/0 : 48[0] -> 72[0] [receive] via NET/IB/0
f16n18:1091866:1092088 [0] NCCL INFO Channel 00/0 : 72[0] -> 48[0] [send] via NET/IB/0
f16n18:1091866:1092088 [0] NCCL INFO Channel 00/0 : 84[0] -> 72[0] [receive] via NET/IB/0
f16n18:1091866:1092088 [0] NCCL INFO Channel 02/0 : 78[0] -> 72[0] [receive] via NET/IB/0
f16n18:1091866:1092088 [0] NCCL INFO Connected all trees
f16n18:1091866:1092088 [0] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f16n18:1091866:1092088 [0] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f16n18:1091866:1092088 [0] NCCL INFO comm 0x118b033a0 rank 72 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init COMPLETE
d17n06:1216533:1216533 [3] NCCL INFO cudaDriverVersion 12020
d17n06:1216533:1216533 [3] NCCL INFO Bootstrap : Using ib0:10.41.9.61<0>
d17n06:1216533:1216533 [3] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d17n06:1216533:1216533 [3] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d17n06:1216533:1216766 [3] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.61<0>
d17n06:1216533:1216766 [3] NCCL INFO Using network IB
d17n06:1216533:1216766 [3] NCCL INFO comm 0x13bff3bb0 rank 51 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init START
d17n06:1216533:1216766 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d17n06:1216533:1216766 [3] NCCL INFO Trees [0] 52/-1/-1->51->50 [1] 53/28/-1->51->52 [2] 52/-1/-1->51->50 [3] 53/-1/-1->51->52
d17n06:1216533:1216766 [3] NCCL INFO P2P Chunksize set to 131072
d17n06:1216533:1216766 [3] NCCL INFO Channel 00/0 : 51[3] -> 52[4] via P2P/IPC
d17n06:1216533:1216766 [3] NCCL INFO Channel 01/0 : 51[3] -> 52[4] via P2P/IPC
d17n06:1216533:1216766 [3] NCCL INFO Channel 02/0 : 51[3] -> 52[4] via P2P/IPC
d17n06:1216533:1216766 [3] NCCL INFO Channel 03/0 : 51[3] -> 52[4] via P2P/IPC
d17n06:1216533:1216766 [3] NCCL INFO Channel 01/0 : 42[0] -> 51[3] [receive] via NET/IB/3
d17n06:1216533:1216766 [3] NCCL INFO Channel 03/0 : 42[0] -> 51[3] [receive] via NET/IB/3
d17n06:1216533:1216766 [3] NCCL INFO Connected all rings
d17n06:1216533:1216766 [3] NCCL INFO Channel 01/0 : 51[3] -> 53[5] via P2P/IPC
d17n06:1216533:1216766 [3] NCCL INFO Channel 03/0 : 51[3] -> 53[5] via P2P/IPC
d17n06:1216533:1216766 [3] NCCL INFO Channel 01/0 : 28[4] -> 51[3] [receive] via NET/IB/3
d17n06:1216533:1216766 [3] NCCL INFO Channel 01/0 : 51[3] -> 28[4] [send] via NET/IB/3
d17n06:1216533:1216766 [3] NCCL INFO Channel 00/0 : 51[3] -> 50[2] via P2P/IPC
d17n06:1216533:1216766 [3] NCCL INFO Channel 02/0 : 51[3] -> 50[2] via P2P/IPC
d17n06:1216533:1216766 [3] NCCL INFO Connected all trees
d17n06:1216533:1216766 [3] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d17n06:1216533:1216766 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d17n06:1216533:1216766 [3] NCCL INFO comm 0x13bff3bb0 rank 51 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init COMPLETE
f16n18:1091868:1091868 [2] NCCL INFO cudaDriverVersion 12020
f16n18:1091868:1091868 [2] NCCL INFO Bootstrap : Using ib0:10.41.14.86<0>
f16n18:1091868:1091868 [2] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f16n18:1091868:1091868 [2] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f16n18:1091868:1092089 [2] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.86<0>
f16n18:1091868:1092089 [2] NCCL INFO Using network IB
f16n18:1091868:1092089 [2] NCCL INFO comm 0x170753b40 rank 74 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init START
f16n18:1091868:1092089 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
f16n18:1091868:1092089 [2] NCCL INFO Trees [0] 75/-1/-1->74->73 [1] -1/-1/-1->74->72 [2] 75/-1/-1->74->73 [3] -1/-1/-1->74->72
f16n18:1091868:1092089 [2] NCCL INFO P2P Chunksize set to 131072
f16n18:1091868:1092089 [2] NCCL INFO Channel 00/0 : 74[2] -> 75[3] via P2P/IPC
f16n18:1091868:1092089 [2] NCCL INFO Channel 02/0 : 74[2] -> 75[3] via P2P/IPC
f16n18:1091868:1092089 [2] NCCL INFO Channel 01/0 : 74[2] -> 73[1] via P2P/IPC
f16n18:1091868:1092089 [2] NCCL INFO Channel 03/0 : 74[2] -> 73[1] via P2P/IPC
f16n18:1091868:1092089 [2] NCCL INFO Connected all rings
f16n18:1091868:1092089 [2] NCCL INFO Channel 01/0 : 74[2] -> 72[0] via P2P/IPC
f16n18:1091868:1092089 [2] NCCL INFO Channel 03/0 : 74[2] -> 72[0] via P2P/IPC
f16n18:1091868:1092089 [2] NCCL INFO Channel 00/0 : 74[2] -> 73[1] via P2P/IPC
f16n18:1091868:1092089 [2] NCCL INFO Channel 02/0 : 74[2] -> 73[1] via P2P/IPC
f16n18:1091868:1092089 [2] NCCL INFO Connected all trees
f16n18:1091868:1092089 [2] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f16n18:1091868:1092089 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f16n18:1091868:1092089 [2] NCCL INFO comm 0x170753b40 rank 74 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init COMPLETE
d17n06:1216535:1216535 [5] NCCL INFO cudaDriverVersion 12020
d17n06:1216535:1216535 [5] NCCL INFO Bootstrap : Using ib0:10.41.9.61<0>
d17n06:1216535:1216535 [5] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d17n06:1216535:1216535 [5] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d17n06:1216535:1216764 [5] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.61<0>
d17n06:1216535:1216764 [5] NCCL INFO Using network IB
d17n06:1216535:1216764 [5] NCCL INFO comm 0x139ae3670 rank 53 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init START
d17n06:1216535:1216764 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d17n06:1216535:1216764 [5] NCCL INFO Trees [0] -1/-1/-1->53->52 [1] 49/-1/-1->53->51 [2] -1/-1/-1->53->52 [3] 49/-1/-1->53->51
d17n06:1216535:1216764 [5] NCCL INFO P2P Chunksize set to 131072
d17n06:1216535:1216764 [5] NCCL INFO Channel 00/0 : 53[5] -> 54[0] [send] via NET/IB/1
d17n06:1216535:1216764 [5] NCCL INFO Channel 02/0 : 53[5] -> 54[0] [send] via NET/IB/1
d17n06:1216535:1216764 [5] NCCL INFO Channel 01/0 : 53[5] -> 50[2] via P2P/IPC
d17n06:1216535:1216764 [5] NCCL INFO Channel 03/0 : 53[5] -> 50[2] via P2P/IPC
d17n06:1216535:1216764 [5] NCCL INFO Connected all rings
d17n06:1216535:1216764 [5] NCCL INFO Channel 01/0 : 53[5] -> 49[1] via P2P/IPC
d17n06:1216535:1216764 [5] NCCL INFO Channel 03/0 : 53[5] -> 49[1] via P2P/IPC
d17n06:1216535:1216764 [5] NCCL INFO Channel 01/0 : 53[5] -> 51[3] via P2P/IPC
d17n06:1216535:1216764 [5] NCCL INFO Channel 03/0 : 53[5] -> 51[3] via P2P/IPC
d17n06:1216535:1216764 [5] NCCL INFO Channel 00/0 : 53[5] -> 52[4] via P2P/IPC
d17n06:1216535:1216764 [5] NCCL INFO Channel 02/0 : 53[5] -> 52[4] via P2P/IPC
d17n06:1216535:1216764 [5] NCCL INFO Connected all trees
d17n06:1216535:1216764 [5] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d17n06:1216535:1216764 [5] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d17n06:1216535:1216764 [5] NCCL INFO comm 0x139ae3670 rank 53 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init COMPLETE
f16n18:1091871:1091871 [5] NCCL INFO cudaDriverVersion 12020
f16n18:1091871:1091871 [5] NCCL INFO Bootstrap : Using ib0:10.41.14.86<0>
f16n18:1091871:1091871 [5] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f16n18:1091871:1091871 [5] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f16n18:1091871:1092087 [5] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.86<0>
f16n18:1091871:1092087 [5] NCCL INFO Using network IB
f16n18:1091871:1092087 [5] NCCL INFO comm 0x14b5b3740 rank 77 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init START
f16n18:1091871:1092087 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
f16n18:1091871:1092087 [5] NCCL INFO Trees [0] -1/-1/-1->77->76 [1] 73/-1/-1->77->75 [2] -1/-1/-1->77->76 [3] 73/-1/-1->77->75
f16n18:1091871:1092087 [5] NCCL INFO P2P Chunksize set to 131072
f16n18:1091871:1092087 [5] NCCL INFO Channel 00/0 : 77[5] -> 78[0] [send] via NET/IB/1
f16n18:1091871:1092087 [5] NCCL INFO Channel 02/0 : 77[5] -> 78[0] [send] via NET/IB/1
f16n18:1091871:1092087 [5] NCCL INFO Channel 01/0 : 77[5] -> 74[2] via P2P/IPC
f16n18:1091871:1092087 [5] NCCL INFO Channel 03/0 : 77[5] -> 74[2] via P2P/IPC
f16n18:1091871:1092087 [5] NCCL INFO Connected all rings
f16n18:1091871:1092087 [5] NCCL INFO Channel 01/0 : 77[5] -> 73[1] via P2P/IPC
f16n18:1091871:1092087 [5] NCCL INFO Channel 03/0 : 77[5] -> 73[1] via P2P/IPC
f16n18:1091871:1092087 [5] NCCL INFO Channel 01/0 : 77[5] -> 75[3] via P2P/IPC
f16n18:1091871:1092087 [5] NCCL INFO Channel 03/0 : 77[5] -> 75[3] via P2P/IPC
f16n18:1091871:1092087 [5] NCCL INFO Channel 00/0 : 77[5] -> 76[4] via P2P/IPC
f16n18:1091871:1092087 [5] NCCL INFO Channel 02/0 : 77[5] -> 76[4] via P2P/IPC
f16n18:1091871:1092087 [5] NCCL INFO Connected all trees
f16n18:1091871:1092087 [5] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f16n18:1091871:1092087 [5] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f16n18:1091871:1092087 [5] NCCL INFO comm 0x14b5b3740 rank 77 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init COMPLETE
f16n18:1091869:1091869 [3] NCCL INFO cudaDriverVersion 12020
f16n18:1091869:1091869 [3] NCCL INFO Bootstrap : Using ib0:10.41.14.86<0>
f16n18:1091869:1091869 [3] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f16n18:1091869:1091869 [3] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f16n18:1091869:1092090 [3] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.86<0>
f16n18:1091869:1092090 [3] NCCL INFO Using network IB
f16n18:1091869:1092090 [3] NCCL INFO comm 0x14c793640 rank 75 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init START
f16n18:1091869:1092090 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
f16n18:1091869:1092090 [3] NCCL INFO Trees [0] 76/-1/-1->75->74 [1] 77/64/-1->75->76 [2] 76/-1/-1->75->74 [3] 77/-1/-1->75->76
f16n18:1091869:1092090 [3] NCCL INFO P2P Chunksize set to 131072
f16n18:1091869:1092090 [3] NCCL INFO Channel 00/0 : 75[3] -> 76[4] via P2P/IPC
f16n18:1091869:1092090 [3] NCCL INFO Channel 01/0 : 75[3] -> 76[4] via P2P/IPC
f16n18:1091869:1092090 [3] NCCL INFO Channel 02/0 : 75[3] -> 76[4] via P2P/IPC
f16n18:1091869:1092090 [3] NCCL INFO Channel 03/0 : 75[3] -> 76[4] via P2P/IPC
f16n18:1091869:1092090 [3] NCCL INFO Channel 01/0 : 66[0] -> 75[3] [receive] via NET/IB/3
f16n18:1091869:1092090 [3] NCCL INFO Channel 03/0 : 66[0] -> 75[3] [receive] via NET/IB/3
f16n18:1091869:1092090 [3] NCCL INFO Connected all rings
f16n18:1091869:1092090 [3] NCCL INFO Channel 01/0 : 75[3] -> 77[5] via P2P/IPC
f16n18:1091869:1092090 [3] NCCL INFO Channel 03/0 : 75[3] -> 77[5] via P2P/IPC
f16n18:1091869:1092090 [3] NCCL INFO Channel 01/0 : 64[4] -> 75[3] [receive] via NET/IB/3
f16n18:1091869:1092090 [3] NCCL INFO Channel 01/0 : 75[3] -> 64[4] [send] via NET/IB/3
f16n18:1091869:1092090 [3] NCCL INFO Channel 00/0 : 75[3] -> 74[2] via P2P/IPC
f16n18:1091869:1092090 [3] NCCL INFO Channel 02/0 : 75[3] -> 74[2] via P2P/IPC
f16n18:1091869:1092090 [3] NCCL INFO Connected all trees
f16n18:1091869:1092090 [3] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f16n18:1091869:1092090 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f16n18:1091869:1092090 [3] NCCL INFO comm 0x14c793640 rank 75 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init COMPLETE
d17n07:1212414:1212414 [4] NCCL INFO cudaDriverVersion 12020
d17n07:1212414:1212414 [4] NCCL INFO Bootstrap : Using ib0:10.41.9.62<0>
d17n07:1212414:1212414 [4] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d17n07:1212414:1212414 [4] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d17n07:1212414:1212645 [4] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.62<0>
d17n07:1212414:1212645 [4] NCCL INFO Using network IB
d17n07:1212414:1212645 [4] NCCL INFO comm 0x177733770 rank 58 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init START
d17n07:1212414:1212645 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d17n07:1212414:1212645 [4] NCCL INFO Trees [0] 59/-1/-1->58->57 [1] 57/-1/-1->58->63 [2] 59/-1/-1->58->57 [3] 57/52/-1->58->70
d17n07:1212414:1212645 [4] NCCL INFO P2P Chunksize set to 131072
d17n07:1212414:1212645 [4] NCCL INFO Channel 00/0 : 58[4] -> 59[5] via P2P/IPC
d17n07:1212414:1212645 [4] NCCL INFO Channel 01/0 : 58[4] -> 59[5] via P2P/IPC
d17n07:1212414:1212645 [4] NCCL INFO Channel 02/0 : 58[4] -> 59[5] via P2P/IPC
d17n07:1212414:1212645 [4] NCCL INFO Channel 03/0 : 58[4] -> 59[5] via P2P/IPC
d17n07:1212414:1212645 [4] NCCL INFO Connected all rings
d17n07:1212414:1212645 [4] NCCL INFO Channel 01/0 : 58[4] -> 63[3] [send] via NET/IB/3
d17n07:1212414:1212645 [4] NCCL INFO Channel 03/0 : 52[4] -> 58[4] [receive] via NET/IB/3
d17n07:1212414:1212645 [4] NCCL INFO Channel 03/0 : 58[4] -> 70[4] [send] via NET/IB/3
d17n07:1212414:1212645 [4] NCCL INFO Channel 03/0 : 70[4] -> 58[4] [receive] via NET/IB/3
d17n07:1212414:1212645 [4] NCCL INFO Channel 03/0 : 58[4] -> 52[4] [send] via NET/IB/3
d17n07:1212414:1212645 [4] NCCL INFO Channel 01/0 : 63[3] -> 58[4] [receive] via NET/IB/3
d17n07:1212414:1212645 [4] NCCL INFO Channel 00/0 : 58[4] -> 57[3] via P2P/IPC
d17n07:1212414:1212645 [4] NCCL INFO Channel 01/0 : 58[4] -> 57[3] via P2P/IPC
d17n07:1212414:1212645 [4] NCCL INFO Channel 02/0 : 58[4] -> 57[3] via P2P/IPC
d17n07:1212414:1212645 [4] NCCL INFO Channel 03/0 : 58[4] -> 57[3] via P2P/IPC
d17n07:1212414:1212645 [4] NCCL INFO Connected all trees
d17n07:1212414:1212645 [4] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d17n07:1212414:1212645 [4] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d17n07:1212414:1212645 [4] NCCL INFO comm 0x177733770 rank 58 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init COMPLETE
d17n07:1212415:1212415 [5] NCCL INFO cudaDriverVersion 12020
d17n07:1212415:1212415 [5] NCCL INFO Bootstrap : Using ib0:10.41.9.62<0>
d17n07:1212415:1212415 [5] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d17n07:1212415:1212415 [5] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d17n07:1212415:1212646 [5] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.62<0>
d17n07:1212415:1212646 [5] NCCL INFO Using network IB
d17n07:1212415:1212646 [5] NCCL INFO comm 0x14c343690 rank 59 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init START
d17n07:1212415:1212646 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d17n07:1212415:1212646 [5] NCCL INFO Trees [0] -1/-1/-1->59->58 [1] 55/-1/-1->59->57 [2] -1/-1/-1->59->58 [3] 55/-1/-1->59->57
d17n07:1212415:1212646 [5] NCCL INFO P2P Chunksize set to 131072
d17n07:1212415:1212646 [5] NCCL INFO Channel 00/0 : 59[5] -> 60[0] [send] via NET/IB/1
d17n07:1212415:1212646 [5] NCCL INFO Channel 02/0 : 59[5] -> 60[0] [send] via NET/IB/1
d17n07:1212415:1212646 [5] NCCL INFO Channel 01/0 : 59[5] -> 56[2] via P2P/IPC
d17n07:1212415:1212646 [5] NCCL INFO Channel 03/0 : 59[5] -> 56[2] via P2P/IPC
d17n07:1212415:1212646 [5] NCCL INFO Connected all rings
d17n07:1212415:1212646 [5] NCCL INFO Channel 01/0 : 59[5] -> 55[1] via P2P/IPC
d17n07:1212415:1212646 [5] NCCL INFO Channel 03/0 : 59[5] -> 55[1] via P2P/IPC
d17n07:1212415:1212646 [5] NCCL INFO Channel 01/0 : 59[5] -> 57[3] via P2P/IPC
d17n07:1212415:1212646 [5] NCCL INFO Channel 03/0 : 59[5] -> 57[3] via P2P/IPC
d17n07:1212415:1212646 [5] NCCL INFO Channel 00/0 : 59[5] -> 58[4] via P2P/IPC
d17n07:1212415:1212646 [5] NCCL INFO Channel 02/0 : 59[5] -> 58[4] via P2P/IPC
d17n07:1212415:1212646 [5] NCCL INFO Connected all trees
d17n07:1212415:1212646 [5] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d17n07:1212415:1212646 [5] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d17n07:1212415:1212646 [5] NCCL INFO comm 0x14c343690 rank 59 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init COMPLETE
f17n01:970278:970278 [2] NCCL INFO cudaDriverVersion 12020
f17n01:970278:970278 [2] NCCL INFO Bootstrap : Using ib0:10.41.14.87<0>
f17n01:970278:970278 [2] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f17n01:970278:970278 [2] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f17n01:970278:970499 [2] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.87<0>
f17n01:970278:970499 [2] NCCL INFO Using network IB
f17n01:970278:970499 [2] NCCL INFO comm 0x155723370 rank 80 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init START
f17n01:970278:970499 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
f17n01:970278:970499 [2] NCCL INFO Trees [0] 81/-1/-1->80->79 [1] -1/-1/-1->80->78 [2] 81/-1/-1->80->79 [3] -1/-1/-1->80->78
f17n01:970278:970499 [2] NCCL INFO P2P Chunksize set to 131072
f17n01:970278:970499 [2] NCCL INFO Channel 00/0 : 80[2] -> 81[3] via P2P/IPC
f17n01:970278:970499 [2] NCCL INFO Channel 02/0 : 80[2] -> 81[3] via P2P/IPC
f17n01:970278:970499 [2] NCCL INFO Channel 01/0 : 80[2] -> 79[1] via P2P/IPC
f17n01:970278:970499 [2] NCCL INFO Channel 03/0 : 80[2] -> 79[1] via P2P/IPC
f17n01:970278:970499 [2] NCCL INFO Connected all rings
f17n01:970278:970499 [2] NCCL INFO Channel 01/0 : 80[2] -> 78[0] via P2P/IPC
f17n01:970278:970499 [2] NCCL INFO Channel 03/0 : 80[2] -> 78[0] via P2P/IPC
f17n01:970278:970499 [2] NCCL INFO Channel 00/0 : 80[2] -> 79[1] via P2P/IPC
f17n01:970278:970499 [2] NCCL INFO Channel 02/0 : 80[2] -> 79[1] via P2P/IPC
f17n01:970278:970499 [2] NCCL INFO Connected all trees
f17n01:970278:970499 [2] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f17n01:970278:970499 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f17n01:970278:970499 [2] NCCL INFO comm 0x155723370 rank 80 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init COMPLETE
f17n01:970277:970277 [1] NCCL INFO cudaDriverVersion 12020
f17n01:970277:970277 [1] NCCL INFO Bootstrap : Using ib0:10.41.14.87<0>
f17n01:970277:970277 [1] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f17n01:970277:970277 [1] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f17n01:970277:970494 [1] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.87<0>
f17n01:970277:970494 [1] NCCL INFO Using network IB
f17n01:970277:970494 [1] NCCL INFO comm 0x145543850 rank 79 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init START
f17n01:970277:970494 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
f17n01:970277:970494 [1] NCCL INFO Trees [0] 80/-1/-1->79->78 [1] 78/-1/-1->79->83 [2] 80/84/-1->79->78 [3] 78/-1/-1->79->83
f17n01:970277:970494 [1] NCCL INFO P2P Chunksize set to 131072
f17n01:970277:970494 [1] NCCL INFO Channel 00/0 : 79[1] -> 80[2] via P2P/IPC
f17n01:970277:970494 [1] NCCL INFO Channel 02/0 : 79[1] -> 80[2] via P2P/IPC
f17n01:970277:970494 [1] NCCL INFO Channel 01/0 : 79[1] -> 78[0] via P2P/IPC
f17n01:970277:970494 [1] NCCL INFO Channel 03/0 : 79[1] -> 78[0] via P2P/IPC
f17n01:970277:970494 [1] NCCL INFO Connected all rings
f17n01:970277:970494 [1] NCCL INFO Channel 01/0 : 79[1] -> 83[5] via P2P/IPC
f17n01:970277:970494 [1] NCCL INFO Channel 03/0 : 79[1] -> 83[5] via P2P/IPC
f17n01:970277:970494 [1] NCCL INFO Channel 02/0 : 79[1] -> 84[0] [send] via NET/IB/0
f17n01:970277:970494 [1] NCCL INFO Channel 02/0 : 84[0] -> 79[1] [receive] via NET/IB/0
f17n01:970277:970494 [1] NCCL INFO Channel 00/0 : 79[1] -> 78[0] via P2P/IPC
f17n01:970277:970494 [1] NCCL INFO Channel 02/0 : 79[1] -> 78[0] via P2P/IPC
f17n01:970277:970494 [1] NCCL INFO Connected all trees
f17n01:970277:970494 [1] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f17n01:970277:970494 [1] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f17n01:970277:970494 [1] NCCL INFO comm 0x145543850 rank 79 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init COMPLETE
f17n01:970276:970276 [0] NCCL INFO cudaDriverVersion 12020
f17n01:970276:970276 [0] NCCL INFO Bootstrap : Using ib0:10.41.14.87<0>
f17n01:970276:970276 [0] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f17n01:970276:970276 [0] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f17n01:970276:970495 [0] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.87<0>
f17n01:970276:970495 [0] NCCL INFO Using network IB
f17n01:970276:970495 [0] NCCL INFO comm 0x159922e60 rank 78 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init START
f17n01:970276:970495 [0] NCCL INFO Setting affinity for GPU 0 to 0f
f17n01:970276:970495 [0] NCCL INFO Trees [0] 79/-1/-1->78->85 [1] 80/-1/-1->78->79 [2] 79/72/-1->78->67 [3] 80/-1/-1->78->79
f17n01:970276:970495 [0] NCCL INFO P2P Chunksize set to 131072
f17n01:970276:970495 [0] NCCL INFO Channel 00/0 : 77[5] -> 78[0] [receive] via NET/IB/0
f17n01:970276:970495 [0] NCCL INFO Channel 02/0 : 77[5] -> 78[0] [receive] via NET/IB/0
f17n01:970276:970495 [0] NCCL INFO Channel 00/0 : 78[0] -> 79[1] via P2P/IPC
f17n01:970276:970495 [0] NCCL INFO Channel 02/0 : 78[0] -> 79[1] via P2P/IPC
f17n01:970276:970495 [0] NCCL INFO Channel 01/0 : 78[0] -> 87[3] [send] via NET/IB/2
f17n01:970276:970495 [0] NCCL INFO Channel 03/0 : 78[0] -> 87[3] [send] via NET/IB/2
f17n01:970276:970495 [0] NCCL INFO Connected all rings
f17n01:970276:970495 [0] NCCL INFO Channel 01/0 : 78[0] -> 79[1] via P2P/IPC
f17n01:970276:970495 [0] NCCL INFO Channel 03/0 : 78[0] -> 79[1] via P2P/IPC
f17n01:970276:970495 [0] NCCL INFO Channel 01/0 : 78[0] -> 80[2] via P2P/IPC
f17n01:970276:970495 [0] NCCL INFO Channel 03/0 : 78[0] -> 80[2] via P2P/IPC
f17n01:970276:970495 [0] NCCL INFO Channel 02/0 : 72[0] -> 78[0] [receive] via NET/IB/0
f17n01:970276:970495 [0] NCCL INFO Channel 00/0 : 78[0] -> 85[1] [send] via NET/IB/0
f17n01:970276:970495 [0] NCCL INFO Channel 02/0 : 67[1] -> 78[0] [receive] via NET/IB/0
f17n01:970276:970495 [0] NCCL INFO Channel 02/0 : 78[0] -> 67[1] [send] via NET/IB/0
f17n01:970276:970495 [0] NCCL INFO Channel 00/0 : 85[1] -> 78[0] [receive] via NET/IB/0
f17n01:970276:970495 [0] NCCL INFO Channel 02/0 : 78[0] -> 72[0] [send] via NET/IB/0
f17n01:970276:970495 [0] NCCL INFO Connected all trees
f17n01:970276:970495 [0] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f17n01:970276:970495 [0] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f17n01:970276:970495 [0] NCCL INFO comm 0x159922e60 rank 78 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init COMPLETE
f16n17:1090960:1090960 [1] NCCL INFO cudaDriverVersion 12020
f16n17:1090960:1090960 [1] NCCL INFO Bootstrap : Using ib0:10.41.14.85<0>
f16n17:1090960:1090960 [1] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f16n17:1090960:1090960 [1] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f16n17:1090960:1091177 [1] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.85<0>
f16n17:1090960:1091177 [1] NCCL INFO Using network IB
f16n17:1090960:1091177 [1] NCCL INFO comm 0x160283880 rank 67 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init START
f16n17:1090960:1091177 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
f16n17:1090960:1091177 [1] NCCL INFO Trees [0] 68/-1/-1->67->66 [1] 66/-1/-1->67->71 [2] 68/78/-1->67->66 [3] 66/-1/-1->67->71
f16n17:1090960:1091177 [1] NCCL INFO P2P Chunksize set to 131072
f16n17:1090960:1091177 [1] NCCL INFO Channel 00/0 : 67[1] -> 68[2] via P2P/IPC
f16n17:1090960:1091177 [1] NCCL INFO Channel 02/0 : 67[1] -> 68[2] via P2P/IPC
f16n17:1090960:1091177 [1] NCCL INFO Channel 01/0 : 67[1] -> 66[0] via P2P/IPC
f16n17:1090960:1091177 [1] NCCL INFO Channel 03/0 : 67[1] -> 66[0] via P2P/IPC
f16n17:1090960:1091177 [1] NCCL INFO Connected all rings
f16n17:1090960:1091177 [1] NCCL INFO Channel 01/0 : 67[1] -> 71[5] via P2P/IPC
f16n17:1090960:1091177 [1] NCCL INFO Channel 03/0 : 67[1] -> 71[5] via P2P/IPC
f16n17:1090960:1091177 [1] NCCL INFO Channel 02/0 : 67[1] -> 78[0] [send] via NET/IB/0
f16n17:1090960:1091177 [1] NCCL INFO Channel 02/0 : 78[0] -> 67[1] [receive] via NET/IB/0
f16n17:1090960:1091177 [1] NCCL INFO Channel 00/0 : 67[1] -> 66[0] via P2P/IPC
f16n17:1090960:1091177 [1] NCCL INFO Channel 02/0 : 67[1] -> 66[0] via P2P/IPC
f16n17:1090960:1091177 [1] NCCL INFO Connected all trees
f16n17:1090960:1091177 [1] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f16n17:1090960:1091177 [1] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f16n17:1090960:1091177 [1] NCCL INFO comm 0x160283880 rank 67 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init COMPLETE
f16n16:1079912:1079912 [0] NCCL INFO cudaDriverVersion 12020
f16n16:1079912:1079912 [0] NCCL INFO Bootstrap : Using ib0:10.41.14.84<0>
f16n16:1079912:1079912 [0] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f16n16:1079912:1079912 [0] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f16n16:1079912:1080132 [0] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.84<0>
f16n16:1079912:1080132 [0] NCCL INFO Using network IB
f16n16:1079912:1080132 [0] NCCL INFO comm 0x140933290 rank 60 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init START
f16n16:1079912:1080132 [0] NCCL INFO Setting affinity for GPU 0 to 0f
f16n16:1079912:1080132 [0] NCCL INFO Trees [0] 61/66/-1->60->73 [1] 62/-1/-1->60->61 [2] 61/-1/-1->60->55 [3] 62/-1/-1->60->61
f16n16:1079912:1080132 [0] NCCL INFO P2P Chunksize set to 131072
f16n16:1079912:1080132 [0] NCCL INFO Channel 00/0 : 59[5] -> 60[0] [receive] via NET/IB/0
f16n16:1079912:1080132 [0] NCCL INFO Channel 02/0 : 59[5] -> 60[0] [receive] via NET/IB/0
f16n16:1079912:1080132 [0] NCCL INFO Channel 00/0 : 60[0] -> 61[1] via P2P/IPC
f16n16:1079912:1080132 [0] NCCL INFO Channel 02/0 : 60[0] -> 61[1] via P2P/IPC
f16n16:1079912:1080132 [0] NCCL INFO Channel 01/0 : 60[0] -> 69[3] [send] via NET/IB/2
f16n16:1079912:1080132 [0] NCCL INFO Channel 03/0 : 60[0] -> 69[3] [send] via NET/IB/2
f16n16:1079912:1080132 [0] NCCL INFO Connected all rings
f16n16:1079912:1080132 [0] NCCL INFO Channel 01/0 : 60[0] -> 61[1] via P2P/IPC
f16n16:1079912:1080132 [0] NCCL INFO Channel 03/0 : 60[0] -> 61[1] via P2P/IPC
f16n16:1079912:1080132 [0] NCCL INFO Channel 01/0 : 60[0] -> 62[2] via P2P/IPC
f16n16:1079912:1080132 [0] NCCL INFO Channel 03/0 : 60[0] -> 62[2] via P2P/IPC
f16n16:1079912:1080132 [0] NCCL INFO Channel 02/0 : 55[1] -> 60[0] [receive] via NET/IB/0
f16n16:1079912:1080132 [0] NCCL INFO Channel 00/0 : 60[0] -> 66[0] [send] via NET/IB/0
f16n16:1079912:1080132 [0] NCCL INFO Channel 00/0 : 60[0] -> 73[1] [send] via NET/IB/0
f16n16:1079912:1080132 [0] NCCL INFO Channel 00/0 : 73[1] -> 60[0] [receive] via NET/IB/0
f16n16:1079912:1080132 [0] NCCL INFO Channel 00/0 : 66[0] -> 60[0] [receive] via NET/IB/0
f16n16:1079912:1080132 [0] NCCL INFO Channel 02/0 : 60[0] -> 55[1] [send] via NET/IB/0
f16n16:1079912:1080132 [0] NCCL INFO Connected all trees
f16n16:1079912:1080132 [0] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f16n16:1079912:1080132 [0] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f16n16:1079912:1080132 [0] NCCL INFO comm 0x140933290 rank 60 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init COMPLETE
f17n01:970280:970280 [4] NCCL INFO cudaDriverVersion 12020
f17n01:970280:970280 [4] NCCL INFO Bootstrap : Using ib0:10.41.14.87<0>
f17n01:970280:970280 [4] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f17n01:970280:970280 [4] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f17n01:970280:970497 [4] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.87<0>
f17n01:970280:970497 [4] NCCL INFO Using network IB
f17n01:970280:970497 [4] NCCL INFO comm 0x1342d39a0 rank 82 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init START
f17n01:970280:970497 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
f17n01:970280:970497 [4] NCCL INFO Trees [0] 83/-1/-1->82->81 [1] 81/-1/-1->82->87 [2] 83/-1/-1->82->81 [3] 81/76/-1->82->69
f17n01:970280:970497 [4] NCCL INFO P2P Chunksize set to 131072
f17n01:970280:970497 [4] NCCL INFO Channel 00/0 : 82[4] -> 83[5] via P2P/IPC
f17n01:970280:970497 [4] NCCL INFO Channel 01/0 : 82[4] -> 83[5] via P2P/IPC
f17n01:970280:970497 [4] NCCL INFO Channel 02/0 : 82[4] -> 83[5] via P2P/IPC
f17n01:970280:970497 [4] NCCL INFO Channel 03/0 : 82[4] -> 83[5] via P2P/IPC
f17n01:970280:970497 [4] NCCL INFO Connected all rings
f17n01:970280:970497 [4] NCCL INFO Channel 01/0 : 82[4] -> 87[3] [send] via NET/IB/3
f17n01:970280:970497 [4] NCCL INFO Channel 03/0 : 76[4] -> 82[4] [receive] via NET/IB/3
f17n01:970280:970497 [4] NCCL INFO Channel 03/0 : 69[3] -> 82[4] [receive] via NET/IB/3
f17n01:970280:970497 [4] NCCL INFO Channel 03/0 : 82[4] -> 69[3] [send] via NET/IB/3
f17n01:970280:970497 [4] NCCL INFO Channel 03/0 : 82[4] -> 76[4] [send] via NET/IB/3
f17n01:970280:970497 [4] NCCL INFO Channel 01/0 : 87[3] -> 82[4] [receive] via NET/IB/3
f17n01:970280:970497 [4] NCCL INFO Channel 00/0 : 82[4] -> 81[3] via P2P/IPC
f17n01:970280:970497 [4] NCCL INFO Channel 01/0 : 82[4] -> 81[3] via P2P/IPC
f17n01:970280:970497 [4] NCCL INFO Channel 02/0 : 82[4] -> 81[3] via P2P/IPC
f17n01:970280:970497 [4] NCCL INFO Channel 03/0 : 82[4] -> 81[3] via P2P/IPC
f17n01:970280:970497 [4] NCCL INFO Connected all trees
f17n01:970280:970497 [4] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f17n01:970280:970497 [4] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f17n01:970280:970497 [4] NCCL INFO comm 0x1342d39a0 rank 82 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init COMPLETE
f16n17:1090961:1090961 [2] NCCL INFO cudaDriverVersion 12020
f16n17:1090961:1090961 [2] NCCL INFO Bootstrap : Using ib0:10.41.14.85<0>
f16n17:1090961:1090961 [2] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f16n17:1090961:1090961 [2] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f16n17:1090961:1091179 [2] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.85<0>
f16n17:1090961:1091179 [2] NCCL INFO Using network IB
f16n17:1090961:1091179 [2] NCCL INFO comm 0x1212a3070 rank 68 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init START
f16n17:1090961:1091179 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
f16n17:1090961:1091179 [2] NCCL INFO Trees [0] 69/-1/-1->68->67 [1] -1/-1/-1->68->66 [2] 69/-1/-1->68->67 [3] -1/-1/-1->68->66
f16n17:1090961:1091179 [2] NCCL INFO P2P Chunksize set to 131072
f16n17:1090961:1091179 [2] NCCL INFO Channel 00/0 : 68[2] -> 69[3] via P2P/IPC
f16n17:1090961:1091179 [2] NCCL INFO Channel 02/0 : 68[2] -> 69[3] via P2P/IPC
f16n17:1090961:1091179 [2] NCCL INFO Channel 01/0 : 68[2] -> 67[1] via P2P/IPC
f16n17:1090961:1091179 [2] NCCL INFO Channel 03/0 : 68[2] -> 67[1] via P2P/IPC
f16n17:1090961:1091179 [2] NCCL INFO Connected all rings
f16n17:1090961:1091179 [2] NCCL INFO Channel 01/0 : 68[2] -> 66[0] via P2P/IPC
f16n17:1090961:1091179 [2] NCCL INFO Channel 03/0 : 68[2] -> 66[0] via P2P/IPC
f16n17:1090961:1091179 [2] NCCL INFO Channel 00/0 : 68[2] -> 67[1] via P2P/IPC
f16n17:1090961:1091179 [2] NCCL INFO Channel 02/0 : 68[2] -> 67[1] via P2P/IPC
f16n17:1090961:1091179 [2] NCCL INFO Connected all trees
f16n17:1090961:1091179 [2] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f16n17:1090961:1091179 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f16n17:1090961:1091179 [2] NCCL INFO comm 0x1212a3070 rank 68 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init COMPLETE
f17n01:970279:970279 [3] NCCL INFO cudaDriverVersion 12020
f17n01:970279:970279 [3] NCCL INFO Bootstrap : Using ib0:10.41.14.87<0>
f17n01:970279:970279 [3] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f17n01:970279:970279 [3] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f17n01:970279:970498 [3] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.87<0>
f17n01:970279:970498 [3] NCCL INFO Using network IB
f17n01:970279:970498 [3] NCCL INFO comm 0x140ad3620 rank 81 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init START
f17n01:970279:970498 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
f17n01:970279:970498 [3] NCCL INFO Trees [0] 82/-1/-1->81->80 [1] 83/-1/-1->81->82 [2] 82/-1/-1->81->80 [3] 83/88/-1->81->82
f17n01:970279:970498 [3] NCCL INFO P2P Chunksize set to 131072
f17n01:970279:970498 [3] NCCL INFO Channel 00/0 : 81[3] -> 82[4] via P2P/IPC
f17n01:970279:970498 [3] NCCL INFO Channel 01/0 : 81[3] -> 82[4] via P2P/IPC
f17n01:970279:970498 [3] NCCL INFO Channel 02/0 : 81[3] -> 82[4] via P2P/IPC
f17n01:970279:970498 [3] NCCL INFO Channel 03/0 : 81[3] -> 82[4] via P2P/IPC
f17n01:970279:970498 [3] NCCL INFO Channel 01/0 : 72[0] -> 81[3] [receive] via NET/IB/3
f17n01:970279:970498 [3] NCCL INFO Channel 03/0 : 72[0] -> 81[3] [receive] via NET/IB/3
f17n01:970279:970498 [3] NCCL INFO Connected all rings
f17n01:970279:970498 [3] NCCL INFO Channel 01/0 : 81[3] -> 83[5] via P2P/IPC
f17n01:970279:970498 [3] NCCL INFO Channel 03/0 : 81[3] -> 83[5] via P2P/IPC
f17n01:970279:970498 [3] NCCL INFO Channel 03/0 : 81[3] -> 88[4] [send] via NET/IB/3
f17n01:970279:970498 [3] NCCL INFO Channel 03/0 : 88[4] -> 81[3] [receive] via NET/IB/3
f17n01:970279:970498 [3] NCCL INFO Channel 00/0 : 81[3] -> 80[2] via P2P/IPC
f17n01:970279:970498 [3] NCCL INFO Channel 02/0 : 81[3] -> 80[2] via P2P/IPC
f17n01:970279:970498 [3] NCCL INFO Connected all trees
f17n01:970279:970498 [3] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f17n01:970279:970498 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f17n01:970279:970498 [3] NCCL INFO comm 0x140ad3620 rank 81 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init COMPLETE
f16n17:1090959:1090959 [0] NCCL INFO cudaDriverVersion 12020
f16n17:1090959:1090959 [0] NCCL INFO Bootstrap : Using ib0:10.41.14.85<0>
f16n17:1090959:1090959 [0] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f16n17:1090959:1090959 [0] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f16n17:1090959:1091178 [0] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.85<0>
f16n17:1090959:1091178 [0] NCCL INFO Using network IB
f16n17:1090959:1091178 [0] NCCL INFO comm 0x1419d3470 rank 66 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init START
f16n17:1090959:1091178 [0] NCCL INFO Setting affinity for GPU 0 to 0f
f16n17:1090959:1091178 [0] NCCL INFO Trees [0] 67/-1/-1->66->60 [1] 68/-1/-1->66->67 [2] 67/54/-1->66->43 [3] 68/-1/-1->66->67
f16n17:1090959:1091178 [0] NCCL INFO P2P Chunksize set to 131072
f16n17:1090959:1091178 [0] NCCL INFO Channel 00/0 : 65[5] -> 66[0] [receive] via NET/IB/0
f16n17:1090959:1091178 [0] NCCL INFO Channel 02/0 : 65[5] -> 66[0] [receive] via NET/IB/0
f16n17:1090959:1091178 [0] NCCL INFO Channel 00/0 : 66[0] -> 67[1] via P2P/IPC
f16n17:1090959:1091178 [0] NCCL INFO Channel 02/0 : 66[0] -> 67[1] via P2P/IPC
f16n17:1090959:1091178 [0] NCCL INFO Channel 01/0 : 66[0] -> 75[3] [send] via NET/IB/2
f16n17:1090959:1091178 [0] NCCL INFO Channel 03/0 : 66[0] -> 75[3] [send] via NET/IB/2
f16n17:1090959:1091178 [0] NCCL INFO Connected all rings
f16n17:1090959:1091178 [0] NCCL INFO Channel 01/0 : 66[0] -> 67[1] via P2P/IPC
f16n17:1090959:1091178 [0] NCCL INFO Channel 03/0 : 66[0] -> 67[1] via P2P/IPC
f16n17:1090959:1091178 [0] NCCL INFO Channel 01/0 : 66[0] -> 68[2] via P2P/IPC
f16n17:1090959:1091178 [0] NCCL INFO Channel 03/0 : 66[0] -> 68[2] via P2P/IPC
f16n17:1090959:1091178 [0] NCCL INFO Channel 00/0 : 60[0] -> 66[0] [receive] via NET/IB/0
f16n17:1090959:1091178 [0] NCCL INFO Channel 02/0 : 54[0] -> 66[0] [receive] via NET/IB/0
f16n17:1090959:1091178 [0] NCCL INFO Channel 02/0 : 43[1] -> 66[0] [receive] via NET/IB/0
f16n17:1090959:1091178 [0] NCCL INFO Channel 02/0 : 66[0] -> 43[1] [send] via NET/IB/0
f16n17:1090959:1091178 [0] NCCL INFO Channel 02/0 : 66[0] -> 54[0] [send] via NET/IB/0
f16n17:1090959:1091178 [0] NCCL INFO Channel 00/0 : 66[0] -> 60[0] [send] via NET/IB/0
f16n17:1090959:1091178 [0] NCCL INFO Connected all trees
f16n17:1090959:1091178 [0] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f16n17:1090959:1091178 [0] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f16n17:1090959:1091178 [0] NCCL INFO comm 0x1419d3470 rank 66 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init COMPLETE
f17n01:970281:970281 [5] NCCL INFO cudaDriverVersion 12020
f17n01:970281:970281 [5] NCCL INFO Bootstrap : Using ib0:10.41.14.87<0>
f17n01:970281:970281 [5] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f17n01:970281:970281 [5] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f17n01:970281:970496 [5] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.87<0>
f17n01:970281:970496 [5] NCCL INFO Using network IB
f17n01:970281:970496 [5] NCCL INFO comm 0x13f9e3800 rank 83 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init START
f17n01:970281:970496 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
f17n01:970281:970496 [5] NCCL INFO Trees [0] -1/-1/-1->83->82 [1] 79/-1/-1->83->81 [2] -1/-1/-1->83->82 [3] 79/-1/-1->83->81
f17n01:970281:970496 [5] NCCL INFO P2P Chunksize set to 131072
f17n01:970281:970496 [5] NCCL INFO Channel 00/0 : 83[5] -> 84[0] [send] via NET/IB/1
f17n01:970281:970496 [5] NCCL INFO Channel 02/0 : 83[5] -> 84[0] [send] via NET/IB/1
f17n01:970281:970496 [5] NCCL INFO Channel 01/0 : 83[5] -> 80[2] via P2P/IPC
f17n01:970281:970496 [5] NCCL INFO Channel 03/0 : 83[5] -> 80[2] via P2P/IPC
f17n01:970281:970496 [5] NCCL INFO Connected all rings
f17n01:970281:970496 [5] NCCL INFO Channel 01/0 : 83[5] -> 79[1] via P2P/IPC
f17n01:970281:970496 [5] NCCL INFO Channel 03/0 : 83[5] -> 79[1] via P2P/IPC
f17n01:970281:970496 [5] NCCL INFO Channel 01/0 : 83[5] -> 81[3] via P2P/IPC
f17n01:970281:970496 [5] NCCL INFO Channel 03/0 : 83[5] -> 81[3] via P2P/IPC
f17n01:970281:970496 [5] NCCL INFO Channel 00/0 : 83[5] -> 82[4] via P2P/IPC
f17n01:970281:970496 [5] NCCL INFO Channel 02/0 : 83[5] -> 82[4] via P2P/IPC
f17n01:970281:970496 [5] NCCL INFO Connected all trees
f17n01:970281:970496 [5] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f17n01:970281:970496 [5] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f17n01:970281:970496 [5] NCCL INFO comm 0x13f9e3800 rank 83 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init COMPLETE
f16n17:1090962:1090962 [3] NCCL INFO cudaDriverVersion 12020
f16n17:1090962:1090962 [3] NCCL INFO Bootstrap : Using ib0:10.41.14.85<0>
f16n17:1090962:1090962 [3] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f16n17:1090962:1090962 [3] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f16n17:1090962:1091180 [3] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.85<0>
f16n17:1090962:1091180 [3] NCCL INFO Using network IB
f16n17:1090962:1091180 [3] NCCL INFO comm 0x136ec3660 rank 69 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init START
f16n17:1090962:1091180 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
f16n17:1090962:1091180 [3] NCCL INFO Trees [0] 70/-1/-1->69->68 [1] 71/-1/-1->69->70 [2] 70/-1/-1->69->68 [3] 71/82/-1->69->70
f16n17:1090962:1091180 [3] NCCL INFO P2P Chunksize set to 131072
f16n17:1090962:1091180 [3] NCCL INFO Channel 00/0 : 69[3] -> 70[4] via P2P/IPC
f16n17:1090962:1091180 [3] NCCL INFO Channel 01/0 : 69[3] -> 70[4] via P2P/IPC
f16n17:1090962:1091180 [3] NCCL INFO Channel 02/0 : 69[3] -> 70[4] via P2P/IPC
f16n17:1090962:1091180 [3] NCCL INFO Channel 03/0 : 69[3] -> 70[4] via P2P/IPC
f16n17:1090962:1091180 [3] NCCL INFO Channel 01/0 : 60[0] -> 69[3] [receive] via NET/IB/3
f16n17:1090962:1091180 [3] NCCL INFO Channel 03/0 : 60[0] -> 69[3] [receive] via NET/IB/3
f16n17:1090962:1091180 [3] NCCL INFO Connected all rings
f16n17:1090962:1091180 [3] NCCL INFO Channel 01/0 : 69[3] -> 71[5] via P2P/IPC
f16n17:1090962:1091180 [3] NCCL INFO Channel 03/0 : 69[3] -> 71[5] via P2P/IPC
f16n17:1090962:1091180 [3] NCCL INFO Channel 03/0 : 69[3] -> 82[4] [send] via NET/IB/3
f16n17:1090962:1091180 [3] NCCL INFO Channel 03/0 : 82[4] -> 69[3] [receive] via NET/IB/3
f16n17:1090962:1091180 [3] NCCL INFO Channel 00/0 : 69[3] -> 68[2] via P2P/IPC
f16n17:1090962:1091180 [3] NCCL INFO Channel 02/0 : 69[3] -> 68[2] via P2P/IPC
f16n17:1090962:1091180 [3] NCCL INFO Connected all trees
f16n17:1090962:1091180 [3] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f16n17:1090962:1091180 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f16n17:1090962:1091180 [3] NCCL INFO comm 0x136ec3660 rank 69 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init COMPLETE
f16n16:1079913:1079913 [1] NCCL INFO cudaDriverVersion 12020
f16n16:1079913:1079913 [1] NCCL INFO Bootstrap : Using ib0:10.41.14.84<0>
f16n16:1079913:1079913 [1] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f16n16:1079913:1079913 [1] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f16n16:1079913:1080131 [1] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.84<0>
f16n16:1079913:1080131 [1] NCCL INFO Using network IB
f16n16:1079913:1080131 [1] NCCL INFO comm 0x17b9e3520 rank 61 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init START
f16n16:1079913:1080131 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
f16n16:1079913:1080131 [1] NCCL INFO Trees [0] 62/54/-1->61->60 [1] 60/-1/-1->61->65 [2] 62/-1/-1->61->60 [3] 60/-1/-1->61->65
f16n16:1079913:1080131 [1] NCCL INFO P2P Chunksize set to 131072
f16n16:1079913:1080131 [1] NCCL INFO Channel 00/0 : 61[1] -> 62[2] via P2P/IPC
f16n16:1079913:1080131 [1] NCCL INFO Channel 02/0 : 61[1] -> 62[2] via P2P/IPC
f16n16:1079913:1080131 [1] NCCL INFO Channel 01/0 : 61[1] -> 60[0] via P2P/IPC
f16n16:1079913:1080131 [1] NCCL INFO Channel 03/0 : 61[1] -> 60[0] via P2P/IPC
f16n16:1079913:1080131 [1] NCCL INFO Connected all rings
f16n16:1079913:1080131 [1] NCCL INFO Channel 01/0 : 61[1] -> 65[5] via P2P/IPC
f16n16:1079913:1080131 [1] NCCL INFO Channel 03/0 : 61[1] -> 65[5] via P2P/IPC
f16n16:1079913:1080131 [1] NCCL INFO Channel 00/0 : 54[0] -> 61[1] [receive] via NET/IB/0
f16n16:1079913:1080131 [1] NCCL INFO Channel 00/0 : 61[1] -> 54[0] [send] via NET/IB/0
f16n16:1079913:1080131 [1] NCCL INFO Channel 00/0 : 61[1] -> 60[0] via P2P/IPC
f16n16:1079913:1080131 [1] NCCL INFO Channel 02/0 : 61[1] -> 60[0] via P2P/IPC
f16n16:1079913:1080131 [1] NCCL INFO Connected all trees
f16n16:1079913:1080131 [1] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f16n16:1079913:1080131 [1] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f16n16:1079913:1080131 [1] NCCL INFO comm 0x17b9e3520 rank 61 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init COMPLETE
d14n09:567667:567667 [1] NCCL INFO cudaDriverVersion 12020
d14n09:567667:567667 [1] NCCL INFO Bootstrap : Using ib0:10.41.9.10<0>
d14n09:567667:567667 [1] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d14n09:567667:567667 [1] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d14n09:567667:567893 [1] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.10<0>
d14n09:567667:567893 [1] NCCL INFO Using network IB
d14n09:567667:567893 [1] NCCL INFO comm 0x14d0e3c50 rank 31 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init START
d14n09:567667:567893 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d14n09:567667:567893 [1] NCCL INFO Trees [0] 32/-1/-1->31->30 [1] 30/-1/-1->31->35 [2] 32/36/-1->31->30 [3] 30/-1/-1->31->35
d14n09:567667:567893 [1] NCCL INFO P2P Chunksize set to 131072
d14n09:567667:567893 [1] NCCL INFO Channel 00/0 : 31[1] -> 32[2] via P2P/IPC
d14n09:567667:567893 [1] NCCL INFO Channel 02/0 : 31[1] -> 32[2] via P2P/IPC
d14n09:567667:567893 [1] NCCL INFO Channel 01/0 : 31[1] -> 30[0] via P2P/IPC
d14n09:567667:567893 [1] NCCL INFO Channel 03/0 : 31[1] -> 30[0] via P2P/IPC
d14n09:567667:567893 [1] NCCL INFO Connected all rings
d14n09:567667:567893 [1] NCCL INFO Channel 01/0 : 31[1] -> 35[5] via P2P/IPC
d14n09:567667:567893 [1] NCCL INFO Channel 03/0 : 31[1] -> 35[5] via P2P/IPC
d14n09:567667:567893 [1] NCCL INFO Channel 02/0 : 31[1] -> 36[0] [send] via NET/IB/0
d14n09:567667:567893 [1] NCCL INFO Channel 02/0 : 36[0] -> 31[1] [receive] via NET/IB/0
d14n09:567667:567893 [1] NCCL INFO Channel 00/0 : 31[1] -> 30[0] via P2P/IPC
d14n09:567667:567893 [1] NCCL INFO Channel 02/0 : 31[1] -> 30[0] via P2P/IPC
d14n09:567667:567893 [1] NCCL INFO Connected all trees
d14n09:567667:567893 [1] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d14n09:567667:567893 [1] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n09:567667:567893 [1] NCCL INFO comm 0x14d0e3c50 rank 31 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init COMPLETE
f16n17:1090963:1090963 [4] NCCL INFO cudaDriverVersion 12020
f16n17:1090963:1090963 [4] NCCL INFO Bootstrap : Using ib0:10.41.14.85<0>
f16n17:1090963:1090963 [4] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f16n17:1090963:1090963 [4] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f16n17:1090963:1091181 [4] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.85<0>
f16n17:1090963:1091181 [4] NCCL INFO Using network IB
f16n17:1090963:1091181 [4] NCCL INFO comm 0x13ab33a90 rank 70 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init START
f16n17:1090963:1091181 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
f16n17:1090963:1091181 [4] NCCL INFO Trees [0] 71/-1/-1->70->69 [1] 69/-1/-1->70->64 [2] 71/-1/-1->70->69 [3] 69/58/-1->70->45
f16n17:1090963:1091181 [4] NCCL INFO P2P Chunksize set to 131072
f16n17:1090963:1091181 [4] NCCL INFO Channel 00/0 : 70[4] -> 71[5] via P2P/IPC
f16n17:1090963:1091181 [4] NCCL INFO Channel 01/0 : 70[4] -> 71[5] via P2P/IPC
f16n17:1090963:1091181 [4] NCCL INFO Channel 02/0 : 70[4] -> 71[5] via P2P/IPC
f16n17:1090963:1091181 [4] NCCL INFO Channel 03/0 : 70[4] -> 71[5] via P2P/IPC
f16n17:1090963:1091181 [4] NCCL INFO Connected all rings
f16n17:1090963:1091181 [4] NCCL INFO Channel 01/0 : 64[4] -> 70[4] [receive] via NET/IB/3
f16n17:1090963:1091181 [4] NCCL INFO Channel 03/0 : 58[4] -> 70[4] [receive] via NET/IB/3
f16n17:1090963:1091181 [4] NCCL INFO Channel 03/0 : 45[3] -> 70[4] [receive] via NET/IB/3
f16n17:1090963:1091181 [4] NCCL INFO Channel 03/0 : 70[4] -> 45[3] [send] via NET/IB/3
f16n17:1090963:1091181 [4] NCCL INFO Channel 03/0 : 70[4] -> 58[4] [send] via NET/IB/3
f16n17:1090963:1091181 [4] NCCL INFO Channel 01/0 : 70[4] -> 64[4] [send] via NET/IB/3
f16n17:1090963:1091181 [4] NCCL INFO Channel 00/0 : 70[4] -> 69[3] via P2P/IPC
f16n17:1090963:1091181 [4] NCCL INFO Channel 01/0 : 70[4] -> 69[3] via P2P/IPC
f16n17:1090963:1091181 [4] NCCL INFO Channel 02/0 : 70[4] -> 69[3] via P2P/IPC
f16n17:1090963:1091181 [4] NCCL INFO Channel 03/0 : 70[4] -> 69[3] via P2P/IPC
f16n17:1090963:1091181 [4] NCCL INFO Connected all trees
f16n17:1090963:1091181 [4] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f16n17:1090963:1091181 [4] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f16n17:1090963:1091181 [4] NCCL INFO comm 0x13ab33a90 rank 70 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init COMPLETE
f16n17:1090964:1090964 [5] NCCL INFO cudaDriverVersion 12020
f16n17:1090964:1090964 [5] NCCL INFO Bootstrap : Using ib0:10.41.14.85<0>
f16n17:1090964:1090964 [5] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f16n17:1090964:1090964 [5] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f16n17:1090964:1091182 [5] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.85<0>
f16n17:1090964:1091182 [5] NCCL INFO Using network IB
f16n17:1090964:1091182 [5] NCCL INFO comm 0x16ce437c0 rank 71 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init START
f16n17:1090964:1091182 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
f16n17:1090964:1091182 [5] NCCL INFO Trees [0] -1/-1/-1->71->70 [1] 67/-1/-1->71->69 [2] -1/-1/-1->71->70 [3] 67/-1/-1->71->69
f16n17:1090964:1091182 [5] NCCL INFO P2P Chunksize set to 131072
f16n17:1090964:1091182 [5] NCCL INFO Channel 00/0 : 71[5] -> 72[0] [send] via NET/IB/1
f16n17:1090964:1091182 [5] NCCL INFO Channel 02/0 : 71[5] -> 72[0] [send] via NET/IB/1
f16n17:1090964:1091182 [5] NCCL INFO Channel 01/0 : 71[5] -> 68[2] via P2P/IPC
f16n17:1090964:1091182 [5] NCCL INFO Channel 03/0 : 71[5] -> 68[2] via P2P/IPC
f16n17:1090964:1091182 [5] NCCL INFO Connected all rings
f16n17:1090964:1091182 [5] NCCL INFO Channel 01/0 : 71[5] -> 67[1] via P2P/IPC
f16n17:1090964:1091182 [5] NCCL INFO Channel 03/0 : 71[5] -> 67[1] via P2P/IPC
f16n17:1090964:1091182 [5] NCCL INFO Channel 01/0 : 71[5] -> 69[3] via P2P/IPC
f16n17:1090964:1091182 [5] NCCL INFO Channel 03/0 : 71[5] -> 69[3] via P2P/IPC
f16n17:1090964:1091182 [5] NCCL INFO Channel 00/0 : 71[5] -> 70[4] via P2P/IPC
f16n17:1090964:1091182 [5] NCCL INFO Channel 02/0 : 71[5] -> 70[4] via P2P/IPC
f16n17:1090964:1091182 [5] NCCL INFO Connected all trees
f16n17:1090964:1091182 [5] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f16n17:1090964:1091182 [5] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f16n17:1090964:1091182 [5] NCCL INFO comm 0x16ce437c0 rank 71 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init COMPLETE
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=1, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=0, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=6, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_sization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=7, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
 > number of parameters on (tensor, pipeline) model parallel rank (6, 0): 840818688
amples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
 > number of parameters on (tensor, pipeline) model parallel rank (7, 0): 840818688
d14n11:1169357:1169357 [1] NCCL INFO cudaDriverVersion 12020
d14n11:1169357:1169357 [1] NCCL INFO Bootstrap : Using ib0:10.41.9.12<0>
d14n11:1169357:1169357 [1] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d14n11:1169357:1169357 [1] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d14n11:1169357:1169592 [1] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.12<0>
d14n11:1169357:1169592 [1] NCCL INFO Using network IB
d14n11:1169357:1169592 [1] NCCL INFO comm 0x12d523c30 rank 43 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init START
d14n11:1169357:1169592 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d14n11:1169357:1169592 [1] NCCL INFO Trees [0] 44/-1/-1->43->42 [1] 42/-1/-1->43->47 [2] 44/66/-1->43->42 [3] 42/-1/-1->43->47
d14n11:1169357:1169592 [1] NCCL INFO P2P Chunksize set to 131072
d14n11:1169357:1169592 [1] NCCL INFO Channel 00/0 : 43[1] -> 44[2] via P2P/IPC
d14n11:1169357:1169592 [1] NCCL INFO Channel 02/0 : 43[1] -> 44[2] via P2P/IPC
d14n11:1169357:1169592 [1] NCCL INFO Channel 01/0 : 43[1] -> 42[0] via P2P/IPC
d14n11:1169357:1169592 [1] NCCL INFO Channel 03/0 : 43[1] -> 42[0] via P2P/IPC
d14n11:1169357:1169592 [1] NCCL INFO Connected all rings
d14n11:1169357:1169592 [1] NCCL INFO Channel 01/0 : 43[1] -> 47[5] via P2P/IPC
d14n11:1169357:1169592 [1] NCCL INFO Channel 03/0 : 43[1] -> 47[5] via P2P/IPC
d14n11:1169357:1169592 [1] NCCL INFO Channel 02/0 : 43[1] -> 66[0] [send] via NET/IB/0
d14n11:1169357:1169592 [1] NCCL INFO Channel 02/0 : 66[0] -> 43[1] [receive] via NET/IB/0
d14n11:1169357:1169592 [1] NCCL INFO Channel 00/0 : 43[1] -> 42[0] via P2P/IPC
d14n11:1169357:1169592 [1] NCCL INFO Channel 02/0 : 43[1] -> 42[0] via P2P/IPC
d14n11:1169357:1169592 [1] NCCL INFO Connected all trees
d14n11:1169357:1169592 [1] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d14n11:1169357:1169592 [1] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n11:1169357:1169592 [1] NCCL INFO comm 0x12d523c30 rank 43 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init COMPLETE
f16n16:1079916:1079916 [4] NCCL INFO cudaDriverVersion 12020
f16n16:1079916:1079916 [4] NCCL INFO Bootstrap : Using ib0:10.41.14.84<0>
f16n16:1079916:1079916 [4] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f16n16:1079916:1079916 [4] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f16n16:1079916:1080135 [4] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.84<0>
f16n16:1079916:1080135 [4] NCCL INFO Using network IB
f16n16:1079916:1080135 [4] NCCL INFO comm 0x14f1338c0 rank 64 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init START
f16n16:1079916:1080135 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
f16n16:1079916:1080135 [4] NCCL INFO Trees [0] 65/-1/-1->64->63 [1] 63/70/-1->64->75 [2] 65/-1/-1->64->63 [3] 63/-1/-1->64->57
f16n16:1079916:1080135 [4] NCCL INFO P2P Chunksize set to 131072
f16n16:1079916:1080135 [4] NCCL INFO Channel 00/0 : 64[4] -> 65[5] via P2P/IPC
f16n16:1079916:1080135 [4] NCCL INFO Channel 01/0 : 64[4] -> 65[5] via P2P/IPC
f16n16:1079916:1080135 [4] NCCL INFO Channel 02/0 : 64[4] -> 65[5] via P2P/IPC
f16n16:1079916:1080135 [4] NCCL INFO Channel 03/0 : 64[4] -> 65[5] via P2P/IPC
f16n16:1079916:1080135 [4] NCCL INFO Connected all rings
f16n16:1079916:1080135 [4] NCCL INFO Channel 01/0 : 64[4] -> 70[4] [send] via NET/IB/3
f16n16:1079916:1080135 [4] NCCL INFO Channel 03/0 : 57[3] -> 64[4] [receive] via NET/IB/3
f16n16:1079916:1080135 [4] NCCL INFO Channel 01/0 : 64[4] -> 75[3] [send] via NET/IB/3
f16n16:1079916:1080135 [4] NCCL INFO Channel 01/0 : 75[3] -> 64[4] [receive] via NET/IB/3
f16n16:1079916:1080135 [4] NCCL INFO Channel 03/0 : 64[4] -> 57[3] [send] via NET/IB/3
f16n16:1079916:1080135 [4] NCCL INFO Channel 01/0 : 70[4] -> 64[4] [receive] via NET/IB/3
f16n16:1079916:1080135 [4] NCCL INFO Channel 00/0 : 64[4] -> 63[3] via P2P/IPC
f16n16:1079916:1080135 [4] NCCL INFO Channel 01/0 : 64[4] -> 63[3] via P2P/IPC
f16n16:1079916:1080135 [4] NCCL INFO Channel 02/0 : 64[4] -> 63[3] via P2P/IPC
f16n16:1079916:1080135 [4] NCCL INFO Channel 03/0 : 64[4] -> 63[3] via P2P/IPC
f16n16:1079916:1080135 [4] NCCL INFO Connected all trees
f16n16:1079916:1080135 [4] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f16n16:1079916:1080135 [4] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f16n16:1079916:1080135 [4] NCCL INFO comm 0x14f1338c0 rank 64 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init COMPLETE
f16n16:1079915:1079915 [3] NCCL INFO cudaDriverVersion 12020
f16n16:1079915:1079915 [3] NCCL INFO Bootstrap : Using ib0:10.41.14.84<0>
f16n16:1079915:1079915 [3] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f16n16:1079915:1079915 [3] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f16n16:1079915:1080134 [3] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.84<0>
f16n16:1079915:1080134 [3] NCCL INFO Using network IB
f16n16:1079915:1080134 [3] NCCL INFO comm 0x161193490 rank 63 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init START
f16n16:1079915:1080134 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
f16n16:1079915:1080134 [3] NCCL INFO Trees [0] 64/-1/-1->63->62 [1] 65/58/-1->63->64 [2] 64/-1/-1->63->62 [3] 65/-1/-1->63->64
f16n16:1079915:1080134 [3] NCCL INFO P2P Chunksize set to 131072
f16n16:1079915:1080134 [3] NCCL INFO Channel 00/0 : 63[3] -> 64[4] via P2P/IPC
f16n16:1079915:1080134 [3] NCCL INFO Channel 01/0 : 63[3] -> 64[4] via P2P/IPC
f16n16:1079915:1080134 [3] NCCL INFO Channel 02/0 : 63[3] -> 64[4] via P2P/IPC
f16n16:1079915:1080134 [3] NCCL INFO Channel 03/0 : 63[3] -> 64[4] via P2P/IPC
f16n16:1079915:1080134 [3] NCCL INFO Channel 01/0 : 54[0] -> 63[3] [receive] via NET/IB/3
f16n16:1079915:1080134 [3] NCCL INFO Channel 03/0 : 54[0] -> 63[3] [receive] via NET/IB/3
f16n16:1079915:1080134 [3] NCCL INFO Connected all rings
f16n16:1079915:1080134 [3] NCCL INFO Channel 01/0 : 63[3] -> 65[5] via P2P/IPC
f16n16:1079915:1080134 [3] NCCL INFO Channel 03/0 : 63[3] -> 65[5] via P2P/IPC
f16n16:1079915:1080134 [3] NCCL INFO Channel 01/0 : 58[4] -> 63[3] [receive] via NET/IB/3
f16n16:1079915:1080134 [3] NCCL INFO Channel 01/0 : 63[3] -> 58[4] [send] via NET/IB/3
f16n16:1079915:1080134 [3] NCCL INFO Channel 00/0 : 63[3] -> 62[2] via P2P/IPC
f16n16:1079915:1080134 [3] NCCL INFO Channel 02/0 : 63[3] -> 62[2] via P2P/IPC
f16n16:1079915:1080134 [3] NCCL INFO Connected all trees
f16n16:1079915:1080134 [3] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f16n16:1079915:1080134 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f16n16:1079915:1080134 [3] NCCL INFO comm 0x161193490 rank 63 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init COMPLETE
f16n16:1079914:1079914 [2] NCCL INFO cudaDriverVersion 12020
f16n16:1079914:1079914 [2] NCCL INFO Bootstrap : Using ib0:10.41.14.84<0>
f16n16:1079914:1079914 [2] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f16n16:1079914:1079914 [2] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f16n16:1079914:1080130 [2] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.84<0>
f16n16:1079914:1080130 [2] NCCL INFO Using network IB
f16n16:1079914:1080130 [2] NCCL INFO comm 0x160b538f0 rank 62 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init START
f16n16:1079914:1080130 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
f16n16:1079914:1080130 [2] NCCL INFO Trees [0] 63/-1/-1->62->61 [1] -1/-1/-1->62->60 [2] 63/-1/-1->62->61 [3] -1/-1/-1->62->60
f16n16:1079914:1080130 [2] NCCL INFO P2P Chunksize set to 131072
f16n16:1079914:1080130 [2] NCCL INFO Channel 00/0 : 62[2] -> 63[3] via P2P/IPC
f16n16:1079914:1080130 [2] NCCL INFO Channel 02/0 : 62[2] -> 63[3] via P2P/IPC
f16n16:1079914:1080130 [2] NCCL INFO Channel 01/0 : 62[2] -> 61[1] via P2P/IPC
f16n16:1079914:1080130 [2] NCCL INFO Channel 03/0 : 62[2] -> 61[1] via P2P/IPC
f16n16:1079914:1080130 [2] NCCL INFO Connected all rings
f16n16:1079914:1080130 [2] NCCL INFO Channel 01/0 : 62[2] -> 60[0] via P2P/IPC
f16n16:1079914:1080130 [2] NCCL INFO Channel 03/0 : 62[2] -> 60[0] via P2P/IPC
f16n16:1079914:1080130 [2] NCCL INFO Channel 00/0 : 62[2] -> 61[1] via P2P/IPC
f16n16:1079914:1080130 [2] NCCL INFO Channel 02/0 : 62[2] -> 61[1] via P2P/IPC
f16n16:1079914:1080130 [2] NCCL INFO Connected all trees
f16n16:1079914:1080130 [2] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f16n16:1079914:1080130 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f16n16:1079914:1080130 [2] NCCL INFO comm 0x160b538f0 rank 62 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init COMPLETE
f16n16:1079917:1079917 [5] NCCL INFO cudaDriverVersion 12020
f16n16:1079917:1079917 [5] NCCL INFO Bootstrap : Using ib0:10.41.14.84<0>
f16n16:1079917:1079917 [5] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
f16n16:1079917:1079917 [5] NCCL INFO NET/Plugin : No plugin found, using internal implementation
f16n16:1079917:1080133 [5] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.14.84<0>
f16n16:1079917:1080133 [5] NCCL INFO Using network IB
f16n16:1079917:1080133 [5] NCCL INFO comm 0x16e0036c0 rank 65 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init START
f16n16:1079917:1080133 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
f16n16:1079917:1080133 [5] NCCL INFO Trees [0] -1/-1/-1->65->64 [1] 61/-1/-1->65->63 [2] -1/-1/-1->65->64 [3] 61/-1/-1->65->63
f16n16:1079917:1080133 [5] NCCL INFO P2P Chunksize set to 131072
f16n16:1079917:1080133 [5] NCCL INFO Channel 00/0 : 65[5] -> 66[0] [send] via NET/IB/1
f16n16:1079917:1080133 [5] NCCL INFO Channel 02/0 : 65[5] -> 66[0] [send] via NET/IB/1
f16n16:1079917:1080133 [5] NCCL INFO Channel 01/0 : 65[5] -> 62[2] via P2P/IPC
f16n16:1079917:1080133 [5] NCCL INFO Channel 03/0 : 65[5] -> 62[2] via P2P/IPC
f16n16:1079917:1080133 [5] NCCL INFO Connected all rings
f16n16:1079917:1080133 [5] NCCL INFO Channel 01/0 : 65[5] -> 61[1] via P2P/IPC
f16n16:1079917:1080133 [5] NCCL INFO Channel 03/0 : 65[5] -> 61[1] via P2P/IPC
f16n16:1079917:1080133 [5] NCCL INFO Channel 01/0 : 65[5] -> 63[3] via P2P/IPC
f16n16:1079917:1080133 [5] NCCL INFO Channel 03/0 : 65[5] -> 63[3] via P2P/IPC
f16n16:1079917:1080133 [5] NCCL INFO Channel 00/0 : 65[5] -> 64[4] via P2P/IPC
f16n16:1079917:1080133 [5] NCCL INFO Channel 02/0 : 65[5] -> 64[4] via P2P/IPC
f16n16:1079917:1080133 [5] NCCL INFO Connected all trees
f16n16:1079917:1080133 [5] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
f16n16:1079917:1080133 [5] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f16n16:1079917:1080133 [5] NCCL INFO comm 0x16e0036c0 rank 65 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init COMPLETE
d14n11:1169358:1169358 [2] NCCL INFO cudaDriverVersion 12020
d14n11:1169358:1169358 [2] NCCL INFO Bootstrap : Using ib0:10.41.9.12<0>
d14n11:1169358:1169358 [2] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d14n11:1169358:1169358 [2] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d14n11:1169358:1169590 [2] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.12<0>
d14n11:1169358:1169590 [2] NCCL INFO Using network IB
d14n11:1169358:1169590 [2] NCCL INFO comm 0x13ef93c10 rank 44 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init START
d14n11:1169358:1169590 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d14n11:1169358:1169590 [2] NCCL INFO Trees [0] 45/-1/-1->44->43 [1] -1/-1/-1->44->42 [2] 45/-1/-1->44->43 [3] -1/-1/-1->44->42
d14n11:1169358:1169590 [2] NCCL INFO P2P Chunksize set to 131072
d14n11:1169358:1169590 [2] NCCL INFO Channel 00/0 : 44[2] -> 45[3] via P2P/IPC
d14n11:1169358:1169590 [2] NCCL INFO Channel 02/0 : 44[2] -> 45[3] via P2P/IPC
d14n11:1169358:1169590 [2] NCCL INFO Channel 01/0 : 44[2] -> 43[1] via P2P/IPC
d14n11:1169358:1169590 [2] NCCL INFO Channel 03/0 : 44[2] -> 43[1] via P2P/IPC
d14n11:1169358:1169590 [2] NCCL INFO Connected all rings
d14n11:1169358:1169590 [2] NCCL INFO Channel 01/0 : 44[2] -> 42[0] via P2P/IPC
d14n11:1169358:1169590 [2] NCCL INFO Channel 03/0 : 44[2] -> 42[0] via P2P/IPC
d14n11:1169358:1169590 [2] NCCL INFO Channel 00/0 : 44[2] -> 43[1] via P2P/IPC
d14n11:1169358:1169590 [2] NCCL INFO Channel 02/0 : 44[2] -> 43[1] via P2P/IPC
d14n11:1169358:1169590 [2] NCCL INFO Connected all trees
d14n11:1169358:1169590 [2] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d14n11:1169358:1169590 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n11:1169358:1169590 [2] NCCL INFO comm 0x13ef93c10 rank 44 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init COMPLETE
d14n11:1169361:1169361 [5] NCCL INFO cudaDriverVersion 12020
d14n11:1169361:1169361 [5] NCCL INFO Bootstrap : Using ib0:10.41.9.12<0>
d14n11:1169361:1169361 [5] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d14n11:1169361:1169361 [5] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d14n11:1169361:1169588 [5] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.12<0>
d14n11:1169361:1169588 [5] NCCL INFO Using network IB
d14n11:1169361:1169588 [5] NCCL INFO comm 0x121512fe0 rank 47 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init START
d14n11:1169361:1169588 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d14n11:1169361:1169588 [5] NCCL INFO Trees [0] -1/-1/-1->47->46 [1] 43/-1/-1->47->45 [2] -1/-1/-1->47->46 [3] 43/-1/-1->47->45
d14n11:1169361:1169588 [5] NCCL INFO P2P Chunksize set to 131072
d14n11:1169361:1169588 [5] NCCL INFO Channel 00/0 : 47[5] -> 48[0] [send] via NET/IB/1
d14n11:1169361:1169588 [5] NCCL INFO Channel 02/0 : 47[5] -> 48[0] [send] via NET/IB/1
d14n11:1169361:1169588 [5] NCCL INFO Channel 01/0 : 47[5] -> 44[2] via P2P/IPC
d14n11:1169361:1169588 [5] NCCL INFO Channel 03/0 : 47[5] -> 44[2] via P2P/IPC
d14n11:1169361:1169588 [5] NCCL INFO Connected all rings
d14n11:1169361:1169588 [5] NCCL INFO Channel 01/0 : 47[5] -> 43[1] via P2P/IPC
d14n11:1169361:1169588 [5] NCCL INFO Channel 03/0 : 47[5] -> 43[1] via P2P/IPC
d14n11:1169361:1169588 [5] NCCL INFO Channel 01/0 : 47[5] -> 45[3] via P2P/IPC
d14n11:1169361:1169588 [5] NCCL INFO Channel 03/0 : 47[5] -> 45[3] via P2P/IPC
d14n11:1169361:1169588 [5] NCCL INFO Channel 00/0 : 47[5] -> 46[4] via P2P/IPC
d14n11:1169361:1169588 [5] NCCL INFO Channel 02/0 : 47[5] -> 46[4] via P2P/IPC
d14n11:1169361:1169588 [5] NCCL INFO Connected all trees
d14n11:1169361:1169588 [5] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d14n11:1169361:1169588 [5] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n11:1169361:1169588 [5] NCCL INFO comm 0x121512fe0 rank 47 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init COMPLETE
d14n08:1173248:1173248 [1] NCCL INFO cudaDriverVersion 12020
d14n08:1173248:1173248 [1] NCCL INFO Bootstrap : Using ib0:10.41.9.9<0>
d14n08:1173248:1173248 [1] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d14n08:1173248:1173248 [1] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d14n08:1173248:1173484 [1] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.9<0>
d14n08:1173248:1173484 [1] NCCL INFO Using network IB
d14n08:1173248:1173484 [1] NCCL INFO comm 0x136793950 rank 25 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init START
d14n08:1173248:1173484 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d14n08:1173248:1173484 [1] NCCL INFO Trees [0] 26/12/-1->25->24 [1] 24/-1/-1->25->29 [2] 26/-1/-1->25->24 [3] 24/-1/-1->25->29
d14n08:1173248:1173484 [1] NCCL INFO P2P Chunksize set to 131072
d14n08:1173248:1173484 [1] NCCL INFO Channel 00/0 : 25[1] -> 26[2] via P2P/IPC
d14n08:1173248:1173484 [1] NCCL INFO Channel 02/0 : 25[1] -> 26[2] via P2P/IPC
d14n08:1173248:1173484 [1] NCCL INFO Channel 01/0 : 25[1] -> 24[0] via P2P/IPC
d14n08:1173248:1173484 [1] NCCL INFO Channel 03/0 : 25[1] -> 24[0] via P2P/IPC
d14n08:1173248:1173484 [1] NCCL INFO Connected all rings
d14n08:1173248:1173484 [1] NCCL INFO Channel 01/0 : 25[1] -> 29[5] via P2P/IPC
d14n08:1173248:1173484 [1] NCCL INFO Channel 03/0 : 25[1] -> 29[5] via P2P/IPC
d14n08:1173248:1173484 [1] NCCL INFO Channel 00/0 : 12[0] -> 25[1] [receive] via NET/IB/0
d14n08:1173248:1173484 [1] NCCL INFO Channel 00/0 : 25[1] -> 12[0] [send] via NET/IB/0
d14n08:1173248:1173484 [1] NCCL INFO Channel 00/0 : 25[1] -> 24[0] via P2P/IPC
d14n08:1173248:1173484 [1] NCCL INFO Channel 02/0 : 25[1] -> 24[0] via P2P/IPC
d14n08:1173248:1173484 [1] NCCL INFO Connected all trees
d14n08:1173248:1173484 [1] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d14n08:1173248:1173484 [1] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n08:1173248:1173484 [1] NCCL INFO comm 0x136793950 rank 25 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init COMPLETE
d14n11:1169359:1169359 [3] NCCL INFO cudaDriverVersion 12020
d14n11:1169359:1169359 [3] NCCL INFO Bootstrap : Using ib0:10.41.9.12<0>
d14n11:1169359:1169359 [3] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d14n11:1169359:1169359 [3] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d14n11:1169359:1169593 [3] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.12<0>
d14n11:1169359:1169593 [3] NCCL INFO Using network IB
d14n11:1169359:1169593 [3] NCCL INFO comm 0x1657b3ed0 rank 45 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init START
d14n11:1169359:1169593 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d14n11:1169359:1169593 [3] NCCL INFO Trees [0] 46/-1/-1->45->44 [1] 47/-1/-1->45->46 [2] 46/-1/-1->45->44 [3] 47/70/-1->45->46
d14n11:1169359:1169593 [3] NCCL INFO P2P Chunksize set to 131072
d14n11:1169359:1169593 [3] NCCL INFO Channel 00/0 : 45[3] -> 46[4] via P2P/IPC
d14n11:1169359:1169593 [3] NCCL INFO Channel 01/0 : 45[3] -> 46[4] via P2P/IPC
d14n11:1169359:1169593 [3] NCCL INFO Channel 02/0 : 45[3] -> 46[4] via P2P/IPC
d14n11:1169359:1169593 [3] NCCL INFO Channel 03/0 : 45[3] -> 46[4] via P2P/IPC
d14n11:1169359:1169593 [3] NCCL INFO Channel 01/0 : 36[0] -> 45[3] [receive] via NET/IB/3
d14n11:1169359:1169593 [3] NCCL INFO Channel 03/0 : 36[0] -> 45[3] [receive] via NET/IB/3
d14n11:1169359:1169593 [3] NCCL INFO Connected all rings
d14n11:1169359:1169593 [3] NCCL INFO Channel 01/0 : 45[3] -> 47[5] via P2P/IPC
d14n11:1169359:1169593 [3] NCCL INFO Channel 03/0 : 45[3] -> 47[5] via P2P/IPC
d14n11:1169359:1169593 [3] NCCL INFO Channel 03/0 : 45[3] -> 70[4] [send] via NET/IB/3
d14n11:1169359:1169593 [3] NCCL INFO Channel 03/0 : 70[4] -> 45[3] [receive] via NET/IB/3
d14n11:1169359:1169593 [3] NCCL INFO Channel 00/0 : 45[3] -> 44[2] via P2P/IPC
d14n11:1169359:1169593 [3] NCCL INFO Channel 02/0 : 45[3] -> 44[2] via P2P/IPC
d14n11:1169359:1169593 [3] NCCL INFO Connected all trees
d14n11:1169359:1169593 [3] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d14n11:1169359:1169593 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n11:1169359:1169593 [3] NCCL INFO comm 0x1657b3ed0 rank 45 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init COMPLETE
d14n11:1169360:1169360 [4] NCCL INFO cudaDriverVersion 12020
d14n11:1169360:1169360 [4] NCCL INFO Bootstrap : Using ib0:10.41.9.12<0>
d14n11:1169360:1169360 [4] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d14n11:1169360:1169360 [4] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d14n11:1169360:1169591 [4] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.12<0>
d14n11:1169360:1169591 [4] NCCL INFO Using network IB
d14n11:1169360:1169591 [4] NCCL INFO comm 0x1147f37b0 rank 46 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init START
d14n11:1169360:1169591 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d14n11:1169360:1169591 [4] NCCL INFO Trees [0] 47/-1/-1->46->45 [1] 45/-1/-1->46->40 [2] 47/-1/-1->46->45 [3] 45/22/-1->46->94
d14n11:1169360:1169591 [4] NCCL INFO P2P Chunksize set to 131072
d14n11:1169360:1169591 [4] NCCL INFO Channel 00/0 : 46[4] -> 47[5] via P2P/IPC
d14n11:1169360:1169591 [4] NCCL INFO Channel 01/0 : 46[4] -> 47[5] via P2P/IPC
d14n11:1169360:1169591 [4] NCCL INFO Channel 02/0 : 46[4] -> 47[5] via P2P/IPC
d14n11:1169360:1169591 [4] NCCL INFO Channel 03/0 : 46[4] -> 47[5] via P2P/IPC
d14n11:1169360:1169591 [4] NCCL INFO Connected all rings
d14n11:1169360:1169591 [4] NCCL INFO Channel 01/0 : 40[4] -> 46[4] [receive] via NET/IB/3
d14n11:1169360:1169591 [4] NCCL INFO Channel 03/0 : 22[4] -> 46[4] [receive] via NET/IB/3
d14n11:1169360:1169591 [4] NCCL INFO Channel 03/0 : 94[4] -> 46[4] [receive] via NET/IB/3
d14n11:1169360:1169591 [4] NCCL INFO Channel 03/0 : 46[4] -> 94[4] [send] via NET/IB/3
d14n11:1169360:1169591 [4] NCCL INFO Channel 03/0 : 46[4] -> 22[4] [send] via NET/IB/3
d14n11:1169360:1169591 [4] NCCL INFO Channel 01/0 : 46[4] -> 40[4] [send] via NET/IB/3
d14n11:1169360:1169591 [4] NCCL INFO Channel 00/0 : 46[4] -> 45[3] via P2P/IPC
d14n11:1169360:1169591 [4] NCCL INFO Channel 01/0 : 46[4] -> 45[3] via P2P/IPC
d14n11:1169360:1169591 [4] NCCL INFO Channel 02/0 : 46[4] -> 45[3] via P2P/IPC
d14n11:1169360:1169591 [4] NCCL INFO Channel 03/0 : 46[4] -> 45[3] via P2P/IPC
d14n11:1169360:1169591 [4] NCCL INFO Connected all trees
d14n11:1169360:1169591 [4] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d14n11:1169360:1169591 [4] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n11:1169360:1169591 [4] NCCL INFO comm 0x1147f37b0 rank 46 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init COMPLETE
d14n08:1173249:1173249 [2] NCCL INFO cudaDriverVersion 12020
d14n08:1173249:1173249 [2] NCCL INFO Bootstrap : Using ib0:10.41.9.9<0>
d14n08:1173249:1173249 [2] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d14n08:1173249:1173249 [2] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d14n08:1173249:1173482 [2] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.9<0>
d14n08:1173249:1173482 [2] NCCL INFO Using network IB
d14n08:1173249:1173482 [2] NCCL INFO comm 0x14eb83990 rank 26 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init START
d14n08:1173249:1173482 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d14n08:1173249:1173482 [2] NCCL INFO Trees [0] 27/-1/-1->26->25 [1] -1/-1/-1->26->24 [2] 27/-1/-1->26->25 [3] -1/-1/-1->26->24
d14n08:1173249:1173482 [2] NCCL INFO P2P Chunksize set to 131072
d14n08:1173249:1173482 [2] NCCL INFO Channel 00/0 : 26[2] -> 27[3] via P2P/IPC
d14n08:1173249:1173482 [2] NCCL INFO Channel 02/0 : 26[2] -> 27[3] via P2P/IPC
d14n08:1173249:1173482 [2] NCCL INFO Channel 01/0 : 26[2] -> 25[1] via P2P/IPC
d14n08:1173249:1173482 [2] NCCL INFO Channel 03/0 : 26[2] -> 25[1] via P2P/IPC
d14n08:1173249:1173482 [2] NCCL INFO Connected all rings
d14n08:1173249:1173482 [2] NCCL INFO Channel 01/0 : 26[2] -> 24[0] via P2P/IPC
d14n08:1173249:1173482 [2] NCCL INFO Channel 03/0 : 26[2] -> 24[0] via P2P/IPC
d14n08:1173249:1173482 [2] NCCL INFO Channel 00/0 : 26[2] -> 25[1] via P2P/IPC
d14n08:1173249:1173482 [2] NCCL INFO Channel 02/0 : 26[2] -> 25[1] via P2P/IPC
d14n08:1173249:1173482 [2] NCCL INFO Connected all trees
d14n08:1173249:1173482 [2] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d14n08:1173249:1173482 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n08:1173249:1173482 [2] NCCL INFO comm 0x14eb83990 rank 26 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init COMPLETE
d14n08:1173247:1173247 [0] NCCL INFO cudaDriverVersion 12020
d14n08:1173247:1173247 [0] NCCL INFO Bootstrap : Using ib0:10.41.9.9<0>
d14n08:1173247:1173247 [0] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d14n08:1173247:1173247 [0] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d14n08:1173247:1173483 [0] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.9<0>
d14n08:1173247:1173483 [0] NCCL INFO Using network IB
d14n08:1173247:1173483 [0] NCCL INFO comm 0x133b73730 rank 24 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init START
d14n08:1173247:1173483 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d14n08:1173247:1173483 [0] NCCL INFO Trees [0] 25/36/-1->24->49 [1] 26/-1/-1->24->25 [2] 25/-1/-1->24->30 [3] 26/-1/-1->24->25
d14n08:1173247:1173483 [0] NCCL INFO P2P Chunksize set to 131072
d14n08:1173247:1173483 [0] NCCL INFO Channel 00/0 : 23[5] -> 24[0] [receive] via NET/IB/0
d14n08:1173247:1173483 [0] NCCL INFO Channel 02/0 : 23[5] -> 24[0] [receive] via NET/IB/0
d14n08:1173247:1173483 [0] NCCL INFO Channel 00/0 : 24[0] -> 25[1] via P2P/IPC
d14n08:1173247:1173483 [0] NCCL INFO Channel 02/0 : 24[0] -> 25[1] via P2P/IPC
d14n08:1173247:1173483 [0] NCCL INFO Channel 01/0 : 24[0] -> 33[3] [send] via NET/IB/2
d14n08:1173247:1173483 [0] NCCL INFO Channel 03/0 : 24[0] -> 33[3] [send] via NET/IB/2
d14n08:1173247:1173483 [0] NCCL INFO Connected all rings
d14n08:1173247:1173483 [0] NCCL INFO Channel 01/0 : 24[0] -> 25[1] via P2P/IPC
d14n08:1173247:1173483 [0] NCCL INFO Channel 03/0 : 24[0] -> 25[1] via P2P/IPC
d14n08:1173247:1173483 [0] NCCL INFO Channel 01/0 : 24[0] -> 26[2] via P2P/IPC
d14n08:1173247:1173483 [0] NCCL INFO Channel 03/0 : 24[0] -> 26[2] via P2P/IPC
d14n08:1173247:1173483 [0] NCCL INFO Channel 02/0 : 24[0] -> 30[0] [send] via NET/IB/0
d14n08:1173247:1173483 [0] NCCL INFO Channel 00/0 : 24[0] -> 36[0] [send] via NET/IB/0
d14n08:1173247:1173483 [0] NCCL INFO Channel 00/0 : 24[0] -> 49[1] [send] via NET/IB/0
d14n08:1173247:1173483 [0] NCCL INFO Channel 00/0 : 49[1] -> 24[0] [receive] via NET/IB/0
d14n08:1173247:1173483 [0] NCCL INFO Channel 00/0 : 36[0] -> 24[0] [receive] via NET/IB/0
d14n08:1173247:1173483 [0] NCCL INFO Channel 02/0 : 30[0] -> 24[0] [receive] via NET/IB/0
d14n08:1173247:1173483 [0] NCCL INFO Connected all trees
d14n08:1173247:1173483 [0] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d14n08:1173247:1173483 [0] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n08:1173247:1173483 [0] NCCL INFO comm 0x133b73730 rank 24 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init COMPLETE
d11n17:1142856:1142856 [2] NCCL INFO cudaDriverVersion 12020
d11n17:1142856:1142856 [2] NCCL INFO Bootstrap : Using ib0:10.41.8.217<0>
d11n17:1142856:1142856 [2] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d11n17:1142856:1142856 [2] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d11n17:1142856:1143078 [2] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.8.217<0>
d11n17:1142856:1143078 [2] NCCL INFO Using network IB
d11n17:1142856:1143078 [2] NCCL INFO comm 0x1389539b0 rank 20 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init START
d11n17:1142856:1143078 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d11n17:1142856:1143078 [2] NCCL INFO Trees [0] 21/-1/-1->20->19 [1] -1/-1/-1->20->18 [2] 21/-1/-1->20->19 [3] -1/-1/-1->20->18
d11n17:1142856:1143078 [2] NCCL INFO P2P Chunksize set to 131072
d11n17:1142856:1143078 [2] NCCL INFO Channel 00/0 : 20[2] -> 21[3] via P2P/IPC
d11n17:1142856:1143078 [2] NCCL INFO Channel 02/0 : 20[2] -> 21[3] via P2P/IPC
d11n17:1142856:1143078 [2] NCCL INFO Channel 01/0 : 20[2] -> 19[1] via P2P/IPC
d11n17:1142856:1143078 [2] NCCL INFO Channel 03/0 : 20[2] -> 19[1] via P2P/IPC
d11n17:1142856:1143078 [2] NCCL INFO Connected all rings
d11n17:1142856:1143078 [2] NCCL INFO Channel 01/0 : 20[2] -> 18[0] via P2P/IPC
d11n17:1142856:1143078 [2] NCCL INFO Channel 03/0 : 20[2] -> 18[0] via P2P/IPC
d11n17:1142856:1143078 [2] NCCL INFO Channel 00/0 : 20[2] -> 19[1] via P2P/IPC
d11n17:1142856:1143078 [2] NCCL INFO Channel 02/0 : 20[2] -> 19[1] via P2P/IPC
d11n17:1142856:1143078 [2] NCCL INFO Connected all trees
d11n17:1142856:1143078 [2] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d11n17:1142856:1143078 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d11n17:1142856:1143078 [2] NCCL INFO comm 0x1389539b0 rank 20 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init COMPLETE
d09n08:1073956:1073956 [2] NCCL INFO cudaDriverVersion 12020
d09n08:1073956:1073956 [2] NCCL INFO Bootstrap : Using ib0:10.41.8.172<0>
d09n08:1073956:1073956 [2] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d09n08:1073956:1073956 [2] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d09n08:1073956:1074180 [2] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.8.172<0>
d09n08:1073956:1074180 [2] NCCL INFO Using network IB
d09n08:1073956:1074180 [2] NCCL INFO comm 0x15b693b50 rank 8 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init START
d09n08:1073956:1074180 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d09n08:1073956:1074180 [2] NCCL INFO Trees [0] 9/-1/-1->8->7 [1] -1/-1/-1->8->6 [2] 9/-1/-1->8->7 [3] -1/-1/-1->8->6
d09n08:1073956:1074180 [2] NCCL INFO P2P Chunksize set to 131072
d09n08:1073956:1074180 [2] NCCL INFO Channel 00/0 : 8[2] -> 9[3] via P2P/IPC
d09n08:1073956:1074180 [2] NCCL INFO Channel 02/0 : 8[2] -> 9[3] via P2P/IPC
d09n08:1073956:1074180 [2] NCCL INFO Channel 01/0 : 8[2] -> 7[1] via P2P/IPC
d09n08:1073956:1074180 [2] NCCL INFO Channel 03/0 : 8[2] -> 7[1] via P2P/IPC
d09n08:1073956:1074180 [2] NCCL INFO Connected all rings
d09n08:1073956:1074180 [2] NCCL INFO Channel 01/0 : 8[2] -> 6[0] via P2P/IPC
d09n08:1073956:1074180 [2] NCCL INFO Channel 03/0 : 8[2] -> 6[0] via P2P/IPC
d09n08:1073956:1074180 [2] NCCL INFO Channel 00/0 : 8[2] -> 7[1] via P2P/IPC
d09n08:1073956:1074180 [2] NCCL INFO Channel 02/0 : 8[2] -> 7[1] via P2P/IPC
d09n08:1073956:1074180 [2] NCCL INFO Connected all trees
d09n08:1073956:1074180 [2] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d09n08:1073956:1074180 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d09n08:1073956:1074180 [2] NCCL INFO comm 0x15b693b50 rank 8 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init COMPLETE
d14n08:1173252:1173252 [5] NCCL INFO cudaDriverVersion 12020
d14n08:1173252:1173252 [5] NCCL INFO Bootstrap : Using ib0:10.41.9.9<0>
d14n08:1173252:1173252 [5] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d14n08:1173252:1173252 [5] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d14n08:1173252:1173481 [5] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.9<0>
d14n08:1173252:1173481 [5] NCCL INFO Using network IB
d14n08:1173252:1173481 [5] NCCL INFO comm 0x1303539c0 rank 29 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init START
d14n08:1173252:1173481 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d14n08:1173252:1173481 [5] NCCL INFO Trees [0] -1/-1/-1->29->28 [1] 25/-1/-1->29->27 [2] -1/-1/-1->29->28 [3] 25/-1/-1->29->27
d14n08:1173252:1173481 [5] NCCL INFO P2P Chunksize set to 131072
d14n08:1173252:1173481 [5] NCCL INFO Channel 00/0 : 29[5] -> 30[0] [send] via NET/IB/1
d14n08:1173252:1173481 [5] NCCL INFO Channel 02/0 : 29[5] -> 30[0] [send] via NET/IB/1
d14n08:1173252:1173481 [5] NCCL INFO Channel 01/0 : 29[5] -> 26[2] via P2P/IPC
d14n08:1173252:1173481 [5] NCCL INFO Channel 03/0 : 29[5] -> 26[2] via P2P/IPC
d14n08:1173252:1173481 [5] NCCL INFO Connected all rings
d14n08:1173252:1173481 [5] NCCL INFO Channel 01/0 : 29[5] -> 25[1] via P2P/IPC
d14n08:1173252:1173481 [5] NCCL INFO Channel 03/0 : 29[5] -> 25[1] via P2P/IPC
d14n08:1173252:1173481 [5] NCCL INFO Channel 01/0 : 29[5] -> 27[3] via P2P/IPC
d14n08:1173252:1173481 [5] NCCL INFO Channel 03/0 : 29[5] -> 27[3] via P2P/IPC
d14n08:1173252:1173481 [5] NCCL INFO Channel 00/0 : 29[5] -> 28[4] via P2P/IPC
d14n08:1173252:1173481 [5] NCCL INFO Channel 02/0 : 29[5] -> 28[4] via P2P/IPC
d14n08:1173252:1173481 [5] NCCL INFO Connected all trees
d14n08:1173252:1173481 [5] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d14n08:1173252:1173481 [5] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n08:1173252:1173481 [5] NCCL INFO comm 0x1303539c0 rank 29 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init COMPLETE
d11n17:1142855:1142855 [1] NCCL INFO cudaDriverVersion 12020
d11n17:1142855:1142855 [1] NCCL INFO Bootstrap : Using ib0:10.41.8.217<0>
d11n17:1142855:1142855 [1] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d11n17:1142855:1142855 [1] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d11n17:1142855:1143073 [1] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.8.217<0>
d11n17:1142855:1143073 [1] NCCL INFO Using network IB
d11n17:1142855:1143073 [1] NCCL INFO comm 0x12c6b3260 rank 19 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init START
d11n17:1142855:1143073 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d11n17:1142855:1143073 [1] NCCL INFO Trees [0] 20/-1/-1->19->18 [1] 18/-1/-1->19->23 [2] 20/30/-1->19->18 [3] 18/-1/-1->19->23
d11n17:1142855:1143073 [1] NCCL INFO P2P Chunksize set to 131072
d11n17:1142855:1143073 [1] NCCL INFO Channel 00/0 : 19[1] -> 20[2] via P2P/IPC
d11n17:1142855:1143073 [1] NCCL INFO Channel 02/0 : 19[1] -> 20[2] via P2P/IPC
d11n17:1142855:1143073 [1] NCCL INFO Channel 01/0 : 19[1] -> 18[0] via P2P/IPC
d11n17:1142855:1143073 [1] NCCL INFO Channel 03/0 : 19[1] -> 18[0] via P2P/IPC
d11n17:1142855:1143073 [1] NCCL INFO Connected all rings
d11n17:1142855:1143073 [1] NCCL INFO Channel 01/0 : 19[1] -> 23[5] via P2P/IPC
d11n17:1142855:1143073 [1] NCCL INFO Channel 03/0 : 19[1] -> 23[5] via P2P/IPC
d11n17:1142855:1143073 [1] NCCL INFO Channel 02/0 : 19[1] -> 30[0] [send] via NET/IB/0
d11n17:1142855:1143073 [1] NCCL INFO Channel 02/0 : 30[0] -> 19[1] [receive] via NET/IB/0
d11n17:1142855:1143073 [1] NCCL INFO Channel 00/0 : 19[1] -> 18[0] via P2P/IPC
d11n17:1142855:1143073 [1] NCCL INFO Channel 02/0 : 19[1] -> 18[0] via P2P/IPC
d11n17:1142855:1143073 [1] NCCL INFO Connected all trees
d11n17:1142855:1143073 [1] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d11n17:1142855:1143073 [1] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d11n17:1142855:1143073 [1] NCCL INFO comm 0x12c6b3260 rank 19 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init COMPLETE
d09n08:1073957:1073957 [3] NCCL INFO cudaDriverVersion 12020
d09n08:1073957:1073957 [3] NCCL INFO Bootstrap : Using ib0:10.41.8.172<0>
d09n08:1073957:1073957 [3] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d09n08:1073957:1073957 [3] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d09n08:1073957:1074176 [3] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.8.172<0>
d09n08:1073957:1074176 [3] NCCL INFO Using network IB
d09n08:1073957:1074176 [3] NCCL INFO comm 0x1564e3700 rank 9 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init START
d09n08:1073957:1074176 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d09n08:1073957:1074176 [3] NCCL INFO Trees [0] 10/-1/-1->9->8 [1] 11/-1/-1->9->10 [2] 10/-1/-1->9->8 [3] 11/16/-1->9->10
d09n08:1073957:1074176 [3] NCCL INFO P2P Chunksize set to 131072
d09n08:1073957:1074176 [3] NCCL INFO Channel 00/0 : 9[3] -> 10[4] via P2P/IPC
d09n08:1073957:1074176 [3] NCCL INFO Channel 01/0 : 9[3] -> 10[4] via P2P/IPC
d09n08:1073957:1074176 [3] NCCL INFO Channel 02/0 : 9[3] -> 10[4] via P2P/IPC
d09n08:1073957:1074176 [3] NCCL INFO Channel 03/0 : 9[3] -> 10[4] via P2P/IPC
d09n08:1073957:1074176 [3] NCCL INFO Channel 01/0 : 0[0] -> 9[3] [receive] via NET/IB/3
d09n08:1073957:1074176 [3] NCCL INFO Channel 03/0 : 0[0] -> 9[3] [receive] via NET/IB/3
d09n08:1073957:1074176 [3] NCCL INFO Connected all rings
d09n08:1073957:1074176 [3] NCCL INFO Channel 01/0 : 9[3] -> 11[5] via P2P/IPC
d09n08:1073957:1074176 [3] NCCL INFO Channel 03/0 : 9[3] -> 11[5] via P2P/IPC
d09n08:1073957:1074176 [3] NCCL INFO Channel 03/0 : 9[3] -> 16[4] [send] via NET/IB/3
d09n08:1073957:1074176 [3] NCCL INFO Channel 03/0 : 16[4] -> 9[3] [receive] via NET/IB/3
d09n08:1073957:1074176 [3] NCCL INFO Channel 00/0 : 9[3] -> 8[2] via P2P/IPC
d09n08:1073957:1074176 [3] NCCL INFO Channel 02/0 : 9[3] -> 8[2] via P2P/IPC
d09n08:1073957:1074176 [3] NCCL INFO Connected all trees
d09n08:1073957:1074176 [3] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d09n08:1073957:1074176 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d09n08:1073957:1074176 [3] NCCL INFO comm 0x1564e3700 rank 9 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init COMPLETE
d14n08:1173251:1173251 [4] NCCL INFO cudaDriverVersion 12020
d14n08:1173251:1173251 [4] NCCL INFO Bootstrap : Using ib0:10.41.9.9<0>
d14n08:1173251:1173251 [4] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d14n08:1173251:1173251 [4] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d14n08:1173251:1173480 [4] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.9<0>
d14n08:1173251:1173480 [4] NCCL INFO Using network IB
d14n08:1173251:1173480 [4] NCCL INFO comm 0x15c273a60 rank 28 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init START
d14n08:1173251:1173480 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d14n08:1173251:1173480 [4] NCCL INFO Trees [0] 29/-1/-1->28->27 [1] 27/40/-1->28->51 [2] 29/-1/-1->28->27 [3] 27/-1/-1->28->34
d14n08:1173251:1173480 [4] NCCL INFO P2P Chunksize set to 131072
d14n08:1173251:1173480 [4] NCCL INFO Channel 00/0 : 28[4] -> 29[5] via P2P/IPC
d14n08:1173251:1173480 [4] NCCL INFO Channel 01/0 : 28[4] -> 29[5] via P2P/IPC
d14n08:1173251:1173480 [4] NCCL INFO Channel 02/0 : 28[4] -> 29[5] via P2P/IPC
d14n08:1173251:1173480 [4] NCCL INFO Channel 03/0 : 28[4] -> 29[5] via P2P/IPC
d14n08:1173251:1173480 [4] NCCL INFO Connected all rings
d14n08:1173251:1173480 [4] NCCL INFO Channel 03/0 : 28[4] -> 34[4] [send] via NET/IB/3
d14n08:1173251:1173480 [4] NCCL INFO Channel 01/0 : 28[4] -> 40[4] [send] via NET/IB/3
d14n08:1173251:1173480 [4] NCCL INFO Channel 01/0 : 28[4] -> 51[3] [send] via NET/IB/3
d14n08:1173251:1173480 [4] NCCL INFO Channel 01/0 : 51[3] -> 28[4] [receive] via NET/IB/3
d14n08:1173251:1173480 [4] NCCL INFO Channel 01/0 : 40[4] -> 28[4] [receive] via NET/IB/3
d14n08:1173251:1173480 [4] NCCL INFO Channel 03/0 : 34[4] -> 28[4] [receive] via NET/IB/3
d14n08:1173251:1173480 [4] NCCL INFO Channel 00/0 : 28[4] -> 27[3] via P2P/IPC
d14n08:1173251:1173480 [4] NCCL INFO Channel 01/0 : 28[4] -> 27[3] via P2P/IPC
d14n08:1173251:1173480 [4] NCCL INFO Channel 02/0 : 28[4] -> 27[3] via P2P/IPC
d14n08:1173251:1173480 [4] NCCL INFO Channel 03/0 : 28[4] -> 27[3] via P2P/IPC
d14n08:1173251:1173480 [4] NCCL INFO Connected all trees
d14n08:1173251:1173480 [4] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d14n08:1173251:1173480 [4] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n08:1173251:1173480 [4] NCCL INFO comm 0x15c273a60 rank 28 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init COMPLETE
d11n17:1142854:1142854 [0] NCCL INFO cudaDriverVersion 12020
d11n17:1142854:1142854 [0] NCCL INFO Bootstrap : Using ib0:10.41.8.217<0>
d11n17:1142854:1142854 [0] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d11n17:1142854:1142854 [0] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d11n17:1142854:1143075 [0] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.8.217<0>
d11n17:1142854:1143075 [0] NCCL INFO Using network IB
d11n17:1142854:1143075 [0] NCCL INFO comm 0x1570b3420 rank 18 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init START
d11n17:1142854:1143075 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d11n17:1142854:1143075 [0] NCCL INFO Trees [0] 19/-1/-1->18->12 [1] 20/-1/-1->18->19 [2] 19/6/-1->18->42 [3] 20/-1/-1->18->19
d11n17:1142854:1143075 [0] NCCL INFO P2P Chunksize set to 131072
d11n17:1142854:1143075 [0] NCCL INFO Channel 00/0 : 17[5] -> 18[0] [receive] via NET/IB/0
d11n17:1142854:1143075 [0] NCCL INFO Channel 02/0 : 17[5] -> 18[0] [receive] via NET/IB/0
d11n17:1142854:1143075 [0] NCCL INFO Channel 00/0 : 18[0] -> 19[1] via P2P/IPC
d11n17:1142854:1143075 [0] NCCL INFO Channel 02/0 : 18[0] -> 19[1] via P2P/IPC
d11n17:1142854:1143075 [0] NCCL INFO Channel 01/0 : 18[0] -> 27[3] [send] via NET/IB/2
d11n17:1142854:1143075 [0] NCCL INFO Channel 03/0 : 18[0] -> 27[3] [send] via NET/IB/2
d11n17:1142854:1143075 [0] NCCL INFO Connected all rings
d11n17:1142854:1143075 [0] NCCL INFO Channel 01/0 : 18[0] -> 19[1] via P2P/IPC
d11n17:1142854:1143075 [0] NCCL INFO Channel 03/0 : 18[0] -> 19[1] via P2P/IPC
d11n17:1142854:1143075 [0] NCCL INFO Channel 01/0 : 18[0] -> 20[2] via P2P/IPC
d11n17:1142854:1143075 [0] NCCL INFO Channel 03/0 : 18[0] -> 20[2] via P2P/IPC
d11n17:1142854:1143075 [0] NCCL INFO Channel 00/0 : 12[0] -> 18[0] [receive] via NET/IB/0
d11n17:1142854:1143075 [0] NCCL INFO Channel 02/0 : 6[0] -> 18[0] [receive] via NET/IB/0
d11n17:1142854:1143075 [0] NCCL INFO Channel 02/0 : 18[0] -> 42[0] [send] via NET/IB/0
d11n17:1142854:1143075 [0] NCCL INFO Channel 02/0 : 42[0] -> 18[0] [receive] via NET/IB/0
d11n17:1142854:1143075 [0] NCCL INFO Channel 02/0 : 18[0] -> 6[0] [send] via NET/IB/0
d11n17:1142854:1143075 [0] NCCL INFO Channel 00/0 : 18[0] -> 12[0] [send] via NET/IB/0
d11n17:1142854:1143075 [0] NCCL INFO Connected all trees
d11n17:1142854:1143075 [0] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d11n17:1142854:1143075 [0] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d11n17:1142854:1143075 [0] NCCL INFO comm 0x1570b3420 rank 18 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init COMPLETE
d09n08:1073959:1073959 [5] NCCL INFO cudaDriverVersion 12020
d09n08:1073959:1073959 [5] NCCL INFO Bootstrap : Using ib0:10.41.8.172<0>
d09n08:1073959:1073959 [5] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d09n08:1073959:1073959 [5] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d09n08:1073959:1074177 [5] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.8.172<0>
d09n08:1073959:1074177 [5] NCCL INFO Using network IB
d09n08:1073959:1074177 [5] NCCL INFO comm 0x158233590 rank 11 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init START
d09n08:1073959:1074177 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d09n08:1073959:1074177 [5] NCCL INFO Trees [0] -1/-1/-1->11->10 [1] 7/-1/-1->11->9 [2] -1/-1/-1->11->10 [3] 7/-1/-1->11->9
d09n08:1073959:1074177 [5] NCCL INFO P2P Chunksize set to 131072
d09n08:1073959:1074177 [5] NCCL INFO Channel 00/0 : 11[5] -> 12[0] [send] via NET/IB/1
d09n08:1073959:1074177 [5] NCCL INFO Channel 02/0 : 11[5] -> 12[0] [send] via NET/IB/1
d09n08:1073959:1074177 [5] NCCL INFO Channel 01/0 : 11[5] -> 8[2] via P2P/IPC
d09n08:1073959:1074177 [5] NCCL INFO Channel 03/0 : 11[5] -> 8[2] via P2P/IPC
d09n08:1073959:1074177 [5] NCCL INFO Connected all rings
d09n08:1073959:1074177 [5] NCCL INFO Channel 01/0 : 11[5] -> 7[1] via P2P/IPC
d09n08:1073959:1074177 [5] NCCL INFO Channel 03/0 : 11[5] -> 7[1] via P2P/IPC
d09n08:1073959:1074177 [5] NCCL INFO Channel 01/0 : 11[5] -> 9[3] via P2P/IPC
d09n08:1073959:1074177 [5] NCCL INFO Channel 03/0 : 11[5] -> 9[3] via P2P/IPC
d09n08:1073959:1074177 [5] NCCL INFO Channel 00/0 : 11[5] -> 10[4] via P2P/IPC
d09n08:1073959:1074177 [5] NCCL INFO Channel 02/0 : 11[5] -> 10[4] via P2P/IPC
d09n08:1073959:1074177 [5] NCCL INFO Connected all trees
d09n08:1073959:1074177 [5] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d09n08:1073959:1074177 [5] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d09n08:1073959:1074177 [5] NCCL INFO comm 0x158233590 rank 11 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init COMPLETE
d14n08:1173250:1173250 [3] NCCL INFO cudaDriverVersion 12020
d14n08:1173250:1173250 [3] NCCL INFO Bootstrap : Using ib0:10.41.9.9<0>
d14n08:1173250:1173250 [3] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d14n08:1173250:1173250 [3] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d14n08:1173250:1173479 [3] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.9<0>
d14n08:1173250:1173479 [3] NCCL INFO Using network IB
d14n08:1173250:1173479 [3] NCCL INFO comm 0x163ef3810 rank 27 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init START
d14n08:1173250:1173479 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d14n08:1173250:1173479 [3] NCCL INFO Trees [0] 28/-1/-1->27->26 [1] 29/16/-1->27->28 [2] 28/-1/-1->27->26 [3] 29/-1/-1->27->28
d14n08:1173250:1173479 [3] NCCL INFO P2P Chunksize set to 131072
d14n08:1173250:1173479 [3] NCCL INFO Channel 00/0 : 27[3] -> 28[4] via P2P/IPC
d14n08:1173250:1173479 [3] NCCL INFO Channel 01/0 : 27[3] -> 28[4] via P2P/IPC
d14n08:1173250:1173479 [3] NCCL INFO Channel 02/0 : 27[3] -> 28[4] via P2P/IPC
d14n08:1173250:1173479 [3] NCCL INFO Channel 03/0 : 27[3] -> 28[4] via P2P/IPC
d14n08:1173250:1173479 [3] NCCL INFO Channel 01/0 : 18[0] -> 27[3] [receive] via NET/IB/3
d14n08:1173250:1173479 [3] NCCL INFO Channel 03/0 : 18[0] -> 27[3] [receive] via NET/IB/3
d14n08:1173250:1173479 [3] NCCL INFO Connected all rings
d14n08:1173250:1173479 [3] NCCL INFO Channel 01/0 : 27[3] -> 29[5] via P2P/IPC
d14n08:1173250:1173479 [3] NCCL INFO Channel 03/0 : 27[3] -> 29[5] via P2P/IPC
d14n08:1173250:1173479 [3] NCCL INFO Channel 01/0 : 16[4] -> 27[3] [receive] via NET/IB/3
d14n08:1173250:1173479 [3] NCCL INFO Channel 01/0 : 27[3] -> 16[4] [send] via NET/IB/3
d14n08:1173250:1173479 [3] NCCL INFO Channel 00/0 : 27[3] -> 26[2] via P2P/IPC
d14n08:1173250:1173479 [3] NCCL INFO Channel 02/0 : 27[3] -> 26[2] via P2P/IPC
d14n08:1173250:1173479 [3] NCCL INFO Connected all trees
d14n08:1173250:1173479 [3] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d14n08:1173250:1173479 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n08:1173250:1173479 [3] NCCL INFO comm 0x163ef3810 rank 27 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init COMPLETE
d09n08:1073958:1073958 [4] NCCL INFO cudaDriverVersion 12020
d09n08:1073958:1073958 [4] NCCL INFO Bootstrap : Using ib0:10.41.8.172<0>
d09n08:1073958:1073958 [4] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d09n08:1073958:1073958 [4] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d09n08:1073958:1074181 [4] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.8.172<0>
d09n08:1073958:1074181 [4] NCCL INFO Using network IB
d09n08:1073958:1074181 [4] NCCL INFO comm 0x14e143790 rank 10 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init START
d09n08:1073958:1074181 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d09n08:1073958:1074181 [4] NCCL INFO Trees [0] 11/-1/-1->10->9 [1] 9/-1/-1->10->15 [2] 11/-1/-1->10->9 [3] 9/4/-1->10->22
d09n08:1073958:1074181 [4] NCCL INFO P2P Chunksize set to 131072
d09n08:1073958:1074181 [4] NCCL INFO Channel 00/0 : 10[4] -> 11[5] via P2P/IPC
d09n08:1073958:1074181 [4] NCCL INFO Channel 01/0 : 10[4] -> 11[5] via P2P/IPC
d09n08:1073958:1074181 [4] NCCL INFO Channel 02/0 : 10[4] -> 11[5] via P2P/IPC
d09n08:1073958:1074181 [4] NCCL INFO Channel 03/0 : 10[4] -> 11[5] via P2P/IPC
d09n08:1073958:1074181 [4] NCCL INFO Connected all rings
d09n08:1073958:1074181 [4] NCCL INFO Channel 01/0 : 10[4] -> 15[3] [send] via NET/IB/3
d09n08:1073958:1074181 [4] NCCL INFO Channel 03/0 : 4[4] -> 10[4] [receive] via NET/IB/3
d09n08:1073958:1074181 [4] NCCL INFO Channel 03/0 : 10[4] -> 22[4] [send] via NET/IB/3
d09n08:1073958:1074181 [4] NCCL INFO Channel 03/0 : 22[4] -> 10[4] [receive] via NET/IB/3
d09n08:1073958:1074181 [4] NCCL INFO Channel 03/0 : 10[4] -> 4[4] [send] via NET/IB/3
d09n08:1073958:1074181 [4] NCCL INFO Channel 01/0 : 15[3] -> 10[4] [receive] via NET/IB/3
d09n08:1073958:1074181 [4] NCCL INFO Channel 00/0 : 10[4] -> 9[3] via P2P/IPC
d09n08:1073958:1074181 [4] NCCL INFO Channel 01/0 : 10[4] -> 9[3] via P2P/IPC
d09n08:1073958:1074181 [4] NCCL INFO Channel 02/0 : 10[4] -> 9[3] via P2P/IPC
d09n08:1073958:1074181 [4] NCCL INFO Channel 03/0 : 10[4] -> 9[3] via P2P/IPC
d09n08:1073958:1074181 [4] NCCL INFO Connected all trees
d09n08:1073958:1074181 [4] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d09n08:1073958:1074181 [4] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d09n08:1073958:1074181 [4] NCCL INFO comm 0x14e143790 rank 10 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init COMPLETE
d09n08:1073954:1073954 [0] NCCL INFO cudaDriverVersion 12020
d09n08:1073954:1073954 [0] NCCL INFO Bootstrap : Using ib0:10.41.8.172<0>
d09n08:1073954:1073954 [0] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d09n08:1073954:1073954 [0] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d09n08:1073954:1074178 [0] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.8.172<0>
d09n08:1073954:1074178 [0] NCCL INFO Using network IB
d09n08:1073954:1074178 [0] NCCL INFO comm 0x1480e3aa0 rank 6 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init START
d09n08:1073954:1074178 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d09n08:1073954:1074178 [0] NCCL INFO Trees [0] 7/-1/-1->6->13 [1] 8/-1/-1->6->7 [2] 7/0/-1->6->18 [3] 8/-1/-1->6->7
d09n08:1073954:1074178 [0] NCCL INFO P2P Chunksize set to 131072
d09n08:1073954:1074178 [0] NCCL INFO Channel 00/0 : 5[5] -> 6[0] [receive] via NET/IB/0
d09n08:1073954:1074178 [0] NCCL INFO Channel 02/0 : 5[5] -> 6[0] [receive] via NET/IB/0
d09n08:1073954:1074178 [0] NCCL INFO Channel 00/0 : 6[0] -> 7[1] via P2P/IPC
d09n08:1073954:1074178 [0] NCCL INFO Channel 02/0 : 6[0] -> 7[1] via P2P/IPC
d09n08:1073954:1074178 [0] NCCL INFO Channel 01/0 : 6[0] -> 15[3] [send] via NET/IB/2
d09n08:1073954:1074178 [0] NCCL INFO Channel 03/0 : 6[0] -> 15[3] [send] via NET/IB/2
d09n08:1073954:1074178 [0] NCCL INFO Connected all rings
d09n08:1073954:1074178 [0] NCCL INFO Channel 01/0 : 6[0] -> 7[1] via P2P/IPC
d09n08:1073954:1074178 [0] NCCL INFO Channel 03/0 : 6[0] -> 7[1] via P2P/IPC
d09n08:1073954:1074178 [0] NCCL INFO Channel 01/0 : 6[0] -> 8[2] via P2P/IPC
d09n08:1073954:1074178 [0] NCCL INFO Channel 03/0 : 6[0] -> 8[2] via P2P/IPC
d09n08:1073954:1074178 [0] NCCL INFO Channel 02/0 : 0[0] -> 6[0] [receive] via NET/IB/0
d09n08:1073954:1074178 [0] NCCL INFO Channel 00/0 : 6[0] -> 13[1] [send] via NET/IB/0
d09n08:1073954:1074178 [0] NCCL INFO Channel 02/0 : 6[0] -> 18[0] [send] via NET/IB/0
d09n08:1073954:1074178 [0] NCCL INFO Channel 02/0 : 18[0] -> 6[0] [receive] via NET/IB/0
d09n08:1073954:1074178 [0] NCCL INFO Channel 00/0 : 13[1] -> 6[0] [receive] via NET/IB/0
d09n08:1073954:1074178 [0] NCCL INFO Channel 02/0 : 6[0] -> 0[0] [send] via NET/IB/0
d09n08:1073954:1074178 [0] NCCL INFO Connected all trees
d09n08:1073954:1074178 [0] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d09n08:1073954:1074178 [0] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d09n08:1073954:1074178 [0] NCCL INFO comm 0x1480e3aa0 rank 6 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init COMPLETE
d09n08:1073955:1073955 [1] NCCL INFO cudaDriverVersion 12020
d09n08:1073955:1073955 [1] NCCL INFO Bootstrap : Using ib0:10.41.8.172<0>
d09n08:1073955:1073955 [1] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d09n08:1073955:1073955 [1] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d09n08:1073955:1074179 [1] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.8.172<0>
d09n08:1073955:1074179 [1] NCCL INFO Using network IB
d09n08:1073955:1074179 [1] NCCL INFO comm 0x158963260 rank 7 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init START
d09n08:1073955:1074179 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d09n08:1073955:1074179 [1] NCCL INFO Trees [0] 8/-1/-1->7->6 [1] 6/-1/-1->7->11 [2] 8/12/-1->7->6 [3] 6/-1/-1->7->11
d09n08:1073955:1074179 [1] NCCL INFO P2P Chunksize set to 131072
d09n08:1073955:1074179 [1] NCCL INFO Channel 00/0 : 7[1] -> 8[2] via P2P/IPC
d09n08:1073955:1074179 [1] NCCL INFO Channel 02/0 : 7[1] -> 8[2] via P2P/IPC
d09n08:1073955:1074179 [1] NCCL INFO Channel 01/0 : 7[1] -> 6[0] via P2P/IPC
d09n08:1073955:1074179 [1] NCCL INFO Channel 03/0 : 7[1] -> 6[0] via P2P/IPC
d09n08:1073955:1074179 [1] NCCL INFO Connected all rings
d09n08:1073955:1074179 [1] NCCL INFO Channel 01/0 : 7[1] -> 11[5] via P2P/IPC
d09n08:1073955:1074179 [1] NCCL INFO Channel 03/0 : 7[1] -> 11[5] via P2P/IPC
d09n08:1073955:1074179 [1] NCCL INFO Channel 02/0 : 7[1] -> 12[0] [send] via NET/IB/0
d09n08:1073955:1074179 [1] NCCL INFO Channel 02/0 : 12[0] -> 7[1] [receive] via NET/IB/0
d09n08:1073955:1074179 [1] NCCL INFO Channel 00/0 : 7[1] -> 6[0] via P2P/IPC
d09n08:1073955:1074179 [1] NCCL INFO Channel 02/0 : 7[1] -> 6[0] via P2P/IPC
d09n08:1073955:1074179 [1] NCCL INFO Connected all trees
d09n08:1073955:1074179 [1] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d09n08:1073955:1074179 [1] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d09n08:1073955:1074179 [1] NCCL INFO comm 0x158963260 rank 7 nranks 96 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa35f79647b16dded - Init COMPLETE
NCCL version 2.18.3+cuda11.8
d14n09:567668:567668 [2] NCCL INFO cudaDriverVersion 12020
d14n09:567668:567668 [2] NCCL INFO Bootstrap : Using ib0:10.41.9.10<0>
d14n09:567668:567668 [2] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d14n09:567668:567668 [2] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d14n09:567668:567894 [2] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.10<0>
d14n09:567668:567894 [2] NCCL INFO Using network IB
d14n09:567668:567894 [2] NCCL INFO comm 0x126ff3a70 rank 32 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init START
d14n09:567668:567894 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d14n09:567668:567894 [2] NCCL INFO Trees [0] 33/-1/-1->32->31 [1] -1/-1/-1->32->30 [2] 33/-1/-1->32->31 [3] -1/-1/-1->32->30
d14n09:567668:567894 [2] NCCL INFO P2P Chunksize set to 131072
d14n09:567668:567894 [2] NCCL INFO Channel 00/0 : 32[2] -> 33[3] via P2P/IPC
d14n09:567668:567894 [2] NCCL INFO Channel 02/0 : 32[2] -> 33[3] via P2P/IPC
d14n09:567668:567894 [2] NCCL INFO Channel 01/0 : 32[2] -> 31[1] via P2P/IPC
d14n09:567668:567894 [2] NCCL INFO Channel 03/0 : 32[2] -> 31[1] via P2P/IPC
d14n09:567668:567894 [2] NCCL INFO Connected all rings
d14n09:567668:567894 [2] NCCL INFO Channel 01/0 : 32[2] -> 30[0] via P2P/IPC
d14n09:567668:567894 [2] NCCL INFO Channel 03/0 : 32[2] -> 30[0] via P2P/IPC
d14n09:567668:567894 [2] NCCL INFO Channel 00/0 : 32[2] -> 31[1] via P2P/IPC
d14n09:567668:567894 [2] NCCL INFO Channel 02/0 : 32[2] -> 31[1] via P2P/IPC
d14n09:567668:567894 [2] NCCL INFO Connected all trees
d14n09:567668:567894 [2] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d14n09:567668:567894 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n09:567668:567894 [2] NCCL INFO comm 0x126ff3a70 rank 32 nranks 96 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa35f79647b16dded - Init COMPLETE
NCCL version 2.18.3+cuda11.8
d14n09:567669:567669 [3] NCCL INFO cudaDriverVersion 12020
d14n09:567669:567669 [3] NCCL INFO Bootstrap : Using ib0:10.41.9.10<0>
d14n09:567669:567669 [3] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d14n09:567669:567669 [3] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d14n09:567669:567896 [3] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.10<0>
d14n09:567669:567896 [3] NCCL INFO Using network IB
d14n09:567669:567896 [3] NCCL INFO comm 0x146c43980 rank 33 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init START
d14n09:567669:567896 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d14n09:567669:567896 [3] NCCL INFO Trees [0] 34/-1/-1->33->32 [1] 35/-1/-1->33->34 [2] 34/-1/-1->33->32 [3] 35/40/-1->33->34
d14n09:567669:567896 [3] NCCL INFO P2P Chunksize set to 131072
d14n09:567669:567896 [3] NCCL INFO Channel 00/0 : 33[3] -> 34[4] via P2P/IPC
d14n09:567669:567896 [3] NCCL INFO Channel 01/0 : 33[3] -> 34[4] via P2P/IPC
d14n09:567669:567896 [3] NCCL INFO Channel 02/0 : 33[3] -> 34[4] via P2P/IPC
d14n09:567669:567896 [3] NCCL INFO Channel 03/0 : 33[3] -> 34[4] via P2P/IPC
d14n09:567669:567896 [3] NCCL INFO Channel 01/0 : 24[0] -> 33[3] [receive] via NET/IB/3
d14n09:567669:567896 [3] NCCL INFO Channel 03/0 : 24[0] -> 33[3] [receive] via NET/IB/3
d14n09:567669:567896 [3] NCCL INFO Connected all rings
d14n09:567669:567896 [3] NCCL INFO Channel 01/0 : 33[3] -> 35[5] via P2P/IPC
d14n09:567669:567896 [3] NCCL INFO Channel 03/0 : 33[3] -> 35[5] via P2P/IPC
d14n09:567669:567896 [3] NCCL INFO Channel 03/0 : 33[3] -> 40[4] [send] via NET/IB/3
d14n09:567669:567896 [3] NCCL INFO Channel 03/0 : 40[4] -> 33[3] [receive] via NET/IB/3
d14n09:567669:567896 [3] NCCL INFO Channel 00/0 : 33[3] -> 32[2] via P2P/IPC
d14n09:567669:567896 [3] NCCL INFO Channel 02/0 : 33[3] -> 32[2] via P2P/IPC
d14n09:567669:567896 [3] NCCL INFO Connected all trees
d14n09:567669:567896 [3] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d14n09:567669:567896 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n09:567669:567896 [3] NCCL INFO comm 0x146c43980 rank 33 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init COMPLETE
d11n17:1142859:1142859 [5] NCCL INFO cudaDriverVersion 12020
d11n17:1142859:1142859 [5] NCCL INFO Bootstrap : Using ib0:10.41.8.217<0>
d11n17:1142859:1142859 [5] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d11n17:1142859:1142859 [5] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d11n17:1142859:1143074 [5] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.8.217<0>
d11n17:1142859:1143074 [5] NCCL INFO Using network IB
d11n17:1142859:1143074 [5] NCCL INFO comm 0x130203960 rank 23 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init START
d11n17:1142859:1143074 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d11n17:1142859:1143074 [5] NCCL INFO Trees [0] -1/-1/-1->23->22 [1] 19/-1/-1->23->21 [2] -1/-1/-1->23->22 [3] 19/-1/-1->23->21
d11n17:1142859:1143074 [5] NCCL INFO P2P Chunksize set to 131072
d11n17:1142859:1143074 [5] NCCL INFO Channel 00/0 : 23[5] -> 24[0] [send] via NET/IB/1
d11n17:1142859:1143074 [5] NCCL INFO Channel 02/0 : 23[5] -> 24[0] [send] via NET/IB/1
d11n17:1142859:1143074 [5] NCCL INFO Channel 01/0 : 23[5] -> 20[2] via P2P/IPC
d11n17:1142859:1143074 [5] NCCL INFO Channel 03/0 : 23[5] -> 20[2] via P2P/IPC
d11n17:1142859:1143074 [5] NCCL INFO Connected all rings
d11n17:1142859:1143074 [5] NCCL INFO Channel 01/0 : 23[5] -> 19[1] via P2P/IPC
d11n17:1142859:1143074 [5] NCCL INFO Channel 03/0 : 23[5] -> 19[1] via P2P/IPC
d11n17:1142859:1143074 [5] NCCL INFO Channel 01/0 : 23[5] -> 21[3] via P2P/IPC
d11n17:1142859:1143074 [5] NCCL INFO Channel 03/0 : 23[5] -> 21[3] via P2P/IPC
d11n17:1142859:1143074 [5] NCCL INFO Channel 00/0 : 23[5] -> 22[4] via P2P/IPC
d11n17:1142859:1143074 [5] NCCL INFO Channel 02/0 : 23[5] -> 22[4] via P2P/IPC
d11n17:1142859:1143074 [5] NCCL INFO Connected all trees
d11n17:1142859:1143074 [5] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d11n17:1142859:1143074 [5] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d11n17:1142859:1143074 [5] NCCL INFO comm 0x130203960 rank 23 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init COMPLETE
NCCL version 2.18.3+cuda11.8
d14n09:567670:567670 [4] NCCL INFO cudaDriverVersion 12020
d14n09:567670:567670 [4] NCCL INFO Bootstrap : Using ib0:10.41.9.10<0>
d14n09:567670:567670 [4] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d14n09:567670:567670 [4] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d14n09:567670:567897 [4] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.10<0>
d14n09:567670:567897 [4] NCCL INFO Using network IB
d14n09:567670:567897 [4] NCCL INFO comm 0x1630835c0 rank 34 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init START
d14n09:567670:567897 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d14n09:567670:567897 [4] NCCL INFO Trees [0] 35/-1/-1->34->33 [1] 33/-1/-1->34->39 [2] 35/-1/-1->34->33 [3] 33/28/-1->34->21
d14n09:567670:567897 [4] NCCL INFO P2P Chunksize set to 131072
d14n09:567670:567897 [4] NCCL INFO Channel 00/0 : 34[4] -> 35[5] via P2P/IPC
d14n09:567670:567897 [4] NCCL INFO Channel 01/0 : 34[4] -> 35[5] via P2P/IPC
d14n09:567670:567897 [4] NCCL INFO Channel 02/0 : 34[4] -> 35[5] via P2P/IPC
d14n09:567670:567897 [4] NCCL INFO Channel 03/0 : 34[4] -> 35[5] via P2P/IPC
d14n09:567670:567897 [4] NCCL INFO Connected all rings
d14n09:567670:567897 [4] NCCL INFO Channel 01/0 : 34[4] -> 39[3] [send] via NET/IB/3
d14n09:567670:567897 [4] NCCL INFO Channel 03/0 : 28[4] -> 34[4] [receive] via NET/IB/3
d14n09:567670:567897 [4] NCCL INFO Channel 03/0 : 21[3] -> 34[4] [receive] via NET/IB/3
d14n09:567670:567897 [4] NCCL INFO Channel 03/0 : 34[4] -> 21[3] [send] via NET/IB/3
d14n09:567670:567897 [4] NCCL INFO Channel 03/0 : 34[4] -> 28[4] [send] via NET/IB/3
d14n09:567670:567897 [4] NCCL INFO Channel 01/0 : 39[3] -> 34[4] [receive] via NET/IB/3
d14n09:567670:567897 [4] NCCL INFO Channel 00/0 : 34[4] -> 33[3] via P2P/IPC
d14n09:567670:567897 [4] NCCL INFO Channel 01/0 : 34[4] -> 33[3] via P2P/IPC
d14n09:567670:567897 [4] NCCL INFO Channel 02/0 : 34[4] -> 33[3] via P2P/IPC
d14n09:567670:567897 [4] NCCL INFO Channel 03/0 : 34[4] -> 33[3] via P2P/IPC
d14n09:567670:567897 [4] NCCL INFO Connected all trees
d14n09:567670:567897 [4] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d14n09:567670:567897 [4] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n09:567670:567897 [4] NCCL INFO comm 0x1630835c0 rank 34 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init COMPLETE
d11n17:1142857:1142857 [3] NCCL INFO cudaDriverVersion 12020
d11n17:1142857:1142857 [3] NCCL INFO Bootstrap : Using ib0:10.41.8.217<0>
d11n17:1142857:1142857 [3] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d11n17:1142857:1142857 [3] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d11n17:1142857:1143077 [3] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.8.217<0>
d11n17:1142857:1143077 [3] NCCL INFO Using network IB
d11n17:1142857:1143077 [3] NCCL INFO comm 0x12d773860 rank 21 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init START
d11n17:1142857:1143077 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d11n17:1142857:1143077 [3] NCCL INFO Trees [0] 22/-1/-1->21->20 [1] 23/-1/-1->21->22 [2] 22/-1/-1->21->20 [3] 23/34/-1->21->22
d11n17:1142857:1143077 [3] NCCL INFO P2P Chunksize set to 131072
d11n17:1142857:1143077 [3] NCCL INFO Channel 00/0 : 21[3] -> 22[4] via P2P/IPC
d11n17:1142857:1143077 [3] NCCL INFO Channel 01/0 : 21[3] -> 22[4] via P2P/IPC
d11n17:1142857:1143077 [3] NCCL INFO Channel 02/0 : 21[3] -> 22[4] via P2P/IPC
d11n17:1142857:1143077 [3] NCCL INFO Channel 03/0 : 21[3] -> 22[4] via P2P/IPC
d11n17:1142857:1143077 [3] NCCL INFO Channel 01/0 : 12[0] -> 21[3] [receive] via NET/IB/3
d11n17:1142857:1143077 [3] NCCL INFO Channel 03/0 : 12[0] -> 21[3] [receive] via NET/IB/3
d11n17:1142857:1143077 [3] NCCL INFO Connected all rings
d11n17:1142857:1143077 [3] NCCL INFO Channel 01/0 : 21[3] -> 23[5] via P2P/IPC
d11n17:1142857:1143077 [3] NCCL INFO Channel 03/0 : 21[3] -> 23[5] via P2P/IPC
d11n17:1142857:1143077 [3] NCCL INFO Channel 03/0 : 21[3] -> 34[4] [send] via NET/IB/3
d11n17:1142857:1143077 [3] NCCL INFO Channel 03/0 : 34[4] -> 21[3] [receive] via NET/IB/3
d11n17:1142857:1143077 [3] NCCL INFO Channel 00/0 : 21[3] -> 20[2] via P2P/IPC
d11n17:1142857:1143077 [3] NCCL INFO Channel 02/0 : 21[3] -> 20[2] via P2P/IPC
d11n17:1142857:1143077 [3] NCCL INFO Connected all trees
d11n17:1142857:1143077 [3] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d11n17:1142857:1143077 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d11n17:1142857:1143077 [3] NCCL INFO comm 0x12d773860 rank 21 nranks 96 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa35f79647b16dded - Init COMPLETE
NCCL version 2.18.3+cuda11.8
d14n09:567671:567671 [5] NCCL INFO cudaDriverVersion 12020
d14n09:567671:567671 [5] NCCL INFO Bootstrap : Using ib0:10.41.9.10<0>
d14n09:567671:567671 [5] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d14n09:567671:567671 [5] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d14n09:567671:567895 [5] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.10<0>
d14n09:567671:567895 [5] NCCL INFO Using network IB
d14n09:567671:567895 [5] NCCL INFO comm 0x1353e3690 rank 35 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init START
d14n09:567671:567895 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d14n09:567671:567895 [5] NCCL INFO Trees [0] -1/-1/-1->35->34 [1] 31/-1/-1->35->33 [2] -1/-1/-1->35->34 [3] 31/-1/-1->35->33
d14n09:567671:567895 [5] NCCL INFO P2P Chunksize set to 131072
d14n09:567671:567895 [5] NCCL INFO Channel 00/0 : 35[5] -> 36[0] [send] via NET/IB/1
d14n09:567671:567895 [5] NCCL INFO Channel 02/0 : 35[5] -> 36[0] [send] via NET/IB/1
d14n09:567671:567895 [5] NCCL INFO Channel 01/0 : 35[5] -> 32[2] via P2P/IPC
d14n09:567671:567895 [5] NCCL INFO Channel 03/0 : 35[5] -> 32[2] via P2P/IPC
d14n09:567671:567895 [5] NCCL INFO Connected all rings
d14n09:567671:567895 [5] NCCL INFO Channel 01/0 : 35[5] -> 31[1] via P2P/IPC
d14n09:567671:567895 [5] NCCL INFO Channel 03/0 : 35[5] -> 31[1] via P2P/IPC
d14n09:567671:567895 [5] NCCL INFO Channel 01/0 : 35[5] -> 33[3] via P2P/IPC
d14n09:567671:567895 [5] NCCL INFO Channel 03/0 : 35[5] -> 33[3] via P2P/IPC
d14n09:567671:567895 [5] NCCL INFO Channel 00/0 : 35[5] -> 34[4] via P2P/IPC
d14n09:567671:567895 [5] NCCL INFO Channel 02/0 : 35[5] -> 34[4] via P2P/IPC
d14n09:567671:567895 [5] NCCL INFO Connected all trees
d14n09:567671:567895 [5] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d14n09:567671:567895 [5] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n09:567671:567895 [5] NCCL INFO comm 0x1353e3690 rank 35 nranks 96 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa35f79647b16dded - Init COMPLETE
d11n17:1142858:1142858 [4] NCCL INFO cudaDriverVersion 12020
d11n17:1142858:1142858 [4] NCCL INFO Bootstrap : Using ib0:10.41.8.217<0>
d11n17:1142858:1142858 [4] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d11n17:1142858:1142858 [4] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d11n17:1142858:1143076 [4] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.8.217<0>
d11n17:1142858:1143076 [4] NCCL INFO Using network IB
d11n17:1142858:1143076 [4] NCCL INFO comm 0x1309c3770 rank 22 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init START
d11n17:1142858:1143076 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d11n17:1142858:1143076 [4] NCCL INFO Trees [0] 23/-1/-1->22->21 [1] 21/-1/-1->22->16 [2] 23/-1/-1->22->21 [3] 21/10/-1->22->46
d11n17:1142858:1143076 [4] NCCL INFO P2P Chunksize set to 131072
d11n17:1142858:1143076 [4] NCCL INFO Channel 00/0 : 22[4] -> 23[5] via P2P/IPC
d11n17:1142858:1143076 [4] NCCL INFO Channel 01/0 : 22[4] -> 23[5] via P2P/IPC
d11n17:1142858:1143076 [4] NCCL INFO Channel 02/0 : 22[4] -> 23[5] via P2P/IPC
d11n17:1142858:1143076 [4] NCCL INFO Channel 03/0 : 22[4] -> 23[5] via P2P/IPC
d11n17:1142858:1143076 [4] NCCL INFO Connected all rings
d11n17:1142858:1143076 [4] NCCL INFO Channel 01/0 : 16[4] -> 22[4] [receive] via NET/IB/3
d11n17:1142858:1143076 [4] NCCL INFO Channel 03/0 : 10[4] -> 22[4] [receive] via NET/IB/3
d11n17:1142858:1143076 [4] NCCL INFO Channel 03/0 : 22[4] -> 46[4] [send] via NET/IB/3
d11n17:1142858:1143076 [4] NCCL INFO Channel 03/0 : 46[4] -> 22[4] [receive] via NET/IB/3
d11n17:1142858:1143076 [4] NCCL INFO Channel 03/0 : 22[4] -> 10[4] [send] via NET/IB/3
d11n17:1142858:1143076 [4] NCCL INFO Channel 01/0 : 22[4] -> 16[4] [send] via NET/IB/3
d11n17:1142858:1143076 [4] NCCL INFO Channel 00/0 : 22[4] -> 21[3] via P2P/IPC
d11n17:1142858:1143076 [4] NCCL INFO Channel 01/0 : 22[4] -> 21[3] via P2P/IPC
d11n17:1142858:1143076 [4] NCCL INFO Channel 02/0 : 22[4] -> 21[3] via P2P/IPC
d11n17:1142858:1143076 [4] NCCL INFO Channel 03/0 : 22[4] -> 21[3] via P2P/IPC
d11n17:1142858:1143076 [4] NCCL INFO Connected all trees
d11n17:1142858:1143076 [4] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d11n17:1142858:1143076 [4] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d11n17:1142858:1143076 [4] NCCL INFO comm 0x1309c3770 rank 22 nranks 96 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa35f79647b16dded - Init COMPLETE
NCCL version 2.18.3+cuda11.8
d14n09:567666:567666 [0] NCCL INFO cudaDriverVersion 12020
d14n09:567666:567666 [0] NCCL INFO Bootstrap : Using ib0:10.41.9.10<0>
d14n09:567666:567666 [0] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d14n09:567666:567666 [0] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d14n09:567666:567892 [0] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.10<0>
d14n09:567666:567892 [0] NCCL INFO Using network IB
d14n09:567666:567892 [0] NCCL INFO comm 0x17e782de0 rank 30 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init START
d14n09:567666:567892 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d14n09:567666:567892 [0] NCCL INFO Trees [0] 31/-1/-1->30->37 [1] 32/-1/-1->30->31 [2] 31/24/-1->30->19 [3] 32/-1/-1->30->31
d14n09:567666:567892 [0] NCCL INFO P2P Chunksize set to 131072
d14n09:567666:567892 [0] NCCL INFO Channel 00/0 : 29[5] -> 30[0] [receive] via NET/IB/0
d14n09:567666:567892 [0] NCCL INFO Channel 02/0 : 29[5] -> 30[0] [receive] via NET/IB/0
d14n09:567666:567892 [0] NCCL INFO Channel 00/0 : 30[0] -> 31[1] via P2P/IPC
d14n09:567666:567892 [0] NCCL INFO Channel 02/0 : 30[0] -> 31[1] via P2P/IPC
d14n09:567666:567892 [0] NCCL INFO Channel 01/0 : 30[0] -> 39[3] [send] via NET/IB/2
d14n09:567666:567892 [0] NCCL INFO Channel 03/0 : 30[0] -> 39[3] [send] via NET/IB/2
d14n09:567666:567892 [0] NCCL INFO Connected all rings
d14n09:567666:567892 [0] NCCL INFO Channel 01/0 : 30[0] -> 31[1] via P2P/IPC
d14n09:567666:567892 [0] NCCL INFO Channel 03/0 : 30[0] -> 31[1] via P2P/IPC
d14n09:567666:567892 [0] NCCL INFO Channel 01/0 : 30[0] -> 32[2] via P2P/IPC
d14n09:567666:567892 [0] NCCL INFO Channel 03/0 : 30[0] -> 32[2] via P2P/IPC
d14n09:567666:567892 [0] NCCL INFO Channel 02/0 : 24[0] -> 30[0] [receive] via NET/IB/0
d14n09:567666:567892 [0] NCCL INFO Channel 00/0 : 30[0] -> 37[1] [send] via NET/IB/0
d14n09:567666:567892 [0] NCCL INFO Channel 02/0 : 19[1] -> 30[0] [receive] via NET/IB/0
d14n09:567666:567892 [0] NCCL INFO Channel 02/0 : 30[0] -> 19[1] [send] via NET/IB/0
d14n09:567666:567892 [0] NCCL INFO Channel 00/0 : 37[1] -> 30[0] [receive] via NET/IB/0
d14n09:567666:567892 [0] NCCL INFO Channel 02/0 : 30[0] -> 24[0] [send] via NET/IB/0
d14n09:567666:567892 [0] NCCL INFO Connected all trees
d14n09:567666:567892 [0] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d14n09:567666:567892 [0] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n09:567666:567892 [0] NCCL INFO comm 0x17e782de0 rank 30 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init COMPLETE
d14n11:1169356:1169356 [0] NCCL INFO cudaDriverVersion 12020
d14n11:1169356:1169356 [0] NCCL INFO Bootstrap : Using ib0:10.41.9.12<0>
d14n11:1169356:1169356 [0] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
d14n11:1169356:1169356 [0] NCCL INFO NET/Plugin : No plugin found, using internal implementation
d14n11:1169356:1169589 [0] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.9.12<0>
d14n11:1169356:1169589 [0] NCCL INFO Using network IB
d14n11:1169356:1169589 [0] NCCL INFO comm 0x151993390 rank 42 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init START
d14n11:1169356:1169589 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d14n11:1169356:1169589 [0] NCCL INFO Trees [0] 43/-1/-1->42->36 [1] 44/-1/-1->42->43 [2] 43/18/-1->42->90 [3] 44/-1/-1->42->43
d14n11:1169356:1169589 [0] NCCL INFO P2P Chunksize set to 131072
d14n11:1169356:1169589 [0] NCCL INFO Channel 00/0 : 41[5] -> 42[0] [receive] via NET/IB/0
d14n11:1169356:1169589 [0] NCCL INFO Channel 02/0 : 41[5] -> 42[0] [receive] via NET/IB/0
d14n11:1169356:1169589 [0] NCCL INFO Channel 00/0 : 42[0] -> 43[1] via P2P/IPC
d14n11:1169356:1169589 [0] NCCL INFO Channel 02/0 : 42[0] -> 43[1] via P2P/IPC
d14n11:1169356:1169589 [0] NCCL INFO Channel 01/0 : 42[0] -> 51[3] [send] via NET/IB/2
d14n11:1169356:1169589 [0] NCCL INFO Channel 03/0 : 42[0] -> 51[3] [send] via NET/IB/2
d14n11:1169356:1169589 [0] NCCL INFO Connected all rings
d14n11:1169356:1169589 [0] NCCL INFO Channel 01/0 : 42[0] -> 43[1] via P2P/IPC
d14n11:1169356:1169589 [0] NCCL INFO Channel 03/0 : 42[0] -> 43[1] via P2P/IPC
d14n11:1169356:1169589 [0] NCCL INFO Channel 01/0 : 42[0] -> 44[2] via P2P/IPC
d14n11:1169356:1169589 [0] NCCL INFO Channel 03/0 : 42[0] -> 44[2] via P2P/IPC
d14n11:1169356:1169589 [0] NCCL INFO Channel 00/0 : 36[0] -> 42[0] [receive] via NET/IB/0
d14n11:1169356:1169589 [0] NCCL INFO Channel 02/0 : 18[0] -> 42[0] [receive] via NET/IB/0
d14n11:1169356:1169589 [0] NCCL INFO Channel 02/0 : 90[0] -> 42[0] [receive] via NET/IB/0
d14n11:1169356:1169589 [0] NCCL INFO Channel 02/0 : 42[0] -> 90[0] [send] via NET/IB/0
d14n11:1169356:1169589 [0] NCCL INFO Channel 02/0 : 42[0] -> 18[0] [send] via NET/IB/0
d14n11:1169356:1169589 [0] NCCL INFO Channel 00/0 : 42[0] -> 36[0] [send] via NET/IB/0
d14n11:1169356:1169589 [0] NCCL INFO Connected all trees
d14n11:1169356:1169589 [0] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d14n11:1169356:1169589 [0] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n11:1169356:1169589 [0] NCCL INFO comm 0x151993390 rank 42 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init COMPLETE
NCCL version 2.18.3+cuda11.8
NCCL version 2.18.3+cuda11.8
d17n07:1212414:1212741 [4] NCCL INFO Using network IB
d17n07:1212414:1212741 [4] NCCL INFO comm 0x17ad8c460 rank 7 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x34523f6e9f712843 - Init START
f17n01:970276:970577 [0] NCCL INFO Using network IB
f17n01:970279:970575 [3] NCCL INFO Using network IB
f17n01:970279:970575 [3] NCCL INFO comm 0x143a29c00 rank 10 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xbe140023bc6012b4 - Init START
f17n01:970280:970574 [4] NCCL INFO Using network IB
f17n01:970280:970574 [4] NCCL INFO comm 0x13792c7a0 rank 10 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x34523f6e9f712843 - Init START
d17n07:1212415:1212739 [5] NCCL INFO Using network IB
d17n07:1212415:1212739 [5] NCCL INFO comm 0x15005a210 rank 7 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x143ee5f2cd24cdfa - Init START
f16n18:1091868:1092188 [2] NCCL INFO Using network IB
f16n18:1091868:1092188 [2] NCCL INFO comm 0x173b9f9e0 rank 9 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0x34523f6e9f712843 - Init START
d17n07:1212411:1212743 [1] NCCL INFO Using network IB
f17n01:970281:970576 [5] NCCL INFO Using network IB
f17n01:970281:970576 [5] NCCL INFO comm 0x14303bdc0 rank 10 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x143ee5f2cd24cdfa - Init START
d17n07:1212413:1212740 [3] NCCL INFO Using network IB
d17n07:1212413:1212740 [3] NCCL INFO comm 0x13668d290 rank 7 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xbe140023bc6012b4 - Init START
f16n18:1091867:1092187 [1] NCCL INFO Using network IB
f16n18:1091867:1092187 [1] NCCL INFO comm 0x15af38800 rank 9 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0xbe140023bc6012b4 - Init START
f17n01:970277:970578 [1] NCCL INFO Using network IB
f16n17:1090963:1091274 [4] NCCL INFO Using network IB
f16n17:1090960:1091270 [1] NCCL INFO Using network IB
f16n17:1090960:1091270 [1] NCCL INFO comm 0x1638dcb50 rank 8 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0x143ee5f2cd24cdfa - Init START
f16n17:1090961:1091272 [2] NCCL INFO Using network IB
f16n17:1090961:1091272 [2] NCCL INFO comm 0x124fc9e70 rank 8 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0xe95ad2ed35e9d312 - Init START
d11n16:1130271:1130583 [3] NCCL INFO Using network IB
f16n18:1091869:1092190 [3] NCCL INFO Using network IB
f16n18:1091869:1092190 [3] NCCL INFO comm 0x14fded150 rank 9 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x143ee5f2cd24cdfa - Init START
d11n16:1130268:1130579 [0] NCCL INFO Using network IB
d11n16:1130268:1130579 [0] NCCL INFO comm 0x15734c2b0 rank 1 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0xe95ad2ed35e9d312 - Init START
f18n05:1008219:1008520 [0] NCCL INFO Using network IB
f18n05:1008219:1008520 [0] NCCL INFO comm 0x15a2fb3d0 rank 11 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0x34523f6e9f712843 - Init START
f18n05:1008221:1008518 [2] NCCL INFO Using network IB
f18n05:1008221:1008518 [2] NCCL INFO comm 0x16420c870 rank 11 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0xe95ad2ed35e9d312 - Init START
f16n18:1091871:1092189 [5] NCCL INFO Using network IB
f16n17:1090964:1091275 [5] NCCL INFO Using network IB
d11n16:1130270:1130582 [2] NCCL INFO Using network IB
d11n16:1130273:1130581 [5] NCCL INFO Using network IB
d11n16:1130273:1130581 [5] NCCL INFO comm 0x1506fda10 rank 2 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xbe140023bc6012b4 - Init START
f16n18:1091870:1092186 [4] NCCL INFO Using network IB
f16n18:1091870:1092186 [4] NCCL INFO comm 0x17017f540 rank 9 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xe95ad2ed35e9d312 - Init START
f16n17:1090959:1091271 [0] NCCL INFO Using network IB
f16n17:1090959:1091271 [0] NCCL INFO comm 0x14502c2c0 rank 8 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0x34523f6e9f712843 - Init START
f16n17:1090962:1091273 [3] NCCL INFO Using network IB
f17n02:1076281:1076578 [2] NCCL INFO Using network IB
f18n05:1008222:1008521 [3] NCCL INFO Using network IB
d14n09:567670:567996 [4] NCCL INFO Using network IB
d14n09:567670:567996 [4] NCCL INFO comm 0x1666dcaa0 rank 4 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x34523f6e9f712843 - Init START
f18n05:1008223:1008522 [4] NCCL INFO Using network IB
d11n16:1130269:1130580 [1] NCCL INFO Using network IB
f18n05:1008220:1008519 [1] NCCL INFO Using network IB
f18n05:1008220:1008519 [1] NCCL INFO comm 0x168f88cd0 rank 11 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0x143ee5f2cd24cdfa - Init START
f17n02:1076284:1076577 [5] NCCL INFO Using network IB
f17n02:1076284:1076577 [5] NCCL INFO comm 0x14a72c3d0 rank 11 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xbe140023bc6012b4 - Init START
d11n17:1142859:1143155 [5] NCCL INFO Using network IB
f17n02:1076279:1076575 [0] NCCL INFO Using network IB
f17n02:1076279:1076575 [0] NCCL INFO comm 0x161bab800 rank 10 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0xe95ad2ed35e9d312 - Init START
d11n17:1142856:1143153 [2] NCCL INFO Using network IB
d11n17:1142856:1143153 [2] NCCL INFO comm 0x13bfac6d0 rank 2 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0xe95ad2ed35e9d312 - Init START
d11n17:1142855:1143152 [1] NCCL INFO Using network IB
d11n17:1142855:1143152 [1] NCCL INFO comm 0x12ef8ebf0 rank 2 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0x143ee5f2cd24cdfa - Init START
f17n02:1076280:1076576 [1] NCCL INFO Using network IB
d11n17:1142858:1143156 [4] NCCL INFO Using network IB
d11n17:1142854:1143154 [0] NCCL INFO Using network IB
d11n17:1142854:1143154 [0] NCCL INFO comm 0x15adda0e0 rank 2 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0x34523f6e9f712843 - Init START
d11n17:1142857:1143157 [3] NCCL INFO Using network IB
d09n08:1073957:1074254 [3] NCCL INFO Using network IB
d09n08:1073957:1074254 [3] NCCL INFO comm 0x1597037c0 rank 1 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xbe140023bc6012b4 - Init START
f17n02:1076282:1076579 [3] NCCL INFO Using network IB
d09n08:1073958:1074256 [4] NCCL INFO Using network IB
d09n08:1073958:1074256 [4] NCCL INFO comm 0x15113c580 rank 1 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x34523f6e9f712843 - Init START
d09n08:1073959:1074255 [5] NCCL INFO Using network IB
d09n08:1073959:1074255 [5] NCCL INFO comm 0x159e8f940 rank 1 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x143ee5f2cd24cdfa - Init START
f16n16:1079914:1080218 [2] NCCL INFO Using network IB
d09n07:1063019:1063392 [2] NCCL INFO Using network IB
d09n07:1063019:1063392 [2] NCCL INFO comm 0x16246b330 rank 0 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0x34523f6e9f712843 - Init START
d09n07:1063020:1063391 [3] NCCL INFO Using network IB
d09n07:1063020:1063391 [3] NCCL INFO comm 0x11e62c510 rank 0 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x143ee5f2cd24cdfa - Init START
d09n08:1073955:1074260 [1] NCCL INFO Using network IB
d09n07:1063021:1063389 [4] NCCL INFO Using network IB
d09n07:1063021:1063389 [4] NCCL INFO comm 0x17aaec630 rank 0 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xe95ad2ed35e9d312 - Init START
f16n16:1079912:1080216 [0] NCCL INFO Using network IB
f16n16:1079912:1080216 [0] NCCL INFO comm 0x143a43a00 rank 7 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0xe95ad2ed35e9d312 - Init START
d09n08:1073954:1074259 [0] NCCL INFO Using network IB
d14n10:565682:565992 [1] NCCL INFO Using network IB
f16n16:1079913:1080215 [1] NCCL INFO Using network IB
f16n16:1079915:1080219 [3] NCCL INFO Using network IB
f16n16:1079917:1080217 [5] NCCL INFO Using network IB
f16n16:1079917:1080217 [5] NCCL INFO comm 0x170fca5c0 rank 8 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xbe140023bc6012b4 - Init START
d14n09:567667:567994 [1] NCCL INFO Using network IB
d14n09:567667:567994 [1] NCCL INFO comm 0x15073d9e0 rank 3 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0xe9f19695db992363 - Init START
d14n10:565683:565994 [2] NCCL INFO Using network IB
d14n10:565683:565994 [2] NCCL INFO comm 0x12ce9bea0 rank 4 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0xeeef2eab3be148e1 - Init START
d09n07:1063018:1063394 [1] NCCL INFO Using network IB
d09n07:1063018:1063394 [1] NCCL INFO comm 0x12544c9d0 rank 0 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0xbe140023bc6012b4 - Init START
d14n09:567666:567998 [0] NCCL INFO Using network IB
d14n09:567666:567998 [0] NCCL INFO comm 0x181ddc4b0 rank 3 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0xeeef2eab3be148e1 - Init START
d14n09:567671:567995 [5] NCCL INFO Using network IB
d14n09:567671:567995 [5] NCCL INFO comm 0x137c75700 rank 4 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x143ee5f2cd24cdfa - Init START
d14n10:565686:565993 [5] NCCL INFO Using network IB
d14n10:565686:565993 [5] NCCL INFO comm 0x117fa8f10 rank 5 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xbe140023bc6012b4 - Init START
d14n11:1169358:1169673 [2] NCCL INFO Using network IB
d14n11:1169358:1169673 [2] NCCL INFO comm 0x1425ec5d0 rank 5 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0xe95ad2ed35e9d312 - Init START
d14n08:1173248:1173568 [1] NCCL INFO Using network IB
d14n08:1173248:1173568 [1] NCCL INFO comm 0x139de8e90 rank 3 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0xbe140023bc6012b4 - Init START
d09n07:1063022:1063390 [5] NCCL INFO Using network IB
d09n07:1063022:1063390 [5] NCCL INFO comm 0x168eccf80 rank 0 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xd3b159694d72ff62 - Init START
d14n11:1169357:1169672 [1] NCCL INFO Using network IB
d14n11:1169357:1169672 [1] NCCL INFO comm 0x1302b2100 rank 5 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0x143ee5f2cd24cdfa - Init START
d14n08:1173251:1173565 [4] NCCL INFO Using network IB
d14n08:1173251:1173565 [4] NCCL INFO comm 0x15f8cc440 rank 3 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xe95ad2ed35e9d312 - Init START
d14n08:1173252:1173564 [5] NCCL INFO Using network IB
d14n08:1173252:1173564 [5] NCCL INFO comm 0x1339a7e80 rank 3 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xd3b159694d72ff62 - Init START
d14n11:1169356:1169677 [0] NCCL INFO Using network IB
d14n11:1169356:1169677 [0] NCCL INFO comm 0x154fe6d70 rank 5 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0x34523f6e9f712843 - Init START
d14n10:565684:565995 [3] NCCL INFO Using network IB
d14n10:565684:565995 [3] NCCL INFO comm 0x12bc5a300 rank 4 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xe9f19695db992363 - Init START
d14n08:1173249:1173567 [2] NCCL INFO Using network IB
d14n08:1173249:1173567 [2] NCCL INFO comm 0x1521dc770 rank 3 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0x34523f6e9f712843 - Init START
d14n08:1173250:1173566 [3] NCCL INFO Using network IB
d14n08:1173250:1173566 [3] NCCL INFO comm 0x16754bd40 rank 3 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x143ee5f2cd24cdfa - Init START
d14n09:567669:567997 [3] NCCL INFO Using network IB
d14n09:567669:567997 [3] NCCL INFO comm 0x149ab7540 rank 4 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xbe140023bc6012b4 - Init START
d14n11:1169360:1169676 [4] NCCL INFO Using network IB
d14n11:1169360:1169676 [4] NCCL INFO comm 0x117e4bd70 rank 5 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xeeef2eab3be148e1 - Init START
d14n10:565681:565991 [0] NCCL INFO Using network IB
d14n10:565681:565991 [0] NCCL INFO comm 0x1660dcd40 rank 4 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0xe95ad2ed35e9d312 - Init START
d17n06:1216532:1216861 [2] NCCL INFO Using network IB
d17n06:1216532:1216861 [2] NCCL INFO comm 0x13155d730 rank 6 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0x34523f6e9f712843 - Init START
f18n05:1008224:1008523 [5] NCCL INFO Using network IB
f18n05:1008224:1008523 [5] NCCL INFO comm 0x14dae4b00 rank 11 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xe9f19695db992363 - Init START
d14n11:1169359:1169675 [3] NCCL INFO Using network IB
d14n11:1169359:1169675 [3] NCCL INFO comm 0x1688666f0 rank 5 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xd3b159694d72ff62 - Init START
d14n11:1169361:1169674 [5] NCCL INFO Using network IB
d14n11:1169361:1169674 [5] NCCL INFO comm 0x124b6cf40 rank 5 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xe9f19695db992363 - Init START
d17n06:1216531:1216860 [1] NCCL INFO Using network IB
d17n06:1216531:1216860 [1] NCCL INFO comm 0x12335b640 rank 6 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0xbe140023bc6012b4 - Init START
d17n06:1216534:1216862 [4] NCCL INFO Using network IB
d17n06:1216534:1216862 [4] NCCL INFO comm 0x12b3cd110 rank 6 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xe95ad2ed35e9d312 - Init START
d17n06:1216535:1216864 [5] NCCL INFO Using network IB
d17n06:1216535:1216864 [5] NCCL INFO comm 0x13c8dc380 rank 6 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xd3b159694d72ff62 - Init START
d17n06:1216533:1216863 [3] NCCL INFO Using network IB
d17n06:1216533:1216863 [3] NCCL INFO comm 0x13f64cc30 rank 6 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x143ee5f2cd24cdfa - Init START
d17n07:1212410:1212742 [0] NCCL INFO Using network IB
d17n07:1212410:1212742 [0] NCCL INFO comm 0x17138c480 rank 6 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0xeeef2eab3be148e1 - Init START
d09n07:1063016:1063303 [0] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_3:1/IB [2]mlx5_0:1/IB [3]mlx5_2:1/IB ; OOB ib0:10.41.8.171<0>
d09n07:1063016:1063303 [0] NCCL INFO Using network IB
d09n07:1063016:1063303 [0] NCCL INFO comm 0x13b8d4570 rank 0 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init START
d09n07:1063016:1063303 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d09n07:1063016:1063303 [0] NCCL INFO Channel 00/04 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19
d09n07:1063016:1063303 [0] NCCL INFO Channel 01/04 :    0   9  10  11   8   7   6  15  16  17  14  13  12  21  22  23  20  19  18  27
d09n07:1063016:1063303 [0] NCCL INFO Channel 02/04 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19
d09n07:1063016:1063303 [0] NCCL INFO Channel 03/04 :    0   9  10  11   8   7   6  15  16  17  14  13  12  21  22  23  20  19  18  27
d09n07:1063016:1063303 [0] NCCL INFO Trees [0] 1/48/-1->0->-1 [1] 2/-1/-1->0->1 [2] 1/-1/-1->0->6 [3] 2/-1/-1->0->1
d09n07:1063016:1063303 [0] NCCL INFO P2P Chunksize set to 131072
d09n07:1063016:1063303 [0] NCCL INFO Channel 00/0 : 95[5] -> 0[0] [receive] via NET/IB/0
d09n07:1063016:1063303 [0] NCCL INFO Channel 02/0 : 95[5] -> 0[0] [receive] via NET/IB/0
d09n07:1063016:1063303 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/IPC
d09n07:1063016:1063303 [0] NCCL INFO Channel 02/0 : 0[0] -> 1[1] via P2P/IPC
d09n07:1063016:1063303 [0] NCCL INFO Channel 01/0 : 0[0] -> 9[3] [send] via NET/IB/2
d09n07:1063016:1063303 [0] NCCL INFO Channel 03/0 : 0[0] -> 9[3] [send] via NET/IB/2
d09n07:1063016:1063303 [0] NCCL INFO Connected all rings
d09n07:1063016:1063303 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/IPC
d09n07:1063016:1063303 [0] NCCL INFO Channel 03/0 : 0[0] -> 1[1] via P2P/IPC
d09n07:1063016:1063303 [0] NCCL INFO Channel 01/0 : 0[0] -> 2[2] via P2P/IPC
d09n07:1063016:1063303 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/IPC
d09n07:1063016:1063303 [0] NCCL INFO Channel 02/0 : 0[0] -> 6[0] [send] via NET/IB/0
d09n07:1063016:1063303 [0] NCCL INFO Channel 00/0 : 48[0] -> 0[0] [receive] via NET/IB/0
d09n07:1063016:1063303 [0] NCCL INFO Channel 00/0 : 0[0] -> 48[0] [send] via NET/IB/0
d09n07:1063016:1063303 [0] NCCL INFO Channel 02/0 : 6[0] -> 0[0] [receive] via NET/IB/0
d09n07:1063016:1063303 [0] NCCL INFO Connected all trees
d09n07:1063016:1063303 [0] NCCL INFO threadThresholds 8/8/64 | 768/8/64 | 512 | 512
d09n07:1063016:1063303 [0] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d09n07:1063016:1063303 [0] NCCL INFO comm 0x13b8d4570 rank 0 nranks 96 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa35f79647b16dded - Init COMPLETE
stage=0 layers=37
     0: _to_float16
     1: EmbeddingPipe
     2: ParallelTransformerLayerPipe
     3: ParallelTransformerLayerPipe
     4: ParallelTransformerLayerPipe
     5: ParallelTransformerLayerPipe
     6: ParallelTransformerLayerPipe
     7: ParallelTransformerLayerPipe
     8: ParallelTransformerLayerPipe
     9: ParallelTransformerLayerPipe
    10: ParallelTransformerLayerPipe
    11: ParallelTransformerLayerPipe
    12: ParallelTransformerLayerPipe
    13: ParallelTransformerLayerPipe
    14: ParallelTransformerLayerPipe
    15: ParallelTransformerLayerPipe
    16: ParallelTransformerLayerPipe
    17: ParallelTransformerLayerPipe
    18: ParallelTransformerLayerPipe
    19: ParallelTransformerLayerPipe
    20: ParallelTransformerLayerPipe
    21: ParallelTransformerLayerPipe
    22: ParallelTransformerLayerPipe
    23: ParallelTransformerLayerPipe
    24: ParallelTransformerLayerPipe
    25: ParallelTransformerLayerPipe
    26: ParallelTransformerLayerPipe
    27: ParallelTransformerLayerPipe
    28: ParallelTransformerLayerPipe
    29: ParallelTransformerLayerPipe
    30: ParallelTransformerLayerPipe
    31: ParallelTransformerLayerPipe
    32: ParallelTransformerLayerPipe
    33: ParallelTransformerLayerPipe
    34: MixedFusedLayerNorm
    35: EmbeddingPipe
    36: float16_to_fp32
  loss: CrossEntropy
[2024-03-04 16:46:25,122] [INFO] [utils.py:785:see_memory_usage] After Building Model
[2024-03-04 16:46:25,123] [INFO] [utils.py:786:see_memory_usage] MA 1.59 GB         Max_MA 1.61 GB         CA 1.62 GB         Max_CA 2 GB 
[2024-03-04 16:46:25,123] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 58.46 GB, percent = 9.8%
 > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 840818688
> learning rate decay style: cosine
DeepSpeed is enabled.
[2024-03-04 16:46:25,130] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.0+f5c834a6e, git-hash=f5c834a6e, git-branch=HEAD
f17n02:1076284:1076577 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
f17n02:1076284:1076577 [5] NCCL INFO Trees [0] -1/-1/-1->11->10 [1] 3/-1/-1->11->-1
f17n02:1076284:1076577 [5] NCCL INFO P2P Chunksize set to 131072
f17n02:1076284:1076577 [5] NCCL INFO Channel 00/0 : 10[3] -> 11[5] [receive] via NET/IB/3
f17n02:1076284:1076577 [5] NCCL INFO Channel 01/0 : 10[3] -> 11[5] [receive] via NET/IB/3
f17n02:1076284:1076577 [5] NCCL INFO Channel 00/0 : 11[5] -> 0[1] [send] via NET/IB/3
f17n02:1076284:1076577 [5] NCCL INFO Channel 01/0 : 11[5] -> 0[1] [send] via NET/IB/3
d17n06:1216531:1216860 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d17n06:1216531:1216860 [1] NCCL INFO Trees [0] 5/7/-1->6->4 [1] -1/-1/-1->6->5
d17n06:1216531:1216860 [1] NCCL INFO P2P Chunksize set to 131072
d17n06:1216531:1216860 [1] NCCL INFO Channel 00/0 : 5[5] -> 6[1] [receive] via NET/IB/2
d17n06:1216531:1216860 [1] NCCL INFO Channel 01/0 : 5[5] -> 6[1] [receive] via NET/IB/2
d17n06:1216531:1216860 [1] NCCL INFO Channel 00/0 : 6[1] -> 7[3] [send] via NET/IB/2
d17n06:1216531:1216860 [1] NCCL INFO Channel 01/0 : 6[1] -> 7[3] [send] via NET/IB/2
d09n07:1063018:1063394 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d09n07:1063018:1063394 [1] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7   8   9  10  11
d09n07:1063018:1063394 [1] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7   8   9  10  11
d09n07:1063018:1063394 [1] NCCL INFO Trees [0] 8/-1/-1->0->-1 [1] -1/-1/-1->0->1
d09n07:1063018:1063394 [1] NCCL INFO P2P Chunksize set to 131072
d09n07:1063018:1063394 [1] NCCL INFO Channel 00/0 : 11[5] -> 0[1] [receive] via NET/IB/2
d09n07:1063018:1063394 [1] NCCL INFO Channel 01/0 : 11[5] -> 0[1] [receive] via NET/IB/2
d09n07:1063018:1063394 [1] NCCL INFO Channel 00/0 : 0[1] -> 1[3] [send] via NET/IB/2
d09n07:1063018:1063394 [1] NCCL INFO Channel 01/0 : 0[1] -> 1[3] [send] via NET/IB/2
d09n08:1073957:1074254 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d09n08:1073957:1074254 [3] NCCL INFO Trees [0] -1/-1/-1->1->2 [1] 2/0/-1->1->3
d09n08:1073957:1074254 [3] NCCL INFO P2P Chunksize set to 131072
d09n08:1073957:1074254 [3] NCCL INFO Channel 00/0 : 0[1] -> 1[3] [receive] via NET/IB/3
d09n08:1073957:1074254 [3] NCCL INFO Channel 01/0 : 0[1] -> 1[3] [receive] via NET/IB/3
d09n08:1073957:1074254 [3] NCCL INFO Channel 00/0 : 1[3] -> 2[5] [send] via NET/IB/3
d09n08:1073957:1074254 [3] NCCL INFO Channel 01/0 : 1[3] -> 2[5] [send] via NET/IB/3
d11n16:1130273:1130581 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d11n16:1130273:1130581 [5] NCCL INFO Trees [0] 1/3/-1->2->4 [1] -1/-1/-1->2->1
d11n16:1130273:1130581 [5] NCCL INFO P2P Chunksize set to 131072
d11n16:1130273:1130581 [5] NCCL INFO Channel 00/0 : 1[3] -> 2[5] [receive] via NET/IB/3
d11n16:1130273:1130581 [5] NCCL INFO Channel 01/0 : 1[3] -> 2[5] [receive] via NET/IB/3
d11n16:1130273:1130581 [5] NCCL INFO Channel 00/0 : 2[5] -> 3[1] [send] via NET/IB/3
d11n16:1130273:1130581 [5] NCCL INFO Channel 01/0 : 2[5] -> 3[1] [send] via NET/IB/3
d09n07:1063020:1063391 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d09n07:1063020:1063391 [3] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7   8   9  10  11
d09n07:1063020:1063391 [3] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7   8   9  10  11
d09n07:1063020:1063391 [3] NCCL INFO Trees [0] 8/-1/-1->0->-1 [1] -1/-1/-1->0->1
d09n07:1063020:1063391 [3] NCCL INFO P2P Chunksize set to 131072
d09n07:1063020:1063391 [3] NCCL INFO Channel 00/0 : 11[1] -> 0[3] [receive] via NET/IB/3
d09n07:1063020:1063391 [3] NCCL INFO Channel 01/0 : 11[1] -> 0[3] [receive] via NET/IB/3
d09n07:1063020:1063391 [3] NCCL INFO Channel 00/0 : 0[3] -> 1[5] [send] via NET/IB/3
d09n07:1063020:1063391 [3] NCCL INFO Channel 01/0 : 0[3] -> 1[5] [send] via NET/IB/3
d17n07:1212415:1212739 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d17n07:1212415:1212739 [5] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] 9/5/-1->7->3
d17n07:1212415:1212739 [5] NCCL INFO P2P Chunksize set to 131072
d17n07:1212415:1212739 [5] NCCL INFO Channel 00/0 : 6[3] -> 7[5] [receive] via NET/IB/3
d17n07:1212415:1212739 [5] NCCL INFO Channel 01/0 : 6[3] -> 7[5] [receive] via NET/IB/3
d17n07:1212415:1212739 [5] NCCL INFO Channel 00/0 : 7[5] -> 8[1] [send] via NET/IB/3
d17n07:1212415:1212739 [5] NCCL INFO Channel 01/0 : 7[5] -> 8[1] [send] via NET/IB/3
f17n01:970280:970574 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
f17n01:970280:970574 [4] NCCL INFO Trees [0] 9/11/-1->10->8 [1] -1/-1/-1->10->9
f17n01:970280:970574 [4] NCCL INFO P2P Chunksize set to 131072
f17n01:970280:970574 [4] NCCL INFO Channel 00/0 : 9[2] -> 10[4] [receive] via NET/IB/1
f17n01:970280:970574 [4] NCCL INFO Channel 01/0 : 9[2] -> 10[4] [receive] via NET/IB/1
f17n01:970280:970574 [4] NCCL INFO Channel 00/0 : 10[4] -> 11[0] [send] via NET/IB/1
f17n01:970280:970574 [4] NCCL INFO Channel 01/0 : 10[4] -> 11[0] [send] via NET/IB/1
f17n01:970279:970575 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
f17n01:970279:970575 [3] NCCL INFO Trees [0] 9/11/-1->10->8 [1] -1/-1/-1->10->9
f17n01:970279:970575 [3] NCCL INFO P2P Chunksize set to 131072
f17n01:970279:970575 [3] NCCL INFO Channel 00/0 : 9[1] -> 10[3] [receive] via NET/IB/3
f17n01:970279:970575 [3] NCCL INFO Channel 01/0 : 9[1] -> 10[3] [receive] via NET/IB/3
f17n01:970279:970575 [3] NCCL INFO Channel 00/0 : 10[3] -> 11[5] [send] via NET/IB/3
f17n01:970279:970575 [3] NCCL INFO Channel 01/0 : 10[3] -> 11[5] [send] via NET/IB/3
d17n07:1212413:1212740 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d17n07:1212413:1212740 [3] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] 9/5/-1->7->3
d17n07:1212413:1212740 [3] NCCL INFO P2P Chunksize set to 131072
d17n07:1212413:1212740 [3] NCCL INFO Channel 00/0 : 6[1] -> 7[3] [receive] via NET/IB/3
d17n07:1212413:1212740 [3] NCCL INFO Channel 01/0 : 6[1] -> 7[3] [receive] via NET/IB/3
d17n07:1212413:1212740 [3] NCCL INFO Channel 00/0 : 7[3] -> 8[5] [send] via NET/IB/3
d17n07:1212413:1212740 [3] NCCL INFO Channel 01/0 : 7[3] -> 8[5] [send] via NET/IB/3
f18n05:1008219:1008520 [0] NCCL INFO Setting affinity for GPU 0 to 0f
f18n05:1008219:1008520 [0] NCCL INFO Trees [0] -1/-1/-1->11->10 [1] 3/-1/-1->11->-1
f18n05:1008219:1008520 [0] NCCL INFO P2P Chunksize set to 131072
f18n05:1008219:1008520 [0] NCCL INFO Channel 00/0 : 10[4] -> 11[0] [receive] via NET/IB/0
f18n05:1008219:1008520 [0] NCCL INFO Channel 01/0 : 10[4] -> 11[0] [receive] via NET/IB/0
f18n05:1008219:1008520 [0] NCCL INFO Channel 00/0 : 11[0] -> 0[2] [send] via NET/IB/0
f18n05:1008219:1008520 [0] NCCL INFO Channel 01/0 : 11[0] -> 0[2] [send] via NET/IB/0
d09n07:1063019:1063392 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d09n07:1063019:1063392 [2] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7   8   9  10  11
d09n07:1063019:1063392 [2] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7   8   9  10  11
d09n07:1063019:1063392 [2] NCCL INFO Trees [0] 8/-1/-1->0->-1 [1] -1/-1/-1->0->1
d09n07:1063019:1063392 [2] NCCL INFO P2P Chunksize set to 131072
d09n07:1063019:1063392 [2] NCCL INFO Channel 00/0 : 11[0] -> 0[2] [receive] via NET/IB/0
d09n07:1063019:1063392 [2] NCCL INFO Channel 01/0 : 11[0] -> 0[2] [receive] via NET/IB/0
d09n07:1063019:1063392 [2] NCCL INFO Channel 00/0 : 0[2] -> 1[4] [send] via NET/IB/0
d09n07:1063019:1063392 [2] NCCL INFO Channel 01/0 : 0[2] -> 1[4] [send] via NET/IB/0
d14n09:567671:567995 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d14n09:567671:567995 [5] NCCL INFO Trees [0] 2/6/-1->4->8 [1] -1/-1/-1->4->5
d14n09:567671:567995 [5] NCCL INFO P2P Chunksize set to 131072
d14n09:567671:567995 [5] NCCL INFO Channel 00/0 : 3[3] -> 4[5] [receive] via NET/IB/3
d14n09:567671:567995 [5] NCCL INFO Channel 01/0 : 3[3] -> 4[5] [receive] via NET/IB/3
d14n09:567671:567995 [5] NCCL INFO Channel 00/0 : 4[5] -> 5[1] [send] via NET/IB/3
d14n09:567671:567995 [5] NCCL INFO Channel 01/0 : 4[5] -> 5[1] [send] via NET/IB/3
d17n07:1212414:1212741 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d17n07:1212414:1212741 [4] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] 9/5/-1->7->3
d17n07:1212414:1212741 [4] NCCL INFO P2P Chunksize set to 131072
d17n07:1212414:1212741 [4] NCCL INFO Channel 00/0 : 6[2] -> 7[4] [receive] via NET/IB/1
d17n07:1212414:1212741 [4] NCCL INFO Channel 01/0 : 6[2] -> 7[4] [receive] via NET/IB/1
d17n07:1212414:1212741 [4] NCCL INFO Channel 00/0 : 7[4] -> 8[0] [send] via NET/IB/1
d17n07:1212414:1212741 [4] NCCL INFO Channel 01/0 : 7[4] -> 8[0] [send] via NET/IB/1
d09n08:1073958:1074256 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d09n08:1073958:1074256 [4] NCCL INFO Trees [0] -1/-1/-1->1->2 [1] 2/0/-1->1->3
d09n08:1073958:1074256 [4] NCCL INFO P2P Chunksize set to 131072
d09n08:1073958:1074256 [4] NCCL INFO Channel 00/0 : 0[2] -> 1[4] [receive] via NET/IB/1
d09n08:1073958:1074256 [4] NCCL INFO Channel 01/0 : 0[2] -> 1[4] [receive] via NET/IB/1
d09n08:1073958:1074256 [4] NCCL INFO Channel 00/0 : 1[4] -> 2[0] [send] via NET/IB/1
d09n08:1073958:1074256 [4] NCCL INFO Channel 01/0 : 1[4] -> 2[0] [send] via NET/IB/1
d11n17:1142854:1143154 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d11n17:1142854:1143154 [0] NCCL INFO Trees [0] 1/3/-1->2->4 [1] -1/-1/-1->2->1
d11n17:1142854:1143154 [0] NCCL INFO P2P Chunksize set to 131072
d11n17:1142854:1143154 [0] NCCL INFO Channel 00/0 : 1[4] -> 2[0] [receive] via NET/IB/0
d11n17:1142854:1143154 [0] NCCL INFO Channel 01/0 : 1[4] -> 2[0] [receive] via NET/IB/0
d11n17:1142854:1143154 [0] NCCL INFO Channel 00/0 : 2[0] -> 3[2] [send] via NET/IB/0
d11n17:1142854:1143154 [0] NCCL INFO Channel 01/0 : 2[0] -> 3[2] [send] via NET/IB/0
f16n18:1091868:1092188 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
f16n18:1091868:1092188 [2] NCCL INFO Trees [0] -1/-1/-1->9->10 [1] 10/8/-1->9->7
f16n18:1091868:1092188 [2] NCCL INFO P2P Chunksize set to 131072
f16n18:1091868:1092188 [2] NCCL INFO Channel 00/0 : 8[0] -> 9[2] [receive] via NET/IB/0
f16n18:1091868:1092188 [2] NCCL INFO Channel 01/0 : 8[0] -> 9[2] [receive] via NET/IB/0
f16n18:1091868:1092188 [2] NCCL INFO Channel 00/0 : 9[2] -> 10[4] [send] via NET/IB/0
f16n18:1091868:1092188 [2] NCCL INFO Channel 01/0 : 9[2] -> 10[4] [send] via NET/IB/0
d17n06:1216532:1216861 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d17n06:1216532:1216861 [2] NCCL INFO Trees [0] 5/7/-1->6->4 [1] -1/-1/-1->6->5
d17n06:1216532:1216861 [2] NCCL INFO P2P Chunksize set to 131072
d17n06:1216532:1216861 [2] NCCL INFO Channel 00/0 : 5[0] -> 6[2] [receive] via NET/IB/0
d17n06:1216532:1216861 [2] NCCL INFO Channel 01/0 : 5[0] -> 6[2] [receive] via NET/IB/0
d17n06:1216532:1216861 [2] NCCL INFO Channel 00/0 : 6[2] -> 7[4] [send] via NET/IB/0
d17n06:1216532:1216861 [2] NCCL INFO Channel 01/0 : 6[2] -> 7[4] [send] via NET/IB/0
f18n05:1008220:1008519 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
f18n05:1008220:1008519 [1] NCCL INFO Trees [0] -1/-1/-1->11->10 [1] 3/-1/-1->11->-1
f18n05:1008220:1008519 [1] NCCL INFO P2P Chunksize set to 131072
f18n05:1008220:1008519 [1] NCCL INFO Channel 00/0 : 10[5] -> 11[1] [receive] via NET/IB/2
f18n05:1008220:1008519 [1] NCCL INFO Channel 01/0 : 10[5] -> 11[1] [receive] via NET/IB/2
f18n05:1008220:1008519 [1] NCCL INFO Channel 00/0 : 11[1] -> 0[3] [send] via NET/IB/2
f18n05:1008220:1008519 [1] NCCL INFO Channel 01/0 : 11[1] -> 0[3] [send] via NET/IB/2
d17n06:1216533:1216863 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d17n06:1216533:1216863 [3] NCCL INFO Trees [0] 5/7/-1->6->4 [1] -1/-1/-1->6->5
d17n06:1216533:1216863 [3] NCCL INFO P2P Chunksize set to 131072
d17n06:1216533:1216863 [3] NCCL INFO Channel 00/0 : 5[1] -> 6[3] [receive] via NET/IB/3
d17n06:1216533:1216863 [3] NCCL INFO Channel 01/0 : 5[1] -> 6[3] [receive] via NET/IB/3
d17n06:1216533:1216863 [3] NCCL INFO Channel 00/0 : 6[3] -> 7[5] [send] via NET/IB/3
d17n06:1216533:1216863 [3] NCCL INFO Channel 01/0 : 6[3] -> 7[5] [send] via NET/IB/3
d11n17:1142855:1143152 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d11n17:1142855:1143152 [1] NCCL INFO Trees [0] 1/3/-1->2->4 [1] -1/-1/-1->2->1
d11n17:1142855:1143152 [1] NCCL INFO P2P Chunksize set to 131072
d11n17:1142855:1143152 [1] NCCL INFO Channel 00/0 : 1[5] -> 2[1] [receive] via NET/IB/2
d11n17:1142855:1143152 [1] NCCL INFO Channel 01/0 : 1[5] -> 2[1] [receive] via NET/IB/2
d11n17:1142855:1143152 [1] NCCL INFO Channel 00/0 : 2[1] -> 3[3] [send] via NET/IB/2
d11n17:1142855:1143152 [1] NCCL INFO Channel 01/0 : 2[1] -> 3[3] [send] via NET/IB/2
f16n17:1090960:1091270 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
f16n17:1090960:1091270 [1] NCCL INFO Trees [0] 4/10/-1->8->0 [1] -1/-1/-1->8->9
f16n17:1090960:1091270 [1] NCCL INFO P2P Chunksize set to 131072
f16n17:1090960:1091270 [1] NCCL INFO Channel 00/0 : 7[5] -> 8[1] [receive] via NET/IB/2
f16n17:1090960:1091270 [1] NCCL INFO Channel 01/0 : 7[5] -> 8[1] [receive] via NET/IB/2
f16n17:1090960:1091270 [1] NCCL INFO Channel 00/0 : 8[1] -> 9[3] [send] via NET/IB/2
f16n17:1090960:1091270 [1] NCCL INFO Channel 01/0 : 8[1] -> 9[3] [send] via NET/IB/2
d14n10:565686:565993 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d14n10:565686:565993 [5] NCCL INFO Trees [0] -1/-1/-1->5->6 [1] 6/4/-1->5->7
d14n10:565686:565993 [5] NCCL INFO P2P Chunksize set to 131072
d14n10:565686:565993 [5] NCCL INFO Channel 00/0 : 4[3] -> 5[5] [receive] via NET/IB/3
d14n10:565686:565993 [5] NCCL INFO Channel 01/0 : 4[3] -> 5[5] [receive] via NET/IB/3
d14n10:565686:565993 [5] NCCL INFO Channel 00/0 : 5[5] -> 6[1] [send] via NET/IB/3
d14n10:565686:565993 [5] NCCL INFO Channel 01/0 : 5[5] -> 6[1] [send] via NET/IB/3
d09n08:1073959:1074255 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d09n08:1073959:1074255 [5] NCCL INFO Trees [0] -1/-1/-1->1->2 [1] 2/0/-1->1->3
d09n08:1073959:1074255 [5] NCCL INFO P2P Chunksize set to 131072
d09n08:1073959:1074255 [5] NCCL INFO Channel 00/0 : 0[3] -> 1[5] [receive] via NET/IB/3
d09n08:1073959:1074255 [5] NCCL INFO Channel 01/0 : 0[3] -> 1[5] [receive] via NET/IB/3
d09n08:1073959:1074255 [5] NCCL INFO Channel 00/0 : 1[5] -> 2[1] [send] via NET/IB/3
d09n08:1073959:1074255 [5] NCCL INFO Channel 01/0 : 1[5] -> 2[1] [send] via NET/IB/3
d14n09:567670:567996 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d14n09:567670:567996 [4] NCCL INFO Trees [0] 2/6/-1->4->8 [1] -1/-1/-1->4->5
d14n09:567670:567996 [4] NCCL INFO P2P Chunksize set to 131072
d14n09:567670:567996 [4] NCCL INFO Channel 00/0 : 3[2] -> 4[4] [receive] via NET/IB/1
d14n09:567670:567996 [4] NCCL INFO Channel 01/0 : 3[2] -> 4[4] [receive] via NET/IB/1
d14n09:567670:567996 [4] NCCL INFO Channel 00/0 : 4[4] -> 5[0] [send] via NET/IB/1
d14n09:567670:567996 [4] NCCL INFO Channel 01/0 : 4[4] -> 5[0] [send] via NET/IB/1
f17n01:970281:970576 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
f17n01:970281:970576 [5] NCCL INFO Trees [0] 9/11/-1->10->8 [1] -1/-1/-1->10->9
f17n01:970281:970576 [5] NCCL INFO P2P Chunksize set to 131072
f17n01:970281:970576 [5] NCCL INFO Channel 00/0 : 9[3] -> 10[5] [receive] via NET/IB/3
f17n01:970281:970576 [5] NCCL INFO Channel 01/0 : 9[3] -> 10[5] [receive] via NET/IB/3
f17n01:970281:970576 [5] NCCL INFO Channel 00/0 : 10[5] -> 11[1] [send] via NET/IB/3
f17n01:970281:970576 [5] NCCL INFO Channel 01/0 : 10[5] -> 11[1] [send] via NET/IB/3
f16n17:1090959:1091271 [0] NCCL INFO Setting affinity for GPU 0 to 0f
f16n17:1090959:1091271 [0] NCCL INFO Trees [0] 4/10/-1->8->0 [1] -1/-1/-1->8->9
f16n17:1090959:1091271 [0] NCCL INFO P2P Chunksize set to 131072
f16n17:1090959:1091271 [0] NCCL INFO Channel 00/0 : 7[4] -> 8[0] [receive] via NET/IB/0
f16n17:1090959:1091271 [0] NCCL INFO Channel 01/0 : 7[4] -> 8[0] [receive] via NET/IB/0
f16n17:1090959:1091271 [0] NCCL INFO Channel 00/0 : 8[0] -> 9[2] [send] via NET/IB/0
f16n17:1090959:1091271 [0] NCCL INFO Channel 01/0 : 8[0] -> 9[2] [send] via NET/IB/0
f16n18:1091867:1092187 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
f16n18:1091867:1092187 [1] NCCL INFO Trees [0] -1/-1/-1->9->10 [1] 10/8/-1->9->7
f16n18:1091867:1092187 [1] NCCL INFO P2P Chunksize set to 131072
f16n18:1091867:1092187 [1] NCCL INFO Channel 00/0 : 8[5] -> 9[1] [receive] via NET/IB/2
f16n18:1091867:1092187 [1] NCCL INFO Channel 01/0 : 8[5] -> 9[1] [receive] via NET/IB/2
f16n18:1091867:1092187 [1] NCCL INFO Channel 00/0 : 9[1] -> 10[3] [send] via NET/IB/2
f16n18:1091867:1092187 [1] NCCL INFO Channel 01/0 : 9[1] -> 10[3] [send] via NET/IB/2
d14n09:567669:567997 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d14n09:567669:567997 [3] NCCL INFO Trees [0] 2/6/-1->4->8 [1] -1/-1/-1->4->5
d14n09:567669:567997 [3] NCCL INFO P2P Chunksize set to 131072
d14n09:567669:567997 [3] NCCL INFO Channel 00/0 : 3[1] -> 4[3] [receive] via NET/IB/3
d14n09:567669:567997 [3] NCCL INFO Channel 01/0 : 3[1] -> 4[3] [receive] via NET/IB/3
d14n09:567669:567997 [3] NCCL INFO Channel 00/0 : 4[3] -> 5[5] [send] via NET/IB/3
d14n09:567669:567997 [3] NCCL INFO Channel 01/0 : 4[3] -> 5[5] [send] via NET/IB/3
f16n18:1091869:1092190 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
f16n18:1091869:1092190 [3] NCCL INFO Trees [0] -1/-1/-1->9->10 [1] 10/8/-1->9->7
f16n18:1091869:1092190 [3] NCCL INFO P2P Chunksize set to 131072
f16n18:1091869:1092190 [3] NCCL INFO Channel 00/0 : 8[1] -> 9[3] [receive] via NET/IB/3
f16n18:1091869:1092190 [3] NCCL INFO Channel 01/0 : 8[1] -> 9[3] [receive] via NET/IB/3
f16n18:1091869:1092190 [3] NCCL INFO Channel 00/0 : 9[3] -> 10[5] [send] via NET/IB/3
f16n18:1091869:1092190 [3] NCCL INFO Channel 01/0 : 9[3] -> 10[5] [send] via NET/IB/3
f16n16:1079917:1080217 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
f16n16:1079917:1080217 [5] NCCL INFO Trees [0] 4/10/-1->8->0 [1] -1/-1/-1->8->9
f16n16:1079917:1080217 [5] NCCL INFO P2P Chunksize set to 131072
f16n16:1079917:1080217 [5] NCCL INFO Channel 00/0 : 7[3] -> 8[5] [receive] via NET/IB/3
f16n16:1079917:1080217 [5] NCCL INFO Channel 01/0 : 7[3] -> 8[5] [receive] via NET/IB/3
f16n16:1079917:1080217 [5] NCCL INFO Channel 00/0 : 8[5] -> 9[1] [send] via NET/IB/3
f16n16:1079917:1080217 [5] NCCL INFO Channel 01/0 : 8[5] -> 9[1] [send] via NET/IB/3
d14n08:1173250:1173566 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d14n08:1173250:1173566 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] 7/1/-1->3->11
d14n08:1173250:1173566 [3] NCCL INFO P2P Chunksize set to 131072
d14n08:1173250:1173566 [3] NCCL INFO Channel 00/0 : 2[1] -> 3[3] [receive] via NET/IB/3
d14n08:1173250:1173566 [3] NCCL INFO Channel 01/0 : 2[1] -> 3[3] [receive] via NET/IB/3
d14n08:1173250:1173566 [3] NCCL INFO Channel 00/0 : 3[3] -> 4[5] [send] via NET/IB/3
d14n08:1173250:1173566 [3] NCCL INFO Channel 01/0 : 3[3] -> 4[5] [send] via NET/IB/3
d14n11:1169357:1169672 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d14n11:1169357:1169672 [1] NCCL INFO Trees [0] -1/-1/-1->5->6 [1] 6/4/-1->5->7
d14n11:1169357:1169672 [1] NCCL INFO P2P Chunksize set to 131072
d14n11:1169357:1169672 [1] NCCL INFO Channel 00/0 : 4[5] -> 5[1] [receive] via NET/IB/2
d14n11:1169357:1169672 [1] NCCL INFO Channel 01/0 : 4[5] -> 5[1] [receive] via NET/IB/2
d14n11:1169357:1169672 [1] NCCL INFO Channel 00/0 : 5[1] -> 6[3] [send] via NET/IB/2
d14n11:1169357:1169672 [1] NCCL INFO Channel 01/0 : 5[1] -> 6[3] [send] via NET/IB/2
d14n08:1173249:1173567 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d14n08:1173249:1173567 [2] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] 7/1/-1->3->11
d14n08:1173249:1173567 [2] NCCL INFO P2P Chunksize set to 131072
d14n08:1173249:1173567 [2] NCCL INFO Channel 00/0 : 2[0] -> 3[2] [receive] via NET/IB/0
d14n08:1173249:1173567 [2] NCCL INFO Channel 01/0 : 2[0] -> 3[2] [receive] via NET/IB/0
d14n08:1173249:1173567 [2] NCCL INFO Channel 00/0 : 3[2] -> 4[4] [send] via NET/IB/0
d14n08:1173249:1173567 [2] NCCL INFO Channel 01/0 : 3[2] -> 4[4] [send] via NET/IB/0
f18n05:1008221:1008518 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
f18n05:1008221:1008518 [2] NCCL INFO Trees [0] -1/-1/-1->11->10 [1] 3/-1/-1->11->-1
f18n05:1008221:1008518 [2] NCCL INFO P2P Chunksize set to 131072
f18n05:1008221:1008518 [2] NCCL INFO Channel 00/0 : 10[0] -> 11[2] [receive] via NET/IB/0
f18n05:1008221:1008518 [2] NCCL INFO Channel 01/0 : 10[0] -> 11[2] [receive] via NET/IB/0
f18n05:1008221:1008518 [2] NCCL INFO Channel 00/0 : 11[2] -> 0[4] [send] via NET/IB/0
f18n05:1008221:1008518 [2] NCCL INFO Channel 01/0 : 11[2] -> 0[4] [send] via NET/IB/0
d14n11:1169356:1169677 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d14n11:1169356:1169677 [0] NCCL INFO Trees [0] -1/-1/-1->5->6 [1] 6/4/-1->5->7
d14n11:1169356:1169677 [0] NCCL INFO P2P Chunksize set to 131072
d14n11:1169356:1169677 [0] NCCL INFO Channel 00/0 : 4[4] -> 5[0] [receive] via NET/IB/0
d14n11:1169356:1169677 [0] NCCL INFO Channel 01/0 : 4[4] -> 5[0] [receive] via NET/IB/0
d14n11:1169356:1169677 [0] NCCL INFO Channel 00/0 : 5[0] -> 6[2] [send] via NET/IB/0
d14n11:1169356:1169677 [0] NCCL INFO Channel 01/0 : 5[0] -> 6[2] [send] via NET/IB/0
d14n11:1169358:1169673 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d14n11:1169358:1169673 [2] NCCL INFO Trees [0] -1/-1/-1->5->6 [1] 6/4/-1->5->7
d14n11:1169358:1169673 [2] NCCL INFO P2P Chunksize set to 131072
d14n11:1169358:1169673 [2] NCCL INFO Channel 00/0 : 4[0] -> 5[2] [receive] via NET/IB/0
d14n11:1169358:1169673 [2] NCCL INFO Channel 01/0 : 4[0] -> 5[2] [receive] via NET/IB/0
d14n11:1169358:1169673 [2] NCCL INFO Channel 00/0 : 5[2] -> 6[4] [send] via NET/IB/0
d14n11:1169358:1169673 [2] NCCL INFO Channel 01/0 : 5[2] -> 6[4] [send] via NET/IB/0
d14n08:1173248:1173568 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d14n08:1173248:1173568 [1] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] 7/1/-1->3->11
d14n08:1173248:1173568 [1] NCCL INFO P2P Chunksize set to 131072
d14n08:1173248:1173568 [1] NCCL INFO Channel 00/0 : 2[5] -> 3[1] [receive] via NET/IB/2
d14n08:1173248:1173568 [1] NCCL INFO Channel 01/0 : 2[5] -> 3[1] [receive] via NET/IB/2
d14n08:1173248:1173568 [1] NCCL INFO Channel 00/0 : 3[1] -> 4[3] [send] via NET/IB/2
d14n08:1173248:1173568 [1] NCCL INFO Channel 01/0 : 3[1] -> 4[3] [send] via NET/IB/2
f16n17:1090961:1091272 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
f16n17:1090961:1091272 [2] NCCL INFO Trees [0] 4/10/-1->8->0 [1] -1/-1/-1->8->9
f16n17:1090961:1091272 [2] NCCL INFO P2P Chunksize set to 131072
f16n17:1090961:1091272 [2] NCCL INFO Channel 00/0 : 7[0] -> 8[2] [receive] via NET/IB/0
f16n17:1090961:1091272 [2] NCCL INFO Channel 01/0 : 7[0] -> 8[2] [receive] via NET/IB/0
f16n17:1090961:1091272 [2] NCCL INFO Channel 00/0 : 8[2] -> 9[4] [send] via NET/IB/0
f16n17:1090961:1091272 [2] NCCL INFO Channel 01/0 : 8[2] -> 9[4] [send] via NET/IB/0
d11n16:1130268:1130579 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d11n16:1130268:1130579 [0] NCCL INFO Trees [0] -1/-1/-1->1->2 [1] 2/0/-1->1->3
d11n16:1130268:1130579 [0] NCCL INFO P2P Chunksize set to 131072
d11n16:1130268:1130579 [0] NCCL INFO Channel 00/0 : 0[4] -> 1[0] [receive] via NET/IB/0
d11n16:1130268:1130579 [0] NCCL INFO Channel 01/0 : 0[4] -> 1[0] [receive] via NET/IB/0
d11n16:1130268:1130579 [0] NCCL INFO Channel 00/0 : 1[0] -> 2[2] [send] via NET/IB/0
d11n16:1130268:1130579 [0] NCCL INFO Channel 01/0 : 1[0] -> 2[2] [send] via NET/IB/0
d11n17:1142856:1143153 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d11n17:1142856:1143153 [2] NCCL INFO Trees [0] 1/3/-1->2->4 [1] -1/-1/-1->2->1
d11n17:1142856:1143153 [2] NCCL INFO P2P Chunksize set to 131072
d11n17:1142856:1143153 [2] NCCL INFO Channel 00/0 : 1[0] -> 2[2] [receive] via NET/IB/0
d11n17:1142856:1143153 [2] NCCL INFO Channel 01/0 : 1[0] -> 2[2] [receive] via NET/IB/0
d11n17:1142856:1143153 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[4] [send] via NET/IB/0
d11n17:1142856:1143153 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[4] [send] via NET/IB/0
d14n10:565681:565991 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d14n10:565681:565991 [0] NCCL INFO Trees [0] 2/6/-1->4->8 [1] -1/-1/-1->4->5
d14n10:565681:565991 [0] NCCL INFO P2P Chunksize set to 131072
d14n10:565681:565991 [0] NCCL INFO Channel 00/0 : 3[4] -> 4[0] [receive] via NET/IB/0
d14n10:565681:565991 [0] NCCL INFO Channel 01/0 : 3[4] -> 4[0] [receive] via NET/IB/0
d14n10:565681:565991 [0] NCCL INFO Channel 00/0 : 4[0] -> 5[2] [send] via NET/IB/0
d14n10:565681:565991 [0] NCCL INFO Channel 01/0 : 4[0] -> 5[2] [send] via NET/IB/0
d09n07:1063021:1063389 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d09n07:1063021:1063389 [4] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7   8   9  10  11
d09n07:1063021:1063389 [4] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7   8   9  10  11
d09n07:1063021:1063389 [4] NCCL INFO Trees [0] 8/-1/-1->0->-1 [1] -1/-1/-1->0->1
d09n07:1063021:1063389 [4] NCCL INFO P2P Chunksize set to 131072
d09n07:1063021:1063389 [4] NCCL INFO Channel 00/0 : 11[2] -> 0[4] [receive] via NET/IB/1
d09n07:1063021:1063389 [4] NCCL INFO Channel 01/0 : 11[2] -> 0[4] [receive] via NET/IB/1
d09n07:1063021:1063389 [4] NCCL INFO Channel 00/0 : 0[4] -> 1[0] [send] via NET/IB/1
d09n07:1063021:1063389 [4] NCCL INFO Channel 01/0 : 0[4] -> 1[0] [send] via NET/IB/1
d17n06:1216534:1216862 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d17n06:1216534:1216862 [4] NCCL INFO Trees [0] 5/7/-1->6->4 [1] -1/-1/-1->6->5
d17n06:1216534:1216862 [4] NCCL INFO P2P Chunksize set to 131072
d17n06:1216534:1216862 [4] NCCL INFO Channel 00/0 : 5[2] -> 6[4] [receive] via NET/IB/1
d17n06:1216534:1216862 [4] NCCL INFO Channel 01/0 : 5[2] -> 6[4] [receive] via NET/IB/1
d17n06:1216534:1216862 [4] NCCL INFO Channel 00/0 : 6[4] -> 7[0] [send] via NET/IB/1
d17n06:1216534:1216862 [4] NCCL INFO Channel 01/0 : 6[4] -> 7[0] [send] via NET/IB/1
f16n18:1091870:1092186 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
f16n18:1091870:1092186 [4] NCCL INFO Trees [0] -1/-1/-1->9->10 [1] 10/8/-1->9->7
f16n18:1091870:1092186 [4] NCCL INFO P2P Chunksize set to 131072
f16n18:1091870:1092186 [4] NCCL INFO Channel 00/0 : 8[2] -> 9[4] [receive] via NET/IB/1
f16n18:1091870:1092186 [4] NCCL INFO Channel 01/0 : 8[2] -> 9[4] [receive] via NET/IB/1
f16n18:1091870:1092186 [4] NCCL INFO Channel 00/0 : 9[4] -> 10[0] [send] via NET/IB/1
f16n18:1091870:1092186 [4] NCCL INFO Channel 01/0 : 9[4] -> 10[0] [send] via NET/IB/1
d09n07:1063022:1063390 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d09n07:1063022:1063390 [5] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7   8   9  10  11
d09n07:1063022:1063390 [5] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7   8   9  10  11
d09n07:1063022:1063390 [5] NCCL INFO Trees [0] 8/-1/-1->0->-1 [1] -1/-1/-1->0->1
d09n07:1063022:1063390 [5] NCCL INFO P2P Chunksize set to 131072
d09n07:1063022:1063390 [5] NCCL INFO Channel 00/0 : 11[3] -> 0[5] [receive] via NET/IB/3
d09n07:1063022:1063390 [5] NCCL INFO Channel 01/0 : 11[3] -> 0[5] [receive] via NET/IB/3
d09n07:1063022:1063390 [5] NCCL INFO Channel 00/0 : 0[5] -> 1[1] [send] via NET/IB/3
d09n07:1063022:1063390 [5] NCCL INFO Channel 01/0 : 0[5] -> 1[1] [send] via NET/IB/3
d14n08:1173251:1173565 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d14n08:1173251:1173565 [4] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] 7/1/-1->3->11
d14n08:1173251:1173565 [4] NCCL INFO P2P Chunksize set to 131072
d14n08:1173251:1173565 [4] NCCL INFO Channel 00/0 : 2[2] -> 3[4] [receive] via NET/IB/1
d14n08:1173251:1173565 [4] NCCL INFO Channel 01/0 : 2[2] -> 3[4] [receive] via NET/IB/1
d14n08:1173251:1173565 [4] NCCL INFO Channel 00/0 : 3[4] -> 4[0] [send] via NET/IB/1
d14n08:1173251:1173565 [4] NCCL INFO Channel 01/0 : 3[4] -> 4[0] [send] via NET/IB/1
d11n16:1130271:1130583 [3] NCCL INFO comm 0x16d12bc10 rank 1 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xe9f19695db992363 - Init START
d11n16:1130271:1130583 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d11n16:1130271:1130583 [3] NCCL INFO Trees [0] -1/-1/-1->1->2 [1] 2/0/-1->1->3
d11n16:1130271:1130583 [3] NCCL INFO P2P Chunksize set to 131072
d11n16:1130271:1130583 [3] NCCL INFO Channel 00/0 : 0[1] -> 1[3] [receive] via NET/IB/3
d11n16:1130271:1130583 [3] NCCL INFO Channel 01/0 : 0[1] -> 1[3] [receive] via NET/IB/3
d11n16:1130271:1130583 [3] NCCL INFO Channel 00/0 : 1[3] -> 2[5] [send] via NET/IB/3
d11n16:1130271:1130583 [3] NCCL INFO Channel 01/0 : 1[3] -> 2[5] [send] via NET/IB/3
f16n17:1090962:1091273 [3] NCCL INFO comm 0x13abc2800 rank 8 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xd3b159694d72ff62 - Init START
f16n17:1090962:1091273 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
f16n17:1090962:1091273 [3] NCCL INFO Trees [0] 4/10/-1->8->0 [1] -1/-1/-1->8->9
f16n17:1090962:1091273 [3] NCCL INFO P2P Chunksize set to 131072
f16n17:1090962:1091273 [3] NCCL INFO Channel 00/0 : 7[1] -> 8[3] [receive] via NET/IB/3
f16n17:1090962:1091273 [3] NCCL INFO Channel 01/0 : 7[1] -> 8[3] [receive] via NET/IB/3
f16n17:1090962:1091273 [3] NCCL INFO Channel 00/0 : 8[3] -> 9[5] [send] via NET/IB/3
f16n17:1090962:1091273 [3] NCCL INFO Channel 01/0 : 8[3] -> 9[5] [send] via NET/IB/3
f18n05:1008222:1008521 [3] NCCL INFO comm 0x152d5c9d0 rank 11 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xd3b159694d72ff62 - Init START
f18n05:1008222:1008521 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
f18n05:1008222:1008521 [3] NCCL INFO Trees [0] -1/-1/-1->11->10 [1] 3/-1/-1->11->-1
f18n05:1008222:1008521 [3] NCCL INFO P2P Chunksize set to 131072
f18n05:1008222:1008521 [3] NCCL INFO Channel 00/0 : 10[1] -> 11[3] [receive] via NET/IB/3
f18n05:1008222:1008521 [3] NCCL INFO Channel 01/0 : 10[1] -> 11[3] [receive] via NET/IB/3
f18n05:1008222:1008521 [3] NCCL INFO Channel 00/0 : 11[3] -> 0[5] [send] via NET/IB/3
f18n05:1008222:1008521 [3] NCCL INFO Channel 01/0 : 11[3] -> 0[5] [send] via NET/IB/3
d14n10:565682:565992 [1] NCCL INFO comm 0x17826b020 rank 4 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0xd3b159694d72ff62 - Init START
d14n10:565682:565992 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d14n10:565682:565992 [1] NCCL INFO Trees [0] 2/6/-1->4->8 [1] -1/-1/-1->4->5
d14n10:565682:565992 [1] NCCL INFO P2P Chunksize set to 131072
d14n10:565682:565992 [1] NCCL INFO Channel 00/0 : 3[5] -> 4[1] [receive] via NET/IB/2
d14n10:565682:565992 [1] NCCL INFO Channel 01/0 : 3[5] -> 4[1] [receive] via NET/IB/2
d14n10:565682:565992 [1] NCCL INFO Channel 00/0 : 4[1] -> 5[3] [send] via NET/IB/2
d14n10:565682:565992 [1] NCCL INFO Channel 01/0 : 4[1] -> 5[3] [send] via NET/IB/2
f16n18:1091871:1092189 [5] NCCL INFO comm 0x14ec0bb80 rank 9 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xd3b159694d72ff62 - Init START
f16n18:1091871:1092189 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
f16n18:1091871:1092189 [5] NCCL INFO Trees [0] -1/-1/-1->9->10 [1] 10/8/-1->9->7
f16n18:1091871:1092189 [5] NCCL INFO P2P Chunksize set to 131072
f16n18:1091871:1092189 [5] NCCL INFO Channel 00/0 : 8[3] -> 9[5] [receive] via NET/IB/3
f16n18:1091871:1092189 [5] NCCL INFO Channel 01/0 : 8[3] -> 9[5] [receive] via NET/IB/3
f16n18:1091871:1092189 [5] NCCL INFO Channel 00/0 : 9[5] -> 10[1] [send] via NET/IB/3
f16n18:1091871:1092189 [5] NCCL INFO Channel 01/0 : 9[5] -> 10[1] [send] via NET/IB/3
f17n02:1076279:1076575 [0] NCCL INFO Setting affinity for GPU 0 to 0f
f17n02:1076279:1076575 [0] NCCL INFO Trees [0] 9/11/-1->10->8 [1] -1/-1/-1->10->9
f17n02:1076279:1076575 [0] NCCL INFO P2P Chunksize set to 131072
f17n02:1076279:1076575 [0] NCCL INFO Channel 00/0 : 9[4] -> 10[0] [receive] via NET/IB/0
f17n02:1076279:1076575 [0] NCCL INFO Channel 01/0 : 9[4] -> 10[0] [receive] via NET/IB/0
f17n02:1076279:1076575 [0] NCCL INFO Channel 00/0 : 10[0] -> 11[2] [send] via NET/IB/0
f17n02:1076279:1076575 [0] NCCL INFO Channel 01/0 : 10[0] -> 11[2] [send] via NET/IB/0
f18n05:1008224:1008523 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
f18n05:1008224:1008523 [5] NCCL INFO Trees [0] -1/-1/-1->11->10 [1] 3/-1/-1->11->-1
f18n05:1008224:1008523 [5] NCCL INFO P2P Chunksize set to 131072
f18n05:1008224:1008523 [5] NCCL INFO Channel 00/0 : 10[3] -> 11[5] [receive] via NET/IB/3
f18n05:1008224:1008523 [5] NCCL INFO Channel 01/0 : 10[3] -> 11[5] [receive] via NET/IB/3
f18n05:1008224:1008523 [5] NCCL INFO Channel 00/0 : 11[5] -> 0[1] [send] via NET/IB/3
f18n05:1008224:1008523 [5] NCCL INFO Channel 01/0 : 11[5] -> 0[1] [send] via NET/IB/3
f16n16:1079912:1080216 [0] NCCL INFO Setting affinity for GPU 0 to 0f
f16n16:1079912:1080216 [0] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] 9/5/-1->7->3
f16n16:1079912:1080216 [0] NCCL INFO P2P Chunksize set to 131072
f16n16:1079912:1080216 [0] NCCL INFO Channel 00/0 : 6[4] -> 7[0] [receive] via NET/IB/0
f16n16:1079912:1080216 [0] NCCL INFO Channel 01/0 : 6[4] -> 7[0] [receive] via NET/IB/0
f16n16:1079912:1080216 [0] NCCL INFO Channel 00/0 : 7[0] -> 8[2] [send] via NET/IB/0
f16n16:1079912:1080216 [0] NCCL INFO Channel 01/0 : 7[0] -> 8[2] [send] via NET/IB/0
d14n09:567667:567994 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d14n09:567667:567994 [1] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] 7/1/-1->3->11
d14n09:567667:567994 [1] NCCL INFO P2P Chunksize set to 131072
d14n09:567667:567994 [1] NCCL INFO Channel 00/0 : 2[5] -> 3[1] [receive] via NET/IB/2
d14n09:567667:567994 [1] NCCL INFO Channel 01/0 : 2[5] -> 3[1] [receive] via NET/IB/2
d14n09:567667:567994 [1] NCCL INFO Channel 00/0 : 3[1] -> 4[3] [send] via NET/IB/2
d14n09:567667:567994 [1] NCCL INFO Channel 01/0 : 3[1] -> 4[3] [send] via NET/IB/2
d11n16:1130270:1130582 [2] NCCL INFO comm 0x14a48ebc0 rank 1 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0xeeef2eab3be148e1 - Init START
d11n16:1130270:1130582 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d11n16:1130270:1130582 [2] NCCL INFO Trees [0] -1/-1/-1->1->2 [1] 2/0/-1->1->3
d11n16:1130270:1130582 [2] NCCL INFO P2P Chunksize set to 131072
d11n16:1130270:1130582 [2] NCCL INFO Channel 00/0 : 0[0] -> 1[2] [receive] via NET/IB/0
d11n16:1130270:1130582 [2] NCCL INFO Channel 01/0 : 0[0] -> 1[2] [receive] via NET/IB/0
d11n16:1130270:1130582 [2] NCCL INFO Channel 00/0 : 1[2] -> 2[4] [send] via NET/IB/0
d11n16:1130270:1130582 [2] NCCL INFO Channel 01/0 : 1[2] -> 2[4] [send] via NET/IB/0
d14n11:1169359:1169675 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d14n11:1169359:1169675 [3] NCCL INFO Trees [0] -1/-1/-1->5->6 [1] 6/4/-1->5->7
d14n11:1169359:1169675 [3] NCCL INFO P2P Chunksize set to 131072
d14n11:1169359:1169675 [3] NCCL INFO Channel 00/0 : 4[1] -> 5[3] [receive] via NET/IB/3
d14n11:1169359:1169675 [3] NCCL INFO Channel 01/0 : 4[1] -> 5[3] [receive] via NET/IB/3
d14n11:1169359:1169675 [3] NCCL INFO Channel 00/0 : 5[3] -> 6[5] [send] via NET/IB/3
d14n11:1169359:1169675 [3] NCCL INFO Channel 01/0 : 5[3] -> 6[5] [send] via NET/IB/3
d11n17:1142857:1143157 [3] NCCL INFO comm 0x130dc8710 rank 2 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xd3b159694d72ff62 - Init START
d11n17:1142857:1143157 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d11n17:1142857:1143157 [3] NCCL INFO Trees [0] 1/3/-1->2->4 [1] -1/-1/-1->2->1
d11n17:1142857:1143157 [3] NCCL INFO P2P Chunksize set to 131072
d11n17:1142857:1143157 [3] NCCL INFO Channel 00/0 : 1[1] -> 2[3] [receive] via NET/IB/3
d11n17:1142857:1143157 [3] NCCL INFO Channel 01/0 : 1[1] -> 2[3] [receive] via NET/IB/3
d11n17:1142857:1143157 [3] NCCL INFO Channel 00/0 : 2[3] -> 3[5] [send] via NET/IB/3
d11n17:1142857:1143157 [3] NCCL INFO Channel 01/0 : 2[3] -> 3[5] [send] via NET/IB/3
d14n11:1169361:1169674 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d14n11:1169361:1169674 [5] NCCL INFO Trees [0] -1/-1/-1->5->6 [1] 6/4/-1->5->7
d14n11:1169361:1169674 [5] NCCL INFO P2P Chunksize set to 131072
d14n11:1169361:1169674 [5] NCCL INFO Channel 00/0 : 4[3] -> 5[5] [receive] via NET/IB/3
d14n11:1169361:1169674 [5] NCCL INFO Channel 01/0 : 4[3] -> 5[5] [receive] via NET/IB/3
d14n11:1169361:1169674 [5] NCCL INFO Channel 00/0 : 5[5] -> 6[1] [send] via NET/IB/3
d14n11:1169361:1169674 [5] NCCL INFO Channel 01/0 : 5[5] -> 6[1] [send] via NET/IB/3
d14n09:567666:567998 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d14n09:567666:567998 [0] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] 7/1/-1->3->11
d14n09:567666:567998 [0] NCCL INFO P2P Chunksize set to 131072
d14n09:567666:567998 [0] NCCL INFO Channel 00/0 : 2[4] -> 3[0] [receive] via NET/IB/0
d14n09:567666:567998 [0] NCCL INFO Channel 01/0 : 2[4] -> 3[0] [receive] via NET/IB/0
d14n09:567666:567998 [0] NCCL INFO Channel 00/0 : 3[0] -> 4[2] [send] via NET/IB/0
d14n09:567666:567998 [0] NCCL INFO Channel 01/0 : 3[0] -> 4[2] [send] via NET/IB/0
d11n17:1142859:1143155 [5] NCCL INFO comm 0x133858b10 rank 2 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xe9f19695db992363 - Init START
d11n17:1142859:1143155 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d11n17:1142859:1143155 [5] NCCL INFO Trees [0] 1/3/-1->2->4 [1] -1/-1/-1->2->1
d11n17:1142859:1143155 [5] NCCL INFO P2P Chunksize set to 131072
d11n17:1142859:1143155 [5] NCCL INFO Channel 00/0 : 1[3] -> 2[5] [receive] via NET/IB/3
d11n17:1142859:1143155 [5] NCCL INFO Channel 01/0 : 1[3] -> 2[5] [receive] via NET/IB/3
d11n17:1142859:1143155 [5] NCCL INFO Channel 00/0 : 2[5] -> 3[1] [send] via NET/IB/3
d11n17:1142859:1143155 [5] NCCL INFO Channel 01/0 : 2[5] -> 3[1] [send] via NET/IB/3
d14n08:1173252:1173564 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d14n08:1173252:1173564 [5] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] 7/1/-1->3->11
d14n08:1173252:1173564 [5] NCCL INFO P2P Chunksize set to 131072
d14n08:1173252:1173564 [5] NCCL INFO Channel 00/0 : 2[3] -> 3[5] [receive] via NET/IB/3
d14n08:1173252:1173564 [5] NCCL INFO Channel 01/0 : 2[3] -> 3[5] [receive] via NET/IB/3
d14n08:1173252:1173564 [5] NCCL INFO Channel 00/0 : 3[5] -> 4[1] [send] via NET/IB/3
d14n08:1173252:1173564 [5] NCCL INFO Channel 01/0 : 3[5] -> 4[1] [send] via NET/IB/3
d11n17:1142858:1143156 [4] NCCL INFO comm 0x134018c60 rank 2 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xeeef2eab3be148e1 - Init START
d11n17:1142858:1143156 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d11n17:1142858:1143156 [4] NCCL INFO Trees [0] 1/3/-1->2->4 [1] -1/-1/-1->2->1
d11n17:1142858:1143156 [4] NCCL INFO P2P Chunksize set to 131072
d11n17:1142858:1143156 [4] NCCL INFO Channel 00/0 : 1[2] -> 2[4] [receive] via NET/IB/1
d11n17:1142858:1143156 [4] NCCL INFO Channel 01/0 : 1[2] -> 2[4] [receive] via NET/IB/1
d11n17:1142858:1143156 [4] NCCL INFO Channel 00/0 : 2[4] -> 3[0] [send] via NET/IB/1
d11n17:1142858:1143156 [4] NCCL INFO Channel 01/0 : 2[4] -> 3[0] [send] via NET/IB/1
d17n06:1216535:1216864 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d17n06:1216535:1216864 [5] NCCL INFO Trees [0] 5/7/-1->6->4 [1] -1/-1/-1->6->5
d17n06:1216535:1216864 [5] NCCL INFO P2P Chunksize set to 131072
d17n06:1216535:1216864 [5] NCCL INFO Channel 00/0 : 5[3] -> 6[5] [receive] via NET/IB/3
d17n06:1216535:1216864 [5] NCCL INFO Channel 01/0 : 5[3] -> 6[5] [receive] via NET/IB/3
d17n06:1216535:1216864 [5] NCCL INFO Channel 00/0 : 6[5] -> 7[1] [send] via NET/IB/3
d17n06:1216535:1216864 [5] NCCL INFO Channel 01/0 : 6[5] -> 7[1] [send] via NET/IB/3
f17n01:970277:970578 [1] NCCL INFO comm 0x148b9cee0 rank 9 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0xe9f19695db992363 - Init START
f17n01:970277:970578 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
f17n01:970277:970578 [1] NCCL INFO Trees [0] -1/-1/-1->9->10 [1] 10/8/-1->9->7
f17n01:970277:970578 [1] NCCL INFO P2P Chunksize set to 131072
f17n01:970277:970578 [1] NCCL INFO Channel 00/0 : 8[5] -> 9[1] [receive] via NET/IB/2
f17n01:970277:970578 [1] NCCL INFO Channel 01/0 : 8[5] -> 9[1] [receive] via NET/IB/2
f17n01:970277:970578 [1] NCCL INFO Channel 00/0 : 9[1] -> 10[3] [send] via NET/IB/2
f17n01:970277:970578 [1] NCCL INFO Channel 01/0 : 9[1] -> 10[3] [send] via NET/IB/2
d17n07:1212411:1212743 [1] NCCL INFO comm 0x17a692b40 rank 6 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0xe9f19695db992363 - Init START
d17n07:1212411:1212743 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d17n07:1212411:1212743 [1] NCCL INFO Trees [0] 5/7/-1->6->4 [1] -1/-1/-1->6->5
d17n07:1212411:1212743 [1] NCCL INFO P2P Chunksize set to 131072
d17n07:1212411:1212743 [1] NCCL INFO Channel 00/0 : 5[5] -> 6[1] [receive] via NET/IB/2
d17n07:1212411:1212743 [1] NCCL INFO Channel 01/0 : 5[5] -> 6[1] [receive] via NET/IB/2
d17n07:1212411:1212743 [1] NCCL INFO Channel 00/0 : 6[1] -> 7[3] [send] via NET/IB/2
d17n07:1212411:1212743 [1] NCCL INFO Channel 01/0 : 6[1] -> 7[3] [send] via NET/IB/2
f16n17:1090964:1091275 [5] NCCL INFO comm 0x16eabe000 rank 8 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xe9f19695db992363 - Init START
f16n17:1090964:1091275 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
f16n17:1090964:1091275 [5] NCCL INFO Trees [0] 4/10/-1->8->0 [1] -1/-1/-1->8->9
f16n17:1090964:1091275 [5] NCCL INFO P2P Chunksize set to 131072
f16n17:1090964:1091275 [5] NCCL INFO Channel 00/0 : 7[3] -> 8[5] [receive] via NET/IB/3
f16n17:1090964:1091275 [5] NCCL INFO Channel 01/0 : 7[3] -> 8[5] [receive] via NET/IB/3
f16n17:1090964:1091275 [5] NCCL INFO Channel 00/0 : 8[5] -> 9[1] [send] via NET/IB/3
f16n17:1090964:1091275 [5] NCCL INFO Channel 01/0 : 8[5] -> 9[1] [send] via NET/IB/3
f18n05:1008223:1008522 [4] NCCL INFO comm 0x17e70c690 rank 11 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xeeef2eab3be148e1 - Init START
f18n05:1008223:1008522 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
f18n05:1008223:1008522 [4] NCCL INFO Trees [0] -1/-1/-1->11->10 [1] 3/-1/-1->11->-1
f18n05:1008223:1008522 [4] NCCL INFO P2P Chunksize set to 131072
f18n05:1008223:1008522 [4] NCCL INFO Channel 00/0 : 10[2] -> 11[4] [receive] via NET/IB/1
f18n05:1008223:1008522 [4] NCCL INFO Channel 01/0 : 10[2] -> 11[4] [receive] via NET/IB/1
f18n05:1008223:1008522 [4] NCCL INFO Channel 00/0 : 11[4] -> 0[0] [send] via NET/IB/1
f18n05:1008223:1008522 [4] NCCL INFO Channel 01/0 : 11[4] -> 0[0] [send] via NET/IB/1
f16n16:1079914:1080218 [2] NCCL INFO comm 0x163a16fc0 rank 7 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0xeeef2eab3be148e1 - Init START
f16n16:1079914:1080218 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
f16n16:1079914:1080218 [2] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] 9/5/-1->7->3
f16n16:1079914:1080218 [2] NCCL INFO P2P Chunksize set to 131072
f16n16:1079914:1080218 [2] NCCL INFO Channel 00/0 : 6[0] -> 7[2] [receive] via NET/IB/0
f16n16:1079914:1080218 [2] NCCL INFO Channel 01/0 : 6[0] -> 7[2] [receive] via NET/IB/0
f16n16:1079914:1080218 [2] NCCL INFO Channel 00/0 : 7[2] -> 8[4] [send] via NET/IB/0
f16n16:1079914:1080218 [2] NCCL INFO Channel 01/0 : 7[2] -> 8[4] [send] via NET/IB/0
d14n10:565683:565994 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d14n10:565683:565994 [2] NCCL INFO Trees [0] 2/6/-1->4->8 [1] -1/-1/-1->4->5
d14n10:565683:565994 [2] NCCL INFO P2P Chunksize set to 131072
d14n10:565683:565994 [2] NCCL INFO Channel 00/0 : 3[0] -> 4[2] [receive] via NET/IB/0
d14n10:565683:565994 [2] NCCL INFO Channel 01/0 : 3[0] -> 4[2] [receive] via NET/IB/0
d14n10:565683:565994 [2] NCCL INFO Channel 00/0 : 4[2] -> 5[4] [send] via NET/IB/0
d14n10:565683:565994 [2] NCCL INFO Channel 01/0 : 4[2] -> 5[4] [send] via NET/IB/0
d14n11:1169360:1169676 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d14n11:1169360:1169676 [4] NCCL INFO Trees [0] -1/-1/-1->5->6 [1] 6/4/-1->5->7
d14n11:1169360:1169676 [4] NCCL INFO P2P Chunksize set to 131072
d14n11:1169360:1169676 [4] NCCL INFO Channel 00/0 : 4[2] -> 5[4] [receive] via NET/IB/1
d14n11:1169360:1169676 [4] NCCL INFO Channel 01/0 : 4[2] -> 5[4] [receive] via NET/IB/1
d14n11:1169360:1169676 [4] NCCL INFO Channel 00/0 : 5[4] -> 6[0] [send] via NET/IB/1
d14n11:1169360:1169676 [4] NCCL INFO Channel 01/0 : 5[4] -> 6[0] [send] via NET/IB/1
d17n07:1212410:1212742 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d17n07:1212410:1212742 [0] NCCL INFO Trees [0] 5/7/-1->6->4 [1] -1/-1/-1->6->5
d17n07:1212410:1212742 [0] NCCL INFO P2P Chunksize set to 131072
d17n07:1212410:1212742 [0] NCCL INFO Channel 00/0 : 5[4] -> 6[0] [receive] via NET/IB/0
d17n07:1212410:1212742 [0] NCCL INFO Channel 01/0 : 5[4] -> 6[0] [receive] via NET/IB/0
d17n07:1212410:1212742 [0] NCCL INFO Channel 00/0 : 6[0] -> 7[2] [send] via NET/IB/0
d17n07:1212410:1212742 [0] NCCL INFO Channel 01/0 : 6[0] -> 7[2] [send] via NET/IB/0
d14n10:565684:565995 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d14n10:565684:565995 [3] NCCL INFO Trees [0] 2/6/-1->4->8 [1] -1/-1/-1->4->5
d14n10:565684:565995 [3] NCCL INFO P2P Chunksize set to 131072
d14n10:565684:565995 [3] NCCL INFO Channel 00/0 : 3[1] -> 4[3] [receive] via NET/IB/3
d14n10:565684:565995 [3] NCCL INFO Channel 01/0 : 3[1] -> 4[3] [receive] via NET/IB/3
d14n10:565684:565995 [3] NCCL INFO Channel 00/0 : 4[3] -> 5[5] [send] via NET/IB/3
d14n10:565684:565995 [3] NCCL INFO Channel 01/0 : 4[3] -> 5[5] [send] via NET/IB/3
d11n16:1130269:1130580 [1] NCCL INFO comm 0x137450c80 rank 1 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0xd3b159694d72ff62 - Init START
d11n16:1130269:1130580 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d11n16:1130269:1130580 [1] NCCL INFO Trees [0] -1/-1/-1->1->2 [1] 2/0/-1->1->3
d11n16:1130269:1130580 [1] NCCL INFO P2P Chunksize set to 131072
d11n16:1130269:1130580 [1] NCCL INFO Channel 00/0 : 0[5] -> 1[1] [receive] via NET/IB/2
d11n16:1130269:1130580 [1] NCCL INFO Channel 01/0 : 0[5] -> 1[1] [receive] via NET/IB/2
d11n16:1130269:1130580 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[3] [send] via NET/IB/2
d11n16:1130269:1130580 [1] NCCL INFO Channel 01/0 : 1[1] -> 2[3] [send] via NET/IB/2
f17n02:1076281:1076578 [2] NCCL INFO comm 0x17c0bc8b0 rank 10 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0xeeef2eab3be148e1 - Init START
f17n02:1076281:1076578 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
f17n02:1076281:1076578 [2] NCCL INFO Trees [0] 9/11/-1->10->8 [1] -1/-1/-1->10->9
f17n02:1076281:1076578 [2] NCCL INFO P2P Chunksize set to 131072
f17n02:1076281:1076578 [2] NCCL INFO Channel 00/0 : 9[0] -> 10[2] [receive] via NET/IB/0
f17n02:1076281:1076578 [2] NCCL INFO Channel 01/0 : 9[0] -> 10[2] [receive] via NET/IB/0
f17n02:1076281:1076578 [2] NCCL INFO Channel 00/0 : 10[2] -> 11[4] [send] via NET/IB/0
f17n02:1076281:1076578 [2] NCCL INFO Channel 01/0 : 10[2] -> 11[4] [send] via NET/IB/0
f17n02:1076282:1076579 [3] NCCL INFO comm 0x129f6ca10 rank 10 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xe9f19695db992363 - Init START
f17n02:1076282:1076579 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
f17n02:1076282:1076579 [3] NCCL INFO Trees [0] 9/11/-1->10->8 [1] -1/-1/-1->10->9
f17n02:1076282:1076579 [3] NCCL INFO P2P Chunksize set to 131072
f17n02:1076282:1076579 [3] NCCL INFO Channel 00/0 : 9[1] -> 10[3] [receive] via NET/IB/3
f17n02:1076282:1076579 [3] NCCL INFO Channel 01/0 : 9[1] -> 10[3] [receive] via NET/IB/3
f17n02:1076282:1076579 [3] NCCL INFO Channel 00/0 : 10[3] -> 11[5] [send] via NET/IB/3
f17n02:1076282:1076579 [3] NCCL INFO Channel 01/0 : 10[3] -> 11[5] [send] via NET/IB/3
f16n17:1090963:1091274 [4] NCCL INFO comm 0x13e18b9e0 rank 8 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xeeef2eab3be148e1 - Init START
f16n17:1090963:1091274 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
f16n17:1090963:1091274 [4] NCCL INFO Trees [0] 4/10/-1->8->0 [1] -1/-1/-1->8->9
f16n17:1090963:1091274 [4] NCCL INFO P2P Chunksize set to 131072
f16n17:1090963:1091274 [4] NCCL INFO Channel 00/0 : 7[2] -> 8[4] [receive] via NET/IB/1
f16n17:1090963:1091274 [4] NCCL INFO Channel 01/0 : 7[2] -> 8[4] [receive] via NET/IB/1
f16n17:1090963:1091274 [4] NCCL INFO Channel 00/0 : 8[4] -> 9[0] [send] via NET/IB/1
f16n17:1090963:1091274 [4] NCCL INFO Channel 01/0 : 8[4] -> 9[0] [send] via NET/IB/1
f17n01:970276:970577 [0] NCCL INFO comm 0x15cf7c000 rank 9 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0xeeef2eab3be148e1 - Init START
f17n01:970276:970577 [0] NCCL INFO Setting affinity for GPU 0 to 0f
f17n01:970276:970577 [0] NCCL INFO Trees [0] -1/-1/-1->9->10 [1] 10/8/-1->9->7
f17n01:970276:970577 [0] NCCL INFO P2P Chunksize set to 131072
f17n01:970276:970577 [0] NCCL INFO Channel 00/0 : 8[4] -> 9[0] [receive] via NET/IB/0
f17n01:970276:970577 [0] NCCL INFO Channel 01/0 : 8[4] -> 9[0] [receive] via NET/IB/0
f17n01:970276:970577 [0] NCCL INFO Channel 00/0 : 9[0] -> 10[2] [send] via NET/IB/0
f17n01:970276:970577 [0] NCCL INFO Channel 01/0 : 9[0] -> 10[2] [send] via NET/IB/0
d09n08:1073955:1074260 [1] NCCL INFO comm 0x15c61b990 rank 0 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0xe9f19695db992363 - Init START
d09n08:1073955:1074260 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d09n08:1073955:1074260 [1] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7   8   9  10  11
d09n08:1073955:1074260 [1] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7   8   9  10  11
d09n08:1073955:1074260 [1] NCCL INFO Trees [0] 8/-1/-1->0->-1 [1] -1/-1/-1->0->1
d09n08:1073955:1074260 [1] NCCL INFO P2P Chunksize set to 131072
d09n08:1073955:1074260 [1] NCCL INFO Channel 00/0 : 11[5] -> 0[1] [receive] via NET/IB/2
d09n08:1073955:1074260 [1] NCCL INFO Channel 01/0 : 11[5] -> 0[1] [receive] via NET/IB/2
d09n08:1073955:1074260 [1] NCCL INFO Channel 00/0 : 0[1] -> 1[3] [send] via NET/IB/2
d09n08:1073955:1074260 [1] NCCL INFO Channel 01/0 : 0[1] -> 1[3] [send] via NET/IB/2
d09n08:1073954:1074259 [0] NCCL INFO comm 0x14a851580 rank 0 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0xeeef2eab3be148e1 - Init START
d09n08:1073954:1074259 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d09n08:1073954:1074259 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7   8   9  10  11
d09n08:1073954:1074259 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7   8   9  10  11
d09n08:1073954:1074259 [0] NCCL INFO Trees [0] 8/-1/-1->0->-1 [1] -1/-1/-1->0->1
d09n08:1073954:1074259 [0] NCCL INFO P2P Chunksize set to 131072
d09n08:1073954:1074259 [0] NCCL INFO Channel 00/0 : 11[4] -> 0[0] [receive] via NET/IB/0
d09n08:1073954:1074259 [0] NCCL INFO Channel 01/0 : 11[4] -> 0[0] [receive] via NET/IB/0
d09n08:1073954:1074259 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[2] [send] via NET/IB/0
d09n08:1073954:1074259 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[2] [send] via NET/IB/0
f16n16:1079915:1080219 [3] NCCL INFO comm 0x163fb2a00 rank 7 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xe9f19695db992363 - Init START
f16n16:1079915:1080219 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
f16n16:1079915:1080219 [3] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] 9/5/-1->7->3
f16n16:1079915:1080219 [3] NCCL INFO P2P Chunksize set to 131072
f16n16:1079915:1080219 [3] NCCL INFO Channel 00/0 : 6[1] -> 7[3] [receive] via NET/IB/3
f16n16:1079915:1080219 [3] NCCL INFO Channel 01/0 : 6[1] -> 7[3] [receive] via NET/IB/3
f16n16:1079915:1080219 [3] NCCL INFO Channel 00/0 : 7[3] -> 8[5] [send] via NET/IB/3
f16n16:1079915:1080219 [3] NCCL INFO Channel 01/0 : 7[3] -> 8[5] [send] via NET/IB/3
f16n16:1079913:1080215 [1] NCCL INFO comm 0x17ea2aa40 rank 7 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0xd3b159694d72ff62 - Init START
f16n16:1079913:1080215 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
f16n16:1079913:1080215 [1] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] 9/5/-1->7->3
f16n16:1079913:1080215 [1] NCCL INFO P2P Chunksize set to 131072
f16n16:1079913:1080215 [1] NCCL INFO Channel 00/0 : 6[5] -> 7[1] [receive] via NET/IB/2
f16n16:1079913:1080215 [1] NCCL INFO Channel 01/0 : 6[5] -> 7[1] [receive] via NET/IB/2
f16n16:1079913:1080215 [1] NCCL INFO Channel 00/0 : 7[1] -> 8[3] [send] via NET/IB/2
f16n16:1079913:1080215 [1] NCCL INFO Channel 01/0 : 7[1] -> 8[3] [send] via NET/IB/2
f17n02:1076280:1076576 [1] NCCL INFO comm 0x14533e460 rank 10 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0xd3b159694d72ff62 - Init START
f17n02:1076280:1076576 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
f17n02:1076280:1076576 [1] NCCL INFO Trees [0] 9/11/-1->10->8 [1] -1/-1/-1->10->9
f17n02:1076280:1076576 [1] NCCL INFO P2P Chunksize set to 131072
f17n02:1076280:1076576 [1] NCCL INFO Channel 00/0 : 9[5] -> 10[1] [receive] via NET/IB/2
f17n02:1076280:1076576 [1] NCCL INFO Channel 01/0 : 9[5] -> 10[1] [receive] via NET/IB/2
f17n02:1076280:1076576 [1] NCCL INFO Channel 00/0 : 10[1] -> 11[3] [send] via NET/IB/2
f17n02:1076280:1076576 [1] NCCL INFO Channel 01/0 : 10[1] -> 11[3] [send] via NET/IB/2
f18n05:1008220:1008519 [1] NCCL INFO Connected all rings
f18n05:1008220:1008519 [1] NCCL INFO Channel 01/0 : 11[1] -> 3[3] [send] via NET/IB/2
f18n05:1008220:1008519 [1] NCCL INFO Channel 01/0 : 3[3] -> 11[1] [receive] via NET/IB/2
f18n05:1008220:1008519 [1] NCCL INFO Channel 00/0 : 11[1] -> 10[5] [send] via NET/IB/2
d14n11:1169356:1169677 [0] NCCL INFO Connected all rings
d14n11:1169356:1169677 [0] NCCL INFO Channel 01/0 : 5[0] -> 7[4] [send] via NET/IB/0
d14n11:1169356:1169677 [0] NCCL INFO Channel 01/0 : 7[4] -> 5[0] [receive] via NET/IB/0
d14n11:1169356:1169677 [0] NCCL INFO Channel 00/0 : 6[2] -> 5[0] [receive] via NET/IB/0
d14n11:1169356:1169677 [0] NCCL INFO Channel 01/0 : 6[2] -> 5[0] [receive] via NET/IB/0
d14n11:1169356:1169677 [0] NCCL INFO Channel 01/0 : 5[0] -> 4[4] [send] via NET/IB/0
d17n07:1212414:1212741 [4] NCCL INFO Connected all rings
d17n07:1212414:1212741 [4] NCCL INFO Channel 01/0 : 5[0] -> 7[4] [receive] via NET/IB/1
d17n07:1212414:1212741 [4] NCCL INFO Channel 01/0 : 7[4] -> 9[2] [send] via NET/IB/1
d17n07:1212414:1212741 [4] NCCL INFO Channel 01/0 : 3[2] -> 7[4] [receive] via NET/IB/1
d17n07:1212414:1212741 [4] NCCL INFO Channel 01/0 : 7[4] -> 3[2] [send] via NET/IB/1
d17n07:1212414:1212741 [4] NCCL INFO Channel 01/0 : 9[2] -> 7[4] [receive] via NET/IB/1
d17n07:1212414:1212741 [4] NCCL INFO Channel 01/0 : 7[4] -> 5[0] [send] via NET/IB/1
d17n07:1212414:1212741 [4] NCCL INFO Channel 00/0 : 7[4] -> 6[2] [send] via NET/IB/1
d11n17:1142854:1143154 [0] NCCL INFO Connected all rings
d11n17:1142854:1143154 [0] NCCL INFO Channel 00/0 : 2[0] -> 4[4] [send] via NET/IB/0
d11n17:1142854:1143154 [0] NCCL INFO Channel 00/0 : 4[4] -> 2[0] [receive] via NET/IB/0
d11n17:1142854:1143154 [0] NCCL INFO Channel 00/0 : 3[2] -> 2[0] [receive] via NET/IB/0
d11n17:1142854:1143154 [0] NCCL INFO Channel 00/0 : 2[0] -> 1[4] [send] via NET/IB/0
d11n17:1142854:1143154 [0] NCCL INFO Channel 01/0 : 2[0] -> 1[4] [send] via NET/IB/0
f16n17:1090959:1091271 [0] NCCL INFO Connected all rings
f16n17:1090959:1091271 [0] NCCL INFO Channel 00/0 : 8[0] -> 10[4] [send] via NET/IB/0
f16n17:1090959:1091271 [0] NCCL INFO Channel 00/0 : 4[4] -> 8[0] [receive] via NET/IB/0
f16n17:1090959:1091271 [0] NCCL INFO Channel 00/0 : 8[0] -> 0[2] [send] via NET/IB/0
f16n17:1090959:1091271 [0] NCCL INFO Channel 00/0 : 0[2] -> 8[0] [receive] via NET/IB/0
f16n17:1090959:1091271 [0] NCCL INFO Channel 00/0 : 8[0] -> 4[4] [send] via NET/IB/0
f16n17:1090959:1091271 [0] NCCL INFO Channel 00/0 : 10[4] -> 8[0] [receive] via NET/IB/0
f16n17:1090959:1091271 [0] NCCL INFO Channel 01/0 : 9[2] -> 8[0] [receive] via NET/IB/0
f16n17:1090960:1091270 [1] NCCL INFO Connected all rings
f16n17:1090960:1091270 [1] NCCL INFO Channel 00/0 : 8[1] -> 10[5] [send] via NET/IB/2
f16n17:1090960:1091270 [1] NCCL INFO Channel 00/0 : 4[5] -> 8[1] [receive] via NET/IB/2
f16n17:1090960:1091270 [1] NCCL INFO Channel 00/0 : 8[1] -> 0[3] [send] via NET/IB/2
f16n17:1090960:1091270 [1] NCCL INFO Channel 00/0 : 0[3] -> 8[1] [receive] via NET/IB/2
f16n17:1090960:1091270 [1] NCCL INFO Channel 00/0 : 8[1] -> 4[5] [send] via NET/IB/2
f16n17:1090960:1091270 [1] NCCL INFO Channel 00/0 : 10[5] -> 8[1] [receive] via NET/IB/2
f16n17:1090960:1091270 [1] NCCL INFO Channel 01/0 : 9[3] -> 8[1] [receive] via NET/IB/2
d14n10:565686:565993 [5] NCCL INFO Connected all rings
d14n10:565686:565993 [5] NCCL INFO Channel 01/0 : 5[5] -> 7[3] [send] via NET/IB/3
d14n10:565686:565993 [5] NCCL INFO Channel 01/0 : 7[3] -> 5[5] [receive] via NET/IB/3
d14n10:565686:565993 [5] NCCL INFO Channel 00/0 : 6[1] -> 5[5] [receive] via NET/IB/3
d14n10:565686:565993 [5] NCCL INFO Channel 01/0 : 6[1] -> 5[5] [receive] via NET/IB/3
d14n10:565686:565993 [5] NCCL INFO Channel 01/0 : 5[5] -> 4[3] [send] via NET/IB/3
d17n07:1212413:1212740 [3] NCCL INFO Connected all rings
d17n07:1212413:1212740 [3] NCCL INFO Channel 01/0 : 5[5] -> 7[3] [receive] via NET/IB/3
d17n07:1212413:1212740 [3] NCCL INFO Channel 01/0 : 7[3] -> 9[1] [send] via NET/IB/3
d17n07:1212413:1212740 [3] NCCL INFO Channel 01/0 : 3[1] -> 7[3] [receive] via NET/IB/3
d17n07:1212413:1212740 [3] NCCL INFO Channel 01/0 : 7[3] -> 3[1] [send] via NET/IB/3
d17n07:1212413:1212740 [3] NCCL INFO Channel 01/0 : 9[1] -> 7[3] [receive] via NET/IB/3
d17n07:1212413:1212740 [3] NCCL INFO Channel 01/0 : 7[3] -> 5[5] [send] via NET/IB/3
d17n07:1212413:1212740 [3] NCCL INFO Channel 00/0 : 7[3] -> 6[1] [send] via NET/IB/3
d11n17:1142855:1143152 [1] NCCL INFO Connected all rings
d11n17:1142855:1143152 [1] NCCL INFO Channel 00/0 : 2[1] -> 4[5] [send] via NET/IB/2
d11n17:1142855:1143152 [1] NCCL INFO Channel 00/0 : 4[5] -> 2[1] [receive] via NET/IB/2
d11n17:1142855:1143152 [1] NCCL INFO Channel 00/0 : 3[3] -> 2[1] [receive] via NET/IB/2
d11n17:1142855:1143152 [1] NCCL INFO Channel 00/0 : 2[1] -> 1[5] [send] via NET/IB/2
d11n17:1142855:1143152 [1] NCCL INFO Channel 01/0 : 2[1] -> 1[5] [send] via NET/IB/2
f17n02:1076284:1076577 [5] NCCL INFO Connected all rings
f17n02:1076284:1076577 [5] NCCL INFO Channel 01/0 : 11[5] -> 3[1] [send] via NET/IB/3
f17n02:1076284:1076577 [5] NCCL INFO Channel 01/0 : 3[1] -> 11[5] [receive] via NET/IB/3
f17n02:1076284:1076577 [5] NCCL INFO Channel 00/0 : 11[5] -> 10[3] [send] via NET/IB/3
d14n09:567670:567996 [4] NCCL INFO Connected all rings
d14n09:567670:567996 [4] NCCL INFO Channel 00/0 : 2[0] -> 4[4] [receive] via NET/IB/1
d14n09:567670:567996 [4] NCCL INFO Channel 00/0 : 4[4] -> 6[2] [send] via NET/IB/1
d14n09:567670:567996 [4] NCCL INFO Channel 00/0 : 4[4] -> 8[0] [send] via NET/IB/1
d14n09:567670:567996 [4] NCCL INFO Channel 00/0 : 8[0] -> 4[4] [receive] via NET/IB/1
d14n09:567670:567996 [4] NCCL INFO Channel 00/0 : 6[2] -> 4[4] [receive] via NET/IB/1
d14n09:567670:567996 [4] NCCL INFO Channel 00/0 : 4[4] -> 2[0] [send] via NET/IB/1
d14n09:567670:567996 [4] NCCL INFO Channel 01/0 : 5[0] -> 4[4] [receive] via NET/IB/1
d14n11:1169357:1169672 [1] NCCL INFO Connected all rings
d14n11:1169357:1169672 [1] NCCL INFO Channel 01/0 : 5[1] -> 7[5] [send] via NET/IB/2
d14n11:1169357:1169672 [1] NCCL INFO Channel 01/0 : 7[5] -> 5[1] [receive] via NET/IB/2
d14n11:1169357:1169672 [1] NCCL INFO Channel 00/0 : 6[3] -> 5[1] [receive] via NET/IB/2
d14n11:1169357:1169672 [1] NCCL INFO Channel 01/0 : 6[3] -> 5[1] [receive] via NET/IB/2
d14n11:1169357:1169672 [1] NCCL INFO Channel 01/0 : 5[1] -> 4[5] [send] via NET/IB/2
f16n16:1079917:1080217 [5] NCCL INFO Connected all rings
f16n16:1079917:1080217 [5] NCCL INFO Channel 00/0 : 8[5] -> 10[3] [send] via NET/IB/3
f16n16:1079917:1080217 [5] NCCL INFO Channel 00/0 : 4[3] -> 8[5] [receive] via NET/IB/3
f16n16:1079917:1080217 [5] NCCL INFO Channel 00/0 : 8[5] -> 0[1] [send] via NET/IB/3
f16n16:1079917:1080217 [5] NCCL INFO Channel 00/0 : 0[1] -> 8[5] [receive] via NET/IB/3
f16n16:1079917:1080217 [5] NCCL INFO Channel 00/0 : 8[5] -> 4[3] [send] via NET/IB/3
f16n16:1079917:1080217 [5] NCCL INFO Channel 00/0 : 10[3] -> 8[5] [receive] via NET/IB/3
f16n16:1079917:1080217 [5] NCCL INFO Channel 01/0 : 9[1] -> 8[5] [receive] via NET/IB/3
d11n16:1130273:1130581 [5] NCCL INFO Connected all rings
d11n16:1130273:1130581 [5] NCCL INFO Channel 00/0 : 2[5] -> 4[3] [send] via NET/IB/3
d11n16:1130273:1130581 [5] NCCL INFO Channel 00/0 : 4[3] -> 2[5] [receive] via NET/IB/3
d11n16:1130273:1130581 [5] NCCL INFO Channel 00/0 : 3[1] -> 2[5] [receive] via NET/IB/3
d11n16:1130273:1130581 [5] NCCL INFO Channel 00/0 : 2[5] -> 1[3] [send] via NET/IB/3
d11n16:1130273:1130581 [5] NCCL INFO Channel 01/0 : 2[5] -> 1[3] [send] via NET/IB/3
f16n18:1091868:1092188 [2] NCCL INFO Connected all rings
f16n18:1091868:1092188 [2] NCCL INFO Channel 01/0 : 7[4] -> 9[2] [receive] via NET/IB/0
f16n18:1091868:1092188 [2] NCCL INFO Channel 01/0 : 9[2] -> 7[4] [send] via NET/IB/0
f16n18:1091868:1092188 [2] NCCL INFO Channel 00/0 : 10[4] -> 9[2] [receive] via NET/IB/0
f16n18:1091868:1092188 [2] NCCL INFO Channel 01/0 : 10[4] -> 9[2] [receive] via NET/IB/0
f16n18:1091868:1092188 [2] NCCL INFO Channel 01/0 : 9[2] -> 8[0] [send] via NET/IB/0
f18n05:1008219:1008520 [0] NCCL INFO Connected all rings
f18n05:1008219:1008520 [0] NCCL INFO Channel 01/0 : 11[0] -> 3[2] [send] via NET/IB/0
f18n05:1008219:1008520 [0] NCCL INFO Channel 01/0 : 3[2] -> 11[0] [receive] via NET/IB/0
f18n05:1008219:1008520 [0] NCCL INFO Channel 00/0 : 11[0] -> 10[4] [send] via NET/IB/0
f17n01:970280:970574 [4] NCCL INFO Connected all rings
f17n01:970280:970574 [4] NCCL INFO Channel 00/0 : 8[0] -> 10[4] [receive] via NET/IB/1
f17n01:970280:970574 [4] NCCL INFO Channel 00/0 : 10[4] -> 8[0] [send] via NET/IB/1
f17n01:970280:970574 [4] NCCL INFO Channel 00/0 : 11[0] -> 10[4] [receive] via NET/IB/1
f17n01:970280:970574 [4] NCCL INFO Channel 00/0 : 10[4] -> 9[2] [send] via NET/IB/1
f17n01:970280:970574 [4] NCCL INFO Channel 01/0 : 10[4] -> 9[2] [send] via NET/IB/1
d17n06:1216532:1216861 [2] NCCL INFO Connected all rings
d17n06:1216532:1216861 [2] NCCL INFO Channel 00/0 : 4[4] -> 6[2] [receive] via NET/IB/0
d17n06:1216532:1216861 [2] NCCL INFO Channel 00/0 : 6[2] -> 4[4] [send] via NET/IB/0
d17n06:1216532:1216861 [2] NCCL INFO Channel 00/0 : 7[4] -> 6[2] [receive] via NET/IB/0
d17n06:1216532:1216861 [2] NCCL INFO Channel 00/0 : 6[2] -> 5[0] [send] via NET/IB/0
d17n06:1216532:1216861 [2] NCCL INFO Channel 01/0 : 6[2] -> 5[0] [send] via NET/IB/0
f16n18:1091867:1092187 [1] NCCL INFO Connected all rings
f16n18:1091867:1092187 [1] NCCL INFO Channel 01/0 : 7[3] -> 9[1] [receive] via NET/IB/2
f16n18:1091867:1092187 [1] NCCL INFO Channel 01/0 : 9[1] -> 7[3] [send] via NET/IB/2
f16n18:1091867:1092187 [1] NCCL INFO Channel 00/0 : 10[3] -> 9[1] [receive] via NET/IB/2
f16n18:1091867:1092187 [1] NCCL INFO Channel 01/0 : 10[3] -> 9[1] [receive] via NET/IB/2
f16n18:1091867:1092187 [1] NCCL INFO Channel 01/0 : 9[1] -> 8[5] [send] via NET/IB/2
d17n07:1212415:1212739 [5] NCCL INFO Connected all rings
d17n07:1212415:1212739 [5] NCCL INFO Channel 01/0 : 5[1] -> 7[5] [receive] via NET/IB/3
d17n07:1212415:1212739 [5] NCCL INFO Channel 01/0 : 7[5] -> 9[3] [send] via NET/IB/3
d17n07:1212415:1212739 [5] NCCL INFO Channel 01/0 : 3[3] -> 7[5] [receive] via NET/IB/3
d17n07:1212415:1212739 [5] NCCL INFO Channel 01/0 : 7[5] -> 3[3] [send] via NET/IB/3
d17n07:1212415:1212739 [5] NCCL INFO Channel 01/0 : 9[3] -> 7[5] [receive] via NET/IB/3
d17n07:1212415:1212739 [5] NCCL INFO Channel 01/0 : 7[5] -> 5[1] [send] via NET/IB/3
d17n07:1212415:1212739 [5] NCCL INFO Channel 00/0 : 7[5] -> 6[3] [send] via NET/IB/3
f17n01:970279:970575 [3] NCCL INFO Connected all rings
f17n01:970279:970575 [3] NCCL INFO Channel 00/0 : 8[5] -> 10[3] [receive] via NET/IB/3
f17n01:970279:970575 [3] NCCL INFO Channel 00/0 : 10[3] -> 8[5] [send] via NET/IB/3
f17n01:970279:970575 [3] NCCL INFO Channel 00/0 : 11[5] -> 10[3] [receive] via NET/IB/3
f17n01:970279:970575 [3] NCCL INFO Channel 00/0 : 10[3] -> 9[1] [send] via NET/IB/3
f17n01:970279:970575 [3] NCCL INFO Channel 01/0 : 10[3] -> 9[1] [send] via NET/IB/3
d14n08:1173248:1173568 [1] NCCL INFO Connected all rings
d14n08:1173248:1173568 [1] NCCL INFO Channel 01/0 : 1[3] -> 3[1] [receive] via NET/IB/2
d14n08:1173248:1173568 [1] NCCL INFO Channel 01/0 : 11[5] -> 3[1] [receive] via NET/IB/2
d14n08:1173248:1173568 [1] NCCL INFO Channel 01/0 : 3[1] -> 7[3] [send] via NET/IB/2
d14n08:1173248:1173568 [1] NCCL INFO Channel 01/0 : 7[3] -> 3[1] [receive] via NET/IB/2
d14n08:1173248:1173568 [1] NCCL INFO Channel 01/0 : 3[1] -> 11[5] [send] via NET/IB/2
d14n08:1173248:1173568 [1] NCCL INFO Channel 01/0 : 3[1] -> 1[3] [send] via NET/IB/2
d14n08:1173248:1173568 [1] NCCL INFO Channel 00/0 : 3[1] -> 2[5] [send] via NET/IB/2
d14n09:567671:567995 [5] NCCL INFO Connected all rings
d14n09:567671:567995 [5] NCCL INFO Channel 00/0 : 2[1] -> 4[5] [receive] via NET/IB/3
d14n09:567671:567995 [5] NCCL INFO Channel 00/0 : 4[5] -> 6[3] [send] via NET/IB/3
d14n09:567671:567995 [5] NCCL INFO Channel 00/0 : 4[5] -> 8[1] [send] via NET/IB/3
d14n09:567671:567995 [5] NCCL INFO Channel 00/0 : 8[1] -> 4[5] [receive] via NET/IB/3
d14n09:567671:567995 [5] NCCL INFO Channel 00/0 : 6[3] -> 4[5] [receive] via NET/IB/3
d14n09:567671:567995 [5] NCCL INFO Channel 00/0 : 4[5] -> 2[1] [send] via NET/IB/3
d14n09:567671:567995 [5] NCCL INFO Channel 01/0 : 5[1] -> 4[5] [receive] via NET/IB/3
d14n08:1173250:1173566 [3] NCCL INFO Connected all rings
d14n08:1173250:1173566 [3] NCCL INFO Channel 01/0 : 1[5] -> 3[3] [receive] via NET/IB/3
d14n08:1173250:1173566 [3] NCCL INFO Channel 01/0 : 11[1] -> 3[3] [receive] via NET/IB/3
d14n08:1173250:1173566 [3] NCCL INFO Channel 01/0 : 3[3] -> 7[5] [send] via NET/IB/3
d14n08:1173250:1173566 [3] NCCL INFO Channel 01/0 : 7[5] -> 3[3] [receive] via NET/IB/3
d14n08:1173250:1173566 [3] NCCL INFO Channel 01/0 : 3[3] -> 11[1] [send] via NET/IB/3
d14n08:1173250:1173566 [3] NCCL INFO Channel 01/0 : 3[3] -> 1[5] [send] via NET/IB/3
d14n08:1173250:1173566 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[1] [send] via NET/IB/3
d17n06:1216533:1216863 [3] NCCL INFO Connected all rings
d17n06:1216533:1216863 [3] NCCL INFO Channel 00/0 : 4[5] -> 6[3] [receive] via NET/IB/3
d17n06:1216533:1216863 [3] NCCL INFO Channel 00/0 : 6[3] -> 4[5] [send] via NET/IB/3
d17n06:1216533:1216863 [3] NCCL INFO Channel 00/0 : 7[5] -> 6[3] [receive] via NET/IB/3
d17n06:1216533:1216863 [3] NCCL INFO Channel 00/0 : 6[3] -> 5[1] [send] via NET/IB/3
d17n06:1216533:1216863 [3] NCCL INFO Channel 01/0 : 6[3] -> 5[1] [send] via NET/IB/3
f17n01:970281:970576 [5] NCCL INFO Connected all rings
f17n01:970281:970576 [5] NCCL INFO Channel 00/0 : 8[1] -> 10[5] [receive] via NET/IB/3
f17n01:970281:970576 [5] NCCL INFO Channel 00/0 : 10[5] -> 8[1] [send] via NET/IB/3
f17n01:970281:970576 [5] NCCL INFO Channel 00/0 : 11[1] -> 10[5] [receive] via NET/IB/3
f17n01:970281:970576 [5] NCCL INFO Channel 00/0 : 10[5] -> 9[3] [send] via NET/IB/3
f17n01:970281:970576 [5] NCCL INFO Channel 01/0 : 10[5] -> 9[3] [send] via NET/IB/3
d09n07:1063019:1063392 [2] NCCL INFO Connected all rings
d09n07:1063019:1063392 [2] NCCL INFO Channel 00/0 : 8[0] -> 0[2] [receive] via NET/IB/0
d09n07:1063019:1063392 [2] NCCL INFO Channel 00/0 : 0[2] -> 8[0] [send] via NET/IB/0
d09n07:1063019:1063392 [2] NCCL INFO Channel 01/0 : 1[4] -> 0[2] [receive] via NET/IB/0
f16n18:1091869:1092190 [3] NCCL INFO Connected all rings
f16n18:1091869:1092190 [3] NCCL INFO Channel 01/0 : 7[5] -> 9[3] [receive] via NET/IB/3
f16n18:1091869:1092190 [3] NCCL INFO Channel 01/0 : 9[3] -> 7[5] [send] via NET/IB/3
f16n18:1091869:1092190 [3] NCCL INFO Channel 00/0 : 10[5] -> 9[3] [receive] via NET/IB/3
f16n18:1091869:1092190 [3] NCCL INFO Channel 01/0 : 10[5] -> 9[3] [receive] via NET/IB/3
f16n18:1091869:1092190 [3] NCCL INFO Channel 01/0 : 9[3] -> 8[1] [send] via NET/IB/3
d09n07:1063018:1063394 [1] NCCL INFO Connected all rings
d09n07:1063018:1063394 [1] NCCL INFO Channel 00/0 : 8[5] -> 0[1] [receive] via NET/IB/2
d09n07:1063018:1063394 [1] NCCL INFO Channel 00/0 : 0[1] -> 8[5] [send] via NET/IB/2
d09n07:1063018:1063394 [1] NCCL INFO Channel 01/0 : 1[3] -> 0[1] [receive] via NET/IB/2
d14n08:1173249:1173567 [2] NCCL INFO Connected all rings
d14n08:1173249:1173567 [2] NCCL INFO Channel 01/0 : 1[4] -> 3[2] [receive] via NET/IB/0
d14n08:1173249:1173567 [2] NCCL INFO Channel 01/0 : 11[0] -> 3[2] [receive] via NET/IB/0
d14n08:1173249:1173567 [2] NCCL INFO Channel 01/0 : 3[2] -> 7[4] [send] via NET/IB/0
d14n08:1173249:1173567 [2] NCCL INFO Channel 01/0 : 7[4] -> 3[2] [receive] via NET/IB/0
d14n08:1173249:1173567 [2] NCCL INFO Channel 01/0 : 3[2] -> 11[0] [send] via NET/IB/0
d14n08:1173249:1173567 [2] NCCL INFO Channel 01/0 : 3[2] -> 1[4] [send] via NET/IB/0
d14n08:1173249:1173567 [2] NCCL INFO Channel 00/0 : 3[2] -> 2[0] [send] via NET/IB/0
d09n07:1063020:1063391 [3] NCCL INFO Connected all rings
d09n07:1063020:1063391 [3] NCCL INFO Channel 00/0 : 8[1] -> 0[3] [receive] via NET/IB/3
d09n07:1063020:1063391 [3] NCCL INFO Channel 00/0 : 0[3] -> 8[1] [send] via NET/IB/3
d09n07:1063020:1063391 [3] NCCL INFO Channel 01/0 : 1[5] -> 0[3] [receive] via NET/IB/3
d17n06:1216531:1216860 [1] NCCL INFO Connected all rings
d17n06:1216531:1216860 [1] NCCL INFO Channel 00/0 : 4[3] -> 6[1] [receive] via NET/IB/2
d17n06:1216531:1216860 [1] NCCL INFO Channel 00/0 : 6[1] -> 4[3] [send] via NET/IB/2
d17n06:1216531:1216860 [1] NCCL INFO Channel 00/0 : 7[3] -> 6[1] [receive] via NET/IB/2
d17n06:1216531:1216860 [1] NCCL INFO Channel 00/0 : 6[1] -> 5[5] [send] via NET/IB/2
d17n06:1216531:1216860 [1] NCCL INFO Channel 01/0 : 6[1] -> 5[5] [send] via NET/IB/2
d14n09:567669:567997 [3] NCCL INFO Connected all rings
d14n09:567669:567997 [3] NCCL INFO Channel 00/0 : 2[5] -> 4[3] [receive] via NET/IB/3
d14n09:567669:567997 [3] NCCL INFO Channel 00/0 : 4[3] -> 6[1] [send] via NET/IB/3
d14n09:567669:567997 [3] NCCL INFO Channel 00/0 : 4[3] -> 8[5] [send] via NET/IB/3
d14n09:567669:567997 [3] NCCL INFO Channel 00/0 : 8[5] -> 4[3] [receive] via NET/IB/3
d14n09:567669:567997 [3] NCCL INFO Channel 00/0 : 6[1] -> 4[3] [receive] via NET/IB/3
d14n09:567669:567997 [3] NCCL INFO Channel 00/0 : 4[3] -> 2[5] [send] via NET/IB/3
d14n09:567669:567997 [3] NCCL INFO Channel 01/0 : 5[5] -> 4[3] [receive] via NET/IB/3
d09n08:1073958:1074256 [4] NCCL INFO Connected all rings
d09n08:1073958:1074256 [4] NCCL INFO Channel 01/0 : 1[4] -> 3[2] [send] via NET/IB/1
d09n08:1073958:1074256 [4] NCCL INFO Channel 01/0 : 3[2] -> 1[4] [receive] via NET/IB/1
d09n08:1073958:1074256 [4] NCCL INFO Channel 00/0 : 2[0] -> 1[4] [receive] via NET/IB/1
d09n08:1073958:1074256 [4] NCCL INFO Channel 01/0 : 2[0] -> 1[4] [receive] via NET/IB/1
d09n08:1073958:1074256 [4] NCCL INFO Channel 01/0 : 1[4] -> 0[2] [send] via NET/IB/1
f16n17:1090961:1091272 [2] NCCL INFO Connected all rings
f16n17:1090961:1091272 [2] NCCL INFO Channel 00/0 : 8[2] -> 10[0] [send] via NET/IB/0
f16n17:1090961:1091272 [2] NCCL INFO Channel 00/0 : 4[0] -> 8[2] [receive] via NET/IB/0
f16n17:1090961:1091272 [2] NCCL INFO Channel 00/0 : 8[2] -> 0[4] [send] via NET/IB/0
f16n17:1090961:1091272 [2] NCCL INFO Channel 00/0 : 0[4] -> 8[2] [receive] via NET/IB/0
f16n17:1090961:1091272 [2] NCCL INFO Channel 00/0 : 8[2] -> 4[0] [send] via NET/IB/0
f16n17:1090961:1091272 [2] NCCL INFO Channel 00/0 : 10[0] -> 8[2] [receive] via NET/IB/0
f16n17:1090961:1091272 [2] NCCL INFO Channel 01/0 : 9[4] -> 8[2] [receive] via NET/IB/0
d09n08:1073957:1074254 [3] NCCL INFO Connected all rings
d09n08:1073957:1074254 [3] NCCL INFO Channel 01/0 : 1[3] -> 3[1] [send] via NET/IB/3
d09n08:1073957:1074254 [3] NCCL INFO Channel 01/0 : 3[1] -> 1[3] [receive] via NET/IB/3
d09n08:1073957:1074254 [3] NCCL INFO Channel 00/0 : 2[5] -> 1[3] [receive] via NET/IB/3
d09n08:1073957:1074254 [3] NCCL INFO Channel 01/0 : 2[5] -> 1[3] [receive] via NET/IB/3
d09n08:1073957:1074254 [3] NCCL INFO Channel 01/0 : 1[3] -> 0[1] [send] via NET/IB/3
d14n11:1169358:1169673 [2] NCCL INFO Connected all rings
d14n11:1169358:1169673 [2] NCCL INFO Channel 01/0 : 5[2] -> 7[0] [send] via NET/IB/0
d14n11:1169358:1169673 [2] NCCL INFO Channel 01/0 : 7[0] -> 5[2] [receive] via NET/IB/0
d14n11:1169358:1169673 [2] NCCL INFO Channel 00/0 : 6[4] -> 5[2] [receive] via NET/IB/0
d14n11:1169358:1169673 [2] NCCL INFO Channel 01/0 : 6[4] -> 5[2] [receive] via NET/IB/0
d14n11:1169358:1169673 [2] NCCL INFO Channel 01/0 : 5[2] -> 4[0] [send] via NET/IB/0
d09n08:1073959:1074255 [5] NCCL INFO Connected all rings
d09n08:1073959:1074255 [5] NCCL INFO Channel 01/0 : 1[5] -> 3[3] [send] via NET/IB/3
d09n08:1073959:1074255 [5] NCCL INFO Channel 01/0 : 3[3] -> 1[5] [receive] via NET/IB/3
d09n08:1073959:1074255 [5] NCCL INFO Channel 00/0 : 2[1] -> 1[5] [receive] via NET/IB/3
d09n08:1073959:1074255 [5] NCCL INFO Channel 01/0 : 2[1] -> 1[5] [receive] via NET/IB/3
d09n08:1073959:1074255 [5] NCCL INFO Channel 01/0 : 1[5] -> 0[3] [send] via NET/IB/3
d11n17:1142856:1143153 [2] NCCL INFO Connected all rings
d11n17:1142856:1143153 [2] NCCL INFO Channel 00/0 : 2[2] -> 4[0] [send] via NET/IB/0
d11n17:1142856:1143153 [2] NCCL INFO Channel 00/0 : 4[0] -> 2[2] [receive] via NET/IB/0
d11n17:1142856:1143153 [2] NCCL INFO Channel 00/0 : 3[4] -> 2[2] [receive] via NET/IB/0
d11n17:1142856:1143153 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[0] [send] via NET/IB/0
d11n17:1142856:1143153 [2] NCCL INFO Channel 01/0 : 2[2] -> 1[0] [send] via NET/IB/0
f17n02:1076279:1076575 [0] NCCL INFO Connected all rings
f17n02:1076279:1076575 [0] NCCL INFO Channel 00/0 : 8[2] -> 10[0] [receive] via NET/IB/0
f17n02:1076279:1076575 [0] NCCL INFO Channel 00/0 : 10[0] -> 8[2] [send] via NET/IB/0
f17n02:1076279:1076575 [0] NCCL INFO Channel 00/0 : 11[2] -> 10[0] [receive] via NET/IB/0
f17n02:1076279:1076575 [0] NCCL INFO Channel 00/0 : 10[0] -> 9[4] [send] via NET/IB/0
f17n02:1076279:1076575 [0] NCCL INFO Channel 01/0 : 10[0] -> 9[4] [send] via NET/IB/0
f18n05:1008221:1008518 [2] NCCL INFO Connected all rings
f18n05:1008221:1008518 [2] NCCL INFO Channel 01/0 : 11[2] -> 3[4] [send] via NET/IB/0
f18n05:1008221:1008518 [2] NCCL INFO Channel 01/0 : 3[4] -> 11[2] [receive] via NET/IB/0
f18n05:1008221:1008518 [2] NCCL INFO Channel 00/0 : 11[2] -> 10[0] [send] via NET/IB/0
d14n08:1173251:1173565 [4] NCCL INFO Connected all rings
d14n08:1173251:1173565 [4] NCCL INFO Channel 01/0 : 1[0] -> 3[4] [receive] via NET/IB/1
d14n08:1173251:1173565 [4] NCCL INFO Channel 01/0 : 11[2] -> 3[4] [receive] via NET/IB/1
d14n08:1173251:1173565 [4] NCCL INFO Channel 01/0 : 3[4] -> 7[0] [send] via NET/IB/1
d14n08:1173251:1173565 [4] NCCL INFO Channel 01/0 : 7[0] -> 3[4] [receive] via NET/IB/1
d14n08:1173251:1173565 [4] NCCL INFO Channel 01/0 : 3[4] -> 11[2] [send] via NET/IB/1
d14n08:1173251:1173565 [4] NCCL INFO Channel 01/0 : 3[4] -> 1[0] [send] via NET/IB/1
d14n08:1173251:1173565 [4] NCCL INFO Channel 00/0 : 3[4] -> 2[2] [send] via NET/IB/1
f18n05:1008223:1008522 [4] NCCL INFO Connected all rings
f18n05:1008223:1008522 [4] NCCL INFO Channel 01/0 : 11[4] -> 3[0] [send] via NET/IB/1
f18n05:1008223:1008522 [4] NCCL INFO Channel 01/0 : 3[0] -> 11[4] [receive] via NET/IB/1
f18n05:1008223:1008522 [4] NCCL INFO Channel 00/0 : 11[4] -> 10[2] [send] via NET/IB/1
d09n07:1063021:1063389 [4] NCCL INFO Connected all rings
d09n07:1063021:1063389 [4] NCCL INFO Channel 00/0 : 8[2] -> 0[4] [receive] via NET/IB/1
d09n07:1063021:1063389 [4] NCCL INFO Channel 00/0 : 0[4] -> 8[2] [send] via NET/IB/1
d09n07:1063021:1063389 [4] NCCL INFO Channel 01/0 : 1[0] -> 0[4] [receive] via NET/IB/1
d14n11:1169359:1169675 [3] NCCL INFO Connected all rings
d14n11:1169359:1169675 [3] NCCL INFO Channel 01/0 : 5[3] -> 7[1] [send] via NET/IB/3
d14n11:1169359:1169675 [3] NCCL INFO Channel 01/0 : 7[1] -> 5[3] [receive] via NET/IB/3
d14n11:1169359:1169675 [3] NCCL INFO Channel 00/0 : 6[5] -> 5[3] [receive] via NET/IB/3
d14n11:1169359:1169675 [3] NCCL INFO Channel 01/0 : 6[5] -> 5[3] [receive] via NET/IB/3
d14n11:1169359:1169675 [3] NCCL INFO Channel 01/0 : 5[3] -> 4[1] [send] via NET/IB/3
f16n18:1091870:1092186 [4] NCCL INFO Connected all rings
f16n18:1091870:1092186 [4] NCCL INFO Channel 01/0 : 7[0] -> 9[4] [receive] via NET/IB/1
f16n18:1091870:1092186 [4] NCCL INFO Channel 01/0 : 9[4] -> 7[0] [send] via NET/IB/1
f16n18:1091870:1092186 [4] NCCL INFO Channel 00/0 : 10[0] -> 9[4] [receive] via NET/IB/1
f16n18:1091870:1092186 [4] NCCL INFO Channel 01/0 : 10[0] -> 9[4] [receive] via NET/IB/1
f16n18:1091870:1092186 [4] NCCL INFO Channel 01/0 : 9[4] -> 8[2] [send] via NET/IB/1
d11n16:1130268:1130579 [0] NCCL INFO Connected all rings
d11n16:1130268:1130579 [0] NCCL INFO Channel 01/0 : 1[0] -> 3[4] [send] via NET/IB/0
d11n16:1130268:1130579 [0] NCCL INFO Channel 01/0 : 3[4] -> 1[0] [receive] via NET/IB/0
d11n16:1130268:1130579 [0] NCCL INFO Channel 00/0 : 2[2] -> 1[0] [receive] via NET/IB/0
d11n16:1130268:1130579 [0] NCCL INFO Channel 01/0 : 2[2] -> 1[0] [receive] via NET/IB/0
d11n16:1130268:1130579 [0] NCCL INFO Channel 01/0 : 1[0] -> 0[4] [send] via NET/IB/0
f18n05:1008224:1008523 [5] NCCL INFO Connected all rings
f18n05:1008224:1008523 [5] NCCL INFO Channel 01/0 : 11[5] -> 3[1] [send] via NET/IB/3
f18n05:1008224:1008523 [5] NCCL INFO Channel 01/0 : 3[1] -> 11[5] [receive] via NET/IB/3
f18n05:1008224:1008523 [5] NCCL INFO Channel 00/0 : 11[5] -> 10[3] [send] via NET/IB/3
d11n17:1142858:1143156 [4] NCCL INFO Connected all rings
d11n17:1142858:1143156 [4] NCCL INFO Channel 00/0 : 2[4] -> 4[2] [send] via NET/IB/1
d11n17:1142858:1143156 [4] NCCL INFO Channel 00/0 : 4[2] -> 2[4] [receive] via NET/IB/1
d11n17:1142858:1143156 [4] NCCL INFO Channel 00/0 : 3[0] -> 2[4] [receive] via NET/IB/1
d11n17:1142858:1143156 [4] NCCL INFO Channel 00/0 : 2[4] -> 1[2] [send] via NET/IB/1
d11n17:1142858:1143156 [4] NCCL INFO Channel 01/0 : 2[4] -> 1[2] [send] via NET/IB/1
d11n17:1142857:1143157 [3] NCCL INFO Connected all rings
d11n17:1142857:1143157 [3] NCCL INFO Channel 00/0 : 2[3] -> 4[1] [send] via NET/IB/3
d11n17:1142857:1143157 [3] NCCL INFO Channel 00/0 : 4[1] -> 2[3] [receive] via NET/IB/3
d11n17:1142857:1143157 [3] NCCL INFO Channel 00/0 : 3[5] -> 2[3] [receive] via NET/IB/3
d11n17:1142857:1143157 [3] NCCL INFO Channel 00/0 : 2[3] -> 1[1] [send] via NET/IB/3
d11n17:1142857:1143157 [3] NCCL INFO Channel 01/0 : 2[3] -> 1[1] [send] via NET/IB/3
d11n16:1130269:1130580 [1] NCCL INFO Connected all rings
d11n16:1130269:1130580 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[5] [send] via NET/IB/2
d11n16:1130269:1130580 [1] NCCL INFO Channel 01/0 : 3[5] -> 1[1] [receive] via NET/IB/2
d11n16:1130269:1130580 [1] NCCL INFO Channel 00/0 : 2[3] -> 1[1] [receive] via NET/IB/2
d11n16:1130269:1130580 [1] NCCL INFO Channel 01/0 : 2[3] -> 1[1] [receive] via NET/IB/2
d11n16:1130269:1130580 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[5] [send] via NET/IB/2
f16n16:1079912:1080216 [0] NCCL INFO Connected all rings
f16n16:1079912:1080216 [0] NCCL INFO Channel 01/0 : 5[2] -> 7[0] [receive] via NET/IB/0
f16n16:1079912:1080216 [0] NCCL INFO Channel 01/0 : 7[0] -> 9[4] [send] via NET/IB/0
f16n16:1079912:1080216 [0] NCCL INFO Channel 01/0 : 3[4] -> 7[0] [receive] via NET/IB/0
f16n16:1079912:1080216 [0] NCCL INFO Channel 01/0 : 7[0] -> 3[4] [send] via NET/IB/0
f16n16:1079912:1080216 [0] NCCL INFO Channel 01/0 : 9[4] -> 7[0] [receive] via NET/IB/0
f16n16:1079912:1080216 [0] NCCL INFO Channel 01/0 : 7[0] -> 5[2] [send] via NET/IB/0
f16n16:1079912:1080216 [0] NCCL INFO Channel 00/0 : 7[0] -> 6[4] [send] via NET/IB/0
d17n06:1216534:1216862 [4] NCCL INFO Connected all rings
d17n06:1216534:1216862 [4] NCCL INFO Channel 00/0 : 4[0] -> 6[4] [receive] via NET/IB/1
d17n06:1216534:1216862 [4] NCCL INFO Channel 00/0 : 6[4] -> 4[0] [send] via NET/IB/1
d17n06:1216534:1216862 [4] NCCL INFO Channel 00/0 : 7[0] -> 6[4] [receive] via NET/IB/1
d17n06:1216534:1216862 [4] NCCL INFO Channel 00/0 : 6[4] -> 5[2] [send] via NET/IB/1
d17n06:1216534:1216862 [4] NCCL INFO Channel 01/0 : 6[4] -> 5[2] [send] via NET/IB/1
d14n11:1169360:1169676 [4] NCCL INFO Connected all rings
d14n11:1169360:1169676 [4] NCCL INFO Channel 01/0 : 5[4] -> 7[2] [send] via NET/IB/1
d14n11:1169360:1169676 [4] NCCL INFO Channel 01/0 : 7[2] -> 5[4] [receive] via NET/IB/1
d14n11:1169360:1169676 [4] NCCL INFO Channel 00/0 : 6[0] -> 5[4] [receive] via NET/IB/1
d14n11:1169360:1169676 [4] NCCL INFO Channel 01/0 : 6[0] -> 5[4] [receive] via NET/IB/1
d14n11:1169360:1169676 [4] NCCL INFO Channel 01/0 : 5[4] -> 4[2] [send] via NET/IB/1
f18n05:1008222:1008521 [3] NCCL INFO Connected all rings
f18n05:1008222:1008521 [3] NCCL INFO Channel 01/0 : 11[3] -> 3[5] [send] via NET/IB/3
f18n05:1008222:1008521 [3] NCCL INFO Channel 01/0 : 3[5] -> 11[3] [receive] via NET/IB/3
f18n05:1008222:1008521 [3] NCCL INFO Channel 00/0 : 11[3] -> 10[1] [send] via NET/IB/3
d14n10:565681:565991 [0] NCCL INFO Connected all rings
d14n10:565681:565991 [0] NCCL INFO Channel 00/0 : 2[2] -> 4[0] [receive] via NET/IB/0
d14n10:565681:565991 [0] NCCL INFO Channel 00/0 : 4[0] -> 6[4] [send] via NET/IB/0
d14n10:565681:565991 [0] NCCL INFO Channel 00/0 : 4[0] -> 8[2] [send] via NET/IB/0
d14n10:565681:565991 [0] NCCL INFO Channel 00/0 : 8[2] -> 4[0] [receive] via NET/IB/0
d14n10:565681:565991 [0] NCCL INFO Channel 00/0 : 6[4] -> 4[0] [receive] via NET/IB/0
d14n10:565681:565991 [0] NCCL INFO Channel 00/0 : 4[0] -> 2[2] [send] via NET/IB/0
d14n10:565681:565991 [0] NCCL INFO Channel 01/0 : 5[2] -> 4[0] [receive] via NET/IB/0
d14n10:565683:565994 [2] NCCL INFO Connected all rings
d14n10:565683:565994 [2] NCCL INFO Channel 00/0 : 2[4] -> 4[2] [receive] via NET/IB/0
d14n10:565683:565994 [2] NCCL INFO Channel 00/0 : 4[2] -> 6[0] [send] via NET/IB/0
d14n10:565683:565994 [2] NCCL INFO Channel 00/0 : 4[2] -> 8[4] [send] via NET/IB/0
d14n10:565683:565994 [2] NCCL INFO Channel 00/0 : 8[4] -> 4[2] [receive] via NET/IB/0
d14n10:565683:565994 [2] NCCL INFO Channel 00/0 : 6[0] -> 4[2] [receive] via NET/IB/0
d14n10:565683:565994 [2] NCCL INFO Channel 00/0 : 4[2] -> 2[4] [send] via NET/IB/0
d14n10:565683:565994 [2] NCCL INFO Channel 01/0 : 5[4] -> 4[2] [receive] via NET/IB/0
d14n10:565682:565992 [1] NCCL INFO Connected all rings
d14n10:565682:565992 [1] NCCL INFO Channel 00/0 : 2[3] -> 4[1] [receive] via NET/IB/2
d14n10:565682:565992 [1] NCCL INFO Channel 00/0 : 4[1] -> 6[5] [send] via NET/IB/2
d14n10:565682:565992 [1] NCCL INFO Channel 00/0 : 4[1] -> 8[3] [send] via NET/IB/2
d14n10:565682:565992 [1] NCCL INFO Channel 00/0 : 8[3] -> 4[1] [receive] via NET/IB/2
d14n10:565682:565992 [1] NCCL INFO Channel 00/0 : 6[5] -> 4[1] [receive] via NET/IB/2
d14n10:565682:565992 [1] NCCL INFO Channel 00/0 : 4[1] -> 2[3] [send] via NET/IB/2
d14n10:565682:565992 [1] NCCL INFO Channel 01/0 : 5[3] -> 4[1] [receive] via NET/IB/2
d17n07:1212410:1212742 [0] NCCL INFO Connected all rings
d17n07:1212410:1212742 [0] NCCL INFO Channel 00/0 : 4[2] -> 6[0] [receive] via NET/IB/0
d17n07:1212410:1212742 [0] NCCL INFO Channel 00/0 : 6[0] -> 4[2] [send] via NET/IB/0
d17n07:1212410:1212742 [0] NCCL INFO Channel 00/0 : 7[2] -> 6[0] [receive] via NET/IB/0
d17n07:1212410:1212742 [0] NCCL INFO Channel 00/0 : 6[0] -> 5[4] [send] via NET/IB/0
d17n07:1212410:1212742 [0] NCCL INFO Channel 01/0 : 6[0] -> 5[4] [send] via NET/IB/0
f17n02:1076280:1076576 [1] NCCL INFO Connected all rings
f17n02:1076280:1076576 [1] NCCL INFO Channel 00/0 : 8[3] -> 10[1] [receive] via NET/IB/2
f17n02:1076280:1076576 [1] NCCL INFO Channel 00/0 : 10[1] -> 8[3] [send] via NET/IB/2
f17n02:1076280:1076576 [1] NCCL INFO Channel 00/0 : 11[3] -> 10[1] [receive] via NET/IB/2
f17n02:1076280:1076576 [1] NCCL INFO Channel 00/0 : 10[1] -> 9[5] [send] via NET/IB/2
f17n02:1076280:1076576 [1] NCCL INFO Channel 01/0 : 10[1] -> 9[5] [send] via NET/IB/2
f16n17:1090962:1091273 [3] NCCL INFO Connected all rings
f16n17:1090962:1091273 [3] NCCL INFO Channel 00/0 : 8[3] -> 10[1] [send] via NET/IB/3
f16n17:1090962:1091273 [3] NCCL INFO Channel 00/0 : 4[1] -> 8[3] [receive] via NET/IB/3
f16n17:1090962:1091273 [3] NCCL INFO Channel 00/0 : 8[3] -> 0[5] [send] via NET/IB/3
f16n17:1090962:1091273 [3] NCCL INFO Channel 00/0 : 0[5] -> 8[3] [receive] via NET/IB/3
f16n17:1090962:1091273 [3] NCCL INFO Channel 00/0 : 8[3] -> 4[1] [send] via NET/IB/3
f16n17:1090962:1091273 [3] NCCL INFO Channel 00/0 : 10[1] -> 8[3] [receive] via NET/IB/3
f16n17:1090962:1091273 [3] NCCL INFO Channel 01/0 : 9[5] -> 8[3] [receive] via NET/IB/3
d14n09:567666:567998 [0] NCCL INFO Connected all rings
d14n09:567666:567998 [0] NCCL INFO Channel 01/0 : 1[2] -> 3[0] [receive] via NET/IB/0
d14n09:567666:567998 [0] NCCL INFO Channel 01/0 : 11[4] -> 3[0] [receive] via NET/IB/0
d14n09:567666:567998 [0] NCCL INFO Channel 01/0 : 3[0] -> 7[2] [send] via NET/IB/0
d14n09:567666:567998 [0] NCCL INFO Channel 01/0 : 7[2] -> 3[0] [receive] via NET/IB/0
d14n09:567666:567998 [0] NCCL INFO Channel 01/0 : 3[0] -> 11[4] [send] via NET/IB/0
d14n09:567666:567998 [0] NCCL INFO Channel 01/0 : 3[0] -> 1[2] [send] via NET/IB/0
d14n09:567666:567998 [0] NCCL INFO Channel 00/0 : 3[0] -> 2[4] [send] via NET/IB/0
d11n17:1142859:1143155 [5] NCCL INFO Connected all rings
d11n17:1142859:1143155 [5] NCCL INFO Channel 00/0 : 2[5] -> 4[3] [send] via NET/IB/3
d11n17:1142859:1143155 [5] NCCL INFO Channel 00/0 : 4[3] -> 2[5] [receive] via NET/IB/3
d11n17:1142859:1143155 [5] NCCL INFO Channel 00/0 : 3[1] -> 2[5] [receive] via NET/IB/3
d11n17:1142859:1143155 [5] NCCL INFO Channel 00/0 : 2[5] -> 1[3] [send] via NET/IB/3
d11n17:1142859:1143155 [5] NCCL INFO Channel 01/0 : 2[5] -> 1[3] [send] via NET/IB/3
d14n08:1173252:1173564 [5] NCCL INFO Connected all rings
d14n08:1173252:1173564 [5] NCCL INFO Channel 01/0 : 1[1] -> 3[5] [receive] via NET/IB/3
d14n08:1173252:1173564 [5] NCCL INFO Channel 01/0 : 11[3] -> 3[5] [receive] via NET/IB/3
d14n08:1173252:1173564 [5] NCCL INFO Channel 01/0 : 3[5] -> 7[1] [send] via NET/IB/3
d14n08:1173252:1173564 [5] NCCL INFO Channel 01/0 : 7[1] -> 3[5] [receive] via NET/IB/3
d14n08:1173252:1173564 [5] NCCL INFO Channel 01/0 : 3[5] -> 11[3] [send] via NET/IB/3
d14n08:1173252:1173564 [5] NCCL INFO Channel 01/0 : 3[5] -> 1[1] [send] via NET/IB/3
d14n08:1173252:1173564 [5] NCCL INFO Channel 00/0 : 3[5] -> 2[3] [send] via NET/IB/3
d09n07:1063022:1063390 [5] NCCL INFO Connected all rings
d09n07:1063022:1063390 [5] NCCL INFO Channel 00/0 : 8[3] -> 0[5] [receive] via NET/IB/3
d09n07:1063022:1063390 [5] NCCL INFO Channel 00/0 : 0[5] -> 8[3] [send] via NET/IB/3
d09n07:1063022:1063390 [5] NCCL INFO Channel 01/0 : 1[1] -> 0[5] [receive] via NET/IB/3
d09n07:1063019:1063392 [2] NCCL INFO Connected all trees
d09n07:1063019:1063392 [2] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d09n07:1063019:1063392 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n16:1130270:1130582 [2] NCCL INFO Connected all rings
d11n16:1130270:1130582 [2] NCCL INFO Channel 01/0 : 1[2] -> 3[0] [send] via NET/IB/0
d11n16:1130270:1130582 [2] NCCL INFO Channel 01/0 : 3[0] -> 1[2] [receive] via NET/IB/0
d11n16:1130270:1130582 [2] NCCL INFO Channel 00/0 : 2[4] -> 1[2] [receive] via NET/IB/0
d11n16:1130270:1130582 [2] NCCL INFO Channel 01/0 : 2[4] -> 1[2] [receive] via NET/IB/0
d11n16:1130270:1130582 [2] NCCL INFO Channel 01/0 : 1[2] -> 0[0] [send] via NET/IB/0
f16n17:1090963:1091274 [4] NCCL INFO Connected all rings
f16n17:1090963:1091274 [4] NCCL INFO Channel 00/0 : 8[4] -> 10[2] [send] via NET/IB/1
f16n17:1090963:1091274 [4] NCCL INFO Channel 00/0 : 4[2] -> 8[4] [receive] via NET/IB/1
f16n17:1090963:1091274 [4] NCCL INFO Channel 00/0 : 8[4] -> 0[0] [send] via NET/IB/1
f16n17:1090963:1091274 [4] NCCL INFO Channel 00/0 : 0[0] -> 8[4] [receive] via NET/IB/1
f16n17:1090963:1091274 [4] NCCL INFO Channel 00/0 : 8[4] -> 4[2] [send] via NET/IB/1
f16n17:1090963:1091274 [4] NCCL INFO Channel 00/0 : 10[2] -> 8[4] [receive] via NET/IB/1
f16n17:1090963:1091274 [4] NCCL INFO Channel 01/0 : 9[0] -> 8[4] [receive] via NET/IB/1
f17n02:1076281:1076578 [2] NCCL INFO Connected all rings
f17n02:1076281:1076578 [2] NCCL INFO Channel 00/0 : 8[4] -> 10[2] [receive] via NET/IB/0
f17n02:1076281:1076578 [2] NCCL INFO Channel 00/0 : 10[2] -> 8[4] [send] via NET/IB/0
f17n02:1076281:1076578 [2] NCCL INFO Channel 00/0 : 11[4] -> 10[2] [receive] via NET/IB/0
f17n02:1076281:1076578 [2] NCCL INFO Channel 00/0 : 10[2] -> 9[0] [send] via NET/IB/0
f17n02:1076281:1076578 [2] NCCL INFO Channel 01/0 : 10[2] -> 9[0] [send] via NET/IB/0
d09n08:1073954:1074259 [0] NCCL INFO Connected all rings
d09n08:1073954:1074259 [0] NCCL INFO Channel 00/0 : 8[4] -> 0[0] [receive] via NET/IB/0
d09n08:1073954:1074259 [0] NCCL INFO Channel 00/0 : 0[0] -> 8[4] [send] via NET/IB/0
d09n08:1073954:1074259 [0] NCCL INFO Channel 01/0 : 1[2] -> 0[0] [receive] via NET/IB/0
d14n09:567667:567994 [1] NCCL INFO Connected all rings
d14n09:567667:567994 [1] NCCL INFO Channel 01/0 : 1[3] -> 3[1] [receive] via NET/IB/2
d14n09:567667:567994 [1] NCCL INFO Channel 01/0 : 11[5] -> 3[1] [receive] via NET/IB/2
d14n09:567667:567994 [1] NCCL INFO Channel 01/0 : 3[1] -> 7[3] [send] via NET/IB/2
d14n09:567667:567994 [1] NCCL INFO Channel 01/0 : 7[3] -> 3[1] [receive] via NET/IB/2
d14n09:567667:567994 [1] NCCL INFO Channel 01/0 : 3[1] -> 11[5] [send] via NET/IB/2
d14n09:567667:567994 [1] NCCL INFO Channel 01/0 : 3[1] -> 1[3] [send] via NET/IB/2
d14n09:567667:567994 [1] NCCL INFO Channel 00/0 : 3[1] -> 2[5] [send] via NET/IB/2
f17n01:970276:970577 [0] NCCL INFO Connected all rings
f17n01:970276:970577 [0] NCCL INFO Channel 01/0 : 7[2] -> 9[0] [receive] via NET/IB/0
f17n01:970276:970577 [0] NCCL INFO Channel 01/0 : 9[0] -> 7[2] [send] via NET/IB/0
f17n01:970276:970577 [0] NCCL INFO Channel 00/0 : 10[2] -> 9[0] [receive] via NET/IB/0
f17n01:970276:970577 [0] NCCL INFO Channel 01/0 : 10[2] -> 9[0] [receive] via NET/IB/0
f17n01:970276:970577 [0] NCCL INFO Channel 01/0 : 9[0] -> 8[4] [send] via NET/IB/0
f16n16:1079915:1080219 [3] NCCL INFO Connected all rings
f16n16:1079915:1080219 [3] NCCL INFO Channel 01/0 : 5[5] -> 7[3] [receive] via NET/IB/3
f16n16:1079915:1080219 [3] NCCL INFO Channel 01/0 : 7[3] -> 9[1] [send] via NET/IB/3
f16n16:1079915:1080219 [3] NCCL INFO Channel 01/0 : 3[1] -> 7[3] [receive] via NET/IB/3
f16n16:1079915:1080219 [3] NCCL INFO Channel 01/0 : 7[3] -> 3[1] [send] via NET/IB/3
f16n16:1079915:1080219 [3] NCCL INFO Channel 01/0 : 9[1] -> 7[3] [receive] via NET/IB/3
f16n16:1079915:1080219 [3] NCCL INFO Channel 01/0 : 7[3] -> 5[5] [send] via NET/IB/3
f16n16:1079915:1080219 [3] NCCL INFO Channel 00/0 : 7[3] -> 6[1] [send] via NET/IB/3
d17n06:1216535:1216864 [5] NCCL INFO Connected all rings
d17n06:1216535:1216864 [5] NCCL INFO Channel 00/0 : 4[1] -> 6[5] [receive] via NET/IB/3
d17n06:1216535:1216864 [5] NCCL INFO Channel 00/0 : 6[5] -> 4[1] [send] via NET/IB/3
d17n06:1216535:1216864 [5] NCCL INFO Channel 00/0 : 7[1] -> 6[5] [receive] via NET/IB/3
d17n06:1216535:1216864 [5] NCCL INFO Channel 00/0 : 6[5] -> 5[3] [send] via NET/IB/3
d17n06:1216535:1216864 [5] NCCL INFO Channel 01/0 : 6[5] -> 5[3] [send] via NET/IB/3
f18n05:1008219:1008520 [0] NCCL INFO Connected all trees
f18n05:1008219:1008520 [0] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f18n05:1008219:1008520 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f18n05:1008220:1008519 [1] NCCL INFO Connected all trees
f18n05:1008220:1008519 [1] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f18n05:1008220:1008519 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n16:1079913:1080215 [1] NCCL INFO Connected all rings
f16n16:1079913:1080215 [1] NCCL INFO Channel 01/0 : 5[3] -> 7[1] [receive] via NET/IB/2
f16n16:1079913:1080215 [1] NCCL INFO Channel 01/0 : 7[1] -> 9[5] [send] via NET/IB/2
f16n16:1079913:1080215 [1] NCCL INFO Channel 01/0 : 3[5] -> 7[1] [receive] via NET/IB/2
f16n16:1079913:1080215 [1] NCCL INFO Channel 01/0 : 7[1] -> 3[5] [send] via NET/IB/2
f16n16:1079913:1080215 [1] NCCL INFO Channel 01/0 : 9[5] -> 7[1] [receive] via NET/IB/2
f16n16:1079913:1080215 [1] NCCL INFO Channel 01/0 : 7[1] -> 5[3] [send] via NET/IB/2
f16n16:1079913:1080215 [1] NCCL INFO Channel 00/0 : 7[1] -> 6[5] [send] via NET/IB/2
f16n18:1091871:1092189 [5] NCCL INFO Connected all rings
f16n18:1091871:1092189 [5] NCCL INFO Channel 01/0 : 7[1] -> 9[5] [receive] via NET/IB/3
f16n18:1091871:1092189 [5] NCCL INFO Channel 01/0 : 9[5] -> 7[1] [send] via NET/IB/3
f16n18:1091871:1092189 [5] NCCL INFO Channel 00/0 : 10[1] -> 9[5] [receive] via NET/IB/3
f16n18:1091871:1092189 [5] NCCL INFO Channel 01/0 : 10[1] -> 9[5] [receive] via NET/IB/3
f16n18:1091871:1092189 [5] NCCL INFO Channel 01/0 : 9[5] -> 8[3] [send] via NET/IB/3
d17n07:1212411:1212743 [1] NCCL INFO Connected all rings
d17n07:1212411:1212743 [1] NCCL INFO Channel 00/0 : 4[3] -> 6[1] [receive] via NET/IB/2
d17n07:1212411:1212743 [1] NCCL INFO Channel 00/0 : 6[1] -> 4[3] [send] via NET/IB/2
d17n07:1212411:1212743 [1] NCCL INFO Channel 00/0 : 7[3] -> 6[1] [receive] via NET/IB/2
d17n07:1212411:1212743 [1] NCCL INFO Channel 00/0 : 6[1] -> 5[5] [send] via NET/IB/2
d17n07:1212411:1212743 [1] NCCL INFO Channel 01/0 : 6[1] -> 5[5] [send] via NET/IB/2
d09n07:1063020:1063391 [3] NCCL INFO Connected all trees
d09n07:1063020:1063391 [3] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d09n07:1063020:1063391 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n16:1079914:1080218 [2] NCCL INFO Connected all rings
f16n16:1079914:1080218 [2] NCCL INFO Channel 01/0 : 5[4] -> 7[2] [receive] via NET/IB/0
f16n16:1079914:1080218 [2] NCCL INFO Channel 01/0 : 7[2] -> 9[0] [send] via NET/IB/0
f16n16:1079914:1080218 [2] NCCL INFO Channel 01/0 : 3[0] -> 7[2] [receive] via NET/IB/0
f16n16:1079914:1080218 [2] NCCL INFO Channel 01/0 : 7[2] -> 3[0] [send] via NET/IB/0
f16n16:1079914:1080218 [2] NCCL INFO Channel 01/0 : 9[0] -> 7[2] [receive] via NET/IB/0
f16n16:1079914:1080218 [2] NCCL INFO Channel 01/0 : 7[2] -> 5[4] [send] via NET/IB/0
f16n16:1079914:1080218 [2] NCCL INFO Channel 00/0 : 7[2] -> 6[0] [send] via NET/IB/0
d14n10:565684:565995 [3] NCCL INFO Connected all rings
d14n10:565684:565995 [3] NCCL INFO Channel 00/0 : 2[5] -> 4[3] [receive] via NET/IB/3
d14n10:565684:565995 [3] NCCL INFO Channel 00/0 : 4[3] -> 6[1] [send] via NET/IB/3
d14n10:565684:565995 [3] NCCL INFO Channel 00/0 : 4[3] -> 8[5] [send] via NET/IB/3
d14n10:565684:565995 [3] NCCL INFO Channel 00/0 : 8[5] -> 4[3] [receive] via NET/IB/3
d14n10:565684:565995 [3] NCCL INFO Channel 00/0 : 6[1] -> 4[3] [receive] via NET/IB/3
d14n10:565684:565995 [3] NCCL INFO Channel 00/0 : 4[3] -> 2[5] [send] via NET/IB/3
d14n10:565684:565995 [3] NCCL INFO Channel 01/0 : 5[5] -> 4[3] [receive] via NET/IB/3
f17n02:1076284:1076577 [5] NCCL INFO Connected all trees
f17n02:1076284:1076577 [5] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f17n02:1076284:1076577 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d09n08:1073955:1074260 [1] NCCL INFO Connected all rings
d09n08:1073955:1074260 [1] NCCL INFO Channel 00/0 : 8[5] -> 0[1] [receive] via NET/IB/2
d09n08:1073955:1074260 [1] NCCL INFO Channel 00/0 : 0[1] -> 8[5] [send] via NET/IB/2
d09n08:1073955:1074260 [1] NCCL INFO Channel 01/0 : 1[3] -> 0[1] [receive] via NET/IB/2
f16n17:1090964:1091275 [5] NCCL INFO Connected all rings
f16n17:1090964:1091275 [5] NCCL INFO Channel 00/0 : 8[5] -> 10[3] [send] via NET/IB/3
f16n17:1090964:1091275 [5] NCCL INFO Channel 00/0 : 4[3] -> 8[5] [receive] via NET/IB/3
f16n17:1090964:1091275 [5] NCCL INFO Channel 00/0 : 8[5] -> 0[1] [send] via NET/IB/3
f16n17:1090964:1091275 [5] NCCL INFO Channel 00/0 : 0[1] -> 8[5] [receive] via NET/IB/3
f16n17:1090964:1091275 [5] NCCL INFO Channel 00/0 : 8[5] -> 4[3] [send] via NET/IB/3
f16n17:1090964:1091275 [5] NCCL INFO Channel 00/0 : 10[3] -> 8[5] [receive] via NET/IB/3
f16n17:1090964:1091275 [5] NCCL INFO Channel 01/0 : 9[1] -> 8[5] [receive] via NET/IB/3
d11n16:1130271:1130583 [3] NCCL INFO Connected all rings
d11n16:1130271:1130583 [3] NCCL INFO Channel 01/0 : 1[3] -> 3[1] [send] via NET/IB/3
d11n16:1130271:1130583 [3] NCCL INFO Channel 01/0 : 3[1] -> 1[3] [receive] via NET/IB/3
d11n16:1130271:1130583 [3] NCCL INFO Channel 00/0 : 2[5] -> 1[3] [receive] via NET/IB/3
d11n16:1130271:1130583 [3] NCCL INFO Channel 01/0 : 2[5] -> 1[3] [receive] via NET/IB/3
d11n16:1130271:1130583 [3] NCCL INFO Channel 01/0 : 1[3] -> 0[1] [send] via NET/IB/3
f17n01:970277:970578 [1] NCCL INFO Connected all rings
f17n01:970277:970578 [1] NCCL INFO Channel 01/0 : 7[3] -> 9[1] [receive] via NET/IB/2
f17n01:970277:970578 [1] NCCL INFO Channel 01/0 : 9[1] -> 7[3] [send] via NET/IB/2
f17n01:970277:970578 [1] NCCL INFO Channel 00/0 : 10[3] -> 9[1] [receive] via NET/IB/2
f17n01:970277:970578 [1] NCCL INFO Channel 01/0 : 10[3] -> 9[1] [receive] via NET/IB/2
f17n01:970277:970578 [1] NCCL INFO Channel 01/0 : 9[1] -> 8[5] [send] via NET/IB/2
d09n07:1063016:1063406 [0] NCCL INFO Using network IB
d09n07:1063016:1063406 [0] NCCL INFO comm 0x13ef1ca00 rank 0 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0x3d0032b5657235cd - Init START
d09n07:1063016:1063406 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d09n07:1063016:1063406 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7   8   9  10  11
d09n07:1063016:1063406 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7   8   9  10  11
d09n07:1063016:1063406 [0] NCCL INFO Trees [0] 8/-1/-1->0->-1 [1] -1/-1/-1->0->1
d09n07:1063016:1063406 [0] NCCL INFO P2P Chunksize set to 131072
d09n07:1063016:1063406 [0] NCCL INFO Channel 00/0 : 11[4] -> 0[0] [receive] via NET/IB/0
d09n07:1063016:1063406 [0] NCCL INFO Channel 01/0 : 11[4] -> 0[0] [receive] via NET/IB/0
d09n07:1063016:1063406 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[2] [send] via NET/IB/0
d09n07:1063016:1063406 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[2] [send] via NET/IB/0
f17n02:1076282:1076579 [3] NCCL INFO Connected all rings
f17n02:1076282:1076579 [3] NCCL INFO Channel 00/0 : 8[5] -> 10[3] [receive] via NET/IB/3
f17n02:1076282:1076579 [3] NCCL INFO Channel 00/0 : 10[3] -> 8[5] [send] via NET/IB/3
f17n02:1076282:1076579 [3] NCCL INFO Channel 00/0 : 11[5] -> 10[3] [receive] via NET/IB/3
f17n02:1076282:1076579 [3] NCCL INFO Channel 00/0 : 10[3] -> 9[1] [send] via NET/IB/3
f17n02:1076282:1076579 [3] NCCL INFO Channel 01/0 : 10[3] -> 9[1] [send] via NET/IB/3
d09n08:1073956:1074271 [2] NCCL INFO Using network IB
d09n08:1073956:1074271 [2] NCCL INFO comm 0x15eced080 rank 1 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0x3d0032b5657235cd - Init START
d09n08:1073956:1074271 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d09n08:1073956:1074271 [2] NCCL INFO Trees [0] -1/-1/-1->1->2 [1] 2/0/-1->1->3
d09n08:1073956:1074271 [2] NCCL INFO P2P Chunksize set to 131072
d09n08:1073956:1074271 [2] NCCL INFO Channel 00/0 : 0[0] -> 1[2] [receive] via NET/IB/0
d09n08:1073956:1074271 [2] NCCL INFO Channel 01/0 : 0[0] -> 1[2] [receive] via NET/IB/0
d09n08:1073956:1074271 [2] NCCL INFO Channel 00/0 : 1[2] -> 2[4] [send] via NET/IB/0
d09n08:1073956:1074271 [2] NCCL INFO Channel 01/0 : 1[2] -> 2[4] [send] via NET/IB/0
d17n06:1216530:1216875 [0] NCCL INFO Using network IB
d17n06:1216530:1216875 [0] NCCL INFO comm 0x146ed8e50 rank 6 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0x3d0032b5657235cd - Init START
d17n06:1216530:1216875 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d17n06:1216530:1216875 [0] NCCL INFO Trees [0] 5/7/-1->6->4 [1] -1/-1/-1->6->5
d17n06:1216530:1216875 [0] NCCL INFO P2P Chunksize set to 131072
d17n06:1216530:1216875 [0] NCCL INFO Channel 00/0 : 5[4] -> 6[0] [receive] via NET/IB/0
d17n06:1216530:1216875 [0] NCCL INFO Channel 01/0 : 5[4] -> 6[0] [receive] via NET/IB/0
d17n06:1216530:1216875 [0] NCCL INFO Channel 00/0 : 6[0] -> 7[2] [send] via NET/IB/0
d17n06:1216530:1216875 [0] NCCL INFO Channel 01/0 : 6[0] -> 7[2] [send] via NET/IB/0
d14n08:1173247:1173579 [0] NCCL INFO Using network IB
d14n08:1173247:1173579 [0] NCCL INFO comm 0x1357cf340 rank 3 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0x3d0032b5657235cd - Init START
d14n08:1173247:1173579 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d14n08:1173247:1173579 [0] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] 7/1/-1->3->11
d14n08:1173247:1173579 [0] NCCL INFO P2P Chunksize set to 131072
d14n08:1173247:1173579 [0] NCCL INFO Channel 00/0 : 2[4] -> 3[0] [receive] via NET/IB/0
d14n08:1173247:1173579 [0] NCCL INFO Channel 01/0 : 2[4] -> 3[0] [receive] via NET/IB/0
d14n08:1173247:1173579 [0] NCCL INFO Channel 00/0 : 3[0] -> 4[2] [send] via NET/IB/0
d14n08:1173247:1173579 [0] NCCL INFO Channel 01/0 : 3[0] -> 4[2] [send] via NET/IB/0
d14n09:567668:568009 [2] NCCL INFO Using network IB
d14n09:567668:568009 [2] NCCL INFO comm 0x129f444c0 rank 4 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0x3d0032b5657235cd - Init START
d14n09:567668:568009 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d14n09:567668:568009 [2] NCCL INFO Trees [0] 2/6/-1->4->8 [1] -1/-1/-1->4->5
d14n09:567668:568009 [2] NCCL INFO P2P Chunksize set to 131072
d14n09:567668:568009 [2] NCCL INFO Channel 00/0 : 3[0] -> 4[2] [receive] via NET/IB/0
d14n09:567668:568009 [2] NCCL INFO Channel 01/0 : 3[0] -> 4[2] [receive] via NET/IB/0
d14n09:567668:568009 [2] NCCL INFO Channel 00/0 : 4[2] -> 5[4] [send] via NET/IB/0
d14n09:567668:568009 [2] NCCL INFO Channel 01/0 : 4[2] -> 5[4] [send] via NET/IB/0
d14n11:1169361:1169674 [5] NCCL INFO Connected all rings
d14n11:1169361:1169674 [5] NCCL INFO Channel 01/0 : 5[5] -> 7[3] [send] via NET/IB/3
d14n11:1169361:1169674 [5] NCCL INFO Channel 01/0 : 7[3] -> 5[5] [receive] via NET/IB/3
d14n11:1169361:1169674 [5] NCCL INFO Channel 00/0 : 6[1] -> 5[5] [receive] via NET/IB/3
d14n11:1169361:1169674 [5] NCCL INFO Channel 01/0 : 6[1] -> 5[5] [receive] via NET/IB/3
d14n11:1169361:1169674 [5] NCCL INFO Channel 01/0 : 5[5] -> 4[3] [send] via NET/IB/3
d17n07:1212412:1212754 [2] NCCL INFO Using network IB
d17n07:1212412:1212754 [2] NCCL INFO comm 0x12d929bc0 rank 7 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0x3d0032b5657235cd - Init START
d17n07:1212412:1212754 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d17n07:1212412:1212754 [2] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] 9/5/-1->7->3
d17n07:1212412:1212754 [2] NCCL INFO P2P Chunksize set to 131072
d17n07:1212412:1212754 [2] NCCL INFO Channel 00/0 : 6[0] -> 7[2] [receive] via NET/IB/0
d17n07:1212412:1212754 [2] NCCL INFO Channel 01/0 : 6[0] -> 7[2] [receive] via NET/IB/0
d17n07:1212412:1212754 [2] NCCL INFO Channel 00/0 : 7[2] -> 8[4] [send] via NET/IB/0
d17n07:1212412:1212754 [2] NCCL INFO Channel 01/0 : 7[2] -> 8[4] [send] via NET/IB/0
d14n10:565685:566006 [4] NCCL INFO Using network IB
d14n10:565685:566006 [4] NCCL INFO comm 0x16207c930 rank 5 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x3d0032b5657235cd - Init START
d14n10:565685:566006 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d14n10:565685:566006 [4] NCCL INFO Trees [0] -1/-1/-1->5->6 [1] 6/4/-1->5->7
d14n10:565685:566006 [4] NCCL INFO P2P Chunksize set to 131072
d14n10:565685:566006 [4] NCCL INFO Channel 00/0 : 4[2] -> 5[4] [receive] via NET/IB/1
d14n10:565685:566006 [4] NCCL INFO Channel 01/0 : 4[2] -> 5[4] [receive] via NET/IB/1
d14n10:565685:566006 [4] NCCL INFO Channel 00/0 : 5[4] -> 6[0] [send] via NET/IB/1
d14n10:565685:566006 [4] NCCL INFO Channel 01/0 : 5[4] -> 6[0] [send] via NET/IB/1
f17n02:1076283:1076590 [4] NCCL INFO Using network IB
f17n02:1076283:1076590 [4] NCCL INFO comm 0x15afb9cb0 rank 11 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x3d0032b5657235cd - Init START
f17n02:1076283:1076590 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
f17n02:1076283:1076590 [4] NCCL INFO Trees [0] -1/-1/-1->11->10 [1] 3/-1/-1->11->-1
f17n02:1076283:1076590 [4] NCCL INFO P2P Chunksize set to 131072
f17n02:1076283:1076590 [4] NCCL INFO Channel 00/0 : 10[2] -> 11[4] [receive] via NET/IB/1
f17n02:1076283:1076590 [4] NCCL INFO Channel 01/0 : 10[2] -> 11[4] [receive] via NET/IB/1
f17n02:1076283:1076590 [4] NCCL INFO Channel 00/0 : 11[4] -> 0[0] [send] via NET/IB/1
f17n02:1076283:1076590 [4] NCCL INFO Channel 01/0 : 11[4] -> 0[0] [send] via NET/IB/1
d09n07:1063018:1063394 [1] NCCL INFO Connected all trees
d09n07:1063018:1063394 [1] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d09n07:1063018:1063394 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f17n01:970278:970589 [2] NCCL INFO Using network IB
f17n01:970278:970589 [2] NCCL INFO comm 0x158d7b690 rank 10 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0x3d0032b5657235cd - Init START
f17n01:970278:970589 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
f17n01:970278:970589 [2] NCCL INFO Trees [0] 9/11/-1->10->8 [1] -1/-1/-1->10->9
f17n01:970278:970589 [2] NCCL INFO P2P Chunksize set to 131072
f17n01:970278:970589 [2] NCCL INFO Channel 00/0 : 9[0] -> 10[2] [receive] via NET/IB/0
f17n01:970278:970589 [2] NCCL INFO Channel 01/0 : 9[0] -> 10[2] [receive] via NET/IB/0
f17n01:970278:970589 [2] NCCL INFO Channel 00/0 : 10[2] -> 11[4] [send] via NET/IB/0
f17n01:970278:970589 [2] NCCL INFO Channel 01/0 : 10[2] -> 11[4] [send] via NET/IB/0
d11n16:1130272:1130594 [4] NCCL INFO Using network IB
d11n16:1130272:1130594 [4] NCCL INFO comm 0x1250ad310 rank 2 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x3d0032b5657235cd - Init START
d11n16:1130272:1130594 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d11n16:1130272:1130594 [4] NCCL INFO Trees [0] 1/3/-1->2->4 [1] -1/-1/-1->2->1
d11n16:1130272:1130594 [4] NCCL INFO P2P Chunksize set to 131072
d11n16:1130272:1130594 [4] NCCL INFO Channel 00/0 : 1[2] -> 2[4] [receive] via NET/IB/1
d11n16:1130272:1130594 [4] NCCL INFO Channel 01/0 : 1[2] -> 2[4] [receive] via NET/IB/1
d11n16:1130272:1130594 [4] NCCL INFO Channel 00/0 : 2[4] -> 3[0] [send] via NET/IB/1
d11n16:1130272:1130594 [4] NCCL INFO Channel 01/0 : 2[4] -> 3[0] [send] via NET/IB/1
f17n01:970280:970574 [4] NCCL INFO Connected all trees
f17n01:970280:970574 [4] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f17n01:970280:970574 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n18:1091866:1092201 [0] NCCL INFO Using network IB
f16n18:1091866:1092201 [0] NCCL INFO comm 0x11bba2700 rank 9 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0x3d0032b5657235cd - Init START
f16n18:1091866:1092201 [0] NCCL INFO Setting affinity for GPU 0 to 0f
f16n18:1091866:1092201 [0] NCCL INFO Trees [0] -1/-1/-1->9->10 [1] 10/8/-1->9->7
f16n18:1091866:1092201 [0] NCCL INFO P2P Chunksize set to 131072
f16n18:1091866:1092201 [0] NCCL INFO Channel 00/0 : 8[4] -> 9[0] [receive] via NET/IB/0
f16n18:1091866:1092201 [0] NCCL INFO Channel 01/0 : 8[4] -> 9[0] [receive] via NET/IB/0
f16n18:1091866:1092201 [0] NCCL INFO Channel 00/0 : 9[0] -> 10[2] [send] via NET/IB/0
f16n18:1091866:1092201 [0] NCCL INFO Channel 01/0 : 9[0] -> 10[2] [send] via NET/IB/0
d09n08:1073954:1074259 [0] NCCL INFO Connected all trees
d09n08:1073954:1074259 [0] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d09n08:1073954:1074259 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d09n07:1063021:1063389 [4] NCCL INFO Connected all trees
d09n07:1063021:1063389 [4] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d09n07:1063021:1063389 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f18n05:1008221:1008518 [2] NCCL INFO Connected all trees
f18n05:1008221:1008518 [2] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f18n05:1008221:1008518 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f18n05:1008219:1008520 [0] NCCL INFO comm 0x15a2fb3d0 rank 11 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0x34523f6e9f712843 - Init COMPLETE
f16n16:1079916:1080230 [4] NCCL INFO Using network IB
f16n16:1079916:1080230 [4] NCCL INFO comm 0x150d4e300 rank 8 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x3d0032b5657235cd - Init START
f16n16:1079916:1080230 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
f16n16:1079916:1080230 [4] NCCL INFO Trees [0] 4/10/-1->8->0 [1] -1/-1/-1->8->9
f16n16:1079916:1080230 [4] NCCL INFO P2P Chunksize set to 131072
f16n16:1079916:1080230 [4] NCCL INFO Channel 00/0 : 7[2] -> 8[4] [receive] via NET/IB/1
f16n16:1079916:1080230 [4] NCCL INFO Channel 01/0 : 7[2] -> 8[4] [receive] via NET/IB/1
f16n16:1079916:1080230 [4] NCCL INFO Channel 00/0 : 8[4] -> 9[0] [send] via NET/IB/1
f16n16:1079916:1080230 [4] NCCL INFO Channel 01/0 : 8[4] -> 9[0] [send] via NET/IB/1
f18n05:1008223:1008522 [4] NCCL INFO Connected all trees
f18n05:1008223:1008522 [4] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f18n05:1008223:1008522 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f18n05:1008220:1008519 [1] NCCL INFO comm 0x168f88cd0 rank 11 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0x143ee5f2cd24cdfa - Init COMPLETE
d09n08:1073955:1074260 [1] NCCL INFO Connected all trees
d09n08:1073955:1074260 [1] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d09n08:1073955:1074260 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d09n08:1073958:1074256 [4] NCCL INFO Connected all trees
d09n08:1073958:1074256 [4] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d09n08:1073958:1074256 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f18n05:1008222:1008521 [3] NCCL INFO Connected all trees
f18n05:1008222:1008521 [3] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f18n05:1008222:1008521 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f17n01:970281:970576 [5] NCCL INFO Connected all trees
f17n01:970281:970576 [5] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f17n01:970281:970576 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d09n07:1063020:1063391 [3] NCCL INFO comm 0x11e62c510 rank 0 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x143ee5f2cd24cdfa - Init COMPLETE
d09n07:1063019:1063392 [2] NCCL INFO comm 0x16246b330 rank 0 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0x34523f6e9f712843 - Init COMPLETE
d09n07:1063018:1063394 [1] NCCL INFO comm 0x12544c9d0 rank 0 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0xbe140023bc6012b4 - Init COMPLETE
d09n07:1063022:1063390 [5] NCCL INFO Connected all trees
d09n07:1063022:1063390 [5] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d09n07:1063022:1063390 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n11:1169356:1169677 [0] NCCL INFO Connected all trees
d14n11:1169356:1169677 [0] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d14n11:1169356:1169677 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f17n01:970279:970575 [3] NCCL INFO Connected all trees
f17n01:970279:970575 [3] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f17n01:970279:970575 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f17n02:1076279:1076575 [0] NCCL INFO Connected all trees
f17n02:1076279:1076575 [0] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f17n02:1076279:1076575 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n16:1130273:1130581 [5] NCCL INFO Connected all trees
d11n16:1130273:1130581 [5] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d11n16:1130273:1130581 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f18n05:1008224:1008523 [5] NCCL INFO Connected all trees
f18n05:1008224:1008523 [5] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f18n05:1008224:1008523 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n06:1216531:1216860 [1] NCCL INFO Connected all trees
d17n06:1216531:1216860 [1] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d17n06:1216531:1216860 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n17:1142854:1143154 [0] NCCL INFO Connected all trees
d11n17:1142854:1143154 [0] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d11n17:1142854:1143154 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d09n08:1073957:1074254 [3] NCCL INFO Connected all trees
d09n08:1073957:1074254 [3] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d09n08:1073957:1074254 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n11:1169357:1169672 [1] NCCL INFO Connected all trees
d14n11:1169357:1169672 [1] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d14n11:1169357:1169672 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n17:1090959:1091271 [0] NCCL INFO Connected all trees
f16n17:1090959:1091271 [0] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f16n17:1090959:1091271 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d09n08:1073959:1074255 [5] NCCL INFO Connected all trees
d09n08:1073959:1074255 [5] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d09n08:1073959:1074255 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n10:565686:565993 [5] NCCL INFO Connected all trees
d14n10:565686:565993 [5] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d14n10:565686:565993 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n17:1090960:1091270 [1] NCCL INFO Connected all trees
f16n17:1090960:1091270 [1] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f16n17:1090960:1091270 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n11:1169358:1169673 [2] NCCL INFO Connected all trees
d14n11:1169358:1169673 [2] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d14n11:1169358:1169673 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n07:1212413:1212740 [3] NCCL INFO Connected all trees
d17n07:1212413:1212740 [3] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d17n07:1212413:1212740 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n17:1142855:1143152 [1] NCCL INFO Connected all trees
d11n17:1142855:1143152 [1] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d11n17:1142855:1143152 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n18:1091869:1092190 [3] NCCL INFO Connected all trees
f16n18:1091869:1092190 [3] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f16n18:1091869:1092190 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n16:1130268:1130579 [0] NCCL INFO Connected all trees
d11n16:1130268:1130579 [0] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d11n16:1130268:1130579 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n09:567669:567997 [3] NCCL INFO Connected all trees
d14n09:567669:567997 [3] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d14n09:567669:567997 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n08:1173249:1173567 [2] NCCL INFO Connected all trees
d14n08:1173249:1173567 [2] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d14n08:1173249:1173567 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n08:1173248:1173568 [1] NCCL INFO Connected all trees
d14n08:1173248:1173568 [1] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d14n08:1173248:1173568 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f17n02:1076280:1076576 [1] NCCL INFO Connected all trees
f17n02:1076280:1076576 [1] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f17n02:1076280:1076576 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n18:1091868:1092188 [2] NCCL INFO Connected all trees
f16n18:1091868:1092188 [2] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f16n18:1091868:1092188 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n18:1091867:1092187 [1] NCCL INFO Connected all trees
f16n18:1091867:1092187 [1] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f16n18:1091867:1092187 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n16:1079917:1080217 [5] NCCL INFO Connected all trees
f16n16:1079917:1080217 [5] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f16n16:1079917:1080217 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n08:1173250:1173566 [3] NCCL INFO Connected all trees
d14n08:1173250:1173566 [3] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d14n08:1173250:1173566 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n18:1091870:1092186 [4] NCCL INFO Connected all trees
f16n18:1091870:1092186 [4] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f16n18:1091870:1092186 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n07:1212414:1212741 [4] NCCL INFO Connected all trees
d17n07:1212414:1212741 [4] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d17n07:1212414:1212741 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n06:1216532:1216861 [2] NCCL INFO Connected all trees
d17n06:1216532:1216861 [2] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d17n06:1216532:1216861 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n09:567670:567996 [4] NCCL INFO Connected all trees
d14n09:567670:567996 [4] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d14n09:567670:567996 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f17n02:1076281:1076578 [2] NCCL INFO Connected all trees
f17n02:1076281:1076578 [2] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f17n02:1076281:1076578 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n17:1090961:1091272 [2] NCCL INFO Connected all trees
f16n17:1090961:1091272 [2] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f16n17:1090961:1091272 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n09:567671:567995 [5] NCCL INFO Connected all trees
d14n09:567671:567995 [5] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d14n09:567671:567995 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n16:1130270:1130582 [2] NCCL INFO Connected all trees
d11n16:1130270:1130582 [2] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d11n16:1130270:1130582 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f17n02:1076282:1076579 [3] NCCL INFO Connected all trees
f17n02:1076282:1076579 [3] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f17n02:1076282:1076579 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n08:1173251:1173565 [4] NCCL INFO Connected all trees
d14n08:1173251:1173565 [4] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d14n08:1173251:1173565 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n17:1142856:1143153 [2] NCCL INFO Connected all trees
d11n17:1142856:1143153 [2] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d11n17:1142856:1143153 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f17n01:970277:970578 [1] NCCL INFO Connected all trees
f17n01:970277:970578 [1] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f17n01:970277:970578 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n16:1130269:1130580 [1] NCCL INFO Connected all trees
d11n16:1130269:1130580 [1] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d11n16:1130269:1130580 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d09n07:1063016:1063406 [0] NCCL INFO Connected all rings
d09n07:1063016:1063406 [0] NCCL INFO Channel 00/0 : 8[4] -> 0[0] [receive] via NET/IB/0
d09n07:1063016:1063406 [0] NCCL INFO Channel 00/0 : 0[0] -> 8[4] [send] via NET/IB/0
d09n07:1063016:1063406 [0] NCCL INFO Channel 01/0 : 1[2] -> 0[0] [receive] via NET/IB/0
f16n16:1079912:1080216 [0] NCCL INFO Connected all trees
f16n16:1079912:1080216 [0] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f16n16:1079912:1080216 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n10:565681:565991 [0] NCCL INFO Connected all trees
d14n10:565681:565991 [0] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d14n10:565681:565991 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n07:1212415:1212739 [5] NCCL INFO Connected all trees
d17n07:1212415:1212739 [5] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d17n07:1212415:1212739 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n06:1216534:1216862 [4] NCCL INFO Connected all trees
d17n06:1216534:1216862 [4] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d17n06:1216534:1216862 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n11:1169360:1169676 [4] NCCL INFO Connected all trees
d14n11:1169360:1169676 [4] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d14n11:1169360:1169676 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n06:1216533:1216863 [3] NCCL INFO Connected all trees
d17n06:1216533:1216863 [3] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d17n06:1216533:1216863 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n17:1090964:1091275 [5] NCCL INFO Connected all trees
f16n17:1090964:1091275 [5] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f16n17:1090964:1091275 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n16:1130271:1130583 [3] NCCL INFO Connected all trees
d11n16:1130271:1130583 [3] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d11n16:1130271:1130583 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n16:1079913:1080215 [1] NCCL INFO Connected all trees
f16n16:1079913:1080215 [1] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f16n16:1079913:1080215 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n08:1173252:1173564 [5] NCCL INFO Connected all trees
d14n08:1173252:1173564 [5] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d14n08:1173252:1173564 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n11:1169361:1169674 [5] NCCL INFO Connected all trees
d14n11:1169361:1169674 [5] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d14n11:1169361:1169674 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n06:1216535:1216864 [5] NCCL INFO Connected all trees
d17n06:1216535:1216864 [5] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d17n06:1216535:1216864 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f17n01:970276:970577 [0] NCCL INFO Connected all trees
f17n01:970276:970577 [0] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f17n01:970276:970577 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n17:1090962:1091273 [3] NCCL INFO Connected all trees
f16n17:1090962:1091273 [3] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f16n17:1090962:1091273 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n16:1079914:1080218 [2] NCCL INFO Connected all trees
f16n16:1079914:1080218 [2] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f16n16:1079914:1080218 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f17n02:1076283:1076590 [4] NCCL INFO Connected all rings
f17n02:1076283:1076590 [4] NCCL INFO Channel 01/0 : 11[4] -> 3[0] [send] via NET/IB/1
f17n02:1076283:1076590 [4] NCCL INFO Channel 01/0 : 3[0] -> 11[4] [receive] via NET/IB/1
f17n02:1076283:1076590 [4] NCCL INFO Channel 00/0 : 11[4] -> 10[2] [send] via NET/IB/1
d17n07:1212410:1212742 [0] NCCL INFO Connected all trees
d17n07:1212410:1212742 [0] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d17n07:1212410:1212742 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n17:1090963:1091274 [4] NCCL INFO Connected all trees
f16n17:1090963:1091274 [4] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f16n17:1090963:1091274 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n16:1130272:1130594 [4] NCCL INFO Connected all rings
d11n16:1130272:1130594 [4] NCCL INFO Channel 00/0 : 2[4] -> 4[2] [send] via NET/IB/1
d11n16:1130272:1130594 [4] NCCL INFO Channel 00/0 : 4[2] -> 2[4] [receive] via NET/IB/1
d11n16:1130272:1130594 [4] NCCL INFO Channel 00/0 : 3[0] -> 2[4] [receive] via NET/IB/1
d11n16:1130272:1130594 [4] NCCL INFO Channel 00/0 : 2[4] -> 1[2] [send] via NET/IB/1
d11n16:1130272:1130594 [4] NCCL INFO Channel 01/0 : 2[4] -> 1[2] [send] via NET/IB/1
d11n17:1142857:1143157 [3] NCCL INFO Connected all trees
d11n17:1142857:1143157 [3] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d11n17:1142857:1143157 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n18:1091871:1092189 [5] NCCL INFO Connected all trees
f16n18:1091871:1092189 [5] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f16n18:1091871:1092189 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n10:565683:565994 [2] NCCL INFO Connected all trees
d14n10:565683:565994 [2] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d14n10:565683:565994 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n09:567666:567998 [0] NCCL INFO Connected all trees
d14n09:567666:567998 [0] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d14n09:567666:567998 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n17:1142858:1143156 [4] NCCL INFO Connected all trees
d11n17:1142858:1143156 [4] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d11n17:1142858:1143156 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n07:1212412:1212754 [2] NCCL INFO Connected all rings
d17n07:1212412:1212754 [2] NCCL INFO Channel 01/0 : 5[4] -> 7[2] [receive] via NET/IB/0
d17n07:1212412:1212754 [2] NCCL INFO Channel 01/0 : 7[2] -> 9[0] [send] via NET/IB/0
d17n07:1212412:1212754 [2] NCCL INFO Channel 01/0 : 3[0] -> 7[2] [receive] via NET/IB/0
d17n07:1212412:1212754 [2] NCCL INFO Channel 01/0 : 7[2] -> 3[0] [send] via NET/IB/0
d17n07:1212412:1212754 [2] NCCL INFO Channel 01/0 : 9[0] -> 7[2] [receive] via NET/IB/0
d17n07:1212412:1212754 [2] NCCL INFO Channel 01/0 : 7[2] -> 5[4] [send] via NET/IB/0
d17n07:1212412:1212754 [2] NCCL INFO Channel 00/0 : 7[2] -> 6[0] [send] via NET/IB/0
d14n11:1169359:1169675 [3] NCCL INFO Connected all trees
d14n11:1169359:1169675 [3] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d14n11:1169359:1169675 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n09:567668:568009 [2] NCCL INFO Connected all rings
d14n09:567668:568009 [2] NCCL INFO Channel 00/0 : 2[4] -> 4[2] [receive] via NET/IB/0
d14n09:567668:568009 [2] NCCL INFO Channel 00/0 : 4[2] -> 6[0] [send] via NET/IB/0
d14n09:567668:568009 [2] NCCL INFO Channel 00/0 : 4[2] -> 8[4] [send] via NET/IB/0
d14n09:567668:568009 [2] NCCL INFO Channel 00/0 : 8[4] -> 4[2] [receive] via NET/IB/0
d14n09:567668:568009 [2] NCCL INFO Channel 00/0 : 6[0] -> 4[2] [receive] via NET/IB/0
d14n09:567668:568009 [2] NCCL INFO Channel 00/0 : 4[2] -> 2[4] [send] via NET/IB/0
d14n09:567668:568009 [2] NCCL INFO Channel 01/0 : 5[4] -> 4[2] [receive] via NET/IB/0
d14n08:1173247:1173579 [0] NCCL INFO Connected all rings
d14n08:1173247:1173579 [0] NCCL INFO Channel 01/0 : 1[2] -> 3[0] [receive] via NET/IB/0
d14n08:1173247:1173579 [0] NCCL INFO Channel 01/0 : 11[4] -> 3[0] [receive] via NET/IB/0
d14n08:1173247:1173579 [0] NCCL INFO Channel 01/0 : 3[0] -> 7[2] [send] via NET/IB/0
d14n08:1173247:1173579 [0] NCCL INFO Channel 01/0 : 7[2] -> 3[0] [receive] via NET/IB/0
d14n08:1173247:1173579 [0] NCCL INFO Channel 01/0 : 3[0] -> 11[4] [send] via NET/IB/0
d14n08:1173247:1173579 [0] NCCL INFO Channel 01/0 : 3[0] -> 1[2] [send] via NET/IB/0
d14n08:1173247:1173579 [0] NCCL INFO Channel 00/0 : 3[0] -> 2[4] [send] via NET/IB/0
f16n16:1079916:1080230 [4] NCCL INFO Connected all rings
f16n16:1079916:1080230 [4] NCCL INFO Channel 00/0 : 8[4] -> 10[2] [send] via NET/IB/1
f16n16:1079916:1080230 [4] NCCL INFO Channel 00/0 : 4[2] -> 8[4] [receive] via NET/IB/1
f16n16:1079916:1080230 [4] NCCL INFO Channel 00/0 : 8[4] -> 0[0] [send] via NET/IB/1
f16n16:1079916:1080230 [4] NCCL INFO Channel 00/0 : 0[0] -> 8[4] [receive] via NET/IB/1
f16n16:1079916:1080230 [4] NCCL INFO Channel 00/0 : 8[4] -> 4[2] [send] via NET/IB/1
f16n16:1079916:1080230 [4] NCCL INFO Channel 00/0 : 10[2] -> 8[4] [receive] via NET/IB/1
f16n16:1079916:1080230 [4] NCCL INFO Channel 01/0 : 9[0] -> 8[4] [receive] via NET/IB/1
d11n17:1142859:1143155 [5] NCCL INFO Connected all trees
d11n17:1142859:1143155 [5] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d11n17:1142859:1143155 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n06:1216530:1216875 [0] NCCL INFO Connected all rings
d17n06:1216530:1216875 [0] NCCL INFO Channel 00/0 : 4[2] -> 6[0] [receive] via NET/IB/0
d17n06:1216530:1216875 [0] NCCL INFO Channel 00/0 : 6[0] -> 4[2] [send] via NET/IB/0
d17n06:1216530:1216875 [0] NCCL INFO Channel 00/0 : 7[2] -> 6[0] [receive] via NET/IB/0
d17n06:1216530:1216875 [0] NCCL INFO Channel 00/0 : 6[0] -> 5[4] [send] via NET/IB/0
d17n06:1216530:1216875 [0] NCCL INFO Channel 01/0 : 6[0] -> 5[4] [send] via NET/IB/0
f16n18:1091866:1092201 [0] NCCL INFO Connected all rings
f16n18:1091866:1092201 [0] NCCL INFO Channel 01/0 : 7[2] -> 9[0] [receive] via NET/IB/0
f16n18:1091866:1092201 [0] NCCL INFO Channel 01/0 : 9[0] -> 7[2] [send] via NET/IB/0
f16n18:1091866:1092201 [0] NCCL INFO Channel 00/0 : 10[2] -> 9[0] [receive] via NET/IB/0
f16n18:1091866:1092201 [0] NCCL INFO Channel 01/0 : 10[2] -> 9[0] [receive] via NET/IB/0
f16n18:1091866:1092201 [0] NCCL INFO Channel 01/0 : 9[0] -> 8[4] [send] via NET/IB/0
d14n09:567667:567994 [1] NCCL INFO Connected all trees
d14n09:567667:567994 [1] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d14n09:567667:567994 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f17n01:970278:970589 [2] NCCL INFO Connected all rings
f17n01:970278:970589 [2] NCCL INFO Channel 00/0 : 8[4] -> 10[2] [receive] via NET/IB/0
f17n01:970278:970589 [2] NCCL INFO Channel 00/0 : 10[2] -> 8[4] [send] via NET/IB/0
f17n01:970278:970589 [2] NCCL INFO Channel 00/0 : 11[4] -> 10[2] [receive] via NET/IB/0
f17n01:970278:970589 [2] NCCL INFO Channel 00/0 : 10[2] -> 9[0] [send] via NET/IB/0
f17n01:970278:970589 [2] NCCL INFO Channel 01/0 : 10[2] -> 9[0] [send] via NET/IB/0
d14n10:565682:565992 [1] NCCL INFO Connected all trees
d14n10:565682:565992 [1] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d14n10:565682:565992 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d09n08:1073956:1074271 [2] NCCL INFO Connected all rings
d09n08:1073956:1074271 [2] NCCL INFO Channel 01/0 : 1[2] -> 3[0] [send] via NET/IB/0
d09n08:1073956:1074271 [2] NCCL INFO Channel 01/0 : 3[0] -> 1[2] [receive] via NET/IB/0
d09n08:1073956:1074271 [2] NCCL INFO Channel 00/0 : 2[4] -> 1[2] [receive] via NET/IB/0
d09n08:1073956:1074271 [2] NCCL INFO Channel 01/0 : 2[4] -> 1[2] [receive] via NET/IB/0
d09n08:1073956:1074271 [2] NCCL INFO Channel 01/0 : 1[2] -> 0[0] [send] via NET/IB/0
d14n10:565684:565995 [3] NCCL INFO Connected all trees
d14n10:565684:565995 [3] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d14n10:565684:565995 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n07:1212411:1212743 [1] NCCL INFO Connected all trees
d17n07:1212411:1212743 [1] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d17n07:1212411:1212743 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n16:1079915:1080219 [3] NCCL INFO Connected all trees
f16n16:1079915:1080219 [3] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f16n16:1079915:1080219 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n10:565685:566006 [4] NCCL INFO Connected all rings
d14n10:565685:566006 [4] NCCL INFO Channel 01/0 : 5[4] -> 7[2] [send] via NET/IB/1
d14n10:565685:566006 [4] NCCL INFO Channel 01/0 : 7[2] -> 5[4] [receive] via NET/IB/1
d14n10:565685:566006 [4] NCCL INFO Channel 00/0 : 6[0] -> 5[4] [receive] via NET/IB/1
d14n10:565685:566006 [4] NCCL INFO Channel 01/0 : 6[0] -> 5[4] [receive] via NET/IB/1
d14n10:565685:566006 [4] NCCL INFO Channel 01/0 : 5[4] -> 4[2] [send] via NET/IB/1
f17n02:1076283:1076590 [4] NCCL INFO Connected all trees
f17n02:1076283:1076590 [4] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f17n02:1076283:1076590 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d09n07:1063016:1063406 [0] NCCL INFO Connected all trees
d09n07:1063016:1063406 [0] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d09n07:1063016:1063406 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f17n01:970278:970589 [2] NCCL INFO Connected all trees
f17n01:970278:970589 [2] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f17n01:970278:970589 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d09n08:1073956:1074271 [2] NCCL INFO Connected all trees
d09n08:1073956:1074271 [2] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d09n08:1073956:1074271 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n10:565685:566006 [4] NCCL INFO Connected all trees
d14n10:565685:566006 [4] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d14n10:565685:566006 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n08:1173247:1173579 [0] NCCL INFO Connected all trees
d14n08:1173247:1173579 [0] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d14n08:1173247:1173579 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n16:1130272:1130594 [4] NCCL INFO Connected all trees
d11n16:1130272:1130594 [4] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d11n16:1130272:1130594 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n09:567668:568009 [2] NCCL INFO Connected all trees
d14n09:567668:568009 [2] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d14n09:567668:568009 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n16:1079916:1080230 [4] NCCL INFO Connected all trees
f16n16:1079916:1080230 [4] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f16n16:1079916:1080230 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n18:1091866:1092201 [0] NCCL INFO Connected all trees
f16n18:1091866:1092201 [0] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f16n18:1091866:1092201 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n07:1212412:1212754 [2] NCCL INFO Connected all trees
d17n07:1212412:1212754 [2] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d17n07:1212412:1212754 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n06:1216530:1216875 [0] NCCL INFO Connected all trees
d17n06:1216530:1216875 [0] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d17n06:1216530:1216875 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f17n01:970276:970577 [0] NCCL INFO comm 0x15cf7c000 rank 9 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0xeeef2eab3be148e1 - Init COMPLETE
d17n07:1212414:1212741 [4] NCCL INFO comm 0x17ad8c460 rank 7 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x34523f6e9f712843 - Init COMPLETE
f17n01:970279:970575 [3] NCCL INFO comm 0x143a29c00 rank 10 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xbe140023bc6012b4 - Init COMPLETE
f17n01:970280:970574 [4] NCCL INFO comm 0x13792c7a0 rank 10 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x34523f6e9f712843 - Init COMPLETE
d17n07:1212415:1212739 [5] NCCL INFO comm 0x15005a210 rank 7 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x143ee5f2cd24cdfa - Init COMPLETE
d17n07:1212411:1212743 [1] NCCL INFO comm 0x17a692b40 rank 6 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0xe9f19695db992363 - Init COMPLETE
f16n18:1091868:1092188 [2] NCCL INFO comm 0x173b9f9e0 rank 9 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0x34523f6e9f712843 - Init COMPLETE
f17n01:970281:970576 [5] NCCL INFO comm 0x14303bdc0 rank 10 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x143ee5f2cd24cdfa - Init COMPLETE
f17n01:970278:970589 [2] NCCL INFO comm 0x158d7b690 rank 10 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0x3d0032b5657235cd - Init COMPLETE
f16n18:1091867:1092187 [1] NCCL INFO comm 0x15af38800 rank 9 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0xbe140023bc6012b4 - Init COMPLETE
d17n07:1212413:1212740 [3] NCCL INFO comm 0x13668d290 rank 7 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xbe140023bc6012b4 - Init COMPLETE
d11n16:1130272:1130594 [4] NCCL INFO comm 0x1250ad310 rank 2 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x3d0032b5657235cd - Init COMPLETE
f17n01:970277:970578 [1] NCCL INFO comm 0x148b9cee0 rank 9 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0xe9f19695db992363 - Init COMPLETE
f16n17:1090963:1091274 [4] NCCL INFO comm 0x13e18b9e0 rank 8 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xeeef2eab3be148e1 - Init COMPLETE
d11n16:1130268:1130579 [0] NCCL INFO comm 0x15734c2b0 rank 1 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0xe95ad2ed35e9d312 - Init COMPLETE
f16n17:1090960:1091270 [1] NCCL INFO comm 0x1638dcb50 rank 8 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0x143ee5f2cd24cdfa - Init COMPLETE
f16n18:1091866:1092201 [0] NCCL INFO comm 0x11bba2700 rank 9 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0x3d0032b5657235cd - Init COMPLETE
f16n17:1090961:1091272 [2] NCCL INFO comm 0x124fc9e70 rank 8 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0xe95ad2ed35e9d312 - Init COMPLETE
f18n05:1008221:1008518 [2] NCCL INFO comm 0x16420c870 rank 11 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0xe95ad2ed35e9d312 - Init COMPLETE
f16n18:1091869:1092190 [3] NCCL INFO comm 0x14fded150 rank 9 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x143ee5f2cd24cdfa - Init COMPLETE
d11n16:1130271:1130583 [3] NCCL INFO comm 0x16d12bc10 rank 1 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xe9f19695db992363 - Init COMPLETE
f16n18:1091871:1092189 [5] NCCL INFO comm 0x14ec0bb80 rank 9 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xd3b159694d72ff62 - Init COMPLETE
f16n17:1090964:1091275 [5] NCCL INFO comm 0x16eabe000 rank 8 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xe9f19695db992363 - Init COMPLETE
d11n16:1130270:1130582 [2] NCCL INFO comm 0x14a48ebc0 rank 1 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0xeeef2eab3be148e1 - Init COMPLETE
d11n16:1130273:1130581 [5] NCCL INFO comm 0x1506fda10 rank 2 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xbe140023bc6012b4 - Init COMPLETE
f16n17:1090959:1091271 [0] NCCL INFO comm 0x14502c2c0 rank 8 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0x34523f6e9f712843 - Init COMPLETE
f16n18:1091870:1092186 [4] NCCL INFO comm 0x17017f540 rank 9 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xe95ad2ed35e9d312 - Init COMPLETE
f17n02:1076281:1076578 [2] NCCL INFO comm 0x17c0bc8b0 rank 10 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0xeeef2eab3be148e1 - Init COMPLETE
d14n09:567670:567996 [4] NCCL INFO comm 0x1666dcaa0 rank 4 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x34523f6e9f712843 - Init COMPLETE
f16n17:1090962:1091273 [3] NCCL INFO comm 0x13abc2800 rank 8 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xd3b159694d72ff62 - Init COMPLETE
f18n05:1008223:1008522 [4] NCCL INFO comm 0x17e70c690 rank 11 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xeeef2eab3be148e1 - Init COMPLETE
d11n16:1130269:1130580 [1] NCCL INFO comm 0x137450c80 rank 1 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0xd3b159694d72ff62 - Init COMPLETE
f18n05:1008222:1008521 [3] NCCL INFO comm 0x152d5c9d0 rank 11 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xd3b159694d72ff62 - Init COMPLETE
[2024-03-04 16:46:25,293] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
f17n02:1076284:1076577 [5] NCCL INFO comm 0x14a72c3d0 rank 11 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xbe140023bc6012b4 - Init COMPLETE
f17n02:1076283:1076590 [4] NCCL INFO comm 0x15afb9cb0 rank 11 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x3d0032b5657235cd - Init COMPLETE
d11n17:1142859:1143155 [5] NCCL INFO comm 0x133858b10 rank 2 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xe9f19695db992363 - Init COMPLETE
f17n02:1076279:1076575 [0] NCCL INFO comm 0x161bab800 rank 10 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0xe95ad2ed35e9d312 - Init COMPLETE
d11n17:1142855:1143152 [1] NCCL INFO comm 0x12ef8ebf0 rank 2 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0x143ee5f2cd24cdfa - Init COMPLETE
d11n17:1142856:1143153 [2] NCCL INFO comm 0x13bfac6d0 rank 2 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0xe95ad2ed35e9d312 - Init COMPLETE
f17n02:1076280:1076576 [1] NCCL INFO comm 0x14533e460 rank 10 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0xd3b159694d72ff62 - Init COMPLETE
d11n17:1142858:1143156 [4] NCCL INFO comm 0x134018c60 rank 2 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xeeef2eab3be148e1 - Init COMPLETE
d09n08:1073956:1074271 [2] NCCL INFO comm 0x15eced080 rank 1 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0x3d0032b5657235cd - Init COMPLETE
d11n17:1142857:1143157 [3] NCCL INFO comm 0x130dc8710 rank 2 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xd3b159694d72ff62 - Init COMPLETE
f17n02:1076282:1076579 [3] NCCL INFO comm 0x129f6ca10 rank 10 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xe9f19695db992363 - Init COMPLETE
d11n17:1142854:1143154 [0] NCCL INFO comm 0x15adda0e0 rank 2 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0x34523f6e9f712843 - Init COMPLETE
d09n08:1073958:1074256 [4] NCCL INFO comm 0x15113c580 rank 1 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x34523f6e9f712843 - Init COMPLETE
d09n08:1073959:1074255 [5] NCCL INFO comm 0x159e8f940 rank 1 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x143ee5f2cd24cdfa - Init COMPLETE
f16n16:1079914:1080218 [2] NCCL INFO comm 0x163a16fc0 rank 7 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0xeeef2eab3be148e1 - Init COMPLETE
d09n08:1073957:1074254 [3] NCCL INFO comm 0x1597037c0 rank 1 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xbe140023bc6012b4 - Init COMPLETE
d09n07:1063021:1063389 [4] NCCL INFO comm 0x17aaec630 rank 0 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xe95ad2ed35e9d312 - Init COMPLETE
f16n16:1079912:1080216 [0] NCCL INFO comm 0x143a43a00 rank 7 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0xe95ad2ed35e9d312 - Init COMPLETE
d14n09:567668:568009 [2] NCCL INFO comm 0x129f444c0 rank 4 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0x3d0032b5657235cd - Init COMPLETE
d14n10:565682:565992 [1] NCCL INFO comm 0x17826b020 rank 4 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0xd3b159694d72ff62 - Init COMPLETE
d09n08:1073955:1074260 [1] NCCL INFO comm 0x15c61b990 rank 0 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0xe9f19695db992363 - Init COMPLETE
f16n16:1079913:1080215 [1] NCCL INFO comm 0x17ea2aa40 rank 7 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0xd3b159694d72ff62 - Init COMPLETE
d09n08:1073954:1074259 [0] NCCL INFO comm 0x14a851580 rank 0 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0xeeef2eab3be148e1 - Init COMPLETE
f16n16:1079915:1080219 [3] NCCL INFO comm 0x163fb2a00 rank 7 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xe9f19695db992363 - Init COMPLETE
f16n16:1079917:1080217 [5] NCCL INFO comm 0x170fca5c0 rank 8 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xbe140023bc6012b4 - Init COMPLETE
f16n16:1079916:1080230 [4] NCCL INFO comm 0x150d4e300 rank 8 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x3d0032b5657235cd - Init COMPLETE
d14n09:567667:567994 [1] NCCL INFO comm 0x15073d9e0 rank 3 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0xe9f19695db992363 - Init COMPLETE
d14n10:565683:565994 [2] NCCL INFO comm 0x12ce9bea0 rank 4 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0xeeef2eab3be148e1 - Init COMPLETE
d14n09:567666:567998 [0] NCCL INFO comm 0x181ddc4b0 rank 3 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0xeeef2eab3be148e1 - Init COMPLETE
d14n09:567671:567995 [5] NCCL INFO comm 0x137c75700 rank 4 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x143ee5f2cd24cdfa - Init COMPLETE
d14n10:565686:565993 [5] NCCL INFO comm 0x117fa8f10 rank 5 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xbe140023bc6012b4 - Init COMPLETE
d14n08:1173248:1173568 [1] NCCL INFO comm 0x139de8e90 rank 3 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0xbe140023bc6012b4 - Init COMPLETE
[2024-03-04 16:46:25,297] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
d09n07:1063022:1063390 [5] NCCL INFO comm 0x168eccf80 rank 0 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xd3b159694d72ff62 - Init COMPLETE
d14n11:1169358:1169673 [2] NCCL INFO comm 0x1425ec5d0 rank 5 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0xe95ad2ed35e9d312 - Init COMPLETE
d14n08:1173247:1173579 [0] NCCL INFO comm 0x1357cf340 rank 3 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0x3d0032b5657235cd - Init COMPLETE
[2024-03-04 16:46:25,297] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
d14n11:1169357:1169672 [1] NCCL INFO comm 0x1302b2100 rank 5 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0x143ee5f2cd24cdfa - Init COMPLETE
d14n08:1173251:1173565 [4] NCCL INFO comm 0x15f8cc440 rank 3 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xe95ad2ed35e9d312 - Init COMPLETE
d14n08:1173252:1173564 [5] NCCL INFO comm 0x1339a7e80 rank 3 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xd3b159694d72ff62 - Init COMPLETE
d14n11:1169356:1169677 [0] NCCL INFO comm 0x154fe6d70 rank 5 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0x34523f6e9f712843 - Init COMPLETE
d14n10:565685:566006 [4] NCCL INFO comm 0x16207c930 rank 5 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x3d0032b5657235cd - Init COMPLETE
d14n10:565684:565995 [3] NCCL INFO comm 0x12bc5a300 rank 4 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xe9f19695db992363 - Init COMPLETE
d14n09:567669:567997 [3] NCCL INFO comm 0x149ab7540 rank 4 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xbe140023bc6012b4 - Init COMPLETE
d14n11:1169360:1169676 [4] NCCL INFO comm 0x117e4bd70 rank 5 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xeeef2eab3be148e1 - Init COMPLETE
d14n08:1173249:1173567 [2] NCCL INFO comm 0x1521dc770 rank 3 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0x34523f6e9f712843 - Init COMPLETE
d14n08:1173250:1173566 [3] NCCL INFO comm 0x16754bd40 rank 3 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x143ee5f2cd24cdfa - Init COMPLETE
d14n10:565681:565991 [0] NCCL INFO comm 0x1660dcd40 rank 4 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0xe95ad2ed35e9d312 - Init COMPLETE
d17n06:1216530:1216875 [0] NCCL INFO comm 0x146ed8e50 rank 6 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0x3d0032b5657235cd - Init COMPLETE
f18n05:1008224:1008523 [5] NCCL INFO comm 0x14dae4b00 rank 11 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xe9f19695db992363 - Init COMPLETE
d14n11:1169359:1169675 [3] NCCL INFO comm 0x1688666f0 rank 5 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xd3b159694d72ff62 - Init COMPLETE
d17n06:1216532:1216861 [2] NCCL INFO comm 0x13155d730 rank 6 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0x34523f6e9f712843 - Init COMPLETE
d14n11:1169361:1169674 [5] NCCL INFO comm 0x124b6cf40 rank 5 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xe9f19695db992363 - Init COMPLETE
d17n07:1212412:1212754 [2] NCCL INFO comm 0x12d929bc0 rank 7 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0x3d0032b5657235cd - Init COMPLETE
d17n06:1216531:1216860 [1] NCCL INFO comm 0x12335b640 rank 6 nranks 12 cudaDev 1 nvmlDev 1 busId 405000 commId 0xbe140023bc6012b4 - Init COMPLETE
d17n06:1216534:1216862 [4] NCCL INFO comm 0x12b3cd110 rank 6 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xe95ad2ed35e9d312 - Init COMPLETE
d17n07:1212410:1212742 [0] NCCL INFO comm 0x17138c480 rank 6 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0xeeef2eab3be148e1 - Init COMPLETE
d17n06:1216535:1216864 [5] NCCL INFO comm 0x13c8dc380 rank 6 nranks 12 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xd3b159694d72ff62 - Init COMPLETE
d17n06:1216533:1216863 [3] NCCL INFO comm 0x13f64cc30 rank 6 nranks 12 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x143ee5f2cd24cdfa - Init COMPLETE
d09n07:1063016:1063406 [0] NCCL INFO comm 0x13ef1ca00 rank 0 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0x3d0032b5657235cd - Init COMPLETE
[2024-03-04 16:46:25,347] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[2024-03-04 16:46:25,347] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'apex.optimizers.fused_adam.FusedAdam'>
[2024-03-04 16:46:25,347] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 1 optimizer
[2024-03-04 16:46:25,347] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 500,000,000
[2024-03-04 16:46:25,348] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 500,000,000
[2024-03-04 16:46:25,348] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: False
[2024-03-04 16:46:25,348] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
NCCL version 2.18.3+cuda11.8
Rank: 0 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:27,334] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2024-03-04 16:46:27,335] [INFO] [utils.py:786:see_memory_usage] MA 1.83 GB         Max_MA 1.83 GB         CA 1.84 GB         Max_CA 2 GB 
[2024-03-04 16:46:27,335] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 65.29 GB, percent = 10.9%
NCCL version 2.18.3+cuda11.8
NCCL version 2.18.3+cuda11.8
NCCL version 2.18.3+cuda11.8
NCCL version 2.18.3+cuda11.8
NCCL version 2.18.3+cuda11.8
NCCL version 2.18.3+cuda11.8
NCCL version 2.18.3+cuda11.8
NCCL version 2.18.3+cuda11.8
NCCL version 2.18.3+cuda11.8
NCCL version 2.18.3+cuda11.8
f17n01:970276:970615 [0] NCCL INFO Using network IB
f17n01:970276:970615 [0] NCCL INFO comm 0x15b570240 rank 6 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x419c2a0ad9e17ee9 - Init START
d17n07:1212414:1212781 [4] NCCL INFO Using network IB
d17n07:1212414:1212781 [4] NCCL INFO comm 0x17b458dc0 rank 2 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x5367495adaa62d15 - Init START
f17n01:970280:970614 [4] NCCL INFO Using network IB
f17n01:970280:970614 [4] NCCL INFO comm 0x1361b55c0 rank 2 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x9f2ca15e6ef47ab - Init START
d17n07:1212415:1212778 [5] NCCL INFO Using network IB
d17n07:1212415:1212778 [5] NCCL INFO comm 0x14f1b75c0 rank 3 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x5367495adaa62d15 - Init START
f17n01:970279:970613 [3] NCCL INFO Using network IB
f17n01:970279:970613 [3] NCCL INFO comm 0x143ad6a40 rank 1 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x9f2ca15e6ef47ab - Init START
f17n01:970281:970612 [5] NCCL INFO Using network IB
f17n01:970281:970612 [5] NCCL INFO comm 0x1429f3c40 rank 3 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x9f2ca15e6ef47ab - Init START
f17n01:970278:970611 [2] NCCL INFO Using network IB
f17n01:970278:970611 [2] NCCL INFO comm 0x158cd2ac0 rank 0 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x9f2ca15e6ef47ab - Init START
d17n07:1212411:1212779 [1] NCCL INFO Using network IB
d17n07:1212411:1212779 [1] NCCL INFO comm 0x17ad21220 rank 7 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x6d43618daca01626 - Init START
d17n07:1212413:1212777 [3] NCCL INFO Using network IB
d17n07:1212413:1212777 [3] NCCL INFO comm 0x135810a80 rank 1 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x5367495adaa62d15 - Init START
f16n18:1091868:1092225 [2] NCCL INFO Using network IB
f16n18:1091868:1092225 [2] NCCL INFO comm 0x1723f4600 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x419c2a0ad9e17ee9 - Init START
f17n01:970277:970616 [1] NCCL INFO Using network IB
f17n01:970277:970616 [1] NCCL INFO comm 0x147e6c080 rank 7 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x419c2a0ad9e17ee9 - Init START
f16n18:1091867:1092224 [1] NCCL INFO Using network IB
f16n18:1091867:1092224 [1] NCCL INFO comm 0x15a85cb00 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x419c2a0ad9e17ee9 - Init START
f16n17:1090961:1091306 [2] NCCL INFO Using network IB
f16n17:1090961:1091306 [2] NCCL INFO comm 0x122f1c400 rank 4 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa97eee98a5fa0988 - Init START
f16n18:1091866:1092223 [0] NCCL INFO Using network IB
f16n18:1091866:1092223 [0] NCCL INFO comm 0x11bb9a640 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x419c2a0ad9e17ee9 - Init START
d11n16:1130272:1130616 [4] NCCL INFO Using network IB
d11n16:1130272:1130616 [4] NCCL INFO comm 0x1248d0300 rank 0 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xfda37076ce67c0f7 - Init START
f16n17:1090960:1091307 [1] NCCL INFO Using network IB
f16n17:1090960:1091307 [1] NCCL INFO comm 0x16340ae40 rank 3 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa97eee98a5fa0988 - Init START
f16n17:1090963:1091311 [4] NCCL INFO Using network IB
f16n17:1090963:1091311 [4] NCCL INFO comm 0x13dafd580 rank 6 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa97eee98a5fa0988 - Init START
d11n16:1130271:1130621 [3] NCCL INFO Using network IB
d11n16:1130271:1130621 [3] NCCL INFO comm 0x16c969b60 rank 7 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa91f9f3e21ae8c0a - Init START
d11n16:1130273:1130617 [5] NCCL INFO Using network IB
d11n16:1130273:1130617 [5] NCCL INFO comm 0x1507718a0 rank 1 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xfda37076ce67c0f7 - Init START
f16n17:1090964:1091309 [5] NCCL INFO Using network IB
f16n17:1090964:1091309 [5] NCCL INFO comm 0x16eaade80 rank 7 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa97eee98a5fa0988 - Init START
d11n16:1130268:1130618 [0] NCCL INFO Using network IB
d11n16:1130268:1130618 [0] NCCL INFO comm 0x156bbcec0 rank 4 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa91f9f3e21ae8c0a - Init START
f16n18:1091869:1092226 [3] NCCL INFO Using network IB
f16n18:1091869:1092226 [3] NCCL INFO comm 0x14fd46050 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x419c2a0ad9e17ee9 - Init START
d11n16:1130270:1130619 [2] NCCL INFO Using network IB
d11n16:1130270:1130619 [2] NCCL INFO comm 0x14a505240 rank 6 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa91f9f3e21ae8c0a - Init START
f16n17:1090959:1091308 [0] NCCL INFO Using network IB
f16n17:1090959:1091308 [0] NCCL INFO comm 0x144eedb80 rank 2 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa97eee98a5fa0988 - Init START
f16n18:1091871:1092227 [5] NCCL INFO Using network IB
f16n18:1091871:1092227 [5] NCCL INFO comm 0x14e761b40 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x419c2a0ad9e17ee9 - Init START
f18n05:1008221:1008554 [2] NCCL INFO Using network IB
f18n05:1008221:1008554 [2] NCCL INFO comm 0x164165680 rank 4 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0xf0d7c583d79fb505 - Init START
f16n18:1091870:1092228 [4] NCCL INFO Using network IB
f16n18:1091870:1092228 [4] NCCL INFO comm 0x1701c3d00 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x419c2a0ad9e17ee9 - Init START
f18n05:1008219:1008555 [0] NCCL INFO Using network IB
f18n05:1008219:1008555 [0] NCCL INFO comm 0x15942e440 rank 2 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0xf0d7c583d79fb505 - Init START
f16n17:1090962:1091310 [3] NCCL INFO Using network IB
f16n17:1090962:1091310 [3] NCCL INFO comm 0x139dc8240 rank 5 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa97eee98a5fa0988 - Init START
f18n05:1008220:1008558 [1] NCCL INFO Using network IB
f18n05:1008220:1008558 [1] NCCL INFO comm 0x168afafc0 rank 3 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0xf0d7c583d79fb505 - Init START
f18n05:1008222:1008559 [3] NCCL INFO Using network IB
f18n05:1008222:1008559 [3] NCCL INFO comm 0x152647900 rank 5 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xf0d7c583d79fb505 - Init START
d11n16:1130269:1130620 [1] NCCL INFO Using network IB
d11n16:1130269:1130620 [1] NCCL INFO comm 0x136d088c0 rank 5 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa91f9f3e21ae8c0a - Init START
f17n02:1076281:1076615 [2] NCCL INFO Using network IB
f17n02:1076281:1076615 [2] NCCL INFO comm 0x17c0146e0 rank 6 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x9f2ca15e6ef47ab - Init START
d14n09:567670:568035 [4] NCCL INFO Using network IB
d14n09:567670:568035 [4] NCCL INFO comm 0x164d44c80 rank 2 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x6960d29931b9c9d9 - Init START
f18n05:1008223:1008556 [4] NCCL INFO Using network IB
f18n05:1008223:1008556 [4] NCCL INFO comm 0x17dfcfda0 rank 6 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xf0d7c583d79fb505 - Init START
f17n02:1076283:1076612 [4] NCCL INFO Using network IB
f17n02:1076283:1076612 [4] NCCL INFO comm 0x15a17b680 rank 0 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xf0d7c583d79fb505 - Init START
f17n02:1076284:1076617 [5] NCCL INFO Using network IB
f17n02:1076284:1076617 [5] NCCL INFO comm 0x14a6847c0 rank 1 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xf0d7c583d79fb505 - Init START
d11n17:1142858:1143191 [4] NCCL INFO Using network IB
d11n17:1142858:1143191 [4] NCCL INFO comm 0x133c87c40 rank 6 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xfda37076ce67c0f7 - Init START
d11n17:1142859:1143192 [5] NCCL INFO Using network IB
d11n17:1142859:1143192 [5] NCCL INFO comm 0x13316bc80 rank 7 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xfda37076ce67c0f7 - Init START
f17n02:1076279:1076616 [0] NCCL INFO Using network IB
f17n02:1076279:1076616 [0] NCCL INFO comm 0x161b97640 rank 4 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x9f2ca15e6ef47ab - Init START
f17n02:1076280:1076614 [1] NCCL INFO Using network IB
f17n02:1076280:1076614 [1] NCCL INFO comm 0x1444da9c0 rank 5 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x9f2ca15e6ef47ab - Init START
d11n17:1142855:1143188 [1] NCCL INFO Using network IB
d11n17:1142855:1143188 [1] NCCL INFO comm 0x12fc64740 rank 3 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0xfda37076ce67c0f7 - Init START
d11n17:1142856:1143189 [2] NCCL INFO Using network IB
d11n17:1142856:1143189 [2] NCCL INFO comm 0x13b217780 rank 4 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0xfda37076ce67c0f7 - Init START
f17n02:1076282:1076613 [3] NCCL INFO Using network IB
f17n02:1076282:1076613 [3] NCCL INFO comm 0x1291ac380 rank 7 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x9f2ca15e6ef47ab - Init START
d11n17:1142857:1143193 [3] NCCL INFO Using network IB
d11n17:1142857:1143193 [3] NCCL INFO comm 0x12fee2fe0 rank 5 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xfda37076ce67c0f7 - Init START
d09n08:1073956:1074293 [2] NCCL INFO Using network IB
d09n08:1073956:1074293 [2] NCCL INFO comm 0x15dd71b00 rank 0 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa91f9f3e21ae8c0a - Init START
d11n17:1142854:1143190 [0] NCCL INFO Using network IB
d11n17:1142854:1143190 [0] NCCL INFO comm 0x15a1f3e40 rank 2 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0xfda37076ce67c0f7 - Init START
d09n08:1073958:1074295 [4] NCCL INFO Using network IB
d09n08:1073958:1074295 [4] NCCL INFO comm 0x14fd68340 rank 2 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa91f9f3e21ae8c0a - Init START
d09n08:1073957:1074296 [3] NCCL INFO Using network IB
d09n08:1073957:1074296 [3] NCCL INFO comm 0x1596fb740 rank 1 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa91f9f3e21ae8c0a - Init START
f16n16:1079912:1080256 [0] NCCL INFO Using network IB
f16n16:1079912:1080256 [0] NCCL INFO comm 0x143ee5190 rank 4 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x5367495adaa62d15 - Init START
d09n08:1073959:1074294 [5] NCCL INFO Using network IB
d09n08:1073959:1074294 [5] NCCL INFO comm 0x159ebaa00 rank 3 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa91f9f3e21ae8c0a - Init START
f16n16:1079914:1080254 [2] NCCL INFO Using network IB
f16n16:1079914:1080254 [2] NCCL INFO comm 0x1649304a0 rank 6 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x5367495adaa62d15 - Init START
f16n16:1079913:1080255 [1] NCCL INFO Using network IB
f16n16:1079913:1080255 [1] NCCL INFO comm 0x17ea22980 rank 5 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x5367495adaa62d15 - Init START
d14n09:567668:568032 [2] NCCL INFO Using network IB
d14n09:567668:568032 [2] NCCL INFO comm 0x12a5a3d80 rank 0 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x6960d29931b9c9d9 - Init START
f16n16:1079915:1080253 [3] NCCL INFO Using network IB
f16n16:1079915:1080253 [3] NCCL INFO comm 0x163fd6cc0 rank 7 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x5367495adaa62d15 - Init START
f16n16:1079916:1080252 [4] NCCL INFO Using network IB
f16n16:1079916:1080252 [4] NCCL INFO comm 0x1520629c0 rank 0 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa97eee98a5fa0988 - Init START
f16n16:1079917:1080257 [5] NCCL INFO Using network IB
f16n16:1079917:1080257 [5] NCCL INFO comm 0x171002a40 rank 1 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa97eee98a5fa0988 - Init START
d14n10:565682:566032 [1] NCCL INFO Using network IB
d14n10:565682:566032 [1] NCCL INFO comm 0x1795799c0 rank 5 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x6960d29931b9c9d9 - Init START
d14n09:567667:568033 [1] NCCL INFO Using network IB
d14n09:567667:568033 [1] NCCL INFO comm 0x14ff73090 rank 7 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x9b8dd052a7b10a2a - Init START
d14n10:565683:566031 [2] NCCL INFO Using network IB
d14n10:565683:566031 [2] NCCL INFO comm 0x12c983500 rank 6 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x6960d29931b9c9d9 - Init START
d14n09:567666:568034 [0] NCCL INFO Using network IB
d14n09:567666:568034 [0] NCCL INFO comm 0x1818e7e40 rank 6 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x9b8dd052a7b10a2a - Init START
d14n11:1169358:1169710 [2] NCCL INFO Using network IB
d14n11:1169358:1169710 [2] NCCL INFO comm 0x14216a700 rank 4 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0xb823d8d2b1ba67a3 - Init START
d14n09:567671:568036 [5] NCCL INFO Using network IB
d14n09:567671:568036 [5] NCCL INFO comm 0x137c71680 rank 3 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x6960d29931b9c9d9 - Init START
d14n11:1169357:1169715 [1] NCCL INFO Using network IB
d14n11:1169357:1169715 [1] NCCL INFO comm 0x130ad17b0 rank 3 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0xb823d8d2b1ba67a3 - Init START
d14n10:565686:566030 [5] NCCL INFO Using network IB
d14n10:565686:566030 [5] NCCL INFO comm 0x1165f5380 rank 1 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xb823d8d2b1ba67a3 - Init START
d14n08:1173247:1173602 [0] NCCL INFO Using network IB
d14n08:1173247:1173602 [0] NCCL INFO comm 0x13709cfe0 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x9b8dd052a7b10a2a - Init START
d14n11:1169356:1169711 [0] NCCL INFO Using network IB
d14n11:1169356:1169711 [0] NCCL INFO comm 0x1541c3600 rank 2 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0xb823d8d2b1ba67a3 - Init START
d14n08:1173248:1173607 [1] NCCL INFO Using network IB
d14n08:1173248:1173607 [1] NCCL INFO comm 0x13975b2c0 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x9b8dd052a7b10a2a - Init START
d14n10:565684:566034 [3] NCCL INFO Using network IB
d14n10:565684:566034 [3] NCCL INFO comm 0x12da594c0 rank 7 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x6960d29931b9c9d9 - Init START
d14n08:1173251:1173605 [4] NCCL INFO Using network IB
d14n08:1173251:1173605 [4] NCCL INFO comm 0x15f43e540 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x9b8dd052a7b10a2a - Init START
d14n09:567669:568037 [3] NCCL INFO Using network IB
d14n09:567669:568037 [3] NCCL INFO comm 0x149aaf4c0 rank 1 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x6960d29931b9c9d9 - Init START
d14n10:565685:566029 [4] NCCL INFO Using network IB
d14n10:565685:566029 [4] NCCL INFO comm 0x161c23e80 rank 0 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xb823d8d2b1ba67a3 - Init START
d14n11:1169360:1169712 [4] NCCL INFO Using network IB
d14n11:1169360:1169712 [4] NCCL INFO comm 0x1177ed1c0 rank 6 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xb823d8d2b1ba67a3 - Init START
d14n08:1173252:1173603 [5] NCCL INFO Using network IB
d14n08:1173252:1173603 [5] NCCL INFO comm 0x133599100 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x9b8dd052a7b10a2a - Init START
d14n08:1173249:1173604 [2] NCCL INFO Using network IB
d14n08:1173249:1173604 [2] NCCL INFO comm 0x151953900 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x9b8dd052a7b10a2a - Init START
d14n08:1173250:1173606 [3] NCCL INFO Using network IB
d14n08:1173250:1173606 [3] NCCL INFO comm 0x1674a4700 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x9b8dd052a7b10a2a - Init START
d14n11:1169359:1169714 [3] NCCL INFO Using network IB
d14n11:1169359:1169714 [3] NCCL INFO comm 0x1685295c0 rank 5 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xb823d8d2b1ba67a3 - Init START
d14n10:565681:566033 [0] NCCL INFO Using network IB
d14n10:565681:566033 [0] NCCL INFO comm 0x166d99680 rank 4 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x6960d29931b9c9d9 - Init START
f18n05:1008224:1008557 [5] NCCL INFO Using network IB
f18n05:1008224:1008557 [5] NCCL INFO comm 0x14ec36e60 rank 7 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xf0d7c583d79fb505 - Init START
d14n11:1169361:1169713 [5] NCCL INFO Using network IB
d14n11:1169361:1169713 [5] NCCL INFO comm 0x124198700 rank 7 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xb823d8d2b1ba67a3 - Init START
d17n06:1216532:1216898 [2] NCCL INFO Using network IB
d17n06:1216532:1216898 [2] NCCL INFO comm 0x1305ee140 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x6d43618daca01626 - Init START
d17n06:1216530:1216897 [0] NCCL INFO Using network IB
d17n06:1216530:1216897 [0] NCCL INFO comm 0x146e31830 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x6d43618daca01626 - Init START
d17n06:1216531:1216902 [1] NCCL INFO Using network IB
d17n06:1216531:1216902 [1] NCCL INFO comm 0x123373840 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x6d43618daca01626 - Init START
d17n06:1216534:1216900 [4] NCCL INFO Using network IB
d17n06:1216534:1216900 [4] NCCL INFO comm 0x1299b2840 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x6d43618daca01626 - Init START
d17n06:1216535:1216899 [5] NCCL INFO Using network IB
d17n06:1216535:1216899 [5] NCCL INFO comm 0x13d8e37c0 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x6d43618daca01626 - Init START
d17n07:1212412:1212776 [2] NCCL INFO Using network IB
d17n07:1212412:1212776 [2] NCCL INFO comm 0x12dc34580 rank 0 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x5367495adaa62d15 - Init START
d17n06:1216533:1216901 [3] NCCL INFO Using network IB
d17n06:1216533:1216901 [3] NCCL INFO comm 0x13ee3a700 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x6d43618daca01626 - Init START
d17n07:1212410:1212780 [0] NCCL INFO Using network IB
d17n07:1212410:1212780 [0] NCCL INFO comm 0x171388400 rank 6 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x6d43618daca01626 - Init START
[2024-03-04 16:46:27,428] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2024-03-04 16:46:27,429] [INFO] [utils.py:786:see_memory_usage] MA 2.36 GB         Max_MA 2.62 GB         CA 2.63 GB         Max_CA 3 GB 
[2024-03-04 16:46:27,430] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 66.07 GB, percent = 11.1%
[2024-03-04 16:46:27,430] [INFO] [stage_1_and_2.py:493:__init__] optimizer state initialized
f17n01:970276:970615 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d17n07:1212411:1212779 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
f17n01:970277:970616 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d11n16:1130272:1130616 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d11n16:1130273:1130617 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
f17n02:1076283:1076612 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
f17n02:1076284:1076617 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d09n08:1073956:1074293 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d09n08:1073958:1074295 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d09n08:1073957:1074296 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d09n08:1073959:1074294 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
f16n16:1079916:1080252 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d14n09:567668:568032 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
f16n16:1079917:1080257 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d14n09:567667:568033 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d14n09:567666:568034 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d14n10:565686:566030 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d14n10:565685:566029 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d17n07:1212410:1212780 [0] NCCL INFO Setting affinity for GPU 0 to 0f
[2024-03-04 16:46:27,506] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2024-03-04 16:46:27,507] [INFO] [utils.py:786:see_memory_usage] MA 2.36 GB         Max_MA 2.36 GB         CA 2.63 GB         Max_CA 3 GB 
[2024-03-04 16:46:27,507] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 66.08 GB, percent = 11.1%
[2024-03-04 16:46:27,510] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam
[2024-03-04 16:46:27,510] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-03-04 16:46:27,510] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <megatron.optimizer_param_scheduler.OptimizerParamScheduler object at 0x20012715f650>
[2024-03-04 16:46:27,510] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-03-04 16:46:27,511] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2024-03-04 16:46:27,512] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-03-04 16:46:27,512] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-03-04 16:46:27,512] [INFO] [config.py:964:print]   amp_enabled .................. False
[2024-03-04 16:46:27,512] [INFO] [config.py:964:print]   amp_params ................... False
[2024-03-04 16:46:27,512] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-03-04 16:46:27,512] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2024-03-04 16:46:27,512] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2024-03-04 16:46:27,512] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2024-03-04 16:46:27,512] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2024-03-04 16:46:27,512] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x20012757e610>
[2024-03-04 16:46:27,512] [INFO] [config.py:964:print]   communication_data_type ...... None
[2024-03-04 16:46:27,512] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-03-04 16:46:27,512] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2024-03-04 16:46:27,512] [INFO] [config.py:964:print]   curriculum_params_legacy ..... {'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}
[2024-03-04 16:46:27,512] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-03-04 16:46:27,512] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2024-03-04 16:46:27,512] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2024-03-04 16:46:27,513] [INFO] [config.py:964:print]   disable_allgather ............ False
[2024-03-04 16:46:27,513] [INFO] [config.py:964:print]   dump_state ................... False
[2024-03-04 16:46:27,513] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 500, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}
[2024-03-04 16:46:27,513] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2024-03-04 16:46:27,513] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2024-03-04 16:46:27,513] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-03-04 16:46:27,513] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2024-03-04 16:46:27,513] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2024-03-04 16:46:27,513] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2024-03-04 16:46:27,513] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2024-03-04 16:46:27,513] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2024-03-04 16:46:27,513] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2024-03-04 16:46:27,513] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-03-04 16:46:27,513] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2024-03-04 16:46:27,513] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2024-03-04 16:46:27,513] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2024-03-04 16:46:27,513] [INFO] [config.py:964:print]   global_rank .................. 0
[2024-03-04 16:46:27,513] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2024-03-04 16:46:27,513] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 2
[2024-03-04 16:46:27,513] [INFO] [config.py:964:print]   gradient_clipping ............ 1.0
[2024-03-04 16:46:27,513] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2024-03-04 16:46:27,513] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-03-04 16:46:27,513] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[2024-03-04 16:46:27,514] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2024-03-04 16:46:27,514] [INFO] [config.py:964:print]   loss_scale ................... 0
[2024-03-04 16:46:27,514] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2024-03-04 16:46:27,514] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2024-03-04 16:46:27,514] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2024-03-04 16:46:27,514] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-03-04 16:46:27,514] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-03-04 16:46:27,514] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2024-03-04 16:46:27,514] [INFO] [config.py:964:print]   optimizer_name ............... None
[2024-03-04 16:46:27,514] [INFO] [config.py:964:print]   optimizer_params ............. None
[2024-03-04 16:46:27,514] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2024-03-04 16:46:27,514] [INFO] [config.py:964:print]   pld_enabled .................. False
[2024-03-04 16:46:27,514] [INFO] [config.py:964:print]   pld_params ................... False
[2024-03-04 16:46:27,514] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2024-03-04 16:46:27,514] [INFO] [config.py:964:print]   scheduler_name ............... None
[2024-03-04 16:46:27,514] [INFO] [config.py:964:print]   scheduler_params ............. None
[2024-03-04 16:46:27,514] [INFO] [config.py:964:print]   sparse_attention ............. None
[2024-03-04 16:46:27,514] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2024-03-04 16:46:27,514] [INFO] [config.py:964:print]   steps_per_print .............. 10
[2024-03-04 16:46:27,514] [INFO] [config.py:964:print]   train_batch_size ............. 24
[2024-03-04 16:46:27,514] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[2024-03-04 16:46:27,514] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2024-03-04 16:46:27,514] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2024-03-04 16:46:27,514] [INFO] [config.py:964:print]   world_size ................... 12
[2024-03-04 16:46:27,514] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  False
[2024-03-04 16:46:27,515] [INFO] [config.py:964:print]   zero_config .................. stage=1 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2024-03-04 16:46:27,515] [INFO] [config.py:964:print]   zero_enabled ................. True
[2024-03-04 16:46:27,515] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2024-03-04 16:46:27,515] [INFO] [config.py:964:print]   zero_optimization_stage ...... 1
[2024-03-04 16:46:27,515] [INFO] [config.py:950:print_user_config]   json = {
    "train_batch_size": 24, 
    "train_micro_batch_size_per_gpu": 1, 
    "steps_per_print": 10, 
    "zero_optimization": {
        "stage": 1
    }, 
    "gradient_clipping": 1.0, 
    "prescale_gradients": false, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "loss_scale_window": 500, 
        "hysteresis": 2, 
        "min_loss_scale": 1, 
        "initial_scale_power": 11
    }, 
    "bf16": {
        "enabled": false
    }, 
    "curriculum_learning": {
        "enabled": false, 
        "curriculum_type": "seqlen", 
        "min_difficulty": 80, 
        "max_difficulty": 2.048000e+03, 
        "schedule_type": "fixed_linear", 
        "schedule_config": {
            "total_curriculum_step": 2.349624e+06, 
            "difficulty_step": 8
        }
    }, 
    "wall_clock_breakdown": false
}
[2024-03-04 16:46:27,515] [INFO] [engine.py:83:__init__] CONFIG: micro_batches=2 micro_batch_size=1
d17n07:1212414:1212781 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
f17n01:970280:970614 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
f17n01:970280:970614 [4] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1
f17n01:970280:970614 [4] NCCL INFO P2P Chunksize set to 131072
d17n07:1212415:1212778 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
f17n01:970281:970612 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
f17n01:970281:970612 [5] NCCL INFO Trees [0] 0/-1/-1->3->2 [1] 0/-1/-1->3->2 [2] 0/-1/-1->3->2 [3] 0/-1/-1->3->2
f17n01:970281:970612 [5] NCCL INFO P2P Chunksize set to 131072
f17n01:970279:970613 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
f17n01:970279:970613 [3] NCCL INFO Trees [0] 2/4/-1->1->-1 [1] 2/4/-1->1->-1 [2] 2/-1/-1->1->4 [3] 2/-1/-1->1->4
f17n01:970279:970613 [3] NCCL INFO P2P Chunksize set to 131072
f17n01:970278:970611 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
f17n01:970278:970611 [2] NCCL INFO Channel 00/04 :    0   1   2   3   4   5   6   7
f17n01:970278:970611 [2] NCCL INFO Channel 01/04 :    0   7   6   5   4   1   2   3
f17n01:970278:970611 [2] NCCL INFO Channel 02/04 :    0   1   2   3   4   5   6   7
f17n01:970278:970611 [2] NCCL INFO Channel 03/04 :    0   7   6   5   4   1   2   3
f17n01:970278:970611 [2] NCCL INFO Trees [0] -1/-1/-1->0->3 [1] -1/-1/-1->0->3 [2] -1/-1/-1->0->3 [3] -1/-1/-1->0->3
f17n01:970278:970611 [2] NCCL INFO P2P Chunksize set to 131072
d17n07:1212413:1212777 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d11n16:1130271:1130621 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
f17n02:1076280:1076614 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
f17n02:1076280:1076614 [1] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/-1/-1->5->4 [3] 6/-1/-1->5->4
f17n02:1076280:1076614 [1] NCCL INFO P2P Chunksize set to 131072
f17n02:1076281:1076615 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
f17n02:1076281:1076615 [2] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5
f17n02:1076281:1076615 [2] NCCL INFO P2P Chunksize set to 131072
d11n16:1130268:1130618 [0] NCCL INFO Setting affinity for GPU 0 to 0f
f17n02:1076282:1076613 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
f17n02:1076282:1076613 [3] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] -1/-1/-1->7->6 [3] -1/-1/-1->7->6
f17n02:1076282:1076613 [3] NCCL INFO P2P Chunksize set to 131072
d11n16:1130270:1130619 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
f17n01:970278:970611 [2] NCCL INFO Channel 00/0 : 7[3] -> 0[2] [receive] via NET/IB/0
f17n01:970278:970611 [2] NCCL INFO Channel 02/0 : 7[3] -> 0[2] [receive] via NET/IB/0
f17n01:970278:970611 [2] NCCL INFO Channel 00/0 : 0[2] -> 1[3] via P2P/IPC
d11n16:1130269:1130620 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d14n09:567670:568035 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
f17n02:1076279:1076616 [0] NCCL INFO Setting affinity for GPU 0 to 0f
f17n02:1076279:1076616 [0] NCCL INFO Trees [0] 5/-1/-1->4->1 [1] 5/-1/-1->4->1 [2] 5/1/-1->4->-1 [3] 5/1/-1->4->-1
f17n02:1076279:1076616 [0] NCCL INFO P2P Chunksize set to 131072
f17n02:1076280:1076614 [1] NCCL INFO Channel 00/0 : 5[1] -> 6[2] via P2P/IPC
f17n01:970278:970611 [2] NCCL INFO Channel 02/0 : 0[2] -> 1[3] via P2P/IPC
f17n02:1076281:1076615 [2] NCCL INFO Channel 00/0 : 6[2] -> 7[3] via P2P/IPC
f17n02:1076282:1076613 [3] NCCL INFO Channel 00/0 : 7[3] -> 0[2] [send] via NET/IB/1
d09n08:1073956:1074293 [2] NCCL INFO Channel 00/04 :    0   1   2   3   4   5   6   7
d09n08:1073956:1074293 [2] NCCL INFO Channel 01/04 :    0   7   6   5   4   1   2   3
d09n08:1073956:1074293 [2] NCCL INFO Channel 02/04 :    0   1   2   3   4   5   6   7
d09n08:1073956:1074293 [2] NCCL INFO Channel 03/04 :    0   7   6   5   4   1   2   3
d09n08:1073956:1074293 [2] NCCL INFO Trees [0] -1/-1/-1->0->3 [1] -1/-1/-1->0->3 [2] -1/-1/-1->0->3 [3] -1/-1/-1->0->3
d09n08:1073956:1074293 [2] NCCL INFO P2P Chunksize set to 131072
d09n08:1073958:1074295 [4] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1
d09n08:1073958:1074295 [4] NCCL INFO P2P Chunksize set to 131072
d09n08:1073957:1074296 [3] NCCL INFO Trees [0] 2/4/-1->1->-1 [1] 2/4/-1->1->-1 [2] 2/-1/-1->1->4 [3] 2/-1/-1->1->4
d09n08:1073957:1074296 [3] NCCL INFO P2P Chunksize set to 131072
f16n16:1079914:1080254 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
f16n16:1079914:1080254 [2] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5
f16n16:1079914:1080254 [2] NCCL INFO P2P Chunksize set to 131072
d09n08:1073959:1074294 [5] NCCL INFO Trees [0] 0/-1/-1->3->2 [1] 0/-1/-1->3->2 [2] 0/-1/-1->3->2 [3] 0/-1/-1->3->2
d09n08:1073959:1074294 [5] NCCL INFO P2P Chunksize set to 131072
f16n16:1079915:1080253 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
f16n16:1079915:1080253 [3] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] -1/-1/-1->7->6 [3] -1/-1/-1->7->6
f16n16:1079915:1080253 [3] NCCL INFO P2P Chunksize set to 131072
f16n16:1079913:1080255 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
f16n16:1079913:1080255 [1] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/-1/-1->5->4 [3] 6/-1/-1->5->4
f16n16:1079913:1080255 [1] NCCL INFO P2P Chunksize set to 131072
d09n08:1073955:1074297 [1] NCCL INFO Using network IB
d09n08:1073955:1074297 [1] NCCL INFO comm 0x15b11a600 rank 7 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa299daa6e1c0b47e - Init START
d09n08:1073955:1074297 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
f16n16:1079912:1080256 [0] NCCL INFO Setting affinity for GPU 0 to 0f
f16n16:1079912:1080256 [0] NCCL INFO Trees [0] 5/-1/-1->4->1 [1] 5/-1/-1->4->1 [2] 5/1/-1->4->-1 [3] 5/1/-1->4->-1
f16n16:1079912:1080256 [0] NCCL INFO P2P Chunksize set to 131072
d09n07:1063020:1063430 [3] NCCL INFO Using network IB
d09n07:1063020:1063430 [3] NCCL INFO comm 0x11d84dd00 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa299daa6e1c0b47e - Init START
d09n08:1073954:1074298 [0] NCCL INFO Using network IB
d09n08:1073954:1074298 [0] NCCL INFO comm 0x14a84e440 rank 6 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa299daa6e1c0b47e - Init START
d09n08:1073954:1074298 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d17n07:1212413:1212777 [3] NCCL INFO Trees [0] 2/4/-1->1->-1 [1] 2/4/-1->1->-1 [2] 2/-1/-1->1->4 [3] 2/-1/-1->1->4
d17n07:1212413:1212777 [3] NCCL INFO P2P Chunksize set to 131072
d17n07:1212415:1212778 [5] NCCL INFO Trees [0] 0/-1/-1->3->2 [1] 0/-1/-1->3->2 [2] 0/-1/-1->3->2 [3] 0/-1/-1->3->2
d17n07:1212415:1212778 [5] NCCL INFO P2P Chunksize set to 131072
f17n02:1076280:1076614 [1] NCCL INFO Channel 02/0 : 5[1] -> 6[2] via P2P/IPC
d09n07:1063021:1063429 [4] NCCL INFO Using network IB
d09n07:1063021:1063429 [4] NCCL INFO comm 0x17910c140 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa299daa6e1c0b47e - Init START
f17n02:1076281:1076615 [2] NCCL INFO Channel 02/0 : 6[2] -> 7[3] via P2P/IPC
d09n07:1063019:1063433 [2] NCCL INFO Using network IB
d09n07:1063019:1063433 [2] NCCL INFO comm 0x1635ca9a0 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa299daa6e1c0b47e - Init START
d17n07:1212414:1212781 [4] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1
d17n07:1212414:1212781 [4] NCCL INFO P2P Chunksize set to 131072
d14n10:565684:566034 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d14n10:565684:566034 [3] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] -1/-1/-1->7->6 [3] -1/-1/-1->7->6
d14n10:565684:566034 [3] NCCL INFO P2P Chunksize set to 131072
f17n01:970279:970613 [3] NCCL INFO Channel 00/0 : 1[3] -> 2[4] via P2P/IPC
d14n09:567668:568032 [2] NCCL INFO Channel 00/04 :    0   1   2   3   4   5   6   7
d14n09:567668:568032 [2] NCCL INFO Channel 01/04 :    0   7   6   5   4   1   2   3
d14n09:567668:568032 [2] NCCL INFO Channel 02/04 :    0   1   2   3   4   5   6   7
d14n09:567668:568032 [2] NCCL INFO Channel 03/04 :    0   7   6   5   4   1   2   3
d14n09:567668:568032 [2] NCCL INFO Trees [0] -1/-1/-1->0->3 [1] -1/-1/-1->0->3 [2] -1/-1/-1->0->3 [3] -1/-1/-1->0->3
d14n09:567668:568032 [2] NCCL INFO P2P Chunksize set to 131072
d14n09:567668:568032 [2] NCCL INFO Channel 00/0 : 7[3] -> 0[2] [receive] via NET/IB/0
d14n09:567668:568032 [2] NCCL INFO Channel 02/0 : 7[3] -> 0[2] [receive] via NET/IB/0
d14n09:567668:568032 [2] NCCL INFO Channel 00/0 : 0[2] -> 1[3] via P2P/IPC
d17n07:1212412:1212776 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d17n07:1212412:1212776 [2] NCCL INFO Channel 00/04 :    0   1   2   3   4   5   6   7
d17n07:1212412:1212776 [2] NCCL INFO Channel 01/04 :    0   7   6   5   4   1   2   3
d17n07:1212412:1212776 [2] NCCL INFO Channel 02/04 :    0   1   2   3   4   5   6   7
d17n07:1212412:1212776 [2] NCCL INFO Channel 03/04 :    0   7   6   5   4   1   2   3
d17n07:1212412:1212776 [2] NCCL INFO Trees [0] -1/-1/-1->0->3 [1] -1/-1/-1->0->3 [2] -1/-1/-1->0->3 [3] -1/-1/-1->0->3
d17n07:1212412:1212776 [2] NCCL INFO P2P Chunksize set to 131072
d17n07:1212412:1212776 [2] NCCL INFO Channel 00/0 : 7[3] -> 0[2] [receive] via NET/IB/0
d17n07:1212412:1212776 [2] NCCL INFO Channel 02/0 : 7[3] -> 0[2] [receive] via NET/IB/0
d17n07:1212412:1212776 [2] NCCL INFO Channel 00/0 : 0[2] -> 1[3] via P2P/IPC
d14n10:565682:566032 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d14n10:565682:566032 [1] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/-1/-1->5->4 [3] 6/-1/-1->5->4
d14n10:565682:566032 [1] NCCL INFO P2P Chunksize set to 131072
d14n10:565683:566031 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d14n10:565683:566031 [2] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5
d14n10:565683:566031 [2] NCCL INFO P2P Chunksize set to 131072
d14n09:567671:568036 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d14n09:567671:568036 [5] NCCL INFO Trees [0] 0/-1/-1->3->2 [1] 0/-1/-1->3->2 [2] 0/-1/-1->3->2 [3] 0/-1/-1->3->2
d14n09:567671:568036 [5] NCCL INFO P2P Chunksize set to 131072
d14n09:567670:568035 [4] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1
d14n09:567670:568035 [4] NCCL INFO P2P Chunksize set to 131072
d11n16:1130271:1130621 [3] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] -1/-1/-1->7->6 [3] -1/-1/-1->7->6
d11n16:1130271:1130621 [3] NCCL INFO P2P Chunksize set to 131072
d14n09:567669:568037 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d14n09:567669:568037 [3] NCCL INFO Trees [0] 2/4/-1->1->-1 [1] 2/4/-1->1->-1 [2] 2/-1/-1->1->4 [3] 2/-1/-1->1->4
d14n09:567669:568037 [3] NCCL INFO P2P Chunksize set to 131072
d11n16:1130270:1130619 [2] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5
d11n16:1130270:1130619 [2] NCCL INFO P2P Chunksize set to 131072
d09n07:1063018:1063432 [1] NCCL INFO Using network IB
d09n07:1063018:1063432 [1] NCCL INFO comm 0x1253a5050 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa299daa6e1c0b47e - Init START
d11n16:1130269:1130620 [1] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/-1/-1->5->4 [3] 6/-1/-1->5->4
d11n16:1130269:1130620 [1] NCCL INFO P2P Chunksize set to 131072
d09n08:1073956:1074293 [2] NCCL INFO Channel 00/0 : 7[3] -> 0[2] [receive] via NET/IB/0
d09n08:1073956:1074293 [2] NCCL INFO Channel 02/0 : 7[3] -> 0[2] [receive] via NET/IB/0
d09n08:1073956:1074293 [2] NCCL INFO Channel 00/0 : 0[2] -> 1[3] via P2P/IPC
f17n02:1076282:1076613 [3] NCCL INFO Channel 02/0 : 7[3] -> 0[2] [send] via NET/IB/1
f17n02:1076282:1076613 [3] NCCL INFO Channel 01/0 : 0[2] -> 7[3] [receive] via NET/IB/3
f17n02:1076282:1076613 [3] NCCL INFO Channel 03/0 : 0[2] -> 7[3] [receive] via NET/IB/3
f17n02:1076282:1076613 [3] NCCL INFO Channel 01/0 : 7[3] -> 6[2] via P2P/IPC
d09n07:1063022:1063431 [5] NCCL INFO Using network IB
d09n07:1063022:1063431 [5] NCCL INFO comm 0x168d681c0 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa299daa6e1c0b47e - Init START
f17n01:970279:970613 [3] NCCL INFO Channel 01/0 : 1[3] -> 2[4] via P2P/IPC
f16n16:1079913:1080255 [1] NCCL INFO Channel 00/0 : 5[1] -> 6[2] via P2P/IPC
d17n07:1212412:1212776 [2] NCCL INFO Channel 02/0 : 0[2] -> 1[3] via P2P/IPC
f16n16:1079914:1080254 [2] NCCL INFO Channel 00/0 : 6[2] -> 7[3] via P2P/IPC
f17n02:1076282:1076613 [3] NCCL INFO Channel 03/0 : 7[3] -> 6[2] via P2P/IPC
d14n10:565682:566032 [1] NCCL INFO Channel 00/0 : 5[1] -> 6[2] via P2P/IPC
d14n09:567668:568032 [2] NCCL INFO Channel 02/0 : 0[2] -> 1[3] via P2P/IPC
f17n01:970279:970613 [3] NCCL INFO Channel 02/0 : 1[3] -> 2[4] via P2P/IPC
f17n01:970280:970614 [4] NCCL INFO Channel 00/0 : 2[4] -> 3[5] via P2P/IPC
d14n09:567669:568037 [3] NCCL INFO Channel 00/0 : 1[3] -> 2[4] via P2P/IPC
d09n08:1073956:1074293 [2] NCCL INFO Channel 02/0 : 0[2] -> 1[3] via P2P/IPC
f17n01:970279:970613 [3] NCCL INFO Channel 03/0 : 1[3] -> 2[4] via P2P/IPC
d17n07:1212413:1212777 [3] NCCL INFO Channel 00/0 : 1[3] -> 2[4] via P2P/IPC
f17n01:970280:970614 [4] NCCL INFO Channel 01/0 : 2[4] -> 3[5] via P2P/IPC
d09n08:1073957:1074296 [3] NCCL INFO Channel 00/0 : 1[3] -> 2[4] via P2P/IPC
f17n01:970280:970614 [4] NCCL INFO Channel 02/0 : 2[4] -> 3[5] via P2P/IPC
d14n10:565681:566033 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d14n10:565681:566033 [0] NCCL INFO Trees [0] 5/-1/-1->4->1 [1] 5/-1/-1->4->1 [2] 5/1/-1->4->-1 [3] 5/1/-1->4->-1
d14n10:565681:566033 [0] NCCL INFO P2P Chunksize set to 131072
d14n09:567669:568037 [3] NCCL INFO Channel 01/0 : 1[3] -> 2[4] via P2P/IPC
f16n16:1079913:1080255 [1] NCCL INFO Channel 02/0 : 5[1] -> 6[2] via P2P/IPC
f17n02:1076281:1076615 [2] NCCL INFO Channel 01/0 : 6[2] -> 5[1] via P2P/IPC
d17n07:1212413:1212777 [3] NCCL INFO Channel 01/0 : 1[3] -> 2[4] via P2P/IPC
d09n08:1073957:1074296 [3] NCCL INFO Channel 01/0 : 1[3] -> 2[4] via P2P/IPC
f16n16:1079914:1080254 [2] NCCL INFO Channel 02/0 : 6[2] -> 7[3] via P2P/IPC
f17n01:970280:970614 [4] NCCL INFO Channel 03/0 : 2[4] -> 3[5] via P2P/IPC
d14n10:565683:566031 [2] NCCL INFO Channel 00/0 : 6[2] -> 7[3] via P2P/IPC
d11n16:1130270:1130619 [2] NCCL INFO Channel 00/0 : 6[2] -> 7[3] via P2P/IPC
d11n16:1130269:1130620 [1] NCCL INFO Channel 00/0 : 5[1] -> 6[2] via P2P/IPC
f17n02:1076281:1076615 [2] NCCL INFO Channel 03/0 : 6[2] -> 5[1] via P2P/IPC
d14n10:565682:566032 [1] NCCL INFO Channel 02/0 : 5[1] -> 6[2] via P2P/IPC
d14n10:565683:566031 [2] NCCL INFO Channel 02/0 : 6[2] -> 7[3] via P2P/IPC
d11n16:1130270:1130619 [2] NCCL INFO Channel 02/0 : 6[2] -> 7[3] via P2P/IPC
d11n16:1130269:1130620 [1] NCCL INFO Channel 02/0 : 5[1] -> 6[2] via P2P/IPC
f16n16:1079915:1080253 [3] NCCL INFO Channel 00/0 : 7[3] -> 0[2] [send] via NET/IB/1
f16n16:1079915:1080253 [3] NCCL INFO Channel 02/0 : 7[3] -> 0[2] [send] via NET/IB/1
f16n16:1079915:1080253 [3] NCCL INFO Channel 01/0 : 0[2] -> 7[3] [receive] via NET/IB/3
f16n16:1079915:1080253 [3] NCCL INFO Channel 03/0 : 0[2] -> 7[3] [receive] via NET/IB/3
f16n16:1079915:1080253 [3] NCCL INFO Channel 01/0 : 7[3] -> 6[2] via P2P/IPC
d14n10:565684:566034 [3] NCCL INFO Channel 00/0 : 7[3] -> 0[2] [send] via NET/IB/1
d14n10:565684:566034 [3] NCCL INFO Channel 02/0 : 7[3] -> 0[2] [send] via NET/IB/1
d14n10:565684:566034 [3] NCCL INFO Channel 01/0 : 0[2] -> 7[3] [receive] via NET/IB/3
d14n10:565684:566034 [3] NCCL INFO Channel 03/0 : 0[2] -> 7[3] [receive] via NET/IB/3
d14n10:565684:566034 [3] NCCL INFO Channel 01/0 : 7[3] -> 6[2] via P2P/IPC
f16n16:1079915:1080253 [3] NCCL INFO Channel 03/0 : 7[3] -> 6[2] via P2P/IPC
d11n16:1130271:1130621 [3] NCCL INFO Channel 00/0 : 7[3] -> 0[2] [send] via NET/IB/1
d11n16:1130271:1130621 [3] NCCL INFO Channel 02/0 : 7[3] -> 0[2] [send] via NET/IB/1
d11n16:1130271:1130621 [3] NCCL INFO Channel 01/0 : 0[2] -> 7[3] [receive] via NET/IB/3
d11n16:1130271:1130621 [3] NCCL INFO Channel 03/0 : 0[2] -> 7[3] [receive] via NET/IB/3
d11n16:1130271:1130621 [3] NCCL INFO Channel 01/0 : 7[3] -> 6[2] via P2P/IPC
d14n10:565684:566034 [3] NCCL INFO Channel 03/0 : 7[3] -> 6[2] via P2P/IPC
f16n16:1079914:1080254 [2] NCCL INFO Channel 01/0 : 6[2] -> 5[1] via P2P/IPC
d17n07:1212413:1212777 [3] NCCL INFO Channel 02/0 : 1[3] -> 2[4] via P2P/IPC
d14n10:565683:566031 [2] NCCL INFO Channel 01/0 : 6[2] -> 5[1] via P2P/IPC
d17n07:1212414:1212781 [4] NCCL INFO Channel 00/0 : 2[4] -> 3[5] via P2P/IPC
d14n09:567669:568037 [3] NCCL INFO Channel 02/0 : 1[3] -> 2[4] via P2P/IPC
d09n08:1073957:1074296 [3] NCCL INFO Channel 02/0 : 1[3] -> 2[4] via P2P/IPC
d14n09:567670:568035 [4] NCCL INFO Channel 00/0 : 2[4] -> 3[5] via P2P/IPC
d09n08:1073958:1074295 [4] NCCL INFO Channel 00/0 : 2[4] -> 3[5] via P2P/IPC
d17n07:1212413:1212777 [3] NCCL INFO Channel 03/0 : 1[3] -> 2[4] via P2P/IPC
d17n07:1212414:1212781 [4] NCCL INFO Channel 01/0 : 2[4] -> 3[5] via P2P/IPC
d14n09:567669:568037 [3] NCCL INFO Channel 03/0 : 1[3] -> 2[4] via P2P/IPC
f16n16:1079914:1080254 [2] NCCL INFO Channel 03/0 : 6[2] -> 5[1] via P2P/IPC
d14n09:567670:568035 [4] NCCL INFO Channel 01/0 : 2[4] -> 3[5] via P2P/IPC
d14n10:565683:566031 [2] NCCL INFO Channel 03/0 : 6[2] -> 5[1] via P2P/IPC
d09n08:1073957:1074296 [3] NCCL INFO Channel 03/0 : 1[3] -> 2[4] via P2P/IPC
d11n16:1130271:1130621 [3] NCCL INFO Channel 03/0 : 7[3] -> 6[2] via P2P/IPC
d09n08:1073958:1074295 [4] NCCL INFO Channel 01/0 : 2[4] -> 3[5] via P2P/IPC
d11n16:1130270:1130619 [2] NCCL INFO Channel 01/0 : 6[2] -> 5[1] via P2P/IPC
d17n07:1212414:1212781 [4] NCCL INFO Channel 02/0 : 2[4] -> 3[5] via P2P/IPC
d11n16:1130270:1130619 [2] NCCL INFO Channel 03/0 : 6[2] -> 5[1] via P2P/IPC
d14n09:567670:568035 [4] NCCL INFO Channel 02/0 : 2[4] -> 3[5] via P2P/IPC
d09n08:1073958:1074295 [4] NCCL INFO Channel 02/0 : 2[4] -> 3[5] via P2P/IPC
d17n07:1212414:1212781 [4] NCCL INFO Channel 03/0 : 2[4] -> 3[5] via P2P/IPC
d14n09:567670:568035 [4] NCCL INFO Channel 03/0 : 2[4] -> 3[5] via P2P/IPC
d09n08:1073958:1074295 [4] NCCL INFO Channel 03/0 : 2[4] -> 3[5] via P2P/IPC
d09n07:1063016:1063428 [0] NCCL INFO Using network IB
d09n07:1063016:1063428 [0] NCCL INFO comm 0x13e5515c0 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa299daa6e1c0b47e - Init START
f17n01:970280:970614 [4] NCCL INFO Connected all rings
f17n01:970280:970614 [4] NCCL INFO Channel 00/0 : 2[4] -> 1[3] via P2P/IPC
d17n07:1212414:1212781 [4] NCCL INFO Connected all rings
d14n09:567670:568035 [4] NCCL INFO Connected all rings
f17n01:970280:970614 [4] NCCL INFO Channel 01/0 : 2[4] -> 1[3] via P2P/IPC
d09n08:1073958:1074295 [4] NCCL INFO Connected all rings
f17n01:970280:970614 [4] NCCL INFO Channel 02/0 : 2[4] -> 1[3] via P2P/IPC
f17n01:970280:970614 [4] NCCL INFO Channel 03/0 : 2[4] -> 1[3] via P2P/IPC
d17n07:1212414:1212781 [4] NCCL INFO Channel 00/0 : 2[4] -> 1[3] via P2P/IPC
d14n09:567670:568035 [4] NCCL INFO Channel 00/0 : 2[4] -> 1[3] via P2P/IPC
d17n07:1212414:1212781 [4] NCCL INFO Channel 01/0 : 2[4] -> 1[3] via P2P/IPC
d09n08:1073958:1074295 [4] NCCL INFO Channel 00/0 : 2[4] -> 1[3] via P2P/IPC
d14n09:567670:568035 [4] NCCL INFO Channel 01/0 : 2[4] -> 1[3] via P2P/IPC
d17n07:1212414:1212781 [4] NCCL INFO Channel 02/0 : 2[4] -> 1[3] via P2P/IPC
d09n08:1073958:1074295 [4] NCCL INFO Channel 01/0 : 2[4] -> 1[3] via P2P/IPC
d14n09:567670:568035 [4] NCCL INFO Channel 02/0 : 2[4] -> 1[3] via P2P/IPC
d17n07:1212414:1212781 [4] NCCL INFO Channel 03/0 : 2[4] -> 1[3] via P2P/IPC
d09n08:1073958:1074295 [4] NCCL INFO Channel 02/0 : 2[4] -> 1[3] via P2P/IPC
d14n09:567670:568035 [4] NCCL INFO Channel 03/0 : 2[4] -> 1[3] via P2P/IPC
d09n08:1073958:1074295 [4] NCCL INFO Channel 03/0 : 2[4] -> 1[3] via P2P/IPC
f17n02:1076279:1076616 [0] NCCL INFO Channel 00/0 : 3[5] -> 4[0] [receive] via NET/IB/0
f17n02:1076279:1076616 [0] NCCL INFO Channel 02/0 : 3[5] -> 4[0] [receive] via NET/IB/0
f17n02:1076279:1076616 [0] NCCL INFO Channel 00/0 : 4[0] -> 5[1] via P2P/IPC
f17n02:1076279:1076616 [0] NCCL INFO Channel 02/0 : 4[0] -> 5[1] via P2P/IPC
f17n01:970281:970612 [5] NCCL INFO Channel 00/0 : 3[5] -> 4[0] [send] via NET/IB/1
f17n01:970281:970612 [5] NCCL INFO Channel 02/0 : 3[5] -> 4[0] [send] via NET/IB/1
f17n01:970281:970612 [5] NCCL INFO Channel 01/0 : 3[5] -> 0[2] via P2P/IPC
f17n01:970279:970613 [3] NCCL INFO Channel 01/0 : 4[0] -> 1[3] [receive] via NET/IB/3
f17n01:970279:970613 [3] NCCL INFO Channel 03/0 : 4[0] -> 1[3] [receive] via NET/IB/3
f17n02:1076279:1076616 [0] NCCL INFO Channel 01/0 : 4[0] -> 1[3] [send] via NET/IB/2
f17n02:1076279:1076616 [0] NCCL INFO Channel 03/0 : 4[0] -> 1[3] [send] via NET/IB/2
f17n01:970281:970612 [5] NCCL INFO Channel 03/0 : 3[5] -> 0[2] via P2P/IPC
f17n02:1076280:1076614 [1] NCCL INFO Channel 01/0 : 5[1] -> 4[0] via P2P/IPC
f17n02:1076280:1076614 [1] NCCL INFO Channel 03/0 : 5[1] -> 4[0] via P2P/IPC
f17n01:970278:970611 [2] NCCL INFO Channel 01/0 : 0[2] -> 7[3] [send] via NET/IB/2
f17n01:970278:970611 [2] NCCL INFO Channel 03/0 : 0[2] -> 7[3] [send] via NET/IB/2
f17n01:970281:970612 [5] NCCL INFO Connected all rings
f17n02:1076280:1076614 [1] NCCL INFO Connected all rings
f17n02:1076281:1076615 [2] NCCL INFO Connected all rings
d14n10:565681:566033 [0] NCCL INFO Channel 00/0 : 3[5] -> 4[0] [receive] via NET/IB/0
d14n10:565681:566033 [0] NCCL INFO Channel 02/0 : 3[5] -> 4[0] [receive] via NET/IB/0
d14n10:565681:566033 [0] NCCL INFO Channel 00/0 : 4[0] -> 5[1] via P2P/IPC
f17n02:1076280:1076614 [1] NCCL INFO Channel 01/0 : 5[1] -> 6[2] via P2P/IPC
d14n10:565681:566033 [0] NCCL INFO Channel 02/0 : 4[0] -> 5[1] via P2P/IPC
f17n02:1076280:1076614 [1] NCCL INFO Channel 03/0 : 5[1] -> 6[2] via P2P/IPC
f17n02:1076281:1076615 [2] NCCL INFO Channel 01/0 : 6[2] -> 7[3] via P2P/IPC
d14n09:567671:568036 [5] NCCL INFO Channel 00/0 : 3[5] -> 4[0] [send] via NET/IB/1
d14n09:567671:568036 [5] NCCL INFO Channel 02/0 : 3[5] -> 4[0] [send] via NET/IB/1
d14n09:567671:568036 [5] NCCL INFO Channel 01/0 : 3[5] -> 0[2] via P2P/IPC
f17n02:1076281:1076615 [2] NCCL INFO Channel 03/0 : 6[2] -> 7[3] via P2P/IPC
d14n09:567669:568037 [3] NCCL INFO Channel 01/0 : 4[0] -> 1[3] [receive] via NET/IB/3
d14n09:567669:568037 [3] NCCL INFO Channel 03/0 : 4[0] -> 1[3] [receive] via NET/IB/3
d14n10:565681:566033 [0] NCCL INFO Channel 01/0 : 4[0] -> 1[3] [send] via NET/IB/2
d14n10:565681:566033 [0] NCCL INFO Channel 03/0 : 4[0] -> 1[3] [send] via NET/IB/2
d14n09:567671:568036 [5] NCCL INFO Channel 03/0 : 3[5] -> 0[2] via P2P/IPC
d14n10:565682:566032 [1] NCCL INFO Channel 01/0 : 5[1] -> 4[0] via P2P/IPC
d14n10:565682:566032 [1] NCCL INFO Channel 03/0 : 5[1] -> 4[0] via P2P/IPC
d14n09:567668:568032 [2] NCCL INFO Channel 01/0 : 0[2] -> 7[3] [send] via NET/IB/2
d14n09:567668:568032 [2] NCCL INFO Channel 03/0 : 0[2] -> 7[3] [send] via NET/IB/2
f17n02:1076279:1076616 [0] NCCL INFO Connected all rings
f17n02:1076279:1076616 [0] NCCL INFO Channel 01/0 : 4[0] -> 5[1] via P2P/IPC
f17n02:1076279:1076616 [0] NCCL INFO Channel 03/0 : 4[0] -> 5[1] via P2P/IPC
d11n16:1130268:1130618 [0] NCCL INFO Trees [0] 5/-1/-1->4->1 [1] 5/-1/-1->4->1 [2] 5/1/-1->4->-1 [3] 5/1/-1->4->-1
d11n16:1130268:1130618 [0] NCCL INFO P2P Chunksize set to 131072
d11n16:1130268:1130618 [0] NCCL INFO Channel 00/0 : 3[5] -> 4[0] [receive] via NET/IB/0
d11n16:1130268:1130618 [0] NCCL INFO Channel 02/0 : 3[5] -> 4[0] [receive] via NET/IB/0
d11n16:1130268:1130618 [0] NCCL INFO Channel 00/0 : 4[0] -> 5[1] via P2P/IPC
f17n02:1076279:1076616 [0] NCCL INFO Channel 00/0 : 1[3] -> 4[0] [receive] via NET/IB/0
f17n02:1076279:1076616 [0] NCCL INFO Channel 01/0 : 1[3] -> 4[0] [receive] via NET/IB/3
f17n02:1076279:1076616 [0] NCCL INFO Channel 02/0 : 1[3] -> 4[0] [receive] via NET/IB/0
f17n02:1076279:1076616 [0] NCCL INFO Channel 03/0 : 1[3] -> 4[0] [receive] via NET/IB/3
f17n02:1076279:1076616 [0] NCCL INFO Channel 00/0 : 4[0] -> 1[3] [send] via NET/IB/0
f17n02:1076279:1076616 [0] NCCL INFO Channel 02/0 : 4[0] -> 1[3] [send] via NET/IB/0
f17n01:970279:970613 [3] NCCL INFO Connected all rings
f17n01:970279:970613 [3] NCCL INFO Channel 00/0 : 1[3] -> 4[0] [send] via NET/IB/3
f17n01:970279:970613 [3] NCCL INFO Channel 01/0 : 1[3] -> 4[0] [send] via NET/IB/0
f17n01:970279:970613 [3] NCCL INFO Channel 02/0 : 1[3] -> 4[0] [send] via NET/IB/3
f17n01:970279:970613 [3] NCCL INFO Channel 03/0 : 1[3] -> 4[0] [send] via NET/IB/0
f17n01:970279:970613 [3] NCCL INFO Channel 00/0 : 4[0] -> 1[3] [receive] via NET/IB/3
f17n01:970279:970613 [3] NCCL INFO Channel 02/0 : 4[0] -> 1[3] [receive] via NET/IB/3
f17n02:1076280:1076614 [1] NCCL INFO Channel 00/0 : 5[1] -> 4[0] via P2P/IPC
d11n16:1130268:1130618 [0] NCCL INFO Channel 02/0 : 4[0] -> 5[1] via P2P/IPC
f17n02:1076280:1076614 [1] NCCL INFO Channel 02/0 : 5[1] -> 4[0] via P2P/IPC
d09n08:1073959:1074294 [5] NCCL INFO Channel 00/0 : 3[5] -> 4[0] [send] via NET/IB/1
d09n08:1073959:1074294 [5] NCCL INFO Channel 02/0 : 3[5] -> 4[0] [send] via NET/IB/1
d09n08:1073959:1074294 [5] NCCL INFO Channel 01/0 : 3[5] -> 0[2] via P2P/IPC
d11n16:1130268:1130618 [0] NCCL INFO Channel 01/0 : 4[0] -> 1[3] [send] via NET/IB/2
d11n16:1130268:1130618 [0] NCCL INFO Channel 03/0 : 4[0] -> 1[3] [send] via NET/IB/2
d09n08:1073959:1074294 [5] NCCL INFO Channel 03/0 : 3[5] -> 0[2] via P2P/IPC
d14n09:567671:568036 [5] NCCL INFO Connected all rings
d09n08:1073957:1074296 [3] NCCL INFO Channel 01/0 : 4[0] -> 1[3] [receive] via NET/IB/3
d09n08:1073957:1074296 [3] NCCL INFO Channel 03/0 : 4[0] -> 1[3] [receive] via NET/IB/3
d17n07:1212415:1212778 [5] NCCL INFO Channel 00/0 : 3[5] -> 4[0] [send] via NET/IB/1
d17n07:1212415:1212778 [5] NCCL INFO Channel 02/0 : 3[5] -> 4[0] [send] via NET/IB/1
d11n16:1130269:1130620 [1] NCCL INFO Channel 01/0 : 5[1] -> 4[0] via P2P/IPC
d17n07:1212413:1212777 [3] NCCL INFO Channel 01/0 : 4[0] -> 1[3] [receive] via NET/IB/3
d17n07:1212413:1212777 [3] NCCL INFO Channel 03/0 : 4[0] -> 1[3] [receive] via NET/IB/3
f16n18:1091868:1092225 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
f16n18:1091867:1092224 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d14n10:565683:566031 [2] NCCL INFO Connected all rings
f16n18:1091866:1092223 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d11n16:1130269:1130620 [1] NCCL INFO Channel 03/0 : 5[1] -> 4[0] via P2P/IPC
f16n17:1090961:1091306 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d09n08:1073956:1074293 [2] NCCL INFO Channel 01/0 : 0[2] -> 7[3] [send] via NET/IB/2
d09n08:1073956:1074293 [2] NCCL INFO Channel 03/0 : 0[2] -> 7[3] [send] via NET/IB/2
f16n18:1091869:1092226 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
f16n17:1090960:1091307 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
f16n17:1090963:1091311 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
f16n18:1091871:1092227 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
f16n17:1090964:1091309 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
f18n05:1008219:1008555 [0] NCCL INFO Setting affinity for GPU 0 to 0f
f16n18:1091870:1092228 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
f16n17:1090959:1091308 [0] NCCL INFO Setting affinity for GPU 0 to 0f
f18n05:1008221:1008554 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d14n10:565682:566032 [1] NCCL INFO Connected all rings
f16n17:1090962:1091310 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
f18n05:1008220:1008558 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
f18n05:1008222:1008559 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d14n10:565683:566031 [2] NCCL INFO Channel 01/0 : 6[2] -> 7[3] via P2P/IPC
f18n05:1008223:1008556 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d11n17:1142856:1143189 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d11n17:1142858:1143191 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d11n17:1142859:1143192 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d11n17:1142855:1143188 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d11n17:1142857:1143193 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d14n10:565682:566032 [1] NCCL INFO Channel 01/0 : 5[1] -> 6[2] via P2P/IPC
d11n17:1142854:1143190 [0] NCCL INFO Setting affinity for GPU 0 to 0f
f16n16:1079912:1080256 [0] NCCL INFO Channel 00/0 : 3[5] -> 4[0] [receive] via NET/IB/0
f16n16:1079912:1080256 [0] NCCL INFO Channel 02/0 : 3[5] -> 4[0] [receive] via NET/IB/0
f16n16:1079912:1080256 [0] NCCL INFO Channel 00/0 : 4[0] -> 5[1] via P2P/IPC
d14n10:565683:566031 [2] NCCL INFO Channel 03/0 : 6[2] -> 7[3] via P2P/IPC
d14n10:565682:566032 [1] NCCL INFO Channel 03/0 : 5[1] -> 6[2] via P2P/IPC
f16n16:1079912:1080256 [0] NCCL INFO Channel 02/0 : 4[0] -> 5[1] via P2P/IPC
d17n07:1212415:1212778 [5] NCCL INFO Channel 01/0 : 3[5] -> 0[2] via P2P/IPC
f16n16:1079912:1080256 [0] NCCL INFO Channel 01/0 : 4[0] -> 1[3] [send] via NET/IB/2
f16n16:1079912:1080256 [0] NCCL INFO Channel 03/0 : 4[0] -> 1[3] [send] via NET/IB/2
d14n08:1173247:1173602 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d14n08:1173248:1173607 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d14n11:1169358:1169710 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d14n08:1173251:1173605 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d17n07:1212415:1212778 [5] NCCL INFO Channel 03/0 : 3[5] -> 0[2] via P2P/IPC
d14n11:1169357:1169715 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d14n08:1173252:1173603 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d14n11:1169356:1169711 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d14n08:1173249:1173604 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d14n08:1173250:1173606 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
f16n16:1079913:1080255 [1] NCCL INFO Channel 01/0 : 5[1] -> 4[0] via P2P/IPC
d14n11:1169360:1169712 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d14n11:1169359:1169714 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d17n06:1216532:1216898 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d14n11:1169361:1169713 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
f18n05:1008224:1008557 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d17n06:1216530:1216897 [0] NCCL INFO Setting affinity for GPU 0 to 0f
f16n16:1079913:1080255 [1] NCCL INFO Channel 03/0 : 5[1] -> 4[0] via P2P/IPC
d17n06:1216531:1216902 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d17n06:1216534:1216900 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d17n06:1216535:1216899 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d17n07:1212412:1212776 [2] NCCL INFO Channel 01/0 : 0[2] -> 7[3] [send] via NET/IB/2
d17n07:1212412:1212776 [2] NCCL INFO Channel 03/0 : 0[2] -> 7[3] [send] via NET/IB/2
d17n06:1216533:1216901 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d09n08:1073959:1074294 [5] NCCL INFO Connected all rings
d11n16:1130270:1130619 [2] NCCL INFO Connected all rings
d11n16:1130269:1130620 [1] NCCL INFO Connected all rings
d11n16:1130270:1130619 [2] NCCL INFO Channel 01/0 : 6[2] -> 7[3] via P2P/IPC
d11n16:1130269:1130620 [1] NCCL INFO Channel 01/0 : 5[1] -> 6[2] via P2P/IPC
d11n16:1130270:1130619 [2] NCCL INFO Channel 03/0 : 6[2] -> 7[3] via P2P/IPC
d11n16:1130269:1130620 [1] NCCL INFO Channel 03/0 : 5[1] -> 6[2] via P2P/IPC
d17n07:1212415:1212778 [5] NCCL INFO Connected all rings
f16n16:1079913:1080255 [1] NCCL INFO Connected all rings
f16n16:1079914:1080254 [2] NCCL INFO Connected all rings
d11n16:1130268:1130618 [0] NCCL INFO Connected all rings
d11n16:1130268:1130618 [0] NCCL INFO Channel 01/0 : 4[0] -> 5[1] via P2P/IPC
d11n16:1130268:1130618 [0] NCCL INFO Channel 03/0 : 4[0] -> 5[1] via P2P/IPC
f16n16:1079913:1080255 [1] NCCL INFO Channel 01/0 : 5[1] -> 6[2] via P2P/IPC
f16n16:1079914:1080254 [2] NCCL INFO Channel 01/0 : 6[2] -> 7[3] via P2P/IPC
f16n16:1079913:1080255 [1] NCCL INFO Channel 03/0 : 5[1] -> 6[2] via P2P/IPC
f16n16:1079914:1080254 [2] NCCL INFO Channel 03/0 : 6[2] -> 7[3] via P2P/IPC
d09n08:1073957:1074296 [3] NCCL INFO Connected all rings
d09n08:1073957:1074296 [3] NCCL INFO Channel 00/0 : 1[3] -> 4[0] [send] via NET/IB/3
d09n08:1073957:1074296 [3] NCCL INFO Channel 01/0 : 1[3] -> 4[0] [send] via NET/IB/0
d09n08:1073957:1074296 [3] NCCL INFO Channel 02/0 : 1[3] -> 4[0] [send] via NET/IB/3
d09n08:1073957:1074296 [3] NCCL INFO Channel 03/0 : 1[3] -> 4[0] [send] via NET/IB/0
d09n08:1073957:1074296 [3] NCCL INFO Channel 00/0 : 4[0] -> 1[3] [receive] via NET/IB/3
d09n08:1073957:1074296 [3] NCCL INFO Channel 02/0 : 4[0] -> 1[3] [receive] via NET/IB/3
d11n16:1130268:1130618 [0] NCCL INFO Channel 00/0 : 1[3] -> 4[0] [receive] via NET/IB/0
d11n16:1130268:1130618 [0] NCCL INFO Channel 01/0 : 1[3] -> 4[0] [receive] via NET/IB/3
d11n16:1130268:1130618 [0] NCCL INFO Channel 02/0 : 1[3] -> 4[0] [receive] via NET/IB/0
d11n16:1130268:1130618 [0] NCCL INFO Channel 03/0 : 1[3] -> 4[0] [receive] via NET/IB/3
d11n16:1130268:1130618 [0] NCCL INFO Channel 00/0 : 4[0] -> 1[3] [send] via NET/IB/0
d11n16:1130268:1130618 [0] NCCL INFO Channel 02/0 : 4[0] -> 1[3] [send] via NET/IB/0
d11n16:1130269:1130620 [1] NCCL INFO Channel 00/0 : 5[1] -> 4[0] via P2P/IPC
d11n16:1130269:1130620 [1] NCCL INFO Channel 02/0 : 5[1] -> 4[0] via P2P/IPC
f17n01:970278:970611 [2] NCCL INFO Connected all rings
f17n01:970278:970611 [2] NCCL INFO Channel 00/0 : 0[2] -> 3[5] via P2P/IPC
f17n01:970278:970611 [2] NCCL INFO Channel 01/0 : 0[2] -> 3[5] via P2P/IPC
f17n01:970278:970611 [2] NCCL INFO Channel 02/0 : 0[2] -> 3[5] via P2P/IPC
f17n01:970278:970611 [2] NCCL INFO Channel 03/0 : 0[2] -> 3[5] via P2P/IPC
f17n02:1076282:1076613 [3] NCCL INFO Connected all rings
f17n01:970281:970612 [5] NCCL INFO Channel 00/0 : 3[5] -> 0[2] via P2P/IPC
f17n02:1076282:1076613 [3] NCCL INFO Channel 00/0 : 7[3] -> 6[2] via P2P/IPC
f17n01:970281:970612 [5] NCCL INFO Channel 02/0 : 3[5] -> 0[2] via P2P/IPC
f17n02:1076282:1076613 [3] NCCL INFO Channel 02/0 : 7[3] -> 6[2] via P2P/IPC
f17n02:1076281:1076615 [2] NCCL INFO Channel 00/0 : 6[2] -> 5[1] via P2P/IPC
f17n01:970281:970612 [5] NCCL INFO Channel 00/0 : 3[5] -> 2[4] via P2P/IPC
f17n02:1076281:1076615 [2] NCCL INFO Channel 02/0 : 6[2] -> 5[1] via P2P/IPC
f17n01:970281:970612 [5] NCCL INFO Channel 01/0 : 3[5] -> 2[4] via P2P/IPC
f17n01:970281:970612 [5] NCCL INFO Channel 02/0 : 3[5] -> 2[4] via P2P/IPC
f17n01:970281:970612 [5] NCCL INFO Channel 03/0 : 3[5] -> 2[4] via P2P/IPC
f17n01:970278:970611 [2] NCCL INFO Connected all trees
f17n01:970278:970611 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f17n01:970278:970611 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f17n02:1076282:1076613 [3] NCCL INFO Connected all trees
f17n02:1076282:1076613 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f17n02:1076282:1076613 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f16n16:1079917:1080257 [5] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
f16n16:1079917:1080257 [5] NCCL INFO P2P Chunksize set to 131072
f17n01:970280:970614 [4] NCCL INFO Connected all trees
f17n01:970280:970614 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f17n01:970280:970614 [4] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n10:565681:566033 [0] NCCL INFO Connected all rings
d14n10:565681:566033 [0] NCCL INFO Channel 01/0 : 4[0] -> 5[1] via P2P/IPC
f17n02:1076280:1076614 [1] NCCL INFO Connected all trees
f17n02:1076280:1076614 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f17n02:1076280:1076614 [1] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f16n17:1090964:1091309 [5] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
f16n17:1090964:1091309 [5] NCCL INFO P2P Chunksize set to 131072
f17n02:1076281:1076615 [2] NCCL INFO Connected all trees
f17n02:1076281:1076615 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f17n02:1076281:1076615 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f16n17:1090962:1091310 [3] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4
f16n17:1090962:1091310 [3] NCCL INFO P2P Chunksize set to 131072
f16n17:1090963:1091311 [4] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5
f16n17:1090963:1091311 [4] NCCL INFO P2P Chunksize set to 131072
d14n10:565681:566033 [0] NCCL INFO Channel 03/0 : 4[0] -> 5[1] via P2P/IPC
f17n01:970281:970612 [5] NCCL INFO Connected all trees
f17n01:970281:970612 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f17n01:970281:970612 [5] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f16n17:1090960:1091307 [1] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2
f16n17:1090960:1091307 [1] NCCL INFO P2P Chunksize set to 131072
d14n09:567667:568033 [1] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
d14n09:567667:568033 [1] NCCL INFO P2P Chunksize set to 131072
f16n17:1090961:1091306 [2] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3
f16n17:1090961:1091306 [2] NCCL INFO P2P Chunksize set to 131072
f17n01:970277:970616 [1] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
f17n01:970277:970616 [1] NCCL INFO P2P Chunksize set to 131072
f17n02:1076284:1076617 [5] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
f17n02:1076284:1076617 [5] NCCL INFO P2P Chunksize set to 131072
d17n07:1212411:1212779 [1] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
d17n07:1212411:1212779 [1] NCCL INFO P2P Chunksize set to 131072
d14n08:1173251:1173605 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3
d14n08:1173251:1173605 [4] NCCL INFO P2P Chunksize set to 131072
d14n08:1173252:1173603 [5] NCCL INFO Trees [0] -1/-1/-1->5->4 [1] -1/-1/-1->5->4
d14n08:1173252:1173603 [5] NCCL INFO P2P Chunksize set to 131072
d11n16:1130273:1130617 [5] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
d11n16:1130273:1130617 [5] NCCL INFO P2P Chunksize set to 131072
d14n08:1173250:1173606 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2
d14n08:1173250:1173606 [3] NCCL INFO P2P Chunksize set to 131072
d14n08:1173249:1173604 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
d14n08:1173249:1173604 [2] NCCL INFO P2P Chunksize set to 131072
d14n08:1173248:1173607 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
d14n08:1173248:1173607 [1] NCCL INFO P2P Chunksize set to 131072
f16n18:1091870:1092228 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3
f16n18:1091870:1092228 [4] NCCL INFO P2P Chunksize set to 131072
f16n18:1091869:1092226 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2
f16n18:1091869:1092226 [3] NCCL INFO P2P Chunksize set to 131072
d17n06:1216535:1216899 [5] NCCL INFO Trees [0] -1/-1/-1->5->4 [1] -1/-1/-1->5->4
d17n06:1216535:1216899 [5] NCCL INFO P2P Chunksize set to 131072
f16n18:1091871:1092227 [5] NCCL INFO Trees [0] -1/-1/-1->5->4 [1] -1/-1/-1->5->4
f16n18:1091871:1092227 [5] NCCL INFO P2P Chunksize set to 131072
d14n09:567669:568037 [3] NCCL INFO Connected all rings
d14n09:567669:568037 [3] NCCL INFO Channel 00/0 : 1[3] -> 4[0] [send] via NET/IB/3
d14n09:567669:568037 [3] NCCL INFO Channel 01/0 : 1[3] -> 4[0] [send] via NET/IB/0
d14n09:567669:568037 [3] NCCL INFO Channel 02/0 : 1[3] -> 4[0] [send] via NET/IB/3
d14n09:567669:568037 [3] NCCL INFO Channel 03/0 : 1[3] -> 4[0] [send] via NET/IB/0
d14n09:567669:568037 [3] NCCL INFO Channel 00/0 : 4[0] -> 1[3] [receive] via NET/IB/3
d14n09:567669:568037 [3] NCCL INFO Channel 02/0 : 4[0] -> 1[3] [receive] via NET/IB/3
d17n06:1216533:1216901 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2
d17n06:1216533:1216901 [3] NCCL INFO P2P Chunksize set to 131072
f16n18:1091868:1092225 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
f16n18:1091868:1092225 [2] NCCL INFO P2P Chunksize set to 131072
f16n18:1091867:1092224 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
f16n18:1091867:1092224 [1] NCCL INFO P2P Chunksize set to 131072
d14n11:1169359:1169714 [3] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4
d14n11:1169359:1169714 [3] NCCL INFO P2P Chunksize set to 131072
d14n09:567668:568032 [2] NCCL INFO Connected all rings
d14n09:567668:568032 [2] NCCL INFO Channel 00/0 : 0[2] -> 3[5] via P2P/IPC
f17n02:1076283:1076612 [4] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7
f17n02:1076283:1076612 [4] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7
f17n02:1076283:1076612 [4] NCCL INFO Trees [0] 1/2/-1->0->-1 [1] 1/-1/-1->0->2
f17n02:1076283:1076612 [4] NCCL INFO P2P Chunksize set to 131072
f17n02:1076283:1076612 [4] NCCL INFO Channel 00/0 : 7[5] -> 0[4] [receive] via NET/IB/1
f17n02:1076283:1076612 [4] NCCL INFO Channel 01/0 : 7[5] -> 0[4] [receive] via NET/IB/1
f17n02:1076283:1076612 [4] NCCL INFO Channel 00/0 : 0[4] -> 1[5] via P2P/IPC
d14n11:1169360:1169712 [4] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5
d14n11:1169360:1169712 [4] NCCL INFO P2P Chunksize set to 131072
d14n10:565686:566030 [5] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
d14n10:565686:566030 [5] NCCL INFO P2P Chunksize set to 131072
d14n11:1169361:1169713 [5] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
d14n11:1169361:1169713 [5] NCCL INFO P2P Chunksize set to 131072
d14n11:1169357:1169715 [1] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2
d14n11:1169357:1169715 [1] NCCL INFO P2P Chunksize set to 131072
d14n11:1169358:1169710 [2] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3
d14n11:1169358:1169710 [2] NCCL INFO P2P Chunksize set to 131072
f18n05:1008223:1008556 [4] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5
f18n05:1008223:1008556 [4] NCCL INFO P2P Chunksize set to 131072
f18n05:1008224:1008557 [5] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
f18n05:1008224:1008557 [5] NCCL INFO P2P Chunksize set to 131072
d11n16:1130272:1130616 [4] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7
d11n16:1130272:1130616 [4] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7
d11n16:1130272:1130616 [4] NCCL INFO Trees [0] 1/2/-1->0->-1 [1] 1/-1/-1->0->2
d11n16:1130272:1130616 [4] NCCL INFO P2P Chunksize set to 131072
d11n16:1130272:1130616 [4] NCCL INFO Channel 00/0 : 7[5] -> 0[4] [receive] via NET/IB/1
d11n16:1130272:1130616 [4] NCCL INFO Channel 01/0 : 7[5] -> 0[4] [receive] via NET/IB/1
d11n16:1130272:1130616 [4] NCCL INFO Channel 00/0 : 0[4] -> 1[5] via P2P/IPC
f18n05:1008221:1008554 [2] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3
f18n05:1008221:1008554 [2] NCCL INFO P2P Chunksize set to 131072
d14n10:565685:566029 [4] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7
d14n10:565685:566029 [4] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7
d14n10:565685:566029 [4] NCCL INFO Trees [0] 1/2/-1->0->-1 [1] 1/-1/-1->0->2
d14n10:565685:566029 [4] NCCL INFO P2P Chunksize set to 131072
d14n10:565685:566029 [4] NCCL INFO Channel 00/0 : 7[5] -> 0[4] [receive] via NET/IB/1
d14n10:565685:566029 [4] NCCL INFO Channel 01/0 : 7[5] -> 0[4] [receive] via NET/IB/1
d14n10:565685:566029 [4] NCCL INFO Channel 00/0 : 0[4] -> 1[5] via P2P/IPC
f18n05:1008220:1008558 [1] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2
f18n05:1008220:1008558 [1] NCCL INFO P2P Chunksize set to 131072
f18n05:1008222:1008559 [3] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4
f18n05:1008222:1008559 [3] NCCL INFO P2P Chunksize set to 131072
f18n05:1008219:1008555 [0] NCCL INFO Trees [0] 3/-1/-1->2->0 [1] 3/0/-1->2->-1
f18n05:1008219:1008555 [0] NCCL INFO P2P Chunksize set to 131072
f18n05:1008219:1008555 [0] NCCL INFO Channel 00/0 : 1[5] -> 2[0] [receive] via NET/IB/0
f18n05:1008219:1008555 [0] NCCL INFO Channel 01/0 : 1[5] -> 2[0] [receive] via NET/IB/0
f18n05:1008219:1008555 [0] NCCL INFO Channel 00/0 : 2[0] -> 3[1] via P2P/IPC
d14n09:567668:568032 [2] NCCL INFO Channel 01/0 : 0[2] -> 3[5] via P2P/IPC
f16n17:1090962:1091310 [3] NCCL INFO Channel 00/0 : 5[3] -> 6[4] via P2P/IPC
d11n17:1142858:1143191 [4] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5
d11n17:1142858:1143191 [4] NCCL INFO P2P Chunksize set to 131072
d14n10:565681:566033 [0] NCCL INFO Channel 00/0 : 1[3] -> 4[0] [receive] via NET/IB/0
d14n10:565681:566033 [0] NCCL INFO Channel 01/0 : 1[3] -> 4[0] [receive] via NET/IB/3
d14n10:565681:566033 [0] NCCL INFO Channel 02/0 : 1[3] -> 4[0] [receive] via NET/IB/0
d14n10:565681:566033 [0] NCCL INFO Channel 03/0 : 1[3] -> 4[0] [receive] via NET/IB/3
d14n10:565681:566033 [0] NCCL INFO Channel 00/0 : 4[0] -> 1[3] [send] via NET/IB/0
d14n10:565681:566033 [0] NCCL INFO Channel 02/0 : 4[0] -> 1[3] [send] via NET/IB/0
f16n17:1090960:1091307 [1] NCCL INFO Channel 00/0 : 3[1] -> 4[2] via P2P/IPC
d11n16:1130272:1130616 [4] NCCL INFO Channel 01/0 : 0[4] -> 1[5] via P2P/IPC
d11n17:1142859:1143192 [5] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
d11n17:1142859:1143192 [5] NCCL INFO P2P Chunksize set to 131072
f16n17:1090963:1091311 [4] NCCL INFO Channel 00/0 : 6[4] -> 7[5] via P2P/IPC
d11n17:1142857:1143193 [3] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4
d11n17:1142857:1143193 [3] NCCL INFO P2P Chunksize set to 131072
d11n17:1142856:1143189 [2] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3
d11n17:1142856:1143189 [2] NCCL INFO P2P Chunksize set to 131072
d17n06:1216532:1216898 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
d17n06:1216532:1216898 [2] NCCL INFO P2P Chunksize set to 131072
f16n17:1090961:1091306 [2] NCCL INFO Channel 00/0 : 4[2] -> 5[3] via P2P/IPC
d11n17:1142855:1143188 [1] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2
d11n17:1142855:1143188 [1] NCCL INFO P2P Chunksize set to 131072
d14n10:565684:566034 [3] NCCL INFO Connected all rings
d14n09:567668:568032 [2] NCCL INFO Channel 02/0 : 0[2] -> 3[5] via P2P/IPC
d17n06:1216534:1216900 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3
d17n06:1216534:1216900 [4] NCCL INFO P2P Chunksize set to 131072
f16n17:1090962:1091310 [3] NCCL INFO Channel 01/0 : 5[3] -> 6[4] via P2P/IPC
f17n02:1076283:1076612 [4] NCCL INFO Channel 01/0 : 0[4] -> 1[5] via P2P/IPC
d17n06:1216531:1216902 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
d17n06:1216531:1216902 [1] NCCL INFO P2P Chunksize set to 131072
f16n17:1090960:1091307 [1] NCCL INFO Channel 01/0 : 3[1] -> 4[2] via P2P/IPC
f16n17:1090961:1091306 [2] NCCL INFO Channel 01/0 : 4[2] -> 5[3] via P2P/IPC
f18n05:1008219:1008555 [0] NCCL INFO Channel 01/0 : 2[0] -> 3[1] via P2P/IPC
f16n17:1090963:1091311 [4] NCCL INFO Channel 01/0 : 6[4] -> 7[5] via P2P/IPC
d14n09:567668:568032 [2] NCCL INFO Channel 03/0 : 0[2] -> 3[5] via P2P/IPC
d14n10:565685:566029 [4] NCCL INFO Channel 01/0 : 0[4] -> 1[5] via P2P/IPC
d17n06:1216533:1216901 [3] NCCL INFO Channel 00/0 : 3[3] -> 4[4] via P2P/IPC
d14n08:1173251:1173605 [4] NCCL INFO Channel 00/0 : 4[4] -> 5[5] via P2P/IPC
d14n08:1173250:1173606 [3] NCCL INFO Channel 00/0 : 3[3] -> 4[4] via P2P/IPC
d14n10:565682:566032 [1] NCCL INFO Channel 00/0 : 5[1] -> 4[0] via P2P/IPC
d14n08:1173249:1173604 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/IPC
f16n18:1091870:1092228 [4] NCCL INFO Channel 00/0 : 4[4] -> 5[5] via P2P/IPC
d14n08:1173248:1173607 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/IPC
f18n05:1008220:1008558 [1] NCCL INFO Channel 00/0 : 3[1] -> 4[2] via P2P/IPC
f16n18:1091869:1092226 [3] NCCL INFO Channel 00/0 : 3[3] -> 4[4] via P2P/IPC
f16n18:1091868:1092225 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/IPC
f16n18:1091867:1092224 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/IPC
d14n11:1169359:1169714 [3] NCCL INFO Channel 00/0 : 5[3] -> 6[4] via P2P/IPC
d14n11:1169360:1169712 [4] NCCL INFO Channel 00/0 : 6[4] -> 7[5] via P2P/IPC
f17n02:1076284:1076617 [5] NCCL INFO Channel 00/0 : 1[5] -> 2[0] [send] via NET/IB/1
f17n02:1076284:1076617 [5] NCCL INFO Channel 01/0 : 1[5] -> 2[0] [send] via NET/IB/1
f18n05:1008223:1008556 [4] NCCL INFO Channel 00/0 : 6[4] -> 7[5] via P2P/IPC
d14n11:1169357:1169715 [1] NCCL INFO Channel 00/0 : 3[1] -> 4[2] via P2P/IPC
d17n06:1216532:1216898 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/IPC
d14n09:567671:568036 [5] NCCL INFO Channel 00/0 : 3[5] -> 0[2] via P2P/IPC
f18n05:1008220:1008558 [1] NCCL INFO Channel 01/0 : 3[1] -> 4[2] via P2P/IPC
d14n11:1169358:1169710 [2] NCCL INFO Channel 00/0 : 4[2] -> 5[3] via P2P/IPC
d11n17:1142857:1143193 [3] NCCL INFO Channel 00/0 : 5[3] -> 6[4] via P2P/IPC
f18n05:1008221:1008554 [2] NCCL INFO Channel 00/0 : 4[2] -> 5[3] via P2P/IPC
d11n17:1142856:1143189 [2] NCCL INFO Channel 00/0 : 4[2] -> 5[3] via P2P/IPC
d11n17:1142858:1143191 [4] NCCL INFO Channel 00/0 : 6[4] -> 7[5] via P2P/IPC
d11n17:1142855:1143188 [1] NCCL INFO Channel 00/0 : 3[1] -> 4[2] via P2P/IPC
d14n11:1169359:1169714 [3] NCCL INFO Channel 01/0 : 5[3] -> 6[4] via P2P/IPC
f18n05:1008223:1008556 [4] NCCL INFO Channel 01/0 : 6[4] -> 7[5] via P2P/IPC
d14n11:1169360:1169712 [4] NCCL INFO Channel 01/0 : 6[4] -> 7[5] via P2P/IPC
d17n06:1216534:1216900 [4] NCCL INFO Channel 00/0 : 4[4] -> 5[5] via P2P/IPC
d11n17:1142857:1143193 [3] NCCL INFO Channel 01/0 : 5[3] -> 6[4] via P2P/IPC
d14n08:1173251:1173605 [4] NCCL INFO Channel 01/0 : 4[4] -> 5[5] via P2P/IPC
f18n05:1008222:1008559 [3] NCCL INFO Channel 00/0 : 5[3] -> 6[4] via P2P/IPC
d14n11:1169357:1169715 [1] NCCL INFO Channel 01/0 : 3[1] -> 4[2] via P2P/IPC
d11n17:1142856:1143189 [2] NCCL INFO Channel 01/0 : 4[2] -> 5[3] via P2P/IPC
f17n01:970279:970613 [3] NCCL INFO Connected all trees
f17n01:970279:970613 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f17n01:970279:970613 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n11:1169358:1169710 [2] NCCL INFO Channel 01/0 : 4[2] -> 5[3] via P2P/IPC
d17n06:1216533:1216901 [3] NCCL INFO Channel 01/0 : 3[3] -> 4[4] via P2P/IPC
d11n17:1142858:1143191 [4] NCCL INFO Channel 01/0 : 6[4] -> 7[5] via P2P/IPC
d14n08:1173250:1173606 [3] NCCL INFO Channel 01/0 : 3[3] -> 4[4] via P2P/IPC
d17n07:1212412:1212776 [2] NCCL INFO Connected all rings
d17n07:1212412:1212776 [2] NCCL INFO Channel 00/0 : 0[2] -> 3[5] via P2P/IPC
f18n05:1008221:1008554 [2] NCCL INFO Channel 01/0 : 4[2] -> 5[3] via P2P/IPC
d14n11:1169361:1169713 [5] NCCL INFO Channel 00/0 : 7[5] -> 0[4] [send] via NET/IB/1
d14n11:1169361:1169713 [5] NCCL INFO Channel 01/0 : 7[5] -> 0[4] [send] via NET/IB/1
d11n17:1142855:1143188 [1] NCCL INFO Channel 01/0 : 3[1] -> 4[2] via P2P/IPC
d14n09:567671:568036 [5] NCCL INFO Channel 02/0 : 3[5] -> 0[2] via P2P/IPC
f18n05:1008224:1008557 [5] NCCL INFO Channel 00/0 : 7[5] -> 0[4] [send] via NET/IB/1
f18n05:1008224:1008557 [5] NCCL INFO Channel 01/0 : 7[5] -> 0[4] [send] via NET/IB/1
f16n17:1090961:1091306 [2] NCCL INFO Connected all rings
d14n08:1173249:1173604 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/IPC
d17n07:1212412:1212776 [2] NCCL INFO Channel 01/0 : 0[2] -> 3[5] via P2P/IPC
f18n05:1008222:1008559 [3] NCCL INFO Channel 01/0 : 5[3] -> 6[4] via P2P/IPC
d14n10:565682:566032 [1] NCCL INFO Channel 02/0 : 5[1] -> 4[0] via P2P/IPC
d14n09:567671:568036 [5] NCCL INFO Channel 00/0 : 3[5] -> 2[4] via P2P/IPC
d11n17:1142859:1143192 [5] NCCL INFO Channel 00/0 : 7[5] -> 0[4] [send] via NET/IB/1
d11n17:1142859:1143192 [5] NCCL INFO Channel 01/0 : 7[5] -> 0[4] [send] via NET/IB/1
d14n08:1173248:1173607 [1] NCCL INFO Channel 01/0 : 1[1] -> 2[2] via P2P/IPC
f16n17:1090963:1091311 [4] NCCL INFO Connected all rings
f16n18:1091870:1092228 [4] NCCL INFO Channel 01/0 : 4[4] -> 5[5] via P2P/IPC
d17n07:1212412:1212776 [2] NCCL INFO Channel 02/0 : 0[2] -> 3[5] via P2P/IPC
f16n17:1090961:1091306 [2] NCCL INFO Channel 00/0 : 4[2] -> 3[1] via P2P/IPC
f16n18:1091869:1092226 [3] NCCL INFO Channel 01/0 : 3[3] -> 4[4] via P2P/IPC
d14n09:567671:568036 [5] NCCL INFO Channel 01/0 : 3[5] -> 2[4] via P2P/IPC
f16n17:1090963:1091311 [4] NCCL INFO Channel 00/0 : 6[4] -> 5[3] via P2P/IPC
f16n18:1091868:1092225 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/IPC
d17n07:1212412:1212776 [2] NCCL INFO Channel 03/0 : 0[2] -> 3[5] via P2P/IPC
f16n17:1090962:1091310 [3] NCCL INFO Connected all rings
d14n11:1169360:1169712 [4] NCCL INFO Connected all rings
f16n18:1091867:1092224 [1] NCCL INFO Channel 01/0 : 1[1] -> 2[2] via P2P/IPC
f16n17:1090961:1091306 [2] NCCL INFO Channel 01/0 : 4[2] -> 3[1] via P2P/IPC
f18n05:1008221:1008554 [2] NCCL INFO Connected all rings
d14n11:1169358:1169710 [2] NCCL INFO Connected all rings
d17n06:1216531:1216902 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/IPC
f16n17:1090963:1091311 [4] NCCL INFO Channel 01/0 : 6[4] -> 5[3] via P2P/IPC
f18n05:1008223:1008556 [4] NCCL INFO Connected all rings
d14n10:565684:566034 [3] NCCL INFO Channel 00/0 : 7[3] -> 6[2] via P2P/IPC
f16n17:1090962:1091310 [3] NCCL INFO Channel 00/0 : 5[3] -> 4[2] via P2P/IPC
d14n11:1169360:1169712 [4] NCCL INFO Channel 00/0 : 6[4] -> 5[3] via P2P/IPC
d17n06:1216532:1216898 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/IPC
f16n17:1090962:1091310 [3] NCCL INFO Channel 01/0 : 5[3] -> 4[2] via P2P/IPC
d14n11:1169358:1169710 [2] NCCL INFO Channel 00/0 : 4[2] -> 3[1] via P2P/IPC
d17n06:1216534:1216900 [4] NCCL INFO Channel 01/0 : 4[4] -> 5[5] via P2P/IPC
d11n17:1142858:1143191 [4] NCCL INFO Connected all rings
d14n11:1169359:1169714 [3] NCCL INFO Connected all rings
d17n06:1216531:1216902 [1] NCCL INFO Channel 01/0 : 1[1] -> 2[2] via P2P/IPC
d11n17:1142857:1143193 [3] NCCL INFO Connected all rings
f17n02:1076279:1076616 [0] NCCL INFO Connected all trees
f17n02:1076279:1076616 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f17n02:1076279:1076616 [0] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n09:567671:568036 [5] NCCL INFO Channel 02/0 : 3[5] -> 2[4] via P2P/IPC
d14n10:565684:566034 [3] NCCL INFO Channel 02/0 : 7[3] -> 6[2] via P2P/IPC
d17n07:1212415:1212778 [5] NCCL INFO Channel 00/0 : 3[5] -> 0[2] via P2P/IPC
f16n16:1079915:1080253 [3] NCCL INFO Connected all rings
d14n09:567671:568036 [5] NCCL INFO Channel 03/0 : 3[5] -> 2[4] via P2P/IPC
d14n10:565683:566031 [2] NCCL INFO Channel 00/0 : 6[2] -> 5[1] via P2P/IPC
d14n09:567668:568032 [2] NCCL INFO Connected all trees
d14n09:567668:568032 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n09:567668:568032 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d17n07:1212415:1212778 [5] NCCL INFO Channel 02/0 : 3[5] -> 0[2] via P2P/IPC
d14n10:565683:566031 [2] NCCL INFO Channel 02/0 : 6[2] -> 5[1] via P2P/IPC
f16n16:1079915:1080253 [3] NCCL INFO Channel 00/0 : 7[3] -> 6[2] via P2P/IPC
d17n07:1212415:1212778 [5] NCCL INFO Channel 00/0 : 3[5] -> 2[4] via P2P/IPC
f16n18:1091869:1092226 [3] NCCL INFO Connected all rings
d17n07:1212415:1212778 [5] NCCL INFO Channel 01/0 : 3[5] -> 2[4] via P2P/IPC
d11n17:1142856:1143189 [2] NCCL INFO Connected all rings
f16n18:1091870:1092228 [4] NCCL INFO Connected all rings
f17n01:970278:970611 [2] NCCL INFO comm 0x158cd2ac0 rank 0 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x9f2ca15e6ef47ab - Init COMPLETE
f16n16:1079915:1080253 [3] NCCL INFO Channel 02/0 : 7[3] -> 6[2] via P2P/IPC
f17n01:970280:970614 [4] NCCL INFO comm 0x1361b55c0 rank 2 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x9f2ca15e6ef47ab - Init COMPLETE
d14n08:1173251:1173605 [4] NCCL INFO Connected all rings
d17n07:1212415:1212778 [5] NCCL INFO Channel 02/0 : 3[5] -> 2[4] via P2P/IPC
d14n08:1173250:1173606 [3] NCCL INFO Connected all rings
f17n01:970281:970612 [5] NCCL INFO comm 0x1429f3c40 rank 3 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x9f2ca15e6ef47ab - Init COMPLETE
d14n08:1173249:1173604 [2] NCCL INFO Connected all rings
f17n01:970279:970613 [3] NCCL INFO comm 0x143ad6a40 rank 1 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x9f2ca15e6ef47ab - Init COMPLETE
f16n16:1079914:1080254 [2] NCCL INFO Channel 00/0 : 6[2] -> 5[1] via P2P/IPC
d09n08:1073956:1074293 [2] NCCL INFO Connected all rings
d09n08:1073956:1074293 [2] NCCL INFO Channel 00/0 : 0[2] -> 3[5] via P2P/IPC
d17n06:1216534:1216900 [4] NCCL INFO Connected all rings
d17n07:1212412:1212776 [2] NCCL INFO Connected all trees
d17n07:1212412:1212776 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d17n07:1212412:1212776 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d17n06:1216532:1216898 [2] NCCL INFO Connected all rings
d17n07:1212415:1212778 [5] NCCL INFO Channel 03/0 : 3[5] -> 2[4] via P2P/IPC
f16n16:1079914:1080254 [2] NCCL INFO Channel 02/0 : 6[2] -> 5[1] via P2P/IPC
f16n18:1091868:1092225 [2] NCCL INFO Connected all rings
d17n06:1216533:1216901 [3] NCCL INFO Connected all rings
f16n16:1079912:1080256 [0] NCCL INFO Connected all rings
f16n16:1079912:1080256 [0] NCCL INFO Channel 01/0 : 4[0] -> 5[1] via P2P/IPC
f16n18:1091869:1092226 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/IPC
f16n18:1091870:1092228 [4] NCCL INFO Channel 00/0 : 4[4] -> 3[3] via P2P/IPC
d14n08:1173251:1173605 [4] NCCL INFO Channel 00/0 : 4[4] -> 3[3] via P2P/IPC
d14n08:1173250:1173606 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/IPC
d14n08:1173249:1173604 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/IPC
f16n16:1079912:1080256 [0] NCCL INFO Channel 03/0 : 4[0] -> 5[1] via P2P/IPC
d17n06:1216534:1216900 [4] NCCL INFO Channel 00/0 : 4[4] -> 3[3] via P2P/IPC
f17n02:1076280:1076614 [1] NCCL INFO comm 0x1444da9c0 rank 5 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x9f2ca15e6ef47ab - Init COMPLETE
d17n06:1216532:1216898 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/IPC
f17n02:1076282:1076613 [3] NCCL INFO comm 0x1291ac380 rank 7 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x9f2ca15e6ef47ab - Init COMPLETE
f16n18:1091869:1092226 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/IPC
f17n02:1076279:1076616 [0] NCCL INFO comm 0x161b97640 rank 4 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x9f2ca15e6ef47ab - Init COMPLETE
f16n18:1091870:1092228 [4] NCCL INFO Channel 01/0 : 4[4] -> 3[3] via P2P/IPC
f17n02:1076281:1076615 [2] NCCL INFO comm 0x17c0146e0 rank 6 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x9f2ca15e6ef47ab - Init COMPLETE
f16n16:1079915:1080253 [3] NCCL INFO Connected all trees
f16n16:1079915:1080253 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n16:1079915:1080253 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d09n08:1073956:1074293 [2] NCCL INFO Channel 01/0 : 0[2] -> 3[5] via P2P/IPC
f16n18:1091868:1092225 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/IPC
d14n08:1173251:1173605 [4] NCCL INFO Channel 01/0 : 4[4] -> 3[3] via P2P/IPC
d14n08:1173250:1173606 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/IPC
d14n11:1169360:1169712 [4] NCCL INFO Channel 01/0 : 6[4] -> 5[3] via P2P/IPC
d14n08:1173249:1173604 [2] NCCL INFO Channel 01/0 : 2[2] -> 1[1] via P2P/IPC
f16n17:1090962:1091310 [3] NCCL INFO Connected all trees
f16n17:1090962:1091310 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n17:1090962:1091310 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n11:1169358:1169710 [2] NCCL INFO Channel 01/0 : 4[2] -> 3[1] via P2P/IPC
d09n08:1073956:1074293 [2] NCCL INFO Channel 02/0 : 0[2] -> 3[5] via P2P/IPC
d11n17:1142857:1143193 [3] NCCL INFO Channel 00/0 : 5[3] -> 4[2] via P2P/IPC
f16n18:1091868:1092225 [2] NCCL INFO Channel 01/0 : 2[2] -> 1[1] via P2P/IPC
d17n06:1216533:1216901 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/IPC
d11n17:1142858:1143191 [4] NCCL INFO Channel 00/0 : 6[4] -> 5[3] via P2P/IPC
d17n06:1216534:1216900 [4] NCCL INFO Channel 01/0 : 4[4] -> 3[3] via P2P/IPC
d14n11:1169359:1169714 [3] NCCL INFO Channel 00/0 : 5[3] -> 4[2] via P2P/IPC
d09n08:1073956:1074293 [2] NCCL INFO Channel 03/0 : 0[2] -> 3[5] via P2P/IPC
d17n06:1216532:1216898 [2] NCCL INFO Channel 01/0 : 2[2] -> 1[1] via P2P/IPC
d17n06:1216533:1216901 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/IPC
d17n07:1212413:1212777 [3] NCCL INFO Connected all rings
d17n07:1212413:1212777 [3] NCCL INFO Channel 00/0 : 1[3] -> 4[0] [send] via NET/IB/3
d17n07:1212413:1212777 [3] NCCL INFO Channel 01/0 : 1[3] -> 4[0] [send] via NET/IB/0
d17n07:1212413:1212777 [3] NCCL INFO Channel 02/0 : 1[3] -> 4[0] [send] via NET/IB/3
d17n07:1212413:1212777 [3] NCCL INFO Channel 03/0 : 1[3] -> 4[0] [send] via NET/IB/0
d17n07:1212413:1212777 [3] NCCL INFO Channel 00/0 : 4[0] -> 1[3] [receive] via NET/IB/3
d17n07:1212413:1212777 [3] NCCL INFO Channel 02/0 : 4[0] -> 1[3] [receive] via NET/IB/3
d11n16:1130271:1130621 [3] NCCL INFO Connected all rings
d14n11:1169359:1169714 [3] NCCL INFO Channel 01/0 : 5[3] -> 4[2] via P2P/IPC
f16n16:1079913:1080255 [1] NCCL INFO Channel 00/0 : 5[1] -> 4[0] via P2P/IPC
f16n16:1079912:1080256 [0] NCCL INFO Channel 00/0 : 1[3] -> 4[0] [receive] via NET/IB/0
f16n16:1079912:1080256 [0] NCCL INFO Channel 01/0 : 1[3] -> 4[0] [receive] via NET/IB/3
f16n16:1079912:1080256 [0] NCCL INFO Channel 02/0 : 1[3] -> 4[0] [receive] via NET/IB/0
f16n16:1079912:1080256 [0] NCCL INFO Channel 03/0 : 1[3] -> 4[0] [receive] via NET/IB/3
f16n16:1079912:1080256 [0] NCCL INFO Channel 00/0 : 4[0] -> 1[3] [send] via NET/IB/0
f16n16:1079912:1080256 [0] NCCL INFO Channel 02/0 : 4[0] -> 1[3] [send] via NET/IB/0
d11n17:1142856:1143189 [2] NCCL INFO Channel 00/0 : 4[2] -> 3[1] via P2P/IPC
d11n17:1142857:1143193 [3] NCCL INFO Channel 01/0 : 5[3] -> 4[2] via P2P/IPC
f16n16:1079913:1080255 [1] NCCL INFO Channel 02/0 : 5[1] -> 4[0] via P2P/IPC
f18n05:1008221:1008554 [2] NCCL INFO Channel 00/0 : 4[2] -> 3[1] via P2P/IPC
d11n17:1142858:1143191 [4] NCCL INFO Channel 01/0 : 6[4] -> 5[3] via P2P/IPC
f18n05:1008223:1008556 [4] NCCL INFO Channel 00/0 : 6[4] -> 5[3] via P2P/IPC
d14n08:1173250:1173606 [3] NCCL INFO Connected all trees
d14n08:1173250:1173606 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n08:1173250:1173606 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f18n05:1008220:1008558 [1] NCCL INFO Connected all rings
d09n08:1073959:1074294 [5] NCCL INFO Channel 00/0 : 3[5] -> 0[2] via P2P/IPC
d11n17:1142856:1143189 [2] NCCL INFO Channel 01/0 : 4[2] -> 3[1] via P2P/IPC
f16n18:1091869:1092226 [3] NCCL INFO Connected all trees
f16n18:1091869:1092226 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n18:1091869:1092226 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f18n05:1008222:1008559 [3] NCCL INFO Connected all rings
d14n11:1169359:1169714 [3] NCCL INFO Connected all trees
d14n11:1169359:1169714 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n11:1169359:1169714 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d09n08:1073959:1074294 [5] NCCL INFO Channel 02/0 : 3[5] -> 0[2] via P2P/IPC
d11n16:1130271:1130621 [3] NCCL INFO Channel 00/0 : 7[3] -> 6[2] via P2P/IPC
f18n05:1008221:1008554 [2] NCCL INFO Channel 01/0 : 4[2] -> 3[1] via P2P/IPC
d09n08:1073959:1074294 [5] NCCL INFO Channel 00/0 : 3[5] -> 2[4] via P2P/IPC
d14n10:565684:566034 [3] NCCL INFO Connected all trees
d14n10:565684:566034 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n10:565684:566034 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f18n05:1008223:1008556 [4] NCCL INFO Channel 01/0 : 6[4] -> 5[3] via P2P/IPC
d14n09:567670:568035 [4] NCCL INFO Connected all trees
d14n09:567670:568035 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n09:567670:568035 [4] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d17n06:1216533:1216901 [3] NCCL INFO Connected all trees
d17n06:1216533:1216901 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d17n06:1216533:1216901 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f18n05:1008220:1008558 [1] NCCL INFO Channel 00/0 : 3[1] -> 2[0] via P2P/IPC
d11n16:1130271:1130621 [3] NCCL INFO Channel 02/0 : 7[3] -> 6[2] via P2P/IPC
d09n08:1073959:1074294 [5] NCCL INFO Channel 01/0 : 3[5] -> 2[4] via P2P/IPC
d14n09:567671:568036 [5] NCCL INFO Connected all trees
d14n09:567671:568036 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n09:567671:568036 [5] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d11n16:1130270:1130619 [2] NCCL INFO Channel 00/0 : 6[2] -> 5[1] via P2P/IPC
d09n08:1073959:1074294 [5] NCCL INFO Channel 02/0 : 3[5] -> 2[4] via P2P/IPC
d11n16:1130270:1130619 [2] NCCL INFO Channel 02/0 : 6[2] -> 5[1] via P2P/IPC
d11n17:1142857:1143193 [3] NCCL INFO Connected all trees
d11n17:1142857:1143193 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d11n17:1142857:1143193 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d09n08:1073956:1074293 [2] NCCL INFO Connected all trees
d09n08:1073956:1074293 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d09n08:1073956:1074293 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n10:565683:566031 [2] NCCL INFO Connected all trees
d14n10:565683:566031 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n10:565683:566031 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f16n17:1090964:1091309 [5] NCCL INFO Channel 00/0 : 7[5] -> 0[4] [send] via NET/IB/1
f16n17:1090964:1091309 [5] NCCL INFO Channel 01/0 : 7[5] -> 0[4] [send] via NET/IB/1
d09n08:1073959:1074294 [5] NCCL INFO Channel 03/0 : 3[5] -> 2[4] via P2P/IPC
d14n10:565682:566032 [1] NCCL INFO Connected all trees
d14n10:565682:566032 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n10:565682:566032 [1] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f16n17:1090959:1091308 [0] NCCL INFO Trees [0] 3/-1/-1->2->0 [1] 3/0/-1->2->-1
f16n17:1090959:1091308 [0] NCCL INFO P2P Chunksize set to 131072
f17n01:970276:970615 [0] NCCL INFO Trees [0] 7/-1/-1->6->0 [1] 7/0/-1->6->-1
f17n01:970276:970615 [0] NCCL INFO P2P Chunksize set to 131072
f16n18:1091866:1092223 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7
f16n18:1091866:1092223 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7
f16n18:1091866:1092223 [0] NCCL INFO Trees [0] 1/6/-1->0->-1 [1] 1/-1/-1->0->6
f16n18:1091866:1092223 [0] NCCL INFO P2P Chunksize set to 131072
d17n07:1212415:1212778 [5] NCCL INFO Connected all trees
d17n07:1212415:1212778 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d17n07:1212415:1212778 [5] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d11n16:1130273:1130617 [5] NCCL INFO Channel 00/0 : 1[5] -> 2[0] [send] via NET/IB/1
d11n16:1130273:1130617 [5] NCCL INFO Channel 01/0 : 1[5] -> 2[0] [send] via NET/IB/1
d17n07:1212411:1212779 [1] NCCL INFO Channel 00/0 : 7[1] -> 0[0] [send] via NET/IB/0
d17n07:1212411:1212779 [1] NCCL INFO Channel 01/0 : 7[1] -> 0[0] [send] via NET/IB/0
f16n18:1091871:1092227 [5] NCCL INFO Channel 00/0 : 5[5] -> 6[0] [send] via NET/IB/1
f16n18:1091871:1092227 [5] NCCL INFO Channel 01/0 : 5[5] -> 6[0] [send] via NET/IB/1
f18n05:1008222:1008559 [3] NCCL INFO Channel 00/0 : 5[3] -> 4[2] via P2P/IPC
f17n01:970277:970616 [1] NCCL INFO Channel 00/0 : 7[1] -> 0[0] [send] via NET/IB/0
f17n01:970277:970616 [1] NCCL INFO Channel 01/0 : 7[1] -> 0[0] [send] via NET/IB/0
d11n17:1142854:1143190 [0] NCCL INFO Trees [0] 3/-1/-1->2->0 [1] 3/0/-1->2->-1
d11n17:1142854:1143190 [0] NCCL INFO P2P Chunksize set to 131072
f17n02:1076283:1076612 [4] NCCL INFO Connected all rings
f17n02:1076283:1076612 [4] NCCL INFO Channel 00/0 : 0[4] -> 2[0] [send] via NET/IB/1
f17n02:1076283:1076612 [4] NCCL INFO Channel 01/0 : 0[4] -> 2[0] [send] via NET/IB/1
f18n05:1008220:1008558 [1] NCCL INFO Channel 01/0 : 3[1] -> 2[0] via P2P/IPC
f16n16:1079916:1080252 [4] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7
f16n16:1079916:1080252 [4] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7
f16n16:1079916:1080252 [4] NCCL INFO Trees [0] 1/2/-1->0->-1 [1] 1/-1/-1->0->2
f16n16:1079916:1080252 [4] NCCL INFO P2P Chunksize set to 131072
f16n16:1079916:1080252 [4] NCCL INFO Channel 00/0 : 7[5] -> 0[4] [receive] via NET/IB/1
f16n16:1079916:1080252 [4] NCCL INFO Channel 01/0 : 7[5] -> 0[4] [receive] via NET/IB/1
f16n16:1079916:1080252 [4] NCCL INFO Channel 00/0 : 0[4] -> 1[5] via P2P/IPC
d14n09:567667:568033 [1] NCCL INFO Channel 00/0 : 7[1] -> 0[0] [send] via NET/IB/0
d14n09:567667:568033 [1] NCCL INFO Channel 01/0 : 7[1] -> 0[0] [send] via NET/IB/0
f18n05:1008222:1008559 [3] NCCL INFO Channel 01/0 : 5[3] -> 4[2] via P2P/IPC
f16n16:1079917:1080257 [5] NCCL INFO Channel 00/0 : 1[5] -> 2[0] [send] via NET/IB/1
f16n16:1079917:1080257 [5] NCCL INFO Channel 01/0 : 1[5] -> 2[0] [send] via NET/IB/1
d14n09:567666:568034 [0] NCCL INFO Trees [0] 7/-1/-1->6->0 [1] 7/0/-1->6->-1
d14n09:567666:568034 [0] NCCL INFO P2P Chunksize set to 131072
f18n05:1008224:1008557 [5] NCCL INFO Connected all rings
f18n05:1008224:1008557 [5] NCCL INFO Channel 00/0 : 7[5] -> 6[4] via P2P/IPC
f18n05:1008224:1008557 [5] NCCL INFO Channel 01/0 : 7[5] -> 6[4] via P2P/IPC
d14n08:1173247:1173602 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7
d14n08:1173247:1173602 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7
d14n08:1173247:1173602 [0] NCCL INFO Trees [0] 1/6/-1->0->-1 [1] 1/-1/-1->0->6
d14n08:1173247:1173602 [0] NCCL INFO P2P Chunksize set to 131072
f18n05:1008221:1008554 [2] NCCL INFO Connected all trees
f18n05:1008221:1008554 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f18n05:1008221:1008554 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n10:565686:566030 [5] NCCL INFO Channel 00/0 : 1[5] -> 2[0] [send] via NET/IB/1
d14n10:565686:566030 [5] NCCL INFO Channel 01/0 : 1[5] -> 2[0] [send] via NET/IB/1
d14n11:1169356:1169711 [0] NCCL INFO Trees [0] 3/-1/-1->2->0 [1] 3/0/-1->2->-1
d14n11:1169356:1169711 [0] NCCL INFO P2P Chunksize set to 131072
f16n16:1079914:1080254 [2] NCCL INFO Connected all trees
f16n16:1079914:1080254 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n16:1079914:1080254 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d17n07:1212410:1212780 [0] NCCL INFO Trees [0] 7/-1/-1->6->0 [1] 7/0/-1->6->-1
d17n07:1212410:1212780 [0] NCCL INFO P2P Chunksize set to 131072
d17n07:1212410:1212780 [0] NCCL INFO Channel 00/0 : 5[5] -> 6[0] [receive] via NET/IB/0
d17n07:1212410:1212780 [0] NCCL INFO Channel 01/0 : 5[5] -> 6[0] [receive] via NET/IB/0
d17n07:1212410:1212780 [0] NCCL INFO Channel 00/0 : 6[0] -> 7[1] via P2P/IPC
f18n05:1008222:1008559 [3] NCCL INFO Connected all trees
f18n05:1008222:1008559 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f18n05:1008222:1008559 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n16:1079913:1080255 [1] NCCL INFO Connected all trees
f16n16:1079913:1080255 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n16:1079913:1080255 [1] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n08:1173252:1173603 [5] NCCL INFO Channel 00/0 : 5[5] -> 6[0] [send] via NET/IB/1
d14n08:1173252:1173603 [5] NCCL INFO Channel 01/0 : 5[5] -> 6[0] [send] via NET/IB/1
d11n16:1130271:1130621 [3] NCCL INFO Connected all trees
d11n16:1130271:1130621 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d11n16:1130271:1130621 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f18n05:1008224:1008557 [5] NCCL INFO Connected all trees
f18n05:1008224:1008557 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f18n05:1008224:1008557 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n06:1216530:1216897 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7
d17n06:1216530:1216897 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7
d17n06:1216530:1216897 [0] NCCL INFO Trees [0] 1/6/-1->0->-1 [1] 1/-1/-1->0->6
d17n06:1216530:1216897 [0] NCCL INFO P2P Chunksize set to 131072
d09n08:1073958:1074295 [4] NCCL INFO Connected all trees
d09n08:1073958:1074295 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d09n08:1073958:1074295 [4] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f18n05:1008223:1008556 [4] NCCL INFO Connected all trees
f18n05:1008223:1008556 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f18n05:1008223:1008556 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n16:1130269:1130620 [1] NCCL INFO Connected all trees
d11n16:1130269:1130620 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d11n16:1130269:1130620 [1] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d17n07:1212410:1212780 [0] NCCL INFO Channel 01/0 : 6[0] -> 7[1] via P2P/IPC
d11n16:1130270:1130619 [2] NCCL INFO Connected all trees
d11n16:1130270:1130619 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d11n16:1130270:1130619 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d09n08:1073959:1074294 [5] NCCL INFO Connected all trees
d09n08:1073959:1074294 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d09n08:1073959:1074294 [5] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d17n06:1216535:1216899 [5] NCCL INFO Channel 00/0 : 5[5] -> 6[0] [send] via NET/IB/1
d17n06:1216535:1216899 [5] NCCL INFO Channel 01/0 : 5[5] -> 6[0] [send] via NET/IB/1
d17n07:1212414:1212781 [4] NCCL INFO Connected all trees
d17n07:1212414:1212781 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d17n07:1212414:1212781 [4] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d09n07:1063016:1063428 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d14n10:565681:566033 [0] NCCL INFO Connected all trees
d14n10:565681:566033 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n10:565681:566033 [0] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n09:567669:568037 [3] NCCL INFO Connected all trees
d14n09:567669:568037 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n09:567669:568037 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d17n06:1216535:1216899 [5] NCCL INFO Connected all rings
d17n06:1216535:1216899 [5] NCCL INFO Channel 00/0 : 5[5] -> 4[4] via P2P/IPC
d17n06:1216535:1216899 [5] NCCL INFO Channel 01/0 : 5[5] -> 4[4] via P2P/IPC
f16n17:1090959:1091308 [0] NCCL INFO Channel 00/0 : 1[5] -> 2[0] [receive] via NET/IB/0
f16n17:1090959:1091308 [0] NCCL INFO Channel 01/0 : 1[5] -> 2[0] [receive] via NET/IB/0
f16n17:1090959:1091308 [0] NCCL INFO Channel 00/0 : 2[0] -> 3[1] via P2P/IPC
f16n17:1090959:1091308 [0] NCCL INFO Channel 01/0 : 2[0] -> 3[1] via P2P/IPC
d09n08:1073957:1074296 [3] NCCL INFO Connected all trees
d09n08:1073957:1074296 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d09n08:1073957:1074296 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d11n16:1130268:1130618 [0] NCCL INFO Connected all trees
d11n16:1130268:1130618 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d11n16:1130268:1130618 [0] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n09:567666:568034 [0] NCCL INFO Channel 00/0 : 5[5] -> 6[0] [receive] via NET/IB/0
d14n09:567666:568034 [0] NCCL INFO Channel 01/0 : 5[5] -> 6[0] [receive] via NET/IB/0
d14n09:567666:568034 [0] NCCL INFO Channel 00/0 : 6[0] -> 7[1] via P2P/IPC
d14n09:567668:568032 [2] NCCL INFO comm 0x12a5a3d80 rank 0 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x6960d29931b9c9d9 - Init COMPLETE
d14n09:567671:568036 [5] NCCL INFO comm 0x137c71680 rank 3 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x6960d29931b9c9d9 - Init COMPLETE
d17n06:1216535:1216899 [5] NCCL INFO Connected all trees
d17n06:1216535:1216899 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d17n06:1216535:1216899 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n09:567669:568037 [3] NCCL INFO comm 0x149aaf4c0 rank 1 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x6960d29931b9c9d9 - Init COMPLETE
d14n10:565682:566032 [1] NCCL INFO comm 0x1795799c0 rank 5 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x6960d29931b9c9d9 - Init COMPLETE
d14n10:565684:566034 [3] NCCL INFO comm 0x12da594c0 rank 7 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x6960d29931b9c9d9 - Init COMPLETE
d14n09:567670:568035 [4] NCCL INFO comm 0x164d44c80 rank 2 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x6960d29931b9c9d9 - Init COMPLETE
d14n09:567666:568034 [0] NCCL INFO Channel 01/0 : 6[0] -> 7[1] via P2P/IPC
d14n10:565681:566033 [0] NCCL INFO comm 0x166d99680 rank 4 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x6960d29931b9c9d9 - Init COMPLETE
d14n10:565683:566031 [2] NCCL INFO comm 0x12c983500 rank 6 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x6960d29931b9c9d9 - Init COMPLETE
d17n06:1216534:1216900 [4] NCCL INFO Connected all trees
d17n06:1216534:1216900 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d17n06:1216534:1216900 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n16:1079912:1080256 [0] NCCL INFO Connected all trees
f16n16:1079912:1080256 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n16:1079912:1080256 [0] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f16n17:1090960:1091307 [1] NCCL INFO Connected all rings
d14n08:1173247:1173602 [0] NCCL INFO Channel 00/0 : 7[1] -> 0[0] [receive] via NET/IB/0
d14n08:1173247:1173602 [0] NCCL INFO Channel 01/0 : 7[1] -> 0[0] [receive] via NET/IB/0
d14n08:1173247:1173602 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/IPC
d14n08:1173247:1173602 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/IPC
f16n17:1090960:1091307 [1] NCCL INFO Channel 00/0 : 3[1] -> 2[0] via P2P/IPC
d17n07:1212413:1212777 [3] NCCL INFO Connected all trees
d17n07:1212413:1212777 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d17n07:1212413:1212777 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f16n17:1090960:1091307 [1] NCCL INFO Channel 01/0 : 3[1] -> 2[0] via P2P/IPC
d09n08:1073956:1074293 [2] NCCL INFO comm 0x15dd71b00 rank 0 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa91f9f3e21ae8c0a - Init COMPLETE
d09n08:1073958:1074295 [4] NCCL INFO comm 0x14fd68340 rank 2 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa91f9f3e21ae8c0a - Init COMPLETE
d11n16:1130268:1130618 [0] NCCL INFO comm 0x156bbcec0 rank 4 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa91f9f3e21ae8c0a - Init COMPLETE
d09n08:1073959:1074294 [5] NCCL INFO comm 0x159ebaa00 rank 3 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa91f9f3e21ae8c0a - Init COMPLETE
d09n08:1073957:1074296 [3] NCCL INFO comm 0x1596fb740 rank 1 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa91f9f3e21ae8c0a - Init COMPLETE
d11n16:1130269:1130620 [1] NCCL INFO comm 0x136d088c0 rank 5 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa91f9f3e21ae8c0a - Init COMPLETE
d11n16:1130270:1130619 [2] NCCL INFO comm 0x14a505240 rank 6 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa91f9f3e21ae8c0a - Init COMPLETE
d11n16:1130271:1130621 [3] NCCL INFO comm 0x16c969b60 rank 7 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa91f9f3e21ae8c0a - Init COMPLETE
f16n17:1090961:1091306 [2] NCCL INFO Connected all trees
f16n17:1090961:1091306 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n17:1090961:1091306 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n08:1173248:1173607 [1] NCCL INFO Connected all rings
d14n08:1173248:1173607 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/IPC
d14n08:1173252:1173603 [5] NCCL INFO Connected all rings
d14n08:1173252:1173603 [5] NCCL INFO Channel 00/0 : 5[5] -> 4[4] via P2P/IPC
d14n08:1173248:1173607 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/IPC
d14n08:1173252:1173603 [5] NCCL INFO Channel 01/0 : 5[5] -> 4[4] via P2P/IPC
d17n07:1212412:1212776 [2] NCCL INFO comm 0x12dc34580 rank 0 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x5367495adaa62d15 - Init COMPLETE
d17n07:1212413:1212777 [3] NCCL INFO comm 0x135810a80 rank 1 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x5367495adaa62d15 - Init COMPLETE
f16n16:1079912:1080256 [0] NCCL INFO comm 0x143ee5190 rank 4 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x5367495adaa62d15 - Init COMPLETE
f16n16:1079913:1080255 [1] NCCL INFO comm 0x17ea22980 rank 5 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x5367495adaa62d15 - Init COMPLETE
d17n07:1212414:1212781 [4] NCCL INFO comm 0x17b458dc0 rank 2 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x5367495adaa62d15 - Init COMPLETE
d17n07:1212415:1212778 [5] NCCL INFO comm 0x14f1b75c0 rank 3 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x5367495adaa62d15 - Init COMPLETE
f16n16:1079914:1080254 [2] NCCL INFO comm 0x1649304a0 rank 6 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x5367495adaa62d15 - Init COMPLETE
d14n09:567667:568033 [1] NCCL INFO Connected all rings
d14n09:567667:568033 [1] NCCL INFO Channel 00/0 : 7[1] -> 6[0] via P2P/IPC
f16n16:1079915:1080253 [3] NCCL INFO comm 0x163fd6cc0 rank 7 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x5367495adaa62d15 - Init COMPLETE
d14n09:567667:568033 [1] NCCL INFO Channel 01/0 : 7[1] -> 6[0] via P2P/IPC
d14n08:1173249:1173604 [2] NCCL INFO Connected all trees
d14n08:1173249:1173604 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n08:1173249:1173604 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n17:1142859:1143192 [5] NCCL INFO Connected all rings
d11n17:1142859:1143192 [5] NCCL INFO Channel 00/0 : 7[5] -> 6[4] via P2P/IPC
d14n09:567666:568034 [0] NCCL INFO Connected all rings
d14n09:567666:568034 [0] NCCL INFO Channel 00/0 : 6[0] -> 0[0] [send] via NET/IB/0
d14n09:567666:568034 [0] NCCL INFO Channel 01/0 : 6[0] -> 0[0] [send] via NET/IB/0
d14n09:567666:568034 [0] NCCL INFO Channel 00/0 : 0[0] -> 6[0] [receive] via NET/IB/0
d14n09:567666:568034 [0] NCCL INFO Channel 01/0 : 0[0] -> 6[0] [receive] via NET/IB/0
d11n17:1142859:1143192 [5] NCCL INFO Channel 01/0 : 7[5] -> 6[4] via P2P/IPC
d14n08:1173247:1173602 [0] NCCL INFO Connected all rings
d14n08:1173247:1173602 [0] NCCL INFO Channel 00/0 : 6[0] -> 0[0] [receive] via NET/IB/0
d14n08:1173247:1173602 [0] NCCL INFO Channel 01/0 : 6[0] -> 0[0] [receive] via NET/IB/0
d14n08:1173247:1173602 [0] NCCL INFO Channel 00/0 : 0[0] -> 6[0] [send] via NET/IB/0
d14n08:1173247:1173602 [0] NCCL INFO Channel 01/0 : 0[0] -> 6[0] [send] via NET/IB/0
d14n08:1173252:1173603 [5] NCCL INFO Connected all trees
d14n08:1173252:1173603 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n08:1173252:1173603 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n08:1173251:1173605 [4] NCCL INFO Connected all trees
d14n08:1173251:1173605 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n08:1173251:1173605 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n09:567667:568033 [1] NCCL INFO Connected all trees
d14n09:567667:568033 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n09:567667:568033 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n17:1142859:1143192 [5] NCCL INFO Connected all trees
d11n17:1142859:1143192 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d11n17:1142859:1143192 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n17:1142858:1143191 [4] NCCL INFO Connected all trees
d11n17:1142858:1143191 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d11n17:1142858:1143191 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n18:1091866:1092223 [0] NCCL INFO Channel 00/0 : 7[1] -> 0[0] [receive] via NET/IB/0
f16n18:1091866:1092223 [0] NCCL INFO Channel 01/0 : 7[1] -> 0[0] [receive] via NET/IB/0
f16n18:1091866:1092223 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/IPC
f16n18:1091866:1092223 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/IPC
d14n08:1173248:1173607 [1] NCCL INFO Connected all trees
d14n08:1173248:1173607 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n08:1173248:1173607 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n16:1079916:1080252 [4] NCCL INFO Channel 01/0 : 0[4] -> 1[5] via P2P/IPC
f16n18:1091867:1092224 [1] NCCL INFO Connected all rings
f16n18:1091867:1092224 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/IPC
f16n18:1091867:1092224 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/IPC
d11n17:1142854:1143190 [0] NCCL INFO Channel 00/0 : 1[5] -> 2[0] [receive] via NET/IB/0
d11n17:1142854:1143190 [0] NCCL INFO Channel 01/0 : 1[5] -> 2[0] [receive] via NET/IB/0
d11n17:1142854:1143190 [0] NCCL INFO Channel 00/0 : 2[0] -> 3[1] via P2P/IPC
d11n17:1142854:1143190 [0] NCCL INFO Channel 01/0 : 2[0] -> 3[1] via P2P/IPC
d14n11:1169356:1169711 [0] NCCL INFO Channel 00/0 : 1[5] -> 2[0] [receive] via NET/IB/0
d14n11:1169356:1169711 [0] NCCL INFO Channel 01/0 : 1[5] -> 2[0] [receive] via NET/IB/0
d14n11:1169356:1169711 [0] NCCL INFO Channel 00/0 : 2[0] -> 3[1] via P2P/IPC
d14n11:1169356:1169711 [0] NCCL INFO Channel 01/0 : 2[0] -> 3[1] via P2P/IPC
f16n18:1091868:1092225 [2] NCCL INFO Connected all trees
f16n18:1091868:1092225 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n18:1091868:1092225 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n06:1216530:1216897 [0] NCCL INFO Channel 00/0 : 7[1] -> 0[0] [receive] via NET/IB/0
d17n06:1216530:1216897 [0] NCCL INFO Channel 01/0 : 7[1] -> 0[0] [receive] via NET/IB/0
d17n06:1216530:1216897 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/IPC
d17n06:1216530:1216897 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/IPC
d11n17:1142855:1143188 [1] NCCL INFO Connected all rings
d14n08:1173247:1173602 [0] NCCL INFO Connected all trees
d14n08:1173247:1173602 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n08:1173247:1173602 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n09:567666:568034 [0] NCCL INFO Connected all trees
d14n09:567666:568034 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n09:567666:568034 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n17:1142855:1143188 [1] NCCL INFO Channel 00/0 : 3[1] -> 2[0] via P2P/IPC
d11n17:1142855:1143188 [1] NCCL INFO Channel 01/0 : 3[1] -> 2[0] via P2P/IPC
d14n11:1169357:1169715 [1] NCCL INFO Connected all rings
f16n16:1079917:1080257 [5] NCCL INFO Connected all rings
f16n16:1079917:1080257 [5] NCCL INFO Channel 00/0 : 1[5] -> 0[4] via P2P/IPC
f16n16:1079917:1080257 [5] NCCL INFO Channel 01/0 : 1[5] -> 0[4] via P2P/IPC
d14n11:1169357:1169715 [1] NCCL INFO Channel 00/0 : 3[1] -> 2[0] via P2P/IPC
d14n11:1169357:1169715 [1] NCCL INFO Channel 01/0 : 3[1] -> 2[0] via P2P/IPC
d17n06:1216531:1216902 [1] NCCL INFO Connected all rings
f16n17:1090964:1091309 [5] NCCL INFO Connected all rings
f16n17:1090964:1091309 [5] NCCL INFO Channel 00/0 : 7[5] -> 6[4] via P2P/IPC
d11n17:1142856:1143189 [2] NCCL INFO Connected all trees
d11n17:1142856:1143189 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d11n17:1142856:1143189 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n06:1216531:1216902 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/IPC
f16n17:1090964:1091309 [5] NCCL INFO Channel 01/0 : 7[5] -> 6[4] via P2P/IPC
d17n06:1216531:1216902 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/IPC
f17n02:1076284:1076617 [5] NCCL INFO Connected all rings
f17n02:1076284:1076617 [5] NCCL INFO Channel 00/0 : 1[5] -> 0[4] via P2P/IPC
d11n16:1130273:1130617 [5] NCCL INFO Connected all rings
d11n16:1130273:1130617 [5] NCCL INFO Channel 00/0 : 1[5] -> 0[4] via P2P/IPC
f16n16:1079916:1080252 [4] NCCL INFO Connected all rings
f16n16:1079916:1080252 [4] NCCL INFO Channel 00/0 : 0[4] -> 2[0] [send] via NET/IB/1
f16n16:1079916:1080252 [4] NCCL INFO Channel 01/0 : 0[4] -> 2[0] [send] via NET/IB/1
f16n16:1079916:1080252 [4] NCCL INFO Channel 00/0 : 2[0] -> 0[4] [receive] via NET/IB/1
f16n16:1079916:1080252 [4] NCCL INFO Channel 01/0 : 2[0] -> 0[4] [receive] via NET/IB/1
d14n11:1169358:1169710 [2] NCCL INFO Connected all trees
d14n11:1169358:1169710 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n11:1169358:1169710 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n16:1130273:1130617 [5] NCCL INFO Channel 01/0 : 1[5] -> 0[4] via P2P/IPC
f17n02:1076284:1076617 [5] NCCL INFO Channel 01/0 : 1[5] -> 0[4] via P2P/IPC
d14n09:567666:568034 [0] NCCL INFO comm 0x1818e7e40 rank 6 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x9b8dd052a7b10a2a - Init COMPLETE
d14n08:1173249:1173604 [2] NCCL INFO comm 0x151953900 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x9b8dd052a7b10a2a - Init COMPLETE
d14n09:567667:568033 [1] NCCL INFO comm 0x14ff73090 rank 7 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x9b8dd052a7b10a2a - Init COMPLETE
d14n08:1173248:1173607 [1] NCCL INFO comm 0x13975b2c0 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x9b8dd052a7b10a2a - Init COMPLETE
d14n08:1173247:1173602 [0] NCCL INFO comm 0x13709cfe0 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x9b8dd052a7b10a2a - Init COMPLETE
d14n08:1173250:1173606 [3] NCCL INFO comm 0x1674a4700 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x9b8dd052a7b10a2a - Init COMPLETE
d14n08:1173252:1173603 [5] NCCL INFO comm 0x133599100 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x9b8dd052a7b10a2a - Init COMPLETE
d14n08:1173251:1173605 [4] NCCL INFO comm 0x15f43e540 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x9b8dd052a7b10a2a - Init COMPLETE
f16n17:1090959:1091308 [0] NCCL INFO Connected all rings
f16n17:1090959:1091308 [0] NCCL INFO Channel 00/0 : 0[4] -> 2[0] [receive] via NET/IB/0
f16n17:1090959:1091308 [0] NCCL INFO Channel 01/0 : 0[4] -> 2[0] [receive] via NET/IB/0
f16n17:1090959:1091308 [0] NCCL INFO Channel 00/0 : 2[0] -> 0[4] [send] via NET/IB/0
f16n17:1090959:1091308 [0] NCCL INFO Channel 01/0 : 2[0] -> 0[4] [send] via NET/IB/0
d14n10:565686:566030 [5] NCCL INFO Connected all rings
d14n10:565686:566030 [5] NCCL INFO Channel 00/0 : 1[5] -> 0[4] via P2P/IPC
d17n06:1216532:1216898 [2] NCCL INFO Connected all trees
d17n06:1216532:1216898 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d17n06:1216532:1216898 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n10:565686:566030 [5] NCCL INFO Channel 01/0 : 1[5] -> 0[4] via P2P/IPC
f18n05:1008219:1008555 [0] NCCL INFO Connected all rings
f18n05:1008219:1008555 [0] NCCL INFO Channel 00/0 : 0[4] -> 2[0] [receive] via NET/IB/0
f18n05:1008219:1008555 [0] NCCL INFO Channel 01/0 : 0[4] -> 2[0] [receive] via NET/IB/0
f18n05:1008219:1008555 [0] NCCL INFO Channel 00/0 : 2[0] -> 0[4] [send] via NET/IB/0
f18n05:1008219:1008555 [0] NCCL INFO Channel 01/0 : 2[0] -> 0[4] [send] via NET/IB/0
f17n02:1076283:1076612 [4] NCCL INFO Channel 00/0 : 2[0] -> 0[4] [receive] via NET/IB/1
f17n02:1076283:1076612 [4] NCCL INFO Channel 01/0 : 2[0] -> 0[4] [receive] via NET/IB/1
d11n16:1130272:1130616 [4] NCCL INFO Connected all rings
d11n16:1130272:1130616 [4] NCCL INFO Channel 00/0 : 0[4] -> 2[0] [send] via NET/IB/1
d11n16:1130272:1130616 [4] NCCL INFO Channel 01/0 : 0[4] -> 2[0] [send] via NET/IB/1
d11n16:1130272:1130616 [4] NCCL INFO Channel 00/0 : 2[0] -> 0[4] [receive] via NET/IB/1
d11n16:1130272:1130616 [4] NCCL INFO Channel 01/0 : 2[0] -> 0[4] [receive] via NET/IB/1
d17n07:1212411:1212779 [1] NCCL INFO Connected all rings
d17n07:1212411:1212779 [1] NCCL INFO Channel 00/0 : 7[1] -> 6[0] via P2P/IPC
d11n17:1142854:1143190 [0] NCCL INFO Connected all rings
d11n17:1142854:1143190 [0] NCCL INFO Channel 00/0 : 0[4] -> 2[0] [receive] via NET/IB/0
d11n17:1142854:1143190 [0] NCCL INFO Channel 01/0 : 0[4] -> 2[0] [receive] via NET/IB/0
d11n17:1142854:1143190 [0] NCCL INFO Channel 00/0 : 2[0] -> 0[4] [send] via NET/IB/0
d11n17:1142854:1143190 [0] NCCL INFO Channel 01/0 : 2[0] -> 0[4] [send] via NET/IB/0
f16n17:1090964:1091309 [5] NCCL INFO Connected all trees
f16n17:1090964:1091309 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n17:1090964:1091309 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n16:1079917:1080257 [5] NCCL INFO Connected all trees
f16n16:1079917:1080257 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n16:1079917:1080257 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n07:1212411:1212779 [1] NCCL INFO Channel 01/0 : 7[1] -> 6[0] via P2P/IPC
d17n07:1212410:1212780 [0] NCCL INFO Connected all rings
d17n07:1212410:1212780 [0] NCCL INFO Channel 00/0 : 6[0] -> 0[0] [send] via NET/IB/0
d17n07:1212410:1212780 [0] NCCL INFO Channel 01/0 : 6[0] -> 0[0] [send] via NET/IB/0
d17n07:1212410:1212780 [0] NCCL INFO Channel 00/0 : 0[0] -> 6[0] [receive] via NET/IB/0
d17n07:1212410:1212780 [0] NCCL INFO Channel 01/0 : 0[0] -> 6[0] [receive] via NET/IB/0
d17n06:1216530:1216897 [0] NCCL INFO Connected all rings
d17n06:1216530:1216897 [0] NCCL INFO Channel 00/0 : 6[0] -> 0[0] [receive] via NET/IB/0
d17n06:1216530:1216897 [0] NCCL INFO Channel 01/0 : 6[0] -> 0[0] [receive] via NET/IB/0
d17n06:1216530:1216897 [0] NCCL INFO Channel 00/0 : 0[0] -> 6[0] [send] via NET/IB/0
d17n06:1216530:1216897 [0] NCCL INFO Channel 01/0 : 0[0] -> 6[0] [send] via NET/IB/0
f17n02:1076284:1076617 [5] NCCL INFO Connected all trees
f17n02:1076284:1076617 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f17n02:1076284:1076617 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n16:1130273:1130617 [5] NCCL INFO Connected all trees
d11n16:1130273:1130617 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d11n16:1130273:1130617 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f18n05:1008220:1008558 [1] NCCL INFO Connected all trees
f18n05:1008220:1008558 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f18n05:1008220:1008558 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n07:1212411:1212779 [1] NCCL INFO Connected all trees
d17n07:1212411:1212779 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d17n07:1212411:1212779 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n17:1142855:1143188 [1] NCCL INFO Connected all trees
d11n17:1142855:1143188 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d11n17:1142855:1143188 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n17:1090963:1091311 [4] NCCL INFO Connected all trees
f16n17:1090963:1091311 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n17:1090963:1091311 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n06:1216531:1216902 [1] NCCL INFO Connected all trees
d17n06:1216531:1216902 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d17n06:1216531:1216902 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n17:1090960:1091307 [1] NCCL INFO Connected all trees
f16n17:1090960:1091307 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n17:1090960:1091307 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n11:1169361:1169713 [5] NCCL INFO Connected all rings
d14n11:1169361:1169713 [5] NCCL INFO Channel 00/0 : 7[5] -> 6[4] via P2P/IPC
d14n11:1169361:1169713 [5] NCCL INFO Channel 01/0 : 7[5] -> 6[4] via P2P/IPC
f17n01:970276:970615 [0] NCCL INFO Channel 00/0 : 5[5] -> 6[0] [receive] via NET/IB/0
f17n01:970276:970615 [0] NCCL INFO Channel 01/0 : 5[5] -> 6[0] [receive] via NET/IB/0
f17n01:970276:970615 [0] NCCL INFO Channel 00/0 : 6[0] -> 7[1] via P2P/IPC
f17n01:970276:970615 [0] NCCL INFO Channel 01/0 : 6[0] -> 7[1] via P2P/IPC
d14n10:565685:566029 [4] NCCL INFO Connected all rings
d14n10:565685:566029 [4] NCCL INFO Channel 00/0 : 0[4] -> 2[0] [send] via NET/IB/1
d14n10:565685:566029 [4] NCCL INFO Channel 01/0 : 0[4] -> 2[0] [send] via NET/IB/1
d14n10:565685:566029 [4] NCCL INFO Channel 00/0 : 2[0] -> 0[4] [receive] via NET/IB/1
d14n10:565685:566029 [4] NCCL INFO Channel 01/0 : 2[0] -> 0[4] [receive] via NET/IB/1
d14n11:1169356:1169711 [0] NCCL INFO Connected all rings
d14n11:1169356:1169711 [0] NCCL INFO Channel 00/0 : 0[4] -> 2[0] [receive] via NET/IB/0
d14n11:1169356:1169711 [0] NCCL INFO Channel 01/0 : 0[4] -> 2[0] [receive] via NET/IB/0
d14n11:1169356:1169711 [0] NCCL INFO Channel 00/0 : 2[0] -> 0[4] [send] via NET/IB/0
d14n11:1169356:1169711 [0] NCCL INFO Channel 01/0 : 2[0] -> 0[4] [send] via NET/IB/0
d14n11:1169361:1169713 [5] NCCL INFO Connected all trees
d14n11:1169361:1169713 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n11:1169361:1169713 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n10:565686:566030 [5] NCCL INFO Connected all trees
d14n10:565686:566030 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n10:565686:566030 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d09n07:1063020:1063430 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d09n07:1063021:1063429 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d09n07:1063019:1063433 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d09n07:1063018:1063432 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d14n11:1169360:1169712 [4] NCCL INFO Connected all trees
d14n11:1169360:1169712 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n11:1169360:1169712 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d09n07:1063022:1063431 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d11n17:1142854:1143190 [0] NCCL INFO Connected all trees
d11n17:1142854:1143190 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d11n17:1142854:1143190 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n16:1130272:1130616 [4] NCCL INFO Connected all trees
d11n16:1130272:1130616 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d11n16:1130272:1130616 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n06:1216530:1216897 [0] NCCL INFO Connected all trees
d17n06:1216530:1216897 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d17n06:1216530:1216897 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n07:1212410:1212780 [0] NCCL INFO Connected all trees
d17n07:1212410:1212780 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d17n07:1212410:1212780 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n17:1090959:1091308 [0] NCCL INFO Connected all trees
f16n17:1090959:1091308 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n17:1090959:1091308 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n18:1091871:1092227 [5] NCCL INFO Connected all rings
f16n18:1091871:1092227 [5] NCCL INFO Channel 00/0 : 5[5] -> 4[4] via P2P/IPC
f17n01:970277:970616 [1] NCCL INFO Connected all rings
f17n01:970277:970616 [1] NCCL INFO Channel 00/0 : 7[1] -> 6[0] via P2P/IPC
f16n18:1091871:1092227 [5] NCCL INFO Channel 01/0 : 5[5] -> 4[4] via P2P/IPC
f16n16:1079916:1080252 [4] NCCL INFO Connected all trees
f16n16:1079916:1080252 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n16:1079916:1080252 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f17n01:970277:970616 [1] NCCL INFO Channel 01/0 : 7[1] -> 6[0] via P2P/IPC
d14n11:1169357:1169715 [1] NCCL INFO Connected all trees
d14n11:1169357:1169715 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n11:1169357:1169715 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f17n01:970276:970615 [0] NCCL INFO Connected all rings
f17n01:970276:970615 [0] NCCL INFO Channel 00/0 : 6[0] -> 0[0] [send] via NET/IB/0
f17n01:970276:970615 [0] NCCL INFO Channel 01/0 : 6[0] -> 0[0] [send] via NET/IB/0
f17n01:970276:970615 [0] NCCL INFO Channel 00/0 : 0[0] -> 6[0] [receive] via NET/IB/0
f17n01:970276:970615 [0] NCCL INFO Channel 01/0 : 0[0] -> 6[0] [receive] via NET/IB/0
d11n17:1142854:1143190 [0] NCCL INFO comm 0x15a1f3e40 rank 2 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0xfda37076ce67c0f7 - Init COMPLETE
d11n17:1142855:1143188 [1] NCCL INFO comm 0x12fc64740 rank 3 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0xfda37076ce67c0f7 - Init COMPLETE
d11n16:1130272:1130616 [4] NCCL INFO comm 0x1248d0300 rank 0 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xfda37076ce67c0f7 - Init COMPLETE
d11n17:1142856:1143189 [2] NCCL INFO comm 0x13b217780 rank 4 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0xfda37076ce67c0f7 - Init COMPLETE
d11n16:1130273:1130617 [5] NCCL INFO comm 0x1507718a0 rank 1 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xfda37076ce67c0f7 - Init COMPLETE
d11n17:1142857:1143193 [3] NCCL INFO comm 0x12fee2fe0 rank 5 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xfda37076ce67c0f7 - Init COMPLETE
f16n18:1091866:1092223 [0] NCCL INFO Connected all rings
f16n18:1091866:1092223 [0] NCCL INFO Channel 00/0 : 6[0] -> 0[0] [receive] via NET/IB/0
f16n18:1091866:1092223 [0] NCCL INFO Channel 01/0 : 6[0] -> 0[0] [receive] via NET/IB/0
f16n18:1091866:1092223 [0] NCCL INFO Channel 00/0 : 0[0] -> 6[0] [send] via NET/IB/0
f16n18:1091866:1092223 [0] NCCL INFO Channel 01/0 : 0[0] -> 6[0] [send] via NET/IB/0
d11n17:1142858:1143191 [4] NCCL INFO comm 0x133c87c40 rank 6 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xfda37076ce67c0f7 - Init COMPLETE
d11n17:1142859:1143192 [5] NCCL INFO comm 0x13316bc80 rank 7 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xfda37076ce67c0f7 - Init COMPLETE
f16n18:1091871:1092227 [5] NCCL INFO Connected all trees
f16n18:1091871:1092227 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n18:1091871:1092227 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f17n01:970277:970616 [1] NCCL INFO Connected all trees
f17n01:970277:970616 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f17n01:970277:970616 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n06:1216530:1216897 [0] NCCL INFO comm 0x146e31830 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x6d43618daca01626 - Init COMPLETE
d17n07:1212410:1212780 [0] NCCL INFO comm 0x171388400 rank 6 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x6d43618daca01626 - Init COMPLETE
d17n06:1216532:1216898 [2] NCCL INFO comm 0x1305ee140 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x6d43618daca01626 - Init COMPLETE
d17n07:1212411:1212779 [1] NCCL INFO comm 0x17ad21220 rank 7 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x6d43618daca01626 - Init COMPLETE
d17n06:1216531:1216902 [1] NCCL INFO comm 0x123373840 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x6d43618daca01626 - Init COMPLETE
d17n06:1216533:1216901 [3] NCCL INFO comm 0x13ee3a700 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x6d43618daca01626 - Init COMPLETE
d17n06:1216534:1216900 [4] NCCL INFO comm 0x1299b2840 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x6d43618daca01626 - Init COMPLETE
d17n06:1216535:1216899 [5] NCCL INFO comm 0x13d8e37c0 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x6d43618daca01626 - Init COMPLETE
f16n17:1090960:1091307 [1] NCCL INFO comm 0x16340ae40 rank 3 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa97eee98a5fa0988 - Init COMPLETE
f16n16:1079917:1080257 [5] NCCL INFO comm 0x171002a40 rank 1 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa97eee98a5fa0988 - Init COMPLETE
f16n17:1090961:1091306 [2] NCCL INFO comm 0x122f1c400 rank 4 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa97eee98a5fa0988 - Init COMPLETE
f16n16:1079916:1080252 [4] NCCL INFO comm 0x1520629c0 rank 0 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa97eee98a5fa0988 - Init COMPLETE
f16n17:1090959:1091308 [0] NCCL INFO comm 0x144eedb80 rank 2 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa97eee98a5fa0988 - Init COMPLETE
f16n17:1090962:1091310 [3] NCCL INFO comm 0x139dc8240 rank 5 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa97eee98a5fa0988 - Init COMPLETE
f16n18:1091870:1092228 [4] NCCL INFO Connected all trees
f16n18:1091870:1092228 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n18:1091870:1092228 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n17:1090963:1091311 [4] NCCL INFO comm 0x13dafd580 rank 6 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa97eee98a5fa0988 - Init COMPLETE
f16n17:1090964:1091309 [5] NCCL INFO comm 0x16eaade80 rank 7 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa97eee98a5fa0988 - Init COMPLETE
f16n18:1091867:1092224 [1] NCCL INFO Connected all trees
f16n18:1091867:1092224 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n18:1091867:1092224 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n11:1169356:1169711 [0] NCCL INFO Connected all trees
d14n11:1169356:1169711 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n11:1169356:1169711 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n10:565685:566029 [4] NCCL INFO Connected all trees
d14n10:565685:566029 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n10:565685:566029 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n11:1169356:1169711 [0] NCCL INFO comm 0x1541c3600 rank 2 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0xb823d8d2b1ba67a3 - Init COMPLETE
d14n11:1169358:1169710 [2] NCCL INFO comm 0x14216a700 rank 4 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0xb823d8d2b1ba67a3 - Init COMPLETE
d14n11:1169357:1169715 [1] NCCL INFO comm 0x130ad17b0 rank 3 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0xb823d8d2b1ba67a3 - Init COMPLETE
d14n11:1169359:1169714 [3] NCCL INFO comm 0x1685295c0 rank 5 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xb823d8d2b1ba67a3 - Init COMPLETE
d14n10:565685:566029 [4] NCCL INFO comm 0x161c23e80 rank 0 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xb823d8d2b1ba67a3 - Init COMPLETE
d14n11:1169360:1169712 [4] NCCL INFO comm 0x1177ed1c0 rank 6 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xb823d8d2b1ba67a3 - Init COMPLETE
d14n10:565686:566030 [5] NCCL INFO comm 0x1165f5380 rank 1 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xb823d8d2b1ba67a3 - Init COMPLETE
d14n11:1169361:1169713 [5] NCCL INFO comm 0x124198700 rank 7 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xb823d8d2b1ba67a3 - Init COMPLETE
f16n18:1091866:1092223 [0] NCCL INFO Connected all trees
f16n18:1091866:1092223 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n18:1091866:1092223 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f17n01:970276:970615 [0] NCCL INFO Connected all trees
f17n01:970276:970615 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f17n01:970276:970615 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f17n01:970276:970615 [0] NCCL INFO comm 0x15b570240 rank 6 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x419c2a0ad9e17ee9 - Init COMPLETE
f16n18:1091869:1092226 [3] NCCL INFO comm 0x14fd46050 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x419c2a0ad9e17ee9 - Init COMPLETE
f17n01:970277:970616 [1] NCCL INFO comm 0x147e6c080 rank 7 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x419c2a0ad9e17ee9 - Init COMPLETE
f16n18:1091867:1092224 [1] NCCL INFO comm 0x15a85cb00 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x419c2a0ad9e17ee9 - Init COMPLETE
f16n18:1091866:1092223 [0] NCCL INFO comm 0x11bb9a640 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x419c2a0ad9e17ee9 - Init COMPLETE
f16n18:1091868:1092225 [2] NCCL INFO comm 0x1723f4600 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x419c2a0ad9e17ee9 - Init COMPLETE
f16n18:1091870:1092228 [4] NCCL INFO comm 0x1701c3d00 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x419c2a0ad9e17ee9 - Init COMPLETE
f16n18:1091871:1092227 [5] NCCL INFO comm 0x14e761b40 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x419c2a0ad9e17ee9 - Init COMPLETE
d09n08:1073955:1074297 [1] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
d09n08:1073955:1074297 [1] NCCL INFO P2P Chunksize set to 131072
d09n07:1063022:1063431 [5] NCCL INFO Trees [0] -1/-1/-1->5->4 [1] -1/-1/-1->5->4
d09n07:1063022:1063431 [5] NCCL INFO P2P Chunksize set to 131072
d09n07:1063020:1063430 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2
d09n07:1063020:1063430 [3] NCCL INFO P2P Chunksize set to 131072
d09n07:1063019:1063433 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
d09n07:1063019:1063433 [2] NCCL INFO P2P Chunksize set to 131072
d09n07:1063016:1063428 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7
d09n07:1063016:1063428 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7
d09n07:1063016:1063428 [0] NCCL INFO Trees [0] 1/6/-1->0->-1 [1] 1/-1/-1->0->6
d09n07:1063016:1063428 [0] NCCL INFO P2P Chunksize set to 131072
d09n07:1063016:1063428 [0] NCCL INFO Channel 00/0 : 7[1] -> 0[0] [receive] via NET/IB/0
d09n07:1063016:1063428 [0] NCCL INFO Channel 01/0 : 7[1] -> 0[0] [receive] via NET/IB/0
d09n07:1063016:1063428 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/IPC
d09n07:1063018:1063432 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
d09n07:1063018:1063432 [1] NCCL INFO P2P Chunksize set to 131072
d09n07:1063016:1063428 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/IPC
d09n07:1063021:1063429 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3
d09n07:1063021:1063429 [4] NCCL INFO P2P Chunksize set to 131072
d09n07:1063020:1063430 [3] NCCL INFO Channel 00/0 : 3[3] -> 4[4] via P2P/IPC
d09n07:1063019:1063433 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/IPC
d09n07:1063018:1063432 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/IPC
d09n07:1063020:1063430 [3] NCCL INFO Channel 01/0 : 3[3] -> 4[4] via P2P/IPC
d09n07:1063019:1063433 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/IPC
d09n07:1063021:1063429 [4] NCCL INFO Channel 00/0 : 4[4] -> 5[5] via P2P/IPC
d09n07:1063018:1063432 [1] NCCL INFO Channel 01/0 : 1[1] -> 2[2] via P2P/IPC
d09n07:1063021:1063429 [4] NCCL INFO Channel 01/0 : 4[4] -> 5[5] via P2P/IPC
f18n05:1008219:1008555 [0] NCCL INFO Connected all trees
f18n05:1008219:1008555 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f18n05:1008219:1008555 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f17n02:1076283:1076612 [4] NCCL INFO Connected all trees
f17n02:1076283:1076612 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f17n02:1076283:1076612 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d09n07:1063020:1063430 [3] NCCL INFO Connected all rings
d09n07:1063021:1063429 [4] NCCL INFO Connected all rings
f18n05:1008219:1008555 [0] NCCL INFO comm 0x15942e440 rank 2 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0xf0d7c583d79fb505 - Init COMPLETE
f18n05:1008220:1008558 [1] NCCL INFO comm 0x168afafc0 rank 3 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0xf0d7c583d79fb505 - Init COMPLETE
f18n05:1008221:1008554 [2] NCCL INFO comm 0x164165680 rank 4 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0xf0d7c583d79fb505 - Init COMPLETE
f18n05:1008222:1008559 [3] NCCL INFO comm 0x152647900 rank 5 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xf0d7c583d79fb505 - Init COMPLETE
f17n02:1076283:1076612 [4] NCCL INFO comm 0x15a17b680 rank 0 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xf0d7c583d79fb505 - Init COMPLETE
f18n05:1008223:1008556 [4] NCCL INFO comm 0x17dfcfda0 rank 6 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xf0d7c583d79fb505 - Init COMPLETE
f17n02:1076284:1076617 [5] NCCL INFO comm 0x14a6847c0 rank 1 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xf0d7c583d79fb505 - Init COMPLETE
f18n05:1008224:1008557 [5] NCCL INFO comm 0x14ec36e60 rank 7 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xf0d7c583d79fb505 - Init COMPLETE
d09n07:1063020:1063430 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/IPC
d09n07:1063021:1063429 [4] NCCL INFO Channel 00/0 : 4[4] -> 3[3] via P2P/IPC
d09n07:1063018:1063432 [1] NCCL INFO Connected all rings
d09n07:1063020:1063430 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/IPC
d09n07:1063021:1063429 [4] NCCL INFO Channel 01/0 : 4[4] -> 3[3] via P2P/IPC
d09n07:1063019:1063433 [2] NCCL INFO Connected all rings
d09n07:1063018:1063432 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/IPC
d09n07:1063018:1063432 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/IPC
d09n07:1063019:1063433 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/IPC
d09n07:1063019:1063433 [2] NCCL INFO Channel 01/0 : 2[2] -> 1[1] via P2P/IPC
d09n08:1073954:1074298 [0] NCCL INFO Trees [0] 7/-1/-1->6->0 [1] 7/0/-1->6->-1
d09n08:1073954:1074298 [0] NCCL INFO P2P Chunksize set to 131072
d09n08:1073954:1074298 [0] NCCL INFO Channel 00/0 : 5[5] -> 6[0] [receive] via NET/IB/0
d09n08:1073954:1074298 [0] NCCL INFO Channel 01/0 : 5[5] -> 6[0] [receive] via NET/IB/0
d09n08:1073954:1074298 [0] NCCL INFO Channel 00/0 : 6[0] -> 7[1] via P2P/IPC
d09n08:1073955:1074297 [1] NCCL INFO Channel 00/0 : 7[1] -> 0[0] [send] via NET/IB/0
d09n08:1073955:1074297 [1] NCCL INFO Channel 01/0 : 7[1] -> 0[0] [send] via NET/IB/0
d09n07:1063020:1063430 [3] NCCL INFO Connected all trees
d09n07:1063020:1063430 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d09n07:1063020:1063430 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d09n07:1063019:1063433 [2] NCCL INFO Connected all trees
d09n07:1063019:1063433 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d09n07:1063019:1063433 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d09n07:1063022:1063431 [5] NCCL INFO Channel 00/0 : 5[5] -> 6[0] [send] via NET/IB/1
d09n07:1063022:1063431 [5] NCCL INFO Channel 01/0 : 5[5] -> 6[0] [send] via NET/IB/1
d09n08:1073954:1074298 [0] NCCL INFO Channel 01/0 : 6[0] -> 7[1] via P2P/IPC
d09n07:1063022:1063431 [5] NCCL INFO Connected all rings
d09n07:1063022:1063431 [5] NCCL INFO Channel 00/0 : 5[5] -> 4[4] via P2P/IPC
d09n08:1073955:1074297 [1] NCCL INFO Connected all rings
d09n08:1073955:1074297 [1] NCCL INFO Channel 00/0 : 7[1] -> 6[0] via P2P/IPC
d09n07:1063022:1063431 [5] NCCL INFO Channel 01/0 : 5[5] -> 4[4] via P2P/IPC
d09n08:1073955:1074297 [1] NCCL INFO Channel 01/0 : 7[1] -> 6[0] via P2P/IPC
d09n08:1073954:1074298 [0] NCCL INFO Connected all rings
d09n08:1073954:1074298 [0] NCCL INFO Channel 00/0 : 6[0] -> 0[0] [send] via NET/IB/0
d09n08:1073954:1074298 [0] NCCL INFO Channel 01/0 : 6[0] -> 0[0] [send] via NET/IB/0
d09n08:1073954:1074298 [0] NCCL INFO Channel 00/0 : 0[0] -> 6[0] [receive] via NET/IB/0
d09n08:1073954:1074298 [0] NCCL INFO Channel 01/0 : 0[0] -> 6[0] [receive] via NET/IB/0
d09n07:1063016:1063428 [0] NCCL INFO Connected all rings
d09n07:1063016:1063428 [0] NCCL INFO Channel 00/0 : 6[0] -> 0[0] [receive] via NET/IB/0
d09n07:1063016:1063428 [0] NCCL INFO Channel 01/0 : 6[0] -> 0[0] [receive] via NET/IB/0
d09n07:1063016:1063428 [0] NCCL INFO Channel 00/0 : 0[0] -> 6[0] [send] via NET/IB/0
d09n07:1063016:1063428 [0] NCCL INFO Channel 01/0 : 0[0] -> 6[0] [send] via NET/IB/0
d09n07:1063022:1063431 [5] NCCL INFO Connected all trees
d09n07:1063022:1063431 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d09n07:1063022:1063431 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d09n07:1063021:1063429 [4] NCCL INFO Connected all trees
d09n07:1063021:1063429 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d09n07:1063021:1063429 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d09n08:1073955:1074297 [1] NCCL INFO Connected all trees
d09n08:1073955:1074297 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d09n08:1073955:1074297 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d09n07:1063018:1063432 [1] NCCL INFO Connected all trees
d09n07:1063018:1063432 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d09n07:1063018:1063432 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d09n08:1073954:1074298 [0] NCCL INFO Connected all trees
d09n08:1073954:1074298 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d09n08:1073954:1074298 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d09n07:1063016:1063428 [0] NCCL INFO Connected all trees
d09n07:1063016:1063428 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d09n07:1063016:1063428 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d09n07:1063016:1063428 [0] NCCL INFO comm 0x13e5515c0 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa299daa6e1c0b47e - Init COMPLETE
d09n08:1073955:1074297 [1] NCCL INFO comm 0x15b11a600 rank 7 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa299daa6e1c0b47e - Init COMPLETE
d09n07:1063018:1063432 [1] NCCL INFO comm 0x1253a5050 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0xa299daa6e1c0b47e - Init COMPLETE
d09n08:1073954:1074298 [0] NCCL INFO comm 0x14a84e440 rank 6 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa299daa6e1c0b47e - Init COMPLETE
d09n07:1063019:1063433 [2] NCCL INFO comm 0x1635ca9a0 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0xa299daa6e1c0b47e - Init COMPLETE
Rank: 6 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,130] [INFO] [engine.py:138:__init__] RANK=6 STAGE=0 LAYERS=37 [0, 37) STAGE_PARAMS=840818688 (840.819M) TOTAL_PARAMS=6726549504 (6726.550M) UNIQUE_PARAMS=6726549504 (6726.550M)
d09n07:1063020:1063430 [3] NCCL INFO comm 0x11d84dd00 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xa299daa6e1c0b47e - Init COMPLETE
Rank: 7 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,130] [INFO] [engine.py:138:__init__] RANK=7 STAGE=0 LAYERS=37 [0, 37) STAGE_PARAMS=840818688 (840.819M) TOTAL_PARAMS=6726549504 (6726.550M) UNIQUE_PARAMS=6726549504 (6726.550M)
d09n07:1063021:1063429 [4] NCCL INFO comm 0x17910c140 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xa299daa6e1c0b47e - Init COMPLETE
d09n07:1063022:1063431 [5] NCCL INFO comm 0x168d681c0 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xa299daa6e1c0b47e - Init COMPLETE
Rank: 1 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,130] [INFO] [engine.py:138:__init__] RANK=1 STAGE=0 LAYERS=37 [0, 37) STAGE_PARAMS=840818688 (840.819M) TOTAL_PARAMS=6726549504 (6726.550M) UNIQUE_PARAMS=6726549504 (6726.550M)
[2024-03-04 16:46:28,130] [INFO] [engine.py:138:__init__] RANK=0 STAGE=0 LAYERS=37 [0, 37) STAGE_PARAMS=840818688 (840.819M) TOTAL_PARAMS=6726549504 (6726.550M) UNIQUE_PARAMS=6726549504 (6726.550M)
Rank: 2 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,130] [INFO] [engine.py:138:__init__] RANK=2 STAGE=0 LAYERS=37 [0, 37) STAGE_PARAMS=840818688 (840.819M) TOTAL_PARAMS=6726549504 (6726.550M) UNIQUE_PARAMS=6726549504 (6726.550M)
Rank: 3 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,130] [INFO] [engine.py:138:__init__] RANK=3 STAGE=0 LAYERS=37 [0, 37) STAGE_PARAMS=840818688 (840.819M) TOTAL_PARAMS=6726549504 (6726.550M) UNIQUE_PARAMS=6726549504 (6726.550M)
Rank: 4 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,130] [INFO] [engine.py:138:__init__] RANK=4 STAGE=0 LAYERS=37 [0, 37) STAGE_PARAMS=840818688 (840.819M) TOTAL_PARAMS=6726549504 (6726.550M) UNIQUE_PARAMS=6726549504 (6726.550M)
Rank: 5 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,130] [INFO] [engine.py:138:__init__] RANK=5 STAGE=0 LAYERS=37 [0, 37) STAGE_PARAMS=840818688 (840.819M) TOTAL_PARAMS=6726549504 (6726.550M) UNIQUE_PARAMS=6726549504 (6726.550M)
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=0, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=3, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=1, lazy_mpu_init=None, use_cpu_initial[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
WARNING: could not find the metadata file /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1 
    will not load any checkpoints and will start from random
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=4, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=5, lazy_mpu_init=None, use_cpu_initial[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=2, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=90, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=0, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=93, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=95, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=94, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=1, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=91, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=5, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=92, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 90 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=0, lazy_mpu_init=None, use_cpu_initialsamples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 93 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=3, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=2, lazy_mpu_init=None, use_cpu_initialsamples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 95 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=4, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=0, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=1, lazy_mpu_init=None, use_cpu_initial[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=8, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_sArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=0, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=42, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 94 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=43, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 91 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 92 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=3, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=1, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=2, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=2, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=47, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=3, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=0, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=3, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=4, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=1, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=5, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=4, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=4, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=5, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=0, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=0, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=2, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=1, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=3, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=9, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_sArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=0, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=5, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=2, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=5, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=4, lazy_mpu_init=None, use_cpu_initialamples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 8 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=1, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=2, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=24, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=10, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=1, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=2, lazy_mpu_init=None, use_cpu_initialamples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 9 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=4, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=3, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=27, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=1, lazy_mpu_init=None, use_cpu_initialsamples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 10 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=3, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=28, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=4, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=48, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=0, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=3, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=5, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=49, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 42 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=2, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=52, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=4, lazy_mpu_init=None, use_cpu_initialsamples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 47 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=11, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=3, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=44, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 48 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=5, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=25, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=5, lazy_mpu_init=None, use_cpu_initialsamples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 43 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=2, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=30, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=70, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=46, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 11 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=1, lazy_mpu_init=None, use_cpu_initialsamples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 44 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=53, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=54, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=67, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=0, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=33, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=45, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=29, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=18, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 45 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=5, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=56, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=66, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 46 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=4, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=0, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=20, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=55, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=68, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 49 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=34, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=26, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=21, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=58, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 67 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=50, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=2, lazy_mpu_init=None, use_cpu_initialsamples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 20 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=4, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=57, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 70 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=2, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=32, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 25 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=23, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 54 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 68 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=51, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=5, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=3, lazy_mpu_init=None, use_cpu_initialsamples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 18 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 55 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=69, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=31, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 52 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 24 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=19, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 57 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 66 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 53 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=4, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=22, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=1, lazy_mpu_init=None, use_cpu_initialsamples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 58 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=71, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=0, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=35, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 26 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 19 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 56 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 69 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 50 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=3, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=78, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 22 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=59, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 71 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 30 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=0, lazy_mpu_init=None, use_cpu_initialsamples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 21 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 51 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 27 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 59 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 23 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=3, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=79, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=14, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 34 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 28 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=5, lazy_mpu_init=None, use_cpu_initialsamples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 33 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 29 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=80, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=4, lazy_mpu_init=None, use_cpu_initialsamples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 32 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=5, lazy_mpu_init=None, use_cpu_initialArgs= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=5, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=81, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=16, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 31 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=2, lazy_mpu_init=None, use_cpu_initialsamples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 78 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 35 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=72, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 79 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=1, lazy_mpu_init=None, use_cpu_initialsamples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 80 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=76, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=1, lazy_mpu_init=None, use_cpu_initialsamples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 81 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=17, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=82, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=75, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=83, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 82 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=60, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 83 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=2, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=13, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=61, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 14 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=4, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=77, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=63, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=73, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=4, lazy_mpu_init=None, use_cpu_initialization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=15, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 72 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=74, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=64, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 76 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 16 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 75 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=3, lazy_mpu_init=None, use_cpu_initialsamples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 77 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=65, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 73 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=3, lazy_mpu_init=None, use_cpu_initialsamples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 17 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 74 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=62, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=12, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=36, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 60 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=2, lazy_mpu_init=None, use_cpu_initialsamples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 13 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 62 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 12 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=39, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 65 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=5, lazy_mpu_init=None, use_cpu_initialsamples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 15 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 61 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=38, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 64 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Args= Namespace(num_layers=32, encoder_num_layers=32, decoder_num_layers=None, num_experts=[1], mlp_type='standard', topk=1, expert_interval=2, hidden_size=4096, ffn_hidden_size=16384, num_attention_heads=32, num_key_value_heads=32, kv_channels=128, max_position_embeddings=2048, use_rotary_position_embeddings=False, rope_theta=10000, rotary_percent=1.0, add_position_embedding=True, make_vocab_size_divisible_by=128, normalization='layernorm', layernorm_epsilon=1e-05, apply_layernorm_1p=False, mem_efficient_ln=True, apply_residual_connection_post_layernorm=False, openai_gelu=False, squared_relu=False, swiglu=False, onnx_safe=None, bert_binary_head=True, num_experts_switch=None, untie_embeddings_and_output_weights=False, embedding_weights_in_fp32=False, attention_dropout=0.1, hidden_dropout=0.1, weight_decay=0.1, start_weight_decay=0.1, end_weight_decay=0.1, weight_decay_incr_style='constant', clip_grad=1.0, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, micro_batch_size=1, global_batch_size=24, rampup_batch_size=None, recompute_granularity=None, distribute_saved_activations=False, recompute_method=None, recompute_num_layers=1, checkpoint_activations=True, distribute_checkpointed_activations=False, checkpoint_num_layers=1, train_iters=18310546, train_samples=None, train_tokens=300000000000, random_ltd=False, log_interval=10, exit_interval=None, exit_duration_in_mins=30000000, exit_signal_handler=False, tensorboard_dir='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/tensorboard/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1_batch5_2024.03.04-16.46.02', masked_softmax_fusion=True, bias_gelu_fusion=True, bias_dropout_fusion=True, moe_token_dropping=True, moe_train_capacity_factor=1.0, moe_eval_capacity_factor=1.0, moe_min_capacity=4, moe_loss_coeff=0.01, create_moe_param_group=False, use_flash_attn_v1=False, use_flash_attn_v2=False, use_flash_attn_triton=False, add_bias_linear=True, optimizer='adam', dataloader_type='single', ds_inference=False, cpu_optimizer=False, cpu_torch_adam=False, ds_fused_adam=False, no_pipeline_parallel=False, use_tutel=False, inference=False, async_tensor_model_parallel_allreduce=False, no_persist_layer_norm=False, sequence_parallel=False, ds_sequence_parallel_size=1, force_ds_sequence_parallel=False, gradient_accumulation_fusion=True, use_dataset_only=False, seed=1234, data_parallel_random_init=False, init_method_std=0.014, init_method_xavier_uniform=False, lr=0.00012, lr_decay_style='cosine', lr_decay_iters=None, lr_decay_samples=None, lr_decay_tokens=300000000000, lr_warmup_fraction=None, lr_warmup_iters=0, lr_warmup_samples=0, lr_warmup_tokens=375000000, min_lr=1e-06, override_opt_param_scheduler=True, use_checkpoint_opt_param_scheduler=False, save='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', save_interval=10000, no_save_optim=None, no_save_rng=None, load='/gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1', load_tag=None, no_load_optim=None, no_load_rng=None, no_load_lr_state=False, finetune=False, perform_initialization=True, use_checkpoint_args=False, exit_on_missing_checkpoint=False, universal_checkpoint=False, fp16=True, bf16=False, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, fp32_residual_connection=False, apply_query_key_layer_scaling=True, attention_softmax_in_fp32=False, accumulate_allreduce_grads_in_fp32=False, fp16_lm_cross_entropy=False, tensor_model_parallel_size=8, enable_expert_tensor_parallelism=False, pipeline_model_parallel_size=1, pipeline_model_parallel_split_rank=None, moe_expert_parallel_size=1, num_layers_per_virtual_pipeline_stage=None, overlap_p2p_comm=False, distributed_backend='nccl', distributed_timeout_minutes=10, DDP_impl='local', use_contiguous_buffers_in_local_ddp=True, scatter_gather_tensors_in_pipeline=True, use_ring_exchange_p2p=False, local_rank=1, lazy_mpu_init=None, use_cpu_initialsamples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 63 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=37, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=85, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=40, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=86, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=41, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=84, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 37 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=87, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 36 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=88, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 39 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 85 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 41 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 84 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,132] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 38 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 86 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 40 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
ization=None, empty_unused_memory_level=0, standalone_embedding_stage=False, use_distributed_optimizer=False, eval_iters=10, eval_interval=100, skip_train=False, aml_data_download_path=None, data_path=['/gpfs/alpine2/stf218/world-shared/sajal/gptdata/gpttext_article_document'], split='98,2,0', train_data_path=None, valid_data_path=None, test_data_path=None, data_cache_path=None, vocab_size=None, vocab_file='gpt2-vocab.json', merge_file='gpt2-merges.txt', vocab_extra_ids=0, seq_length=2048, encoder_seq_length=2048, decoder_seq_length=None, retriever_seq_length=256, sample_rate=1.0, mask_prob=0.15, short_seq_prob=0.1, mmap_warmup=False, num_workers=0, tokenizer_type='GPT2BPETokenizer', tokenizer_model=None, data_impl='mmap', reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, train_data_exact_num_epochs=None, return_data_index=False, data_efficiency_curriculum_learning=False, train_idx_path=None, train_desc_path=None, train_doc_idx_path=None, train_sample_idx_path=None, train_shuffle_idx_path=None, repeated_dataloader=False, adlr_autoresume=False, adlr_autoresume_interval=1000, ict_head_size=None, biencoder_projection_dim=0, biencoder_shared_query_context_model=False, ict_load=None, bert_load=None, titles_data_path=None, query_in_block_prob=0.1, use_one_sent_docs=False, evidence_data_path=None, retriever_report_topk_accuracies=[], retriever_score_scaling=False, block_data_path=None, embedding_path=None, indexer_batch_size=128, indexer_log_interval=1000, num_classes=1000, img_h=224, img_w=224, num_channels=3, patch_dim=16, classes_fraction=1.0, data_per_class_fraction=1.0, data_sharding=True, head_lr_mult=1.0, vision_pretraining=False, vision_pretraining_type='classify', vision_backbone_type='vit', swin_backbone_type='tiny', mask_type='random', mask_factor=1.0, iter_per_epoch=1250, dino_local_img_size=96, dino_local_crops_number=10, dino_head_hidden_size=2048, dino_bottleneck_size=256, dino_freeze_last_layer=1, dino_norm_last_layer=False, dino_warmup_teacher_temp=0.04, dino_teacher_temp=0.07, dino_warmup_teacher_temp_epochs=30, log_params_norm=False, log_num_zeros_in_grad=False, timing_log_level=0, barrier_with_L1_time=True, timing_log_option='minmax', tensorboard_log_interval=1, tensorboard_queue_size=1, log_timers_to_tensorboard=True, log_batch_size_to_tensorboard=True, log_learning_rate_to_tensorboard=True, log_loss_scale_to_tensorboard=True, log_validation_ppl_to_tensorboard=True, log_optimizer_states_to_tensorboard=False, log_memory_to_tensorboard=False, log_world_size_to_tensorboard=False, zero_stage=1.0, zero_reduce_scatter=False, zero_contigious_gradients=False, zero_reduce_bucket_size=0.0, zero_allgather_bucket_size=0.0, remote_device='none', use_pin_memory=False, scattered_embeddings=False, split_transformers=False, memory_centric_tiled_linear=False, tile_factor=1, deepspeed_activation_checkpointing=True, partition_activations=False, contigious_checkpointing=False, checkpoint_in_cpu=False, synchronize_each_layer=False, profile_backward=False, num_layers_teacher=None, num_experts_teacher=[1], hidden_size_teacher=None, num_attention_heads_teacher=None, mos=False, kd=False, kd_alpha_ce=1, kd_beta_ce=1, kd_temp=1.0, reset_iteration=False, load_teacher=None, inference_batch_times_seqlen_threshold=512, max_tokens_to_oom=12000, output_bert_embeddings=False, bert_embedder_type='megatron', fp8_e4m3=False, fp8_hybrid=False, fp8_wgrad=True, fp8_margin=0, fp8_interval=1, transformer_impl='local', fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', retro_workdir=None, retro_add_retriever=False, retro_cyclic_train_iters=None, retro_encoder_layers=2, retro_encoder_hidden_dropout=0.1, retro_encoder_attention_dropout=0.1, retro_num_neighbors=2, retro_num_retrieved_chunks=2, retro_return_doc_ids=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ds_pipeline_enabled=True, rank=89, world_size=96, transformer_pipeline_model_parallel_size=1, data_parallel_size=12, virtual_pipeline_model_parallel_size=None, params_dtype=torch.float16, consumed_train_samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 87 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 89 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
samples=0, consumed_valid_samples=0, consumed_train_tokens=0, variable_seq_lengths=False, curriculum_learning_legacy=False, compression_training=False, use_flash_attn=False, padded_vocab_size=51200, deepspeed_config_dict={'train_batch_size': 24, 'train_micro_batch_size_per_gpu': 1, 'steps_per_print': 10, 'zero_optimization': {'stage': 1}, 'gradient_clipping': 1.0, 'prescale_gradients': False, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 500, 'hysteresis': 2, 'min_loss_scale': 1, 'initial_scale_power': 11}, 'bf16': {'enabled': False}, 'curriculum_learning': {'enabled': False, 'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 2349624, 'difficulty_step': 8}}, 'wall_clock_breakdown': False})
Rank: 88 partition count [12, 12] and sizes[(69992448, False), (75776, False)] 
[2024-03-04 16:46:28,133] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed/output/checkpoint/gpt-6.7B-lr-1.2e-4-minlr-1.0e-6-bs-24-gpus-96-mp-8-pp-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
(min, max) time across ranks (ms):
    load-checkpoint ................................: (2.01, 2.08)
[after model, optimizer, and learning rate scheduler are built] datetime: 2024-03-04 16:46:28 
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      439453104
    validation: 43945440
    test:       240
> building train, validation, and test datasets for GPT ...
Single data path provided for train, valid & test
 > building dataset index ...
    reading sizes...
    reading pointers...
    reading document index...
    creating numpy buffer of mmap...
    creating memory view of numpy buffer...
 > finished creating indexed dataset in 0.020839 seconds
    number of documents: 27933
 > dataset split:
    train:
     document indices in [0, 27374) total of 27374 documents
    validation:
     document indices in [27374, 27933) total of 559 documents
    test:
     document indices in [27933, 27933) total of 0 documents
f17n01:970278:970629 [2] NCCL INFO Using network IB
f16n18:1091866:1092241 [0] NCCL INFO Using network IB
d11n16:1130272:1130634 [4] NCCL INFO Using network IB
f17n02:1076283:1076630 [4] NCCL INFO Using network IB
d09n08:1073956:1074311 [2] NCCL INFO Using network IB
f16n16:1079916:1080270 [4] NCCL INFO Using network IB
d14n09:567668:568050 [2] NCCL INFO Using network IB
d14n08:1173247:1173620 [0] NCCL INFO Using network IB
d14n10:565685:566047 [4] NCCL INFO Using network IB
d17n06:1216530:1216915 [0] NCCL INFO Using network IB
d17n07:1212412:1212795 [2] NCCL INFO Using network IB
d09n07:1063016:1063447 [0] NCCL INFO Using network IB
f17n01:970278:970629 [2] NCCL INFO comm 0x15a7b09d0 rank 10 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0x1653a9cbd662af6b - Init START
f16n18:1091866:1092241 [0] NCCL INFO comm 0x11e317280 rank 9 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0x1653a9cbd662af6b - Init START
d11n16:1130272:1130634 [4] NCCL INFO comm 0x127027400 rank 2 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x1653a9cbd662af6b - Init START
f17n02:1076283:1076630 [4] NCCL INFO comm 0x15a13f240 rank 11 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x1653a9cbd662af6b - Init START
d09n08:1073956:1074311 [2] NCCL INFO comm 0x16123ff40 rank 1 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0x1653a9cbd662af6b - Init START
f16n16:1079916:1080270 [4] NCCL INFO comm 0x150d7a680 rank 8 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x1653a9cbd662af6b - Init START
d14n09:567668:568050 [2] NCCL INFO comm 0x12c5cc9b0 rank 4 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0x1653a9cbd662af6b - Init START
d14n08:1173247:1173620 [0] NCCL INFO comm 0x139a351c0 rank 3 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0x1653a9cbd662af6b - Init START
d14n10:565685:566047 [4] NCCL INFO comm 0x1642e3870 rank 5 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x1653a9cbd662af6b - Init START
d17n06:1216530:1216915 [0] NCCL INFO comm 0x148bbcc60 rank 6 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0x1653a9cbd662af6b - Init START
d17n07:1212412:1212795 [2] NCCL INFO comm 0x12f885410 rank 7 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0x1653a9cbd662af6b - Init START
d09n07:1063016:1063447 [0] NCCL INFO comm 0x140f15460 rank 0 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0x1653a9cbd662af6b - Init START
d14n08:1173247:1173620 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d14n08:1173247:1173620 [0] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] 7/1/-1->3->11
d14n08:1173247:1173620 [0] NCCL INFO P2P Chunksize set to 131072
d14n08:1173247:1173620 [0] NCCL INFO Channel 00/0 : 2[4] -> 3[0] [receive] via NET/IB/0
d14n08:1173247:1173620 [0] NCCL INFO Channel 01/0 : 2[4] -> 3[0] [receive] via NET/IB/0
d14n08:1173247:1173620 [0] NCCL INFO Channel 00/0 : 3[0] -> 4[2] [send] via NET/IB/0
d14n08:1173247:1173620 [0] NCCL INFO Channel 01/0 : 3[0] -> 4[2] [send] via NET/IB/0
d14n10:565685:566047 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d14n10:565685:566047 [4] NCCL INFO Trees [0] -1/-1/-1->5->6 [1] 6/4/-1->5->7
d14n10:565685:566047 [4] NCCL INFO P2P Chunksize set to 131072
d14n10:565685:566047 [4] NCCL INFO Channel 00/0 : 4[2] -> 5[4] [receive] via NET/IB/1
d14n10:565685:566047 [4] NCCL INFO Channel 01/0 : 4[2] -> 5[4] [receive] via NET/IB/1
d14n10:565685:566047 [4] NCCL INFO Channel 00/0 : 5[4] -> 6[0] [send] via NET/IB/1
d14n10:565685:566047 [4] NCCL INFO Channel 01/0 : 5[4] -> 6[0] [send] via NET/IB/1
f16n18:1091866:1092241 [0] NCCL INFO Setting affinity for GPU 0 to 0f
f16n18:1091866:1092241 [0] NCCL INFO Trees [0] -1/-1/-1->9->10 [1] 10/8/-1->9->7
f16n18:1091866:1092241 [0] NCCL INFO P2P Chunksize set to 131072
f16n18:1091866:1092241 [0] NCCL INFO Channel 00/0 : 8[4] -> 9[0] [receive] via NET/IB/0
f16n18:1091866:1092241 [0] NCCL INFO Channel 01/0 : 8[4] -> 9[0] [receive] via NET/IB/0
f16n18:1091866:1092241 [0] NCCL INFO Channel 00/0 : 9[0] -> 10[2] [send] via NET/IB/0
f16n18:1091866:1092241 [0] NCCL INFO Channel 01/0 : 9[0] -> 10[2] [send] via NET/IB/0
d14n09:567668:568050 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d14n09:567668:568050 [2] NCCL INFO Trees [0] 2/6/-1->4->8 [1] -1/-1/-1->4->5
d14n09:567668:568050 [2] NCCL INFO P2P Chunksize set to 131072
d14n09:567668:568050 [2] NCCL INFO Channel 00/0 : 3[0] -> 4[2] [receive] via NET/IB/0
d14n09:567668:568050 [2] NCCL INFO Channel 01/0 : 3[0] -> 4[2] [receive] via NET/IB/0
d14n09:567668:568050 [2] NCCL INFO Channel 00/0 : 4[2] -> 5[4] [send] via NET/IB/0
d14n09:567668:568050 [2] NCCL INFO Channel 01/0 : 4[2] -> 5[4] [send] via NET/IB/0
f16n16:1079916:1080270 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
f16n16:1079916:1080270 [4] NCCL INFO Trees [0] 4/10/-1->8->0 [1] -1/-1/-1->8->9
f16n16:1079916:1080270 [4] NCCL INFO P2P Chunksize set to 131072
f16n16:1079916:1080270 [4] NCCL INFO Channel 00/0 : 7[2] -> 8[4] [receive] via NET/IB/1
f16n16:1079916:1080270 [4] NCCL INFO Channel 01/0 : 7[2] -> 8[4] [receive] via NET/IB/1
f16n16:1079916:1080270 [4] NCCL INFO Channel 00/0 : 8[4] -> 9[0] [send] via NET/IB/1
f16n16:1079916:1080270 [4] NCCL INFO Channel 01/0 : 8[4] -> 9[0] [send] via NET/IB/1
d11n16:1130272:1130634 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d11n16:1130272:1130634 [4] NCCL INFO Trees [0] 1/3/-1->2->4 [1] -1/-1/-1->2->1
d11n16:1130272:1130634 [4] NCCL INFO P2P Chunksize set to 131072
d11n16:1130272:1130634 [4] NCCL INFO Channel 00/0 : 1[2] -> 2[4] [receive] via NET/IB/1
d11n16:1130272:1130634 [4] NCCL INFO Channel 01/0 : 1[2] -> 2[4] [receive] via NET/IB/1
d11n16:1130272:1130634 [4] NCCL INFO Channel 00/0 : 2[4] -> 3[0] [send] via NET/IB/1
d11n16:1130272:1130634 [4] NCCL INFO Channel 01/0 : 2[4] -> 3[0] [send] via NET/IB/1
d09n07:1063016:1063447 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d09n07:1063016:1063447 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7   8   9  10  11
d09n07:1063016:1063447 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7   8   9  10  11
d09n07:1063016:1063447 [0] NCCL INFO Trees [0] 8/-1/-1->0->-1 [1] -1/-1/-1->0->1
d09n07:1063016:1063447 [0] NCCL INFO P2P Chunksize set to 131072
d09n07:1063016:1063447 [0] NCCL INFO Channel 00/0 : 11[4] -> 0[0] [receive] via NET/IB/0
d09n07:1063016:1063447 [0] NCCL INFO Channel 01/0 : 11[4] -> 0[0] [receive] via NET/IB/0
d09n07:1063016:1063447 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[2] [send] via NET/IB/0
d09n07:1063016:1063447 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[2] [send] via NET/IB/0
f17n02:1076283:1076630 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
f17n02:1076283:1076630 [4] NCCL INFO Trees [0] -1/-1/-1->11->10 [1] 3/-1/-1->11->-1
f17n02:1076283:1076630 [4] NCCL INFO P2P Chunksize set to 131072
f17n02:1076283:1076630 [4] NCCL INFO Channel 00/0 : 10[2] -> 11[4] [receive] via NET/IB/1
f17n02:1076283:1076630 [4] NCCL INFO Channel 01/0 : 10[2] -> 11[4] [receive] via NET/IB/1
f17n02:1076283:1076630 [4] NCCL INFO Channel 00/0 : 11[4] -> 0[0] [send] via NET/IB/1
f17n02:1076283:1076630 [4] NCCL INFO Channel 01/0 : 11[4] -> 0[0] [send] via NET/IB/1
f17n01:970278:970629 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
f17n01:970278:970629 [2] NCCL INFO Trees [0] 9/11/-1->10->8 [1] -1/-1/-1->10->9
f17n01:970278:970629 [2] NCCL INFO P2P Chunksize set to 131072
f17n01:970278:970629 [2] NCCL INFO Channel 00/0 : 9[0] -> 10[2] [receive] via NET/IB/0
f17n01:970278:970629 [2] NCCL INFO Channel 01/0 : 9[0] -> 10[2] [receive] via NET/IB/0
f17n01:970278:970629 [2] NCCL INFO Channel 00/0 : 10[2] -> 11[4] [send] via NET/IB/0
f17n01:970278:970629 [2] NCCL INFO Channel 01/0 : 10[2] -> 11[4] [send] via NET/IB/0
d17n06:1216530:1216915 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d17n06:1216530:1216915 [0] NCCL INFO Trees [0] 5/7/-1->6->4 [1] -1/-1/-1->6->5
d17n06:1216530:1216915 [0] NCCL INFO P2P Chunksize set to 131072
d17n06:1216530:1216915 [0] NCCL INFO Channel 00/0 : 5[4] -> 6[0] [receive] via NET/IB/0
d17n06:1216530:1216915 [0] NCCL INFO Channel 01/0 : 5[4] -> 6[0] [receive] via NET/IB/0
d17n06:1216530:1216915 [0] NCCL INFO Channel 00/0 : 6[0] -> 7[2] [send] via NET/IB/0
d17n06:1216530:1216915 [0] NCCL INFO Channel 01/0 : 6[0] -> 7[2] [send] via NET/IB/0
d17n07:1212412:1212795 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d17n07:1212412:1212795 [2] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] 9/5/-1->7->3
d17n07:1212412:1212795 [2] NCCL INFO P2P Chunksize set to 131072
d17n07:1212412:1212795 [2] NCCL INFO Channel 00/0 : 6[0] -> 7[2] [receive] via NET/IB/0
d17n07:1212412:1212795 [2] NCCL INFO Channel 01/0 : 6[0] -> 7[2] [receive] via NET/IB/0
d17n07:1212412:1212795 [2] NCCL INFO Channel 00/0 : 7[2] -> 8[4] [send] via NET/IB/0
d17n07:1212412:1212795 [2] NCCL INFO Channel 01/0 : 7[2] -> 8[4] [send] via NET/IB/0
d09n08:1073956:1074311 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d09n08:1073956:1074311 [2] NCCL INFO Trees [0] -1/-1/-1->1->2 [1] 2/0/-1->1->3
d09n08:1073956:1074311 [2] NCCL INFO P2P Chunksize set to 131072
d09n08:1073956:1074311 [2] NCCL INFO Channel 00/0 : 0[0] -> 1[2] [receive] via NET/IB/0
d09n08:1073956:1074311 [2] NCCL INFO Channel 01/0 : 0[0] -> 1[2] [receive] via NET/IB/0
d09n08:1073956:1074311 [2] NCCL INFO Channel 00/0 : 1[2] -> 2[4] [send] via NET/IB/0
d09n08:1073956:1074311 [2] NCCL INFO Channel 01/0 : 1[2] -> 2[4] [send] via NET/IB/0
f17n02:1076283:1076630 [4] NCCL INFO Connected all rings
f17n02:1076283:1076630 [4] NCCL INFO Channel 01/0 : 11[4] -> 3[0] [send] via NET/IB/1
f17n02:1076283:1076630 [4] NCCL INFO Channel 01/0 : 3[0] -> 11[4] [receive] via NET/IB/1
f17n02:1076283:1076630 [4] NCCL INFO Channel 00/0 : 11[4] -> 10[2] [send] via NET/IB/1
d17n07:1212412:1212795 [2] NCCL INFO Connected all rings
d17n07:1212412:1212795 [2] NCCL INFO Channel 01/0 : 5[4] -> 7[2] [receive] via NET/IB/0
d17n07:1212412:1212795 [2] NCCL INFO Channel 01/0 : 7[2] -> 9[0] [send] via NET/IB/0
d17n07:1212412:1212795 [2] NCCL INFO Channel 01/0 : 3[0] -> 7[2] [receive] via NET/IB/0
d17n07:1212412:1212795 [2] NCCL INFO Channel 01/0 : 7[2] -> 3[0] [send] via NET/IB/0
d17n07:1212412:1212795 [2] NCCL INFO Channel 01/0 : 9[0] -> 7[2] [receive] via NET/IB/0
d17n07:1212412:1212795 [2] NCCL INFO Channel 01/0 : 7[2] -> 5[4] [send] via NET/IB/0
d17n07:1212412:1212795 [2] NCCL INFO Channel 00/0 : 7[2] -> 6[0] [send] via NET/IB/0
d14n09:567668:568050 [2] NCCL INFO Connected all rings
d14n09:567668:568050 [2] NCCL INFO Channel 00/0 : 2[4] -> 4[2] [receive] via NET/IB/0
d14n09:567668:568050 [2] NCCL INFO Channel 00/0 : 4[2] -> 6[0] [send] via NET/IB/0
d14n09:567668:568050 [2] NCCL INFO Channel 00/0 : 4[2] -> 8[4] [send] via NET/IB/0
d14n09:567668:568050 [2] NCCL INFO Channel 00/0 : 8[4] -> 4[2] [receive] via NET/IB/0
d14n09:567668:568050 [2] NCCL INFO Channel 00/0 : 6[0] -> 4[2] [receive] via NET/IB/0
d14n09:567668:568050 [2] NCCL INFO Channel 00/0 : 4[2] -> 2[4] [send] via NET/IB/0
d14n09:567668:568050 [2] NCCL INFO Channel 01/0 : 5[4] -> 4[2] [receive] via NET/IB/0
d11n16:1130272:1130634 [4] NCCL INFO Connected all rings
d11n16:1130272:1130634 [4] NCCL INFO Channel 00/0 : 2[4] -> 4[2] [send] via NET/IB/1
d11n16:1130272:1130634 [4] NCCL INFO Channel 00/0 : 4[2] -> 2[4] [receive] via NET/IB/1
d11n16:1130272:1130634 [4] NCCL INFO Channel 00/0 : 3[0] -> 2[4] [receive] via NET/IB/1
d11n16:1130272:1130634 [4] NCCL INFO Channel 00/0 : 2[4] -> 1[2] [send] via NET/IB/1
d11n16:1130272:1130634 [4] NCCL INFO Channel 01/0 : 2[4] -> 1[2] [send] via NET/IB/1
d09n08:1073956:1074311 [2] NCCL INFO Connected all rings
d09n08:1073956:1074311 [2] NCCL INFO Channel 01/0 : 1[2] -> 3[0] [send] via NET/IB/0
d09n08:1073956:1074311 [2] NCCL INFO Channel 01/0 : 3[0] -> 1[2] [receive] via NET/IB/0
d09n08:1073956:1074311 [2] NCCL INFO Channel 00/0 : 2[4] -> 1[2] [receive] via NET/IB/0
d09n08:1073956:1074311 [2] NCCL INFO Channel 01/0 : 2[4] -> 1[2] [receive] via NET/IB/0
d09n08:1073956:1074311 [2] NCCL INFO Channel 01/0 : 1[2] -> 0[0] [send] via NET/IB/0
f16n18:1091866:1092241 [0] NCCL INFO Connected all rings
f16n18:1091866:1092241 [0] NCCL INFO Channel 01/0 : 7[2] -> 9[0] [receive] via NET/IB/0
f16n18:1091866:1092241 [0] NCCL INFO Channel 01/0 : 9[0] -> 7[2] [send] via NET/IB/0
f16n18:1091866:1092241 [0] NCCL INFO Channel 00/0 : 10[2] -> 9[0] [receive] via NET/IB/0
f16n18:1091866:1092241 [0] NCCL INFO Channel 01/0 : 10[2] -> 9[0] [receive] via NET/IB/0
f16n18:1091866:1092241 [0] NCCL INFO Channel 01/0 : 9[0] -> 8[4] [send] via NET/IB/0
d17n06:1216530:1216915 [0] NCCL INFO Connected all rings
d17n06:1216530:1216915 [0] NCCL INFO Channel 00/0 : 4[2] -> 6[0] [receive] via NET/IB/0
d17n06:1216530:1216915 [0] NCCL INFO Channel 00/0 : 6[0] -> 4[2] [send] via NET/IB/0
d17n06:1216530:1216915 [0] NCCL INFO Channel 00/0 : 7[2] -> 6[0] [receive] via NET/IB/0
d17n06:1216530:1216915 [0] NCCL INFO Channel 00/0 : 6[0] -> 5[4] [send] via NET/IB/0
d17n06:1216530:1216915 [0] NCCL INFO Channel 01/0 : 6[0] -> 5[4] [send] via NET/IB/0
d14n08:1173247:1173620 [0] NCCL INFO Connected all rings
d14n08:1173247:1173620 [0] NCCL INFO Channel 01/0 : 1[2] -> 3[0] [receive] via NET/IB/0
d14n08:1173247:1173620 [0] NCCL INFO Channel 01/0 : 11[4] -> 3[0] [receive] via NET/IB/0
d14n08:1173247:1173620 [0] NCCL INFO Channel 01/0 : 3[0] -> 7[2] [send] via NET/IB/0
d14n08:1173247:1173620 [0] NCCL INFO Channel 01/0 : 7[2] -> 3[0] [receive] via NET/IB/0
d14n08:1173247:1173620 [0] NCCL INFO Channel 01/0 : 3[0] -> 11[4] [send] via NET/IB/0
d14n08:1173247:1173620 [0] NCCL INFO Channel 01/0 : 3[0] -> 1[2] [send] via NET/IB/0
d14n08:1173247:1173620 [0] NCCL INFO Channel 00/0 : 3[0] -> 2[4] [send] via NET/IB/0
f16n16:1079916:1080270 [4] NCCL INFO Connected all rings
f16n16:1079916:1080270 [4] NCCL INFO Channel 00/0 : 8[4] -> 10[2] [send] via NET/IB/1
f16n16:1079916:1080270 [4] NCCL INFO Channel 00/0 : 4[2] -> 8[4] [receive] via NET/IB/1
f16n16:1079916:1080270 [4] NCCL INFO Channel 00/0 : 8[4] -> 0[0] [send] via NET/IB/1
f16n16:1079916:1080270 [4] NCCL INFO Channel 00/0 : 0[0] -> 8[4] [receive] via NET/IB/1
f16n16:1079916:1080270 [4] NCCL INFO Channel 00/0 : 8[4] -> 4[2] [send] via NET/IB/1
f16n16:1079916:1080270 [4] NCCL INFO Channel 00/0 : 10[2] -> 8[4] [receive] via NET/IB/1
f16n16:1079916:1080270 [4] NCCL INFO Channel 01/0 : 9[0] -> 8[4] [receive] via NET/IB/1
d09n07:1063016:1063447 [0] NCCL INFO Connected all rings
d09n07:1063016:1063447 [0] NCCL INFO Channel 00/0 : 8[4] -> 0[0] [receive] via NET/IB/0
d09n07:1063016:1063447 [0] NCCL INFO Channel 00/0 : 0[0] -> 8[4] [send] via NET/IB/0
d09n07:1063016:1063447 [0] NCCL INFO Channel 01/0 : 1[2] -> 0[0] [receive] via NET/IB/0
f17n01:970278:970629 [2] NCCL INFO Connected all rings
f17n01:970278:970629 [2] NCCL INFO Channel 00/0 : 8[4] -> 10[2] [receive] via NET/IB/0
f17n01:970278:970629 [2] NCCL INFO Channel 00/0 : 10[2] -> 8[4] [send] via NET/IB/0
f17n01:970278:970629 [2] NCCL INFO Channel 00/0 : 11[4] -> 10[2] [receive] via NET/IB/0
f17n01:970278:970629 [2] NCCL INFO Channel 00/0 : 10[2] -> 9[0] [send] via NET/IB/0
f17n01:970278:970629 [2] NCCL INFO Channel 01/0 : 10[2] -> 9[0] [send] via NET/IB/0
d14n10:565685:566047 [4] NCCL INFO Connected all rings
d14n10:565685:566047 [4] NCCL INFO Channel 01/0 : 5[4] -> 7[2] [send] via NET/IB/1
d14n10:565685:566047 [4] NCCL INFO Channel 01/0 : 7[2] -> 5[4] [receive] via NET/IB/1
d14n10:565685:566047 [4] NCCL INFO Channel 00/0 : 6[0] -> 5[4] [receive] via NET/IB/1
d14n10:565685:566047 [4] NCCL INFO Channel 01/0 : 6[0] -> 5[4] [receive] via NET/IB/1
d14n10:565685:566047 [4] NCCL INFO Channel 01/0 : 5[4] -> 4[2] [send] via NET/IB/1
f17n02:1076283:1076630 [4] NCCL INFO Connected all trees
f17n02:1076283:1076630 [4] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f17n02:1076283:1076630 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d09n07:1063016:1063447 [0] NCCL INFO Connected all trees
d09n07:1063016:1063447 [0] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d09n07:1063016:1063447 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f17n01:970278:970629 [2] NCCL INFO Connected all trees
f17n01:970278:970629 [2] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f17n01:970278:970629 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d09n08:1073956:1074311 [2] NCCL INFO Connected all trees
d09n08:1073956:1074311 [2] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d09n08:1073956:1074311 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n10:565685:566047 [4] NCCL INFO Connected all trees
d14n10:565685:566047 [4] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d14n10:565685:566047 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n09:567668:568050 [2] NCCL INFO Connected all trees
d14n09:567668:568050 [2] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d14n09:567668:568050 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n16:1130272:1130634 [4] NCCL INFO Connected all trees
d11n16:1130272:1130634 [4] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d11n16:1130272:1130634 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n08:1173247:1173620 [0] NCCL INFO Connected all trees
d14n08:1173247:1173620 [0] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d14n08:1173247:1173620 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n18:1091866:1092241 [0] NCCL INFO Connected all trees
f16n18:1091866:1092241 [0] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f16n18:1091866:1092241 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n16:1079916:1080270 [4] NCCL INFO Connected all trees
f16n16:1079916:1080270 [4] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
f16n16:1079916:1080270 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n06:1216530:1216915 [0] NCCL INFO Connected all trees
d17n06:1216530:1216915 [0] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d17n06:1216530:1216915 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n07:1212412:1212795 [2] NCCL INFO Connected all trees
d17n07:1212412:1212795 [2] NCCL INFO threadThresholds 8/8/64 | 96/8/64 | 512 | 512
d17n07:1212412:1212795 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f17n01:970278:970629 [2] NCCL INFO comm 0x15a7b09d0 rank 10 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0x1653a9cbd662af6b - Init COMPLETE
f17n01:970278:970633 [2] NCCL INFO Using network IB
f17n01:970278:970633 [2] NCCL INFO comm 0x15a7c3590 rank 0 nranks 1 cudaDev 2 nvmlDev 2 busId 406000 commId 0x952dced75d91f8e8 - Init START
f17n01:970278:970633 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
f16n18:1091866:1092241 [0] NCCL INFO comm 0x11e317280 rank 9 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0x1653a9cbd662af6b - Init COMPLETE
f16n18:1091866:1092245 [0] NCCL INFO Using network IB
f16n18:1091866:1092245 [0] NCCL INFO comm 0x11e32af80 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa43366171e320842 - Init START
d11n16:1130272:1130634 [4] NCCL INFO comm 0x127027400 rank 2 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x1653a9cbd662af6b - Init COMPLETE
d11n16:1130272:1130638 [4] NCCL INFO Using network IB
d11n16:1130272:1130638 [4] NCCL INFO comm 0x12703b100 rank 0 nranks 1 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x4dd36a03424e2bab - Init START
f17n02:1076283:1076630 [4] NCCL INFO comm 0x15a13f240 rank 11 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x1653a9cbd662af6b - Init COMPLETE
f17n02:1076283:1076634 [4] NCCL INFO Using network IB
f17n02:1076283:1076634 [4] NCCL INFO comm 0x15a143280 rank 0 nranks 1 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x683fd5ee6517db2e - Init START
f17n02:1076283:1076634 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
f17n02:1076283:1076634 [4] NCCL INFO Channel 00/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Channel 01/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Channel 02/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Channel 03/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Channel 04/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Channel 05/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Channel 06/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Channel 07/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Channel 08/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Channel 09/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Channel 10/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Channel 11/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Channel 12/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Channel 13/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Channel 14/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Channel 15/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Channel 16/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Channel 17/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Channel 18/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Channel 19/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Channel 20/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Channel 21/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Channel 22/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Channel 23/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Channel 24/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Channel 25/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Channel 26/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Channel 27/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Channel 28/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Channel 29/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Channel 30/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Channel 31/32 :    0
f17n02:1076283:1076634 [4] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
f17n02:1076283:1076634 [4] NCCL INFO P2P Chunksize set to 131072
f17n02:1076283:1076634 [4] NCCL INFO Connected all rings
f17n02:1076283:1076634 [4] NCCL INFO Connected all trees
f17n02:1076283:1076634 [4] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
d09n07:1063016:1063447 [0] NCCL INFO comm 0x140f15460 rank 0 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0x1653a9cbd662af6b - Init COMPLETE
d09n07:1063016:1063451 [0] NCCL INFO Using network IB
d09n07:1063016:1063451 [0] NCCL INFO comm 0x140f28020 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 404000 commId 0xcf6cabb34ea25fcd - Init START
d09n07:1063016:1063451 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d09n07:1063016:1063451 [0] NCCL INFO Channel 00/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Channel 01/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Channel 02/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Channel 03/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Channel 04/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Channel 05/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Channel 06/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Channel 07/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Channel 08/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Channel 09/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Channel 10/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Channel 11/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Channel 12/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Channel 13/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Channel 14/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Channel 15/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Channel 16/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Channel 17/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Channel 18/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Channel 19/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Channel 20/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Channel 21/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Channel 22/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Channel 23/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Channel 24/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Channel 25/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Channel 26/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Channel 27/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Channel 28/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Channel 29/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Channel 30/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Channel 31/32 :    0
d09n07:1063016:1063451 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
d09n07:1063016:1063451 [0] NCCL INFO P2P Chunksize set to 131072
d09n07:1063016:1063451 [0] NCCL INFO Connected all rings
d09n07:1063016:1063451 [0] NCCL INFO Connected all trees
d09n07:1063016:1063451 [0] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
f17n01:970278:970633 [2] NCCL INFO Channel 00/32 :    0
f17n01:970278:970633 [2] NCCL INFO Channel 01/32 :    0
f17n01:970278:970633 [2] NCCL INFO Channel 02/32 :    0
f17n01:970278:970633 [2] NCCL INFO Channel 03/32 :    0
f17n01:970278:970633 [2] NCCL INFO Channel 04/32 :    0
f17n01:970278:970633 [2] NCCL INFO Channel 05/32 :    0
f17n01:970278:970633 [2] NCCL INFO Channel 06/32 :    0
f17n01:970278:970633 [2] NCCL INFO Channel 07/32 :    0
f17n01:970278:970633 [2] NCCL INFO Channel 08/32 :    0
f17n01:970278:970633 [2] NCCL INFO Channel 09/32 :    0
f17n01:970278:970633 [2] NCCL INFO Channel 10/32 :    0
f17n01:970278:970633 [2] NCCL INFO Channel 11/32 :    0
f17n01:970278:970633 [2] NCCL INFO Channel 12/32 :    0
f17n01:970278:970633 [2] NCCL INFO Channel 13/32 :    0
f17n01:970278:970633 [2] NCCL INFO Channel 14/32 :    0
f17n01:970278:970633 [2] NCCL INFO Channel 15/32 :    0
f17n01:970278:970633 [2] NCCL INFO Channel 16/32 :    0
f17n01:970278:970633 [2] NCCL INFO Channel 17/32 :    0
f17n01:970278:970633 [2] NCCL INFO Channel 18/32 :    0
f17n01:970278:970633 [2] NCCL INFO Channel 19/32 :    0
f17n01:970278:970633 [2] NCCL INFO Channel 20/32 :    0
f17n01:970278:970633 [2] NCCL INFO Channel 21/32 :    0
f17n01:970278:970633 [2] NCCL INFO Channel 22/32 :    0
f17n01:970278:970633 [2] NCCL INFO Channel 23/32 :    0
f17n01:970278:970633 [2] NCCL INFO Channel 24/32 :    0
f17n01:970278:970633 [2] NCCL INFO Channel 25/32 :    0
f17n01:970278:970633 [2] NCCL INFO Channel 26/32 :    0
f17n01:970278:970633 [2] NCCL INFO Channel 27/32 :    0
f17n01:970278:970633 [2] NCCL INFO Channel 28/32 :    0
f17n01:970278:970633 [2] NCCL INFO Channel 29/32 :    0
f17n01:970278:970633 [2] NCCL INFO Channel 30/32 :    0
f17n01:970278:970633 [2] NCCL INFO Channel 31/32 :    0
f17n01:970278:970633 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
f17n01:970278:970633 [2] NCCL INFO P2P Chunksize set to 131072
f17n01:970278:970633 [2] NCCL INFO Connected all rings
f17n01:970278:970633 [2] NCCL INFO Connected all trees
f17n01:970278:970633 [2] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
d09n08:1073956:1074311 [2] NCCL INFO comm 0x16123ff40 rank 1 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0x1653a9cbd662af6b - Init COMPLETE
d09n08:1073956:1074315 [2] NCCL INFO Using network IB
d09n08:1073956:1074315 [2] NCCL INFO comm 0x161253c40 rank 0 nranks 1 cudaDev 2 nvmlDev 2 busId 406000 commId 0x51d8b57c0c4808dc - Init START
f16n16:1079916:1080270 [4] NCCL INFO comm 0x150d7a680 rank 8 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x1653a9cbd662af6b - Init COMPLETE
f16n16:1079916:1080274 [4] NCCL INFO Using network IB
f16n16:1079916:1080274 [4] NCCL INFO comm 0x150d4a280 rank 0 nranks 1 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xd21ba9a95f0fd02f - Init START
d14n09:567668:568050 [2] NCCL INFO comm 0x12c5cc9b0 rank 4 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0x1653a9cbd662af6b - Init COMPLETE
d14n09:567668:568054 [2] NCCL INFO Using network IB
d14n09:567668:568054 [2] NCCL INFO comm 0x12c5e0480 rank 0 nranks 1 cudaDev 2 nvmlDev 2 busId 406000 commId 0xd72de65b47e4732e - Init START
d14n08:1173247:1173620 [0] NCCL INFO comm 0x139a351c0 rank 3 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0x1653a9cbd662af6b - Init COMPLETE
d14n08:1173247:1173624 [0] NCCL INFO Using network IB
d14n08:1173247:1173624 [0] NCCL INFO comm 0x139a48ea0 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 404000 commId 0x35b965edf90054bf - Init START
d14n10:565685:566047 [4] NCCL INFO comm 0x1642e3870 rank 5 nranks 12 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x1653a9cbd662af6b - Init COMPLETE
d14n10:565685:566051 [4] NCCL INFO Using network IB
d14n10:565685:566051 [4] NCCL INFO comm 0x1642f7340 rank 0 nranks 1 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xeafdba86674f90d9 - Init START
d14n10:565685:566051 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d14n10:565685:566051 [4] NCCL INFO Channel 00/32 :    0
d14n10:565685:566051 [4] NCCL INFO Channel 01/32 :    0
d14n10:565685:566051 [4] NCCL INFO Channel 02/32 :    0
d14n10:565685:566051 [4] NCCL INFO Channel 03/32 :    0
d14n10:565685:566051 [4] NCCL INFO Channel 04/32 :    0
d14n10:565685:566051 [4] NCCL INFO Channel 05/32 :    0
d14n10:565685:566051 [4] NCCL INFO Channel 06/32 :    0
d14n10:565685:566051 [4] NCCL INFO Channel 07/32 :    0
d14n10:565685:566051 [4] NCCL INFO Channel 08/32 :    0
d14n10:565685:566051 [4] NCCL INFO Channel 09/32 :    0
d14n10:565685:566051 [4] NCCL INFO Channel 10/32 :    0
d14n10:565685:566051 [4] NCCL INFO Channel 11/32 :    0
d14n10:565685:566051 [4] NCCL INFO Channel 12/32 :    0
d14n10:565685:566051 [4] NCCL INFO Channel 13/32 :    0
d14n10:565685:566051 [4] NCCL INFO Channel 14/32 :    0
d14n10:565685:566051 [4] NCCL INFO Channel 15/32 :    0
d14n10:565685:566051 [4] NCCL INFO Channel 16/32 :    0
d14n10:565685:566051 [4] NCCL INFO Channel 17/32 :    0
d14n10:565685:566051 [4] NCCL INFO Channel 18/32 :    0
d14n10:565685:566051 [4] NCCL INFO Channel 19/32 :    0
d14n10:565685:566051 [4] NCCL INFO Channel 20/32 :    0
d14n10:565685:566051 [4] NCCL INFO Channel 21/32 :    0
d14n10:565685:566051 [4] NCCL INFO Channel 22/32 :    0
d14n10:565685:566051 [4] NCCL INFO Channel 23/32 :    0
d14n10:565685:566051 [4] NCCL INFO Channel 24/32 :    0
d14n10:565685:566051 [4] NCCL INFO Channel 25/32 :    0
d14n10:565685:566051 [4] NCCL INFO Channel 26/32 :    0
d14n10:565685:566051 [4] NCCL INFO Channel 27/32 :    0
d14n10:565685:566051 [4] NCCL INFO Channel 28/32 :    0
d14n10:565685:566051 [4] NCCL INFO Channel 29/32 :    0
d14n10:565685:566051 [4] NCCL INFO Channel 30/32 :    0
d14n10:565685:566051 [4] NCCL INFO Channel 31/32 :    0
d14n10:565685:566051 [4] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
d14n10:565685:566051 [4] NCCL INFO P2P Chunksize set to 131072
d17n06:1216530:1216915 [0] NCCL INFO comm 0x148bbcc60 rank 6 nranks 12 cudaDev 0 nvmlDev 0 busId 404000 commId 0x1653a9cbd662af6b - Init COMPLETE
d17n06:1216530:1216919 [0] NCCL INFO Using network IB
d17n06:1216530:1216919 [0] NCCL INFO comm 0x147f6f840 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 404000 commId 0xae282dfd84e8444d - Init START
d09n08:1073956:1074315 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d09n08:1073956:1074315 [2] NCCL INFO Channel 00/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Channel 01/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Channel 02/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Channel 03/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Channel 04/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Channel 05/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Channel 06/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Channel 07/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Channel 08/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Channel 09/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Channel 10/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Channel 11/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Channel 12/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Channel 13/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Channel 14/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Channel 15/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Channel 16/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Channel 17/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Channel 18/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Channel 19/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Channel 20/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Channel 21/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Channel 22/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Channel 23/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Channel 24/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Channel 25/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Channel 26/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Channel 27/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Channel 28/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Channel 29/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Channel 30/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Channel 31/32 :    0
d09n08:1073956:1074315 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
d09n08:1073956:1074315 [2] NCCL INFO P2P Chunksize set to 131072
d09n08:1073956:1074315 [2] NCCL INFO Connected all rings
d09n08:1073956:1074315 [2] NCCL INFO Connected all trees
d09n08:1073956:1074315 [2] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
d09n07:1063016:1063451 [0] NCCL INFO comm 0x140f28020 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 404000 commId 0xcf6cabb34ea25fcd - Init COMPLETE
d17n07:1212412:1212795 [2] NCCL INFO comm 0x12f885410 rank 7 nranks 12 cudaDev 2 nvmlDev 2 busId 406000 commId 0x1653a9cbd662af6b - Init COMPLETE
d17n07:1212412:1212799 [2] NCCL INFO Using network IB
d17n07:1212412:1212799 [2] NCCL INFO comm 0x12f897fd0 rank 0 nranks 1 cudaDev 2 nvmlDev 2 busId 406000 commId 0xcfcf0aa6f4958569 - Init START
d17n07:1212412:1212799 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
 > loading doc-idx mapping from /gpfs/alpine2/stf218/world-shared/sajal/gptdata/index-cache/b03a1c5153aea8a63ec7eb8e74212aa9_doc_idx.npy
f17n01:970278:970633 [2] NCCL INFO comm 0x15a7c3590 rank 0 nranks 1 cudaDev 2 nvmlDev 2 busId 406000 commId 0x952dced75d91f8e8 - Init COMPLETE
d14n10:565685:566051 [4] NCCL INFO Connected all rings
d14n10:565685:566051 [4] NCCL INFO Connected all trees
d14n10:565685:566051 [4] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
d11n16:1130272:1130638 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d11n16:1130272:1130638 [4] NCCL INFO Channel 00/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Channel 01/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Channel 02/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Channel 03/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Channel 04/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Channel 05/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Channel 06/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Channel 07/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Channel 08/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Channel 09/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Channel 10/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Channel 11/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Channel 12/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Channel 13/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Channel 14/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Channel 15/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Channel 16/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Channel 17/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Channel 18/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Channel 19/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Channel 20/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Channel 21/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Channel 22/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Channel 23/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Channel 24/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Channel 25/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Channel 26/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Channel 27/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Channel 28/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Channel 29/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Channel 30/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Channel 31/32 :    0
d11n16:1130272:1130638 [4] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
d11n16:1130272:1130638 [4] NCCL INFO P2P Chunksize set to 131072
d11n16:1130272:1130638 [4] NCCL INFO Connected all rings
d11n16:1130272:1130638 [4] NCCL INFO Connected all trees
d11n16:1130272:1130638 [4] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
d14n08:1173247:1173624 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d14n08:1173247:1173624 [0] NCCL INFO Channel 00/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Channel 01/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Channel 02/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Channel 03/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Channel 04/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Channel 05/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Channel 06/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Channel 07/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Channel 08/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Channel 09/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Channel 10/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Channel 11/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Channel 12/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Channel 13/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Channel 14/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Channel 15/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Channel 16/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Channel 17/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Channel 18/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Channel 19/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Channel 20/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Channel 21/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Channel 22/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Channel 23/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Channel 24/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Channel 25/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Channel 26/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Channel 27/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Channel 28/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Channel 29/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Channel 30/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Channel 31/32 :    0
d14n08:1173247:1173624 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
d14n08:1173247:1173624 [0] NCCL INFO P2P Chunksize set to 131072
d14n08:1173247:1173624 [0] NCCL INFO Connected all rings
d14n08:1173247:1173624 [0] NCCL INFO Connected all trees
d14n08:1173247:1173624 [0] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
f17n02:1076283:1076634 [4] NCCL INFO comm 0x15a143280 rank 0 nranks 1 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x683fd5ee6517db2e - Init COMPLETE
f16n16:1079916:1080274 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
f16n16:1079916:1080274 [4] NCCL INFO Channel 00/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Channel 01/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Channel 02/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Channel 03/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Channel 04/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Channel 05/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Channel 06/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Channel 07/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Channel 08/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Channel 09/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Channel 10/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Channel 11/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Channel 12/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Channel 13/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Channel 14/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Channel 15/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Channel 16/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Channel 17/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Channel 18/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Channel 19/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Channel 20/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Channel 21/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Channel 22/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Channel 23/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Channel 24/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Channel 25/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Channel 26/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Channel 27/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Channel 28/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Channel 29/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Channel 30/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Channel 31/32 :    0
f16n16:1079916:1080274 [4] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
f16n16:1079916:1080274 [4] NCCL INFO P2P Chunksize set to 131072
f16n16:1079916:1080274 [4] NCCL INFO Connected all rings
f16n16:1079916:1080274 [4] NCCL INFO Connected all trees
f16n16:1079916:1080274 [4] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
d14n09:567668:568054 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d14n09:567668:568054 [2] NCCL INFO Channel 00/32 :    0
d14n09:567668:568054 [2] NCCL INFO Channel 01/32 :    0
d14n09:567668:568054 [2] NCCL INFO Channel 02/32 :    0
d14n09:567668:568054 [2] NCCL INFO Channel 03/32 :    0
d14n09:567668:568054 [2] NCCL INFO Channel 04/32 :    0
d14n09:567668:568054 [2] NCCL INFO Channel 05/32 :    0
d14n09:567668:568054 [2] NCCL INFO Channel 06/32 :    0
d14n09:567668:568054 [2] NCCL INFO Channel 07/32 :    0
d14n09:567668:568054 [2] NCCL INFO Channel 08/32 :    0
d14n09:567668:568054 [2] NCCL INFO Channel 09/32 :    0
d14n09:567668:568054 [2] NCCL INFO Channel 10/32 :    0
d14n09:567668:568054 [2] NCCL INFO Channel 11/32 :    0
d14n09:567668:568054 [2] NCCL INFO Channel 12/32 :    0
d14n09:567668:568054 [2] NCCL INFO Channel 13/32 :    0
d14n09:567668:568054 [2] NCCL INFO Channel 14/32 :    0
d14n09:567668:568054 [2] NCCL INFO Channel 15/32 :    0
d14n09:567668:568054 [2] NCCL INFO Channel 16/32 :    0
d14n09:567668:568054 [2] NCCL INFO Channel 17/32 :    0
d14n09:567668:568054 [2] NCCL INFO Channel 18/32 :    0
d14n09:567668:568054 [2] NCCL INFO Channel 19/32 :    0
d14n09:567668:568054 [2] NCCL INFO Channel 20/32 :    0
d14n09:567668:568054 [2] NCCL INFO Channel 21/32 :    0
d14n09:567668:568054 [2] NCCL INFO Channel 22/32 :    0
d14n09:567668:568054 [2] NCCL INFO Channel 23/32 :    0
d14n09:567668:568054 [2] NCCL INFO Channel 24/32 :    0
d14n09:567668:568054 [2] NCCL INFO Channel 25/32 :    0
d14n09:567668:568054 [2] NCCL INFO Channel 26/32 :    0
d14n09:567668:568054 [2] NCCL INFO Channel 27/32 :    0
d14n09:567668:568054 [2] NCCL INFO Channel 28/32 :    0
d14n09:567668:568054 [2] NCCL INFO Channel 29/32 :    0
d14n09:567668:568054 [2] NCCL INFO Channel 30/32 :    0
d14n09:567668:568054 [2] NCCL INFO Channel 31/32 :    0
d14n09:567668:568054 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
d14n09:567668:568054 [2] NCCL INFO P2P Chunksize set to 131072
d14n09:567668:568054 [2] NCCL INFO Connected all rings
d14n09:567668:568054 [2] NCCL INFO Connected all trees
d14n09:567668:568054 [2] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
f16n18:1091866:1092245 [0] NCCL INFO Setting affinity for GPU 0 to 0f
f16n18:1091866:1092245 [0] NCCL INFO Channel 00/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Channel 01/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Channel 02/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Channel 03/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Channel 04/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Channel 05/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Channel 06/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Channel 07/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Channel 08/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Channel 09/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Channel 10/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Channel 11/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Channel 12/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Channel 13/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Channel 14/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Channel 15/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Channel 16/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Channel 17/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Channel 18/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Channel 19/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Channel 20/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Channel 21/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Channel 22/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Channel 23/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Channel 24/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Channel 25/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Channel 26/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Channel 27/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Channel 28/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Channel 29/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Channel 30/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Channel 31/32 :    0
f16n18:1091866:1092245 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
f16n18:1091866:1092245 [0] NCCL INFO P2P Chunksize set to 131072
f16n18:1091866:1092245 [0] NCCL INFO Connected all rings
f16n18:1091866:1092245 [0] NCCL INFO Connected all trees
f16n18:1091866:1092245 [0] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
d17n07:1212412:1212799 [2] NCCL INFO Channel 00/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Channel 01/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Channel 02/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Channel 03/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Channel 04/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Channel 05/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Channel 06/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Channel 07/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Channel 08/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Channel 09/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Channel 10/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Channel 11/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Channel 12/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Channel 13/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Channel 14/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Channel 15/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Channel 16/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Channel 17/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Channel 18/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Channel 19/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Channel 20/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Channel 21/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Channel 22/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Channel 23/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Channel 24/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Channel 25/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Channel 26/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Channel 27/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Channel 28/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Channel 29/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Channel 30/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Channel 31/32 :    0
d17n07:1212412:1212799 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
d17n07:1212412:1212799 [2] NCCL INFO P2P Chunksize set to 131072
d17n07:1212412:1212799 [2] NCCL INFO Connected all rings
d17n07:1212412:1212799 [2] NCCL INFO Connected all trees
d17n07:1212412:1212799 [2] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
d17n06:1216530:1216919 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d17n06:1216530:1216919 [0] NCCL INFO Channel 00/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Channel 01/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Channel 02/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Channel 03/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Channel 04/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Channel 05/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Channel 06/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Channel 07/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Channel 08/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Channel 09/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Channel 10/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Channel 11/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Channel 12/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Channel 13/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Channel 14/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Channel 15/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Channel 16/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Channel 17/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Channel 18/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Channel 19/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Channel 20/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Channel 21/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Channel 22/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Channel 23/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Channel 24/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Channel 25/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Channel 26/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Channel 27/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Channel 28/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Channel 29/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Channel 30/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Channel 31/32 :    0
d17n06:1216530:1216919 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
d17n06:1216530:1216919 [0] NCCL INFO P2P Chunksize set to 131072
d17n06:1216530:1216919 [0] NCCL INFO Connected all rings
d17n06:1216530:1216919 [0] NCCL INFO Connected all trees
d17n06:1216530:1216919 [0] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
d09n08:1073956:1074315 [2] NCCL INFO comm 0x161253c40 rank 0 nranks 1 cudaDev 2 nvmlDev 2 busId 406000 commId 0x51d8b57c0c4808dc - Init COMPLETE
d14n10:565685:566051 [4] NCCL INFO comm 0x1642f7340 rank 0 nranks 1 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xeafdba86674f90d9 - Init COMPLETE
d11n16:1130272:1130638 [4] NCCL INFO comm 0x12703b100 rank 0 nranks 1 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x4dd36a03424e2bab - Init COMPLETE
d14n08:1173247:1173624 [0] NCCL INFO comm 0x139a48ea0 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 404000 commId 0x35b965edf90054bf - Init COMPLETE
f16n16:1079916:1080274 [4] NCCL INFO comm 0x150d4a280 rank 0 nranks 1 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xd21ba9a95f0fd02f - Init COMPLETE
d14n09:567668:568054 [2] NCCL INFO comm 0x12c5e0480 rank 0 nranks 1 cudaDev 2 nvmlDev 2 busId 406000 commId 0xd72de65b47e4732e - Init COMPLETE
f16n18:1091866:1092245 [0] NCCL INFO comm 0x11e32af80 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 404000 commId 0xa43366171e320842 - Init COMPLETE
d17n07:1212412:1212799 [2] NCCL INFO comm 0x12f897fd0 rank 0 nranks 1 cudaDev 2 nvmlDev 2 busId 406000 commId 0xcfcf0aa6f4958569 - Init COMPLETE
d17n06:1216530:1216919 [0] NCCL INFO comm 0x147f6f840 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 404000 commId 0xae282dfd84e8444d - Init COMPLETE
 > loading sample-idx mapping from /gpfs/alpine2/stf218/world-shared/sajal/gptdata/index-cache/b03a1c5153aea8a63ec7eb8e74212aa9_sample_idx.npy
 > loading shuffle-idx mapping from /gpfs/alpine2/stf218/world-shared/sajal/gptdata/index-cache/b03a1c5153aea8a63ec7eb8e74212aa9_shuffle_idx.npy
    loaded indexed file in 0.075 seconds
    total number of samples: 439455219
    total number of epochs: 93214
 > loading doc-idx mapping from /gpfs/alpine2/stf218/world-shared/sajal/gptdata/index-cache/a718afb52de469266fb9bff4c0883da9_doc_idx.npy
 > loading sample-idx mapping from /gpfs/alpine2/stf218/world-shared/sajal/gptdata/index-cache/a718afb52de469266fb9bff4c0883da9_sample_idx.npy
 > loading shuffle-idx mapping from /gpfs/alpine2/stf218/world-shared/sajal/gptdata/index-cache/a718afb52de469266fb9bff4c0883da9_shuffle_idx.npy
    loaded indexed file in 0.095 seconds
    total number of samples: 43945467
    total number of epochs: 534358
> finished creating GPT datasets ...
f17n01:970276:970641 [0] NCCL INFO Using network IB
f17n01:970276:970641 [0] NCCL INFO comm 0x15e00e130 rank 6 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x13974c2855421d4b - Init START
f17n01:970280:970638 [4] NCCL INFO Using network IB
f17n01:970280:970638 [4] NCCL INFO comm 0x136191280 rank 2 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x3a0bc024a5812684 - Init START
d17n07:1212414:1212805 [4] NCCL INFO Using network IB
d17n07:1212415:1212804 [5] NCCL INFO Using network IB
f17n01:970279:970640 [3] NCCL INFO Using network IB
f17n01:970279:970640 [3] NCCL INFO comm 0x143aa6680 rank 1 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x3a0bc024a5812684 - Init START
f17n01:970281:970639 [5] NCCL INFO Using network IB
f17n01:970281:970639 [5] NCCL INFO comm 0x14667fb70 rank 3 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x3a0bc024a5812684 - Init START
f17n01:970278:970637 [2] NCCL INFO Using network IB
f17n01:970278:970637 [2] NCCL INFO comm 0x15a795e10 rank 0 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x3a0bc024a5812684 - Init START
d17n07:1212411:1212808 [1] NCCL INFO Using network IB
d17n07:1212411:1212808 [1] NCCL INFO comm 0x17bea82c0 rank 7 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x2ed1f251b0bfef39 - Init START
f16n18:1091868:1092251 [2] NCCL INFO Using network IB
f16n18:1091868:1092251 [2] NCCL INFO comm 0x17341dfc0 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x13974c2855421d4b - Init START
d17n07:1212413:1212806 [3] NCCL INFO Using network IB
f17n01:970277:970642 [1] NCCL INFO Using network IB
f17n01:970277:970642 [1] NCCL INFO comm 0x149c54d50 rank 7 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x13974c2855421d4b - Init START
f16n18:1091867:1092250 [1] NCCL INFO Using network IB
f16n18:1091867:1092250 [1] NCCL INFO comm 0x15caffa60 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x13974c2855421d4b - Init START
f16n18:1091866:1092249 [0] NCCL INFO Using network IB
f16n18:1091866:1092249 [0] NCCL INFO comm 0x11e2fcf80 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x13974c2855421d4b - Init START
f16n17:1090961:1091324 [2] NCCL INFO Using network IB
f16n17:1090963:1091328 [4] NCCL INFO Using network IB
f16n17:1090960:1091325 [1] NCCL INFO Using network IB
f16n17:1090964:1091329 [5] NCCL INFO Using network IB
d11n16:1130271:1130647 [3] NCCL INFO Using network IB
d11n16:1130271:1130647 [3] NCCL INFO comm 0x16fb767b0 rank 7 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xc3dd8166c9a61f34 - Init START
d11n16:1130272:1130642 [4] NCCL INFO Using network IB
d11n16:1130272:1130642 [4] NCCL INFO comm 0x12700d100 rank 0 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x6a336f573a53dcba - Init START
d11n16:1130273:1130643 [5] NCCL INFO Using network IB
d11n16:1130273:1130643 [5] NCCL INFO comm 0x152baf340 rank 1 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x6a336f573a53dcba - Init START
f16n17:1090959:1091326 [0] NCCL INFO Using network IB
d11n16:1130270:1130645 [2] NCCL INFO Using network IB
d11n16:1130270:1130645 [2] NCCL INFO comm 0x14cf86610 rank 6 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0xc3dd8166c9a61f34 - Init START
f16n18:1091869:1092253 [3] NCCL INFO Using network IB
f16n18:1091869:1092253 [3] NCCL INFO comm 0x151a05600 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x13974c2855421d4b - Init START
f18n05:1008219:1008573 [0] NCCL INFO Using network IB
f18n05:1008219:1008573 [0] NCCL INFO comm 0x158e1a8c0 rank 2 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x42a519b1adea69c3 - Init START
d11n16:1130268:1130646 [0] NCCL INFO Using network IB
d11n16:1130268:1130646 [0] NCCL INFO comm 0x156bacd40 rank 4 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0xc3dd8166c9a61f34 - Init START
f18n05:1008221:1008572 [2] NCCL INFO Using network IB
f18n05:1008221:1008572 [2] NCCL INFO comm 0x1666582c0 rank 4 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x42a519b1adea69c3 - Init START
f16n17:1090962:1091327 [3] NCCL INFO Using network IB
f16n18:1091871:1092252 [5] NCCL INFO Using network IB
f16n18:1091871:1092252 [5] NCCL INFO comm 0x14e7194c0 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x13974c2855421d4b - Init START
f16n18:1091870:1092254 [4] NCCL INFO Using network IB
f16n18:1091870:1092254 [4] NCCL INFO comm 0x170167300 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x13974c2855421d4b - Init START
f18n05:1008220:1008574 [1] NCCL INFO Using network IB
f18n05:1008220:1008574 [1] NCCL INFO comm 0x16bcbf110 rank 3 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x42a519b1adea69c3 - Init START
d14n09:567670:568063 [4] NCCL INFO Using network IB
f18n05:1008223:1008575 [4] NCCL INFO Using network IB
f18n05:1008223:1008575 [4] NCCL INFO comm 0x182732820 rank 6 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x42a519b1adea69c3 - Init START
d11n16:1130269:1130644 [1] NCCL INFO Using network IB
d11n16:1130269:1130644 [1] NCCL INFO comm 0x138c05090 rank 5 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0xc3dd8166c9a61f34 - Init START
f17n02:1076281:1076640 [2] NCCL INFO Using network IB
f17n02:1076281:1076640 [2] NCCL INFO comm 0x17e032ad0 rank 6 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x3a0bc024a5812684 - Init START
f18n05:1008222:1008576 [3] NCCL INFO Using network IB
f18n05:1008222:1008576 [3] NCCL INFO comm 0x152663bc0 rank 5 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x42a519b1adea69c3 - Init START
f17n02:1076283:1076638 [4] NCCL INFO Using network IB
f17n02:1076283:1076638 [4] NCCL INFO comm 0x15a14b300 rank 0 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x42a519b1adea69c3 - Init START
f17n02:1076284:1076643 [5] NCCL INFO Using network IB
f17n02:1076284:1076643 [5] NCCL INFO comm 0x14e0939c0 rank 1 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x42a519b1adea69c3 - Init START
f17n02:1076279:1076641 [0] NCCL INFO Using network IB
f17n02:1076279:1076641 [0] NCCL INFO comm 0x161aa34c0 rank 4 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x3a0bc024a5812684 - Init START
d11n17:1142856:1143207 [2] NCCL INFO Using network IB
d11n17:1142856:1143207 [2] NCCL INFO comm 0x13de3a6f0 rank 4 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x6a336f573a53dcba - Init START
d11n17:1142858:1143210 [4] NCCL INFO Using network IB
d11n17:1142858:1143210 [4] NCCL INFO comm 0x134f342e0 rank 6 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x6a336f573a53dcba - Init START
f17n02:1076280:1076639 [1] NCCL INFO Using network IB
f17n02:1076280:1076639 [1] NCCL INFO comm 0x143931470 rank 5 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x3a0bc024a5812684 - Init START
d11n17:1142859:1143211 [5] NCCL INFO Using network IB
d11n17:1142859:1143211 [5] NCCL INFO comm 0x1371c4ff0 rank 7 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x6a336f573a53dcba - Init START
d11n17:1142855:1143206 [1] NCCL INFO Using network IB
d11n17:1142855:1143206 [1] NCCL INFO comm 0x131a44b10 rank 3 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x6a336f573a53dcba - Init START
d11n17:1142857:1143209 [3] NCCL INFO Using network IB
d11n17:1142857:1143209 [3] NCCL INFO comm 0x132a99450 rank 5 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x6a336f573a53dcba - Init START
d11n17:1142854:1143208 [0] NCCL INFO Using network IB
d11n17:1142854:1143208 [0] NCCL INFO comm 0x15c758320 rank 2 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x6a336f573a53dcba - Init START
f17n02:1076282:1076642 [3] NCCL INFO Using network IB
f17n02:1076282:1076642 [3] NCCL INFO comm 0x12aeb4b90 rank 7 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x3a0bc024a5812684 - Init START
f16n16:1079914:1080281 [2] NCCL INFO Using network IB
d09n08:1073956:1074319 [2] NCCL INFO Using network IB
d09n08:1073956:1074319 [2] NCCL INFO comm 0x161225c40 rank 0 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0xc3dd8166c9a61f34 - Init START
d09n08:1073958:1074320 [4] NCCL INFO Using network IB
d09n08:1073958:1074320 [4] NCCL INFO comm 0x14fd946c0 rank 2 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xc3dd8166c9a61f34 - Init START
d09n08:1073954:1074323 [0] NCCL INFO Using network IB
d09n08:1073954:1074323 [0] NCCL INFO comm 0x14d8a2080 rank 6 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x1cb338cf47f3186f - Init START
f16n16:1079912:1080280 [0] NCCL INFO Using network IB
d09n08:1073957:1074321 [3] NCCL INFO Using network IB
d09n08:1073957:1074321 [3] NCCL INFO comm 0x15b80a480 rank 1 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xc3dd8166c9a61f34 - Init START
d09n08:1073959:1074322 [5] NCCL INFO Using network IB
d09n08:1073959:1074322 [5] NCCL INFO comm 0x15db7f480 rank 3 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xc3dd8166c9a61f34 - Init START
f16n16:1079915:1080283 [3] NCCL INFO Using network IB
d09n07:1063021:1063456 [4] NCCL INFO Using network IB
d09n07:1063021:1063456 [4] NCCL INFO comm 0x179bc6a50 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x1cb338cf47f3186f - Init START
f16n16:1079913:1080279 [1] NCCL INFO Using network IB
d14n09:567668:568058 [2] NCCL INFO Using network IB
d09n07:1063020:1063457 [3] NCCL INFO Using network IB
d09n07:1063020:1063457 [3] NCCL INFO comm 0x120750bb0 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x1cb338cf47f3186f - Init START
d09n07:1063019:1063460 [2] NCCL INFO Using network IB
d09n07:1063019:1063460 [2] NCCL INFO comm 0x161a26780 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x1cb338cf47f3186f - Init START
f16n16:1079916:1080278 [4] NCCL INFO Using network IB
d14n09:567667:568059 [1] NCCL INFO Using network IB
f16n16:1079917:1080282 [5] NCCL INFO Using network IB
d14n09:567666:568060 [0] NCCL INFO Using network IB
d14n10:565683:566056 [2] NCCL INFO Using network IB
d14n09:567671:568061 [5] NCCL INFO Using network IB
d09n07:1063018:1063459 [1] NCCL INFO Using network IB
d09n07:1063018:1063459 [1] NCCL INFO comm 0x12716e210 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x1cb338cf47f3186f - Init START
d14n10:565682:566057 [1] NCCL INFO Using network IB
d09n07:1063022:1063458 [5] NCCL INFO Using network IB
d09n07:1063022:1063458 [5] NCCL INFO comm 0x16ad47a60 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x1cb338cf47f3186f - Init START
d14n08:1173248:1173633 [1] NCCL INFO Using network IB
d14n11:1169357:1169728 [1] NCCL INFO Using network IB
d14n11:1169357:1169728 [1] NCCL INFO comm 0x132cafab0 rank 3 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x66e3f535c9700c0f - Init START
d14n10:565686:566058 [5] NCCL INFO Using network IB
d14n10:565686:566058 [5] NCCL INFO comm 0x11fc6ca10 rank 1 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x66e3f535c9700c0f - Init START
d14n08:1173247:1173628 [0] NCCL INFO Using network IB
d14n11:1169358:1169730 [2] NCCL INFO Using network IB
d14n11:1169358:1169730 [2] NCCL INFO comm 0x142196b00 rank 4 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x66e3f535c9700c0f - Init START
d14n10:565685:566055 [4] NCCL INFO Using network IB
d14n10:565685:566055 [4] NCCL INFO comm 0x1642c9590 rank 0 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x66e3f535c9700c0f - Init START
d14n11:1169356:1169733 [0] NCCL INFO Using network IB
d14n11:1169356:1169733 [0] NCCL INFO comm 0x15719da10 rank 2 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x66e3f535c9700c0f - Init START
d14n10:565684:566060 [3] NCCL INFO Using network IB
d14n08:1173251:1173631 [4] NCCL INFO Using network IB
d14n08:1173252:1173629 [5] NCCL INFO Using network IB
d14n08:1173249:1173632 [2] NCCL INFO Using network IB
d14n08:1173250:1173630 [3] NCCL INFO Using network IB
d14n09:567669:568062 [3] NCCL INFO Using network IB
d14n10:565681:566059 [0] NCCL INFO Using network IB
d09n08:1073955:1074324 [1] NCCL INFO Using network IB
d09n08:1073955:1074324 [1] NCCL INFO comm 0x15da36520 rank 7 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x1cb338cf47f3186f - Init START
d14n11:1169360:1169731 [4] NCCL INFO Using network IB
d14n11:1169360:1169731 [4] NCCL INFO comm 0x119bfe460 rank 6 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x66e3f535c9700c0f - Init START
d17n06:1216532:1216926 [2] NCCL INFO Using network IB
d17n06:1216532:1216926 [2] NCCL INFO comm 0x130d1c880 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x2ed1f251b0bfef39 - Init START
d17n06:1216530:1216923 [0] NCCL INFO Using network IB
d17n06:1216530:1216923 [0] NCCL INFO comm 0x147f44c70 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x2ed1f251b0bfef39 - Init START
f18n05:1008224:1008577 [5] NCCL INFO Using network IB
f18n05:1008224:1008577 [5] NCCL INFO comm 0x150aabfd0 rank 7 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x42a519b1adea69c3 - Init START
d17n07:1212412:1212803 [2] NCCL INFO Using network IB
d17n06:1216531:1216928 [1] NCCL INFO Using network IB
d17n06:1216531:1216928 [1] NCCL INFO comm 0x12333ff00 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x2ed1f251b0bfef39 - Init START
d17n07:1212410:1212807 [0] NCCL INFO Using network IB
d17n07:1212410:1212807 [0] NCCL INFO comm 0x1741b81d0 rank 6 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x2ed1f251b0bfef39 - Init START
d17n06:1216534:1216925 [4] NCCL INFO Using network IB
d17n06:1216534:1216925 [4] NCCL INFO comm 0x12ae2ac40 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x2ed1f251b0bfef39 - Init START
d14n11:1169359:1169729 [3] NCCL INFO Using network IB
d14n11:1169359:1169729 [3] NCCL INFO comm 0x168968a00 rank 5 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x66e3f535c9700c0f - Init START
d17n06:1216535:1216924 [5] NCCL INFO Using network IB
d17n06:1216535:1216924 [5] NCCL INFO comm 0x13d8db700 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x2ed1f251b0bfef39 - Init START
d14n11:1169361:1169732 [5] NCCL INFO Using network IB
d14n11:1169361:1169732 [5] NCCL INFO comm 0x12c82f150 rank 7 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x66e3f535c9700c0f - Init START
d17n06:1216533:1216927 [3] NCCL INFO Using network IB
d17n06:1216533:1216927 [3] NCCL INFO comm 0x13ee572a0 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x2ed1f251b0bfef39 - Init START
d09n07:1063016:1063455 [0] NCCL INFO Using network IB
d09n07:1063016:1063455 [0] NCCL INFO comm 0x140efa8a0 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x1cb338cf47f3186f - Init START
d17n07:1212414:1212805 [4] NCCL INFO comm 0x17cb3f600 rank 2 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xb4380781c8b9c34c - Init START
d17n07:1212415:1212804 [5] NCCL INFO comm 0x1512d5af0 rank 3 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xb4380781c8b9c34c - Init START
d17n07:1212413:1212806 [3] NCCL INFO comm 0x139fd6f80 rank 1 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xb4380781c8b9c34c - Init START
f16n17:1090961:1091324 [2] NCCL INFO comm 0x122eeff80 rank 4 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x26c01b22882866ea - Init START
f16n17:1090963:1091328 [4] NCCL INFO comm 0x13fea43d0 rank 6 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x26c01b22882866ea - Init START
f16n17:1090964:1091329 [5] NCCL INFO comm 0x17515e920 rank 7 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x26c01b22882866ea - Init START
f16n17:1090960:1091325 [1] NCCL INFO comm 0x162933540 rank 3 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x26c01b22882866ea - Init START
d11n16:1130272:1130642 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d11n16:1130273:1130643 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
f16n17:1090959:1091326 [0] NCCL INFO comm 0x1472aad40 rank 2 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x26c01b22882866ea - Init START
f16n17:1090962:1091327 [3] NCCL INFO comm 0x13c1790f0 rank 5 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x26c01b22882866ea - Init START
d14n09:567670:568063 [4] NCCL INFO comm 0x164d3cbc0 rank 2 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x2d88817d8ea3a688 - Init START
f17n02:1076283:1076638 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
f17n02:1076284:1076643 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d09n08:1073954:1074323 [0] NCCL INFO Setting affinity for GPU 0 to 0f
f16n16:1079914:1080281 [2] NCCL INFO comm 0x165ac6060 rank 6 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0xb4380781c8b9c34c - Init START
f16n16:1079912:1080280 [0] NCCL INFO comm 0x143af5350 rank 4 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0xb4380781c8b9c34c - Init START
f16n16:1079915:1080283 [3] NCCL INFO comm 0x1640ed2e0 rank 7 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xb4380781c8b9c34c - Init START
f16n16:1079913:1080279 [1] NCCL INFO comm 0x17ec25cc0 rank 5 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0xb4380781c8b9c34c - Init START
d14n09:567668:568058 [2] NCCL INFO comm 0x12c5b26d0 rank 0 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x2d88817d8ea3a688 - Init START
f16n16:1079916:1080278 [4] NCCL INFO comm 0x150d1de40 rank 0 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x26c01b22882866ea - Init START
f16n16:1079917:1080282 [5] NCCL INFO comm 0x171006ac0 rank 1 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x26c01b22882866ea - Init START
d14n10:565683:566056 [2] NCCL INFO comm 0x12c9d4b80 rank 6 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x2d88817d8ea3a688 - Init START
d14n09:567667:568059 [1] NCCL INFO comm 0x1522b2b00 rank 7 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x1c908ef09309e642 - Init START
d14n09:567666:568060 [0] NCCL INFO comm 0x1818e3dc0 rank 6 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x1c908ef09309e642 - Init START
d14n10:565682:566057 [1] NCCL INFO comm 0x17a9539a0 rank 5 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x2d88817d8ea3a688 - Init START
d14n09:567671:568061 [5] NCCL INFO comm 0x13a2d4d90 rank 3 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x2d88817d8ea3a688 - Init START
d14n08:1173248:1173633 [1] NCCL INFO comm 0x13b012820 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x1c908ef09309e642 - Init START
d14n08:1173247:1173628 [0] NCCL INFO comm 0x139a1aea0 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x1c908ef09309e642 - Init START
d14n10:565686:566058 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d14n10:565685:566055 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d14n10:565684:566060 [3] NCCL INFO comm 0x12f1e1010 rank 7 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x2d88817d8ea3a688 - Init START
d14n08:1173251:1173631 [4] NCCL INFO comm 0x16180f260 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x1c908ef09309e642 - Init START
d14n08:1173252:1173629 [5] NCCL INFO comm 0x1356e14f0 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x1c908ef09309e642 - Init START
d14n08:1173249:1173632 [2] NCCL INFO comm 0x151d4bdc0 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x1c908ef09309e642 - Init START
d14n08:1173250:1173630 [3] NCCL INFO comm 0x166da4ff0 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x1c908ef09309e642 - Init START
d14n09:567669:568062 [3] NCCL INFO comm 0x149346280 rank 1 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x2d88817d8ea3a688 - Init START
d14n10:565681:566059 [0] NCCL INFO comm 0x16eca6d30 rank 4 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x2d88817d8ea3a688 - Init START
d09n08:1073955:1074324 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d17n07:1212412:1212803 [2] NCCL INFO comm 0x12f86a850 rank 0 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0xb4380781c8b9c34c - Init START
f17n01:970276:970641 [0] NCCL INFO Setting affinity for GPU 0 to 0f
f17n01:970277:970642 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
f17n02:1076281:1076640 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d17n07:1212414:1212805 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
f17n01:970280:970638 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
f17n01:970281:970639 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d17n07:1212415:1212804 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
f17n01:970279:970640 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d17n07:1212411:1212808 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
f17n01:970278:970637 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d17n07:1212413:1212806 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d11n16:1130271:1130647 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
f18n05:1008221:1008572 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d11n16:1130270:1130645 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d11n16:1130268:1130646 [0] NCCL INFO Setting affinity for GPU 0 to 0f
f18n05:1008219:1008573 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d11n16:1130269:1130644 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
f18n05:1008220:1008574 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
f18n05:1008222:1008576 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
f18n05:1008223:1008575 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
f17n02:1076279:1076641 [0] NCCL INFO Setting affinity for GPU 0 to 0f
f17n02:1076280:1076639 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d11n17:1142855:1143206 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
f17n02:1076282:1076642 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
f16n16:1079914:1080281 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d09n08:1073956:1074319 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d09n08:1073958:1074320 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d09n08:1073957:1074321 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
f16n16:1079912:1080280 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d09n08:1073959:1074322 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
f16n16:1079915:1080283 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
f16n16:1079913:1080279 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d09n07:1063021:1063456 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d09n07:1063020:1063457 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d09n07:1063019:1063460 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
f16n16:1079916:1080278 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
f16n16:1079917:1080282 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d14n10:565683:566056 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d14n09:567667:568059 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d09n07:1063018:1063459 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d14n09:567666:568060 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d14n10:565682:566057 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d09n07:1063022:1063458 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d14n10:565684:566060 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d14n10:565681:566059 [0] NCCL INFO Setting affinity for GPU 0 to 0f
f18n05:1008224:1008577 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d17n07:1212412:1212803 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d17n07:1212410:1212807 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d09n07:1063016:1063455 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d09n08:1073957:1074321 [3] NCCL INFO Trees [0] 2/4/-1->1->-1 [1] 2/4/-1->1->-1 [2] 2/-1/-1->1->4 [3] 2/-1/-1->1->4
d09n08:1073957:1074321 [3] NCCL INFO P2P Chunksize set to 131072
d09n08:1073958:1074320 [4] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1
d09n08:1073958:1074320 [4] NCCL INFO P2P Chunksize set to 131072
d11n16:1130269:1130644 [1] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/-1/-1->5->4 [3] 6/-1/-1->5->4
d11n16:1130269:1130644 [1] NCCL INFO P2P Chunksize set to 131072
d09n08:1073956:1074319 [2] NCCL INFO Channel 00/04 :    0   1   2   3   4   5   6   7
d09n08:1073956:1074319 [2] NCCL INFO Channel 01/04 :    0   7   6   5   4   1   2   3
d09n08:1073956:1074319 [2] NCCL INFO Channel 02/04 :    0   1   2   3   4   5   6   7
d09n08:1073956:1074319 [2] NCCL INFO Channel 03/04 :    0   7   6   5   4   1   2   3
d09n08:1073956:1074319 [2] NCCL INFO Trees [0] -1/-1/-1->0->3 [1] -1/-1/-1->0->3 [2] -1/-1/-1->0->3 [3] -1/-1/-1->0->3
d09n08:1073956:1074319 [2] NCCL INFO P2P Chunksize set to 131072
d09n08:1073956:1074319 [2] NCCL INFO Channel 00/0 : 7[3] -> 0[2] [receive] via NET/IB/0
d09n08:1073956:1074319 [2] NCCL INFO Channel 02/0 : 7[3] -> 0[2] [receive] via NET/IB/0
d09n08:1073956:1074319 [2] NCCL INFO Channel 00/0 : 0[2] -> 1[3] via P2P/IPC
d11n16:1130270:1130645 [2] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5
d11n16:1130270:1130645 [2] NCCL INFO P2P Chunksize set to 131072
d11n16:1130271:1130647 [3] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] -1/-1/-1->7->6 [3] -1/-1/-1->7->6
d11n16:1130271:1130647 [3] NCCL INFO P2P Chunksize set to 131072
d11n16:1130268:1130646 [0] NCCL INFO Trees [0] 5/-1/-1->4->1 [1] 5/-1/-1->4->1 [2] 5/1/-1->4->-1 [3] 5/1/-1->4->-1
d11n16:1130268:1130646 [0] NCCL INFO P2P Chunksize set to 131072
d11n16:1130268:1130646 [0] NCCL INFO Channel 00/0 : 3[5] -> 4[0] [receive] via NET/IB/0
d11n16:1130268:1130646 [0] NCCL INFO Channel 02/0 : 3[5] -> 4[0] [receive] via NET/IB/0
d11n16:1130268:1130646 [0] NCCL INFO Channel 00/0 : 4[0] -> 5[1] via P2P/IPC
d09n08:1073956:1074319 [2] NCCL INFO Channel 02/0 : 0[2] -> 1[3] via P2P/IPC
d11n16:1130268:1130646 [0] NCCL INFO Channel 02/0 : 4[0] -> 5[1] via P2P/IPC
d09n08:1073957:1074321 [3] NCCL INFO Channel 00/0 : 1[3] -> 2[4] via P2P/IPC
d11n16:1130269:1130644 [1] NCCL INFO Channel 00/0 : 5[1] -> 6[2] via P2P/IPC
d11n16:1130270:1130645 [2] NCCL INFO Channel 00/0 : 6[2] -> 7[3] via P2P/IPC
d09n08:1073957:1074321 [3] NCCL INFO Channel 01/0 : 1[3] -> 2[4] via P2P/IPC
d11n16:1130269:1130644 [1] NCCL INFO Channel 02/0 : 5[1] -> 6[2] via P2P/IPC
d11n16:1130270:1130645 [2] NCCL INFO Channel 02/0 : 6[2] -> 7[3] via P2P/IPC
d09n08:1073957:1074321 [3] NCCL INFO Channel 02/0 : 1[3] -> 2[4] via P2P/IPC
d09n08:1073958:1074320 [4] NCCL INFO Channel 00/0 : 2[4] -> 3[5] via P2P/IPC
d09n08:1073957:1074321 [3] NCCL INFO Channel 03/0 : 1[3] -> 2[4] via P2P/IPC
d09n08:1073958:1074320 [4] NCCL INFO Channel 01/0 : 2[4] -> 3[5] via P2P/IPC
d11n16:1130271:1130647 [3] NCCL INFO Channel 00/0 : 7[3] -> 0[2] [send] via NET/IB/1
d11n16:1130271:1130647 [3] NCCL INFO Channel 02/0 : 7[3] -> 0[2] [send] via NET/IB/1
d11n16:1130271:1130647 [3] NCCL INFO Channel 01/0 : 0[2] -> 7[3] [receive] via NET/IB/3
d11n16:1130271:1130647 [3] NCCL INFO Channel 03/0 : 0[2] -> 7[3] [receive] via NET/IB/3
d11n16:1130271:1130647 [3] NCCL INFO Channel 01/0 : 7[3] -> 6[2] via P2P/IPC
d09n08:1073958:1074320 [4] NCCL INFO Channel 02/0 : 2[4] -> 3[5] via P2P/IPC
f17n01:970280:970638 [4] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1
f17n01:970280:970638 [4] NCCL INFO P2P Chunksize set to 131072
d11n16:1130271:1130647 [3] NCCL INFO Channel 03/0 : 7[3] -> 6[2] via P2P/IPC
f17n01:970279:970640 [3] NCCL INFO Trees [0] 2/4/-1->1->-1 [1] 2/4/-1->1->-1 [2] 2/-1/-1->1->4 [3] 2/-1/-1->1->4
f17n01:970279:970640 [3] NCCL INFO P2P Chunksize set to 131072
d09n08:1073958:1074320 [4] NCCL INFO Channel 03/0 : 2[4] -> 3[5] via P2P/IPC
f17n01:970278:970637 [2] NCCL INFO Channel 00/04 :    0   1   2   3   4   5   6   7
f17n01:970278:970637 [2] NCCL INFO Channel 01/04 :    0   7   6   5   4   1   2   3
f17n01:970278:970637 [2] NCCL INFO Channel 02/04 :    0   1   2   3   4   5   6   7
f17n01:970278:970637 [2] NCCL INFO Channel 03/04 :    0   7   6   5   4   1   2   3
f17n01:970278:970637 [2] NCCL INFO Trees [0] -1/-1/-1->0->3 [1] -1/-1/-1->0->3 [2] -1/-1/-1->0->3 [3] -1/-1/-1->0->3
f17n01:970278:970637 [2] NCCL INFO P2P Chunksize set to 131072
f17n01:970278:970637 [2] NCCL INFO Channel 00/0 : 7[3] -> 0[2] [receive] via NET/IB/0
f17n01:970278:970637 [2] NCCL INFO Channel 02/0 : 7[3] -> 0[2] [receive] via NET/IB/0
f17n01:970278:970637 [2] NCCL INFO Channel 00/0 : 0[2] -> 1[3] via P2P/IPC
f17n02:1076282:1076642 [3] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] -1/-1/-1->7->6 [3] -1/-1/-1->7->6
f17n02:1076282:1076642 [3] NCCL INFO P2P Chunksize set to 131072
f17n02:1076280:1076639 [1] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/-1/-1->5->4 [3] 6/-1/-1->5->4
f17n02:1076280:1076639 [1] NCCL INFO P2P Chunksize set to 131072
d11n16:1130269:1130644 [1] NCCL INFO Channel 01/0 : 5[1] -> 4[0] via P2P/IPC
d11n16:1130270:1130645 [2] NCCL INFO Channel 01/0 : 6[2] -> 5[1] via P2P/IPC
f17n02:1076281:1076640 [2] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5
f17n02:1076281:1076640 [2] NCCL INFO P2P Chunksize set to 131072
f17n02:1076279:1076641 [0] NCCL INFO Trees [0] 5/-1/-1->4->1 [1] 5/-1/-1->4->1 [2] 5/1/-1->4->-1 [3] 5/1/-1->4->-1
f17n02:1076279:1076641 [0] NCCL INFO P2P Chunksize set to 131072
f17n02:1076279:1076641 [0] NCCL INFO Channel 00/0 : 3[5] -> 4[0] [receive] via NET/IB/0
f17n02:1076279:1076641 [0] NCCL INFO Channel 02/0 : 3[5] -> 4[0] [receive] via NET/IB/0
f17n02:1076279:1076641 [0] NCCL INFO Channel 00/0 : 4[0] -> 5[1] via P2P/IPC
d11n16:1130270:1130645 [2] NCCL INFO Channel 03/0 : 6[2] -> 5[1] via P2P/IPC
d11n16:1130269:1130644 [1] NCCL INFO Channel 03/0 : 5[1] -> 4[0] via P2P/IPC
f17n01:970278:970637 [2] NCCL INFO Channel 02/0 : 0[2] -> 1[3] via P2P/IPC
f17n01:970279:970640 [3] NCCL INFO Channel 00/0 : 1[3] -> 2[4] via P2P/IPC
f17n02:1076279:1076641 [0] NCCL INFO Channel 02/0 : 4[0] -> 5[1] via P2P/IPC
f17n01:970279:970640 [3] NCCL INFO Channel 01/0 : 1[3] -> 2[4] via P2P/IPC
f17n02:1076280:1076639 [1] NCCL INFO Channel 00/0 : 5[1] -> 6[2] via P2P/IPC
f17n02:1076281:1076640 [2] NCCL INFO Channel 00/0 : 6[2] -> 7[3] via P2P/IPC
f17n01:970279:970640 [3] NCCL INFO Channel 02/0 : 1[3] -> 2[4] via P2P/IPC
f17n01:970280:970638 [4] NCCL INFO Channel 00/0 : 2[4] -> 3[5] via P2P/IPC
f17n02:1076280:1076639 [1] NCCL INFO Channel 02/0 : 5[1] -> 6[2] via P2P/IPC
f17n02:1076281:1076640 [2] NCCL INFO Channel 02/0 : 6[2] -> 7[3] via P2P/IPC
f17n01:970279:970640 [3] NCCL INFO Channel 03/0 : 1[3] -> 2[4] via P2P/IPC
f17n01:970280:970638 [4] NCCL INFO Channel 01/0 : 2[4] -> 3[5] via P2P/IPC
d11n16:1130270:1130645 [2] NCCL INFO Connected all rings
f17n01:970280:970638 [4] NCCL INFO Channel 02/0 : 2[4] -> 3[5] via P2P/IPC
f17n02:1076282:1076642 [3] NCCL INFO Channel 00/0 : 7[3] -> 0[2] [send] via NET/IB/1
f17n02:1076282:1076642 [3] NCCL INFO Channel 02/0 : 7[3] -> 0[2] [send] via NET/IB/1
f17n02:1076282:1076642 [3] NCCL INFO Channel 01/0 : 0[2] -> 7[3] [receive] via NET/IB/3
f17n02:1076282:1076642 [3] NCCL INFO Channel 03/0 : 0[2] -> 7[3] [receive] via NET/IB/3
f17n02:1076282:1076642 [3] NCCL INFO Channel 01/0 : 7[3] -> 6[2] via P2P/IPC
f17n01:970280:970638 [4] NCCL INFO Channel 03/0 : 2[4] -> 3[5] via P2P/IPC
d11n16:1130270:1130645 [2] NCCL INFO Channel 01/0 : 6[2] -> 7[3] via P2P/IPC
f17n02:1076282:1076642 [3] NCCL INFO Channel 03/0 : 7[3] -> 6[2] via P2P/IPC
d11n16:1130270:1130645 [2] NCCL INFO Channel 03/0 : 6[2] -> 7[3] via P2P/IPC
f17n02:1076280:1076639 [1] NCCL INFO Channel 01/0 : 5[1] -> 4[0] via P2P/IPC
f17n02:1076281:1076640 [2] NCCL INFO Channel 01/0 : 6[2] -> 5[1] via P2P/IPC
f17n02:1076281:1076640 [2] NCCL INFO Channel 03/0 : 6[2] -> 5[1] via P2P/IPC
f17n02:1076280:1076639 [1] NCCL INFO Channel 03/0 : 5[1] -> 4[0] via P2P/IPC
f17n02:1076281:1076640 [2] NCCL INFO Connected all rings
f17n02:1076281:1076640 [2] NCCL INFO Channel 01/0 : 6[2] -> 7[3] via P2P/IPC
f17n02:1076281:1076640 [2] NCCL INFO Channel 03/0 : 6[2] -> 7[3] via P2P/IPC
f16n16:1079914:1080281 [2] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5
f16n16:1079914:1080281 [2] NCCL INFO P2P Chunksize set to 131072
f16n16:1079915:1080283 [3] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] -1/-1/-1->7->6 [3] -1/-1/-1->7->6
f16n16:1079915:1080283 [3] NCCL INFO P2P Chunksize set to 131072
d17n07:1212414:1212805 [4] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1
d17n07:1212414:1212805 [4] NCCL INFO P2P Chunksize set to 131072
f16n16:1079912:1080280 [0] NCCL INFO Trees [0] 5/-1/-1->4->1 [1] 5/-1/-1->4->1 [2] 5/1/-1->4->-1 [3] 5/1/-1->4->-1
f16n16:1079912:1080280 [0] NCCL INFO P2P Chunksize set to 131072
f16n16:1079912:1080280 [0] NCCL INFO Channel 00/0 : 3[5] -> 4[0] [receive] via NET/IB/0
f16n16:1079912:1080280 [0] NCCL INFO Channel 02/0 : 3[5] -> 4[0] [receive] via NET/IB/0
f16n16:1079912:1080280 [0] NCCL INFO Channel 00/0 : 4[0] -> 5[1] via P2P/IPC
d17n07:1212413:1212806 [3] NCCL INFO Trees [0] 2/4/-1->1->-1 [1] 2/4/-1->1->-1 [2] 2/-1/-1->1->4 [3] 2/-1/-1->1->4
d17n07:1212413:1212806 [3] NCCL INFO P2P Chunksize set to 131072
d17n07:1212415:1212804 [5] NCCL INFO Trees [0] 0/-1/-1->3->2 [1] 0/-1/-1->3->2 [2] 0/-1/-1->3->2 [3] 0/-1/-1->3->2
d17n07:1212415:1212804 [5] NCCL INFO P2P Chunksize set to 131072
d17n07:1212412:1212803 [2] NCCL INFO Channel 00/04 :    0   1   2   3   4   5   6   7
d17n07:1212412:1212803 [2] NCCL INFO Channel 01/04 :    0   7   6   5   4   1   2   3
d17n07:1212412:1212803 [2] NCCL INFO Channel 02/04 :    0   1   2   3   4   5   6   7
d17n07:1212412:1212803 [2] NCCL INFO Channel 03/04 :    0   7   6   5   4   1   2   3
d17n07:1212412:1212803 [2] NCCL INFO Trees [0] -1/-1/-1->0->3 [1] -1/-1/-1->0->3 [2] -1/-1/-1->0->3 [3] -1/-1/-1->0->3
d17n07:1212412:1212803 [2] NCCL INFO P2P Chunksize set to 131072
d17n07:1212412:1212803 [2] NCCL INFO Channel 00/0 : 7[3] -> 0[2] [receive] via NET/IB/0
d17n07:1212412:1212803 [2] NCCL INFO Channel 02/0 : 7[3] -> 0[2] [receive] via NET/IB/0
d17n07:1212412:1212803 [2] NCCL INFO Channel 00/0 : 0[2] -> 1[3] via P2P/IPC
f16n16:1079912:1080280 [0] NCCL INFO Channel 02/0 : 4[0] -> 5[1] via P2P/IPC
f16n16:1079914:1080281 [2] NCCL INFO Channel 00/0 : 6[2] -> 7[3] via P2P/IPC
d17n07:1212412:1212803 [2] NCCL INFO Channel 02/0 : 0[2] -> 1[3] via P2P/IPC
f16n16:1079914:1080281 [2] NCCL INFO Channel 02/0 : 6[2] -> 7[3] via P2P/IPC
d17n07:1212413:1212806 [3] NCCL INFO Channel 00/0 : 1[3] -> 2[4] via P2P/IPC
f16n16:1079915:1080283 [3] NCCL INFO Channel 00/0 : 7[3] -> 0[2] [send] via NET/IB/1
f16n16:1079915:1080283 [3] NCCL INFO Channel 02/0 : 7[3] -> 0[2] [send] via NET/IB/1
f16n16:1079915:1080283 [3] NCCL INFO Channel 01/0 : 0[2] -> 7[3] [receive] via NET/IB/3
f16n16:1079915:1080283 [3] NCCL INFO Channel 03/0 : 0[2] -> 7[3] [receive] via NET/IB/3
f16n16:1079915:1080283 [3] NCCL INFO Channel 01/0 : 7[3] -> 6[2] via P2P/IPC
f16n16:1079915:1080283 [3] NCCL INFO Channel 03/0 : 7[3] -> 6[2] via P2P/IPC
d17n07:1212413:1212806 [3] NCCL INFO Channel 01/0 : 1[3] -> 2[4] via P2P/IPC
d17n07:1212414:1212805 [4] NCCL INFO Channel 00/0 : 2[4] -> 3[5] via P2P/IPC
d17n07:1212413:1212806 [3] NCCL INFO Channel 02/0 : 1[3] -> 2[4] via P2P/IPC
d17n07:1212414:1212805 [4] NCCL INFO Channel 01/0 : 2[4] -> 3[5] via P2P/IPC
d17n07:1212413:1212806 [3] NCCL INFO Channel 03/0 : 1[3] -> 2[4] via P2P/IPC
d17n07:1212414:1212805 [4] NCCL INFO Channel 02/0 : 2[4] -> 3[5] via P2P/IPC
d17n07:1212414:1212805 [4] NCCL INFO Channel 03/0 : 2[4] -> 3[5] via P2P/IPC
d17n07:1212415:1212804 [5] NCCL INFO Channel 00/0 : 3[5] -> 4[0] [send] via NET/IB/1
d17n07:1212415:1212804 [5] NCCL INFO Channel 02/0 : 3[5] -> 4[0] [send] via NET/IB/1
d17n07:1212415:1212804 [5] NCCL INFO Channel 01/0 : 3[5] -> 0[2] via P2P/IPC
d17n07:1212415:1212804 [5] NCCL INFO Channel 03/0 : 3[5] -> 0[2] via P2P/IPC
d17n07:1212412:1212803 [2] NCCL INFO Channel 01/0 : 0[2] -> 7[3] [send] via NET/IB/2
d17n07:1212412:1212803 [2] NCCL INFO Channel 03/0 : 0[2] -> 7[3] [send] via NET/IB/2
d17n07:1212414:1212805 [4] NCCL INFO Connected all rings
d17n07:1212414:1212805 [4] NCCL INFO Channel 00/0 : 2[4] -> 1[3] via P2P/IPC
d17n07:1212414:1212805 [4] NCCL INFO Channel 01/0 : 2[4] -> 1[3] via P2P/IPC
d17n07:1212414:1212805 [4] NCCL INFO Channel 02/0 : 2[4] -> 1[3] via P2P/IPC
d17n07:1212414:1212805 [4] NCCL INFO Channel 03/0 : 2[4] -> 1[3] via P2P/IPC
d09n08:1073959:1074322 [5] NCCL INFO Trees [0] 0/-1/-1->3->2 [1] 0/-1/-1->3->2 [2] 0/-1/-1->3->2 [3] 0/-1/-1->3->2
d09n08:1073959:1074322 [5] NCCL INFO P2P Chunksize set to 131072
d11n16:1130268:1130646 [0] NCCL INFO Channel 01/0 : 4[0] -> 1[3] [send] via NET/IB/2
d11n16:1130268:1130646 [0] NCCL INFO Channel 03/0 : 4[0] -> 1[3] [send] via NET/IB/2
d09n08:1073957:1074321 [3] NCCL INFO Channel 01/0 : 4[0] -> 1[3] [receive] via NET/IB/3
d09n08:1073957:1074321 [3] NCCL INFO Channel 03/0 : 4[0] -> 1[3] [receive] via NET/IB/3
f17n01:970279:970640 [3] NCCL INFO Channel 01/0 : 4[0] -> 1[3] [receive] via NET/IB/3
f17n01:970279:970640 [3] NCCL INFO Channel 03/0 : 4[0] -> 1[3] [receive] via NET/IB/3
f17n01:970281:970639 [5] NCCL INFO Trees [0] 0/-1/-1->3->2 [1] 0/-1/-1->3->2 [2] 0/-1/-1->3->2 [3] 0/-1/-1->3->2
f17n01:970281:970639 [5] NCCL INFO P2P Chunksize set to 131072
d09n08:1073959:1074322 [5] NCCL INFO Channel 00/0 : 3[5] -> 4[0] [send] via NET/IB/1
d09n08:1073959:1074322 [5] NCCL INFO Channel 02/0 : 3[5] -> 4[0] [send] via NET/IB/1
d09n08:1073959:1074322 [5] NCCL INFO Channel 01/0 : 3[5] -> 0[2] via P2P/IPC
d17n07:1212413:1212806 [3] NCCL INFO Channel 01/0 : 4[0] -> 1[3] [receive] via NET/IB/3
d17n07:1212413:1212806 [3] NCCL INFO Channel 03/0 : 4[0] -> 1[3] [receive] via NET/IB/3
f16n18:1091868:1092251 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
f16n18:1091866:1092249 [0] NCCL INFO Setting affinity for GPU 0 to 0f
f16n18:1091869:1092253 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
f16n18:1091871:1092252 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
f16n18:1091870:1092254 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d09n08:1073959:1074322 [5] NCCL INFO Channel 03/0 : 3[5] -> 0[2] via P2P/IPC
d14n09:567670:568063 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d11n17:1142859:1143211 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d11n17:1142856:1143207 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d11n17:1142858:1143210 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d11n17:1142854:1143208 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d11n17:1142857:1143209 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d09n08:1073954:1074323 [0] NCCL INFO Trees [0] 7/-1/-1->6->0 [1] 7/0/-1->6->-1
d09n08:1073954:1074323 [0] NCCL INFO P2P Chunksize set to 131072
d09n08:1073956:1074319 [2] NCCL INFO Channel 01/0 : 0[2] -> 7[3] [send] via NET/IB/2
d09n08:1073956:1074319 [2] NCCL INFO Channel 03/0 : 0[2] -> 7[3] [send] via NET/IB/2
f17n02:1076284:1076643 [5] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
f17n02:1076284:1076643 [5] NCCL INFO P2P Chunksize set to 131072
f16n16:1079913:1080279 [1] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/-1/-1->5->4 [3] 6/-1/-1->5->4
f16n16:1079913:1080279 [1] NCCL INFO P2P Chunksize set to 131072
d09n07:1063021:1063456 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3
d09n07:1063021:1063456 [4] NCCL INFO P2P Chunksize set to 131072
d14n09:567668:568058 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d09n07:1063020:1063457 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2
d09n07:1063020:1063457 [3] NCCL INFO P2P Chunksize set to 131072
d09n07:1063019:1063460 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
d09n07:1063019:1063460 [2] NCCL INFO P2P Chunksize set to 131072
d09n07:1063018:1063459 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
d09n07:1063018:1063459 [1] NCCL INFO P2P Chunksize set to 131072
f17n02:1076283:1076638 [4] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7
f17n02:1076283:1076638 [4] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7
f17n02:1076283:1076638 [4] NCCL INFO Trees [0] 1/2/-1->0->-1 [1] 1/-1/-1->0->2
f17n02:1076283:1076638 [4] NCCL INFO P2P Chunksize set to 131072
f17n02:1076283:1076638 [4] NCCL INFO Channel 00/0 : 7[5] -> 0[4] [receive] via NET/IB/1
f17n02:1076283:1076638 [4] NCCL INFO Channel 01/0 : 7[5] -> 0[4] [receive] via NET/IB/1
f17n02:1076283:1076638 [4] NCCL INFO Channel 00/0 : 0[4] -> 1[5] via P2P/IPC
d09n07:1063022:1063458 [5] NCCL INFO Trees [0] -1/-1/-1->5->4 [1] -1/-1/-1->5->4
d09n07:1063022:1063458 [5] NCCL INFO P2P Chunksize set to 131072
d14n09:567671:568061 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
f17n02:1076283:1076638 [4] NCCL INFO Channel 01/0 : 0[4] -> 1[5] via P2P/IPC
d09n08:1073955:1074324 [1] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
d09n08:1073955:1074324 [1] NCCL INFO P2P Chunksize set to 131072
d14n10:565684:566060 [3] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] -1/-1/-1->7->6 [3] -1/-1/-1->7->6
d14n10:565684:566060 [3] NCCL INFO P2P Chunksize set to 131072
f18n05:1008224:1008577 [5] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
f18n05:1008224:1008577 [5] NCCL INFO P2P Chunksize set to 131072
f18n05:1008223:1008575 [4] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5
f18n05:1008223:1008575 [4] NCCL INFO P2P Chunksize set to 131072
f18n05:1008222:1008576 [3] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4
f18n05:1008222:1008576 [3] NCCL INFO P2P Chunksize set to 131072
d14n11:1169357:1169728 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d14n11:1169358:1169730 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d14n08:1173252:1173629 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d14n11:1169356:1169733 [0] NCCL INFO Setting affinity for GPU 0 to 0f
f18n05:1008220:1008574 [1] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2
f18n05:1008220:1008574 [1] NCCL INFO P2P Chunksize set to 131072
f18n05:1008221:1008572 [2] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3
f18n05:1008221:1008572 [2] NCCL INFO P2P Chunksize set to 131072
f18n05:1008219:1008573 [0] NCCL INFO Trees [0] 3/-1/-1->2->0 [1] 3/0/-1->2->-1
f18n05:1008219:1008573 [0] NCCL INFO P2P Chunksize set to 131072
f18n05:1008219:1008573 [0] NCCL INFO Channel 00/0 : 1[5] -> 2[0] [receive] via NET/IB/0
f18n05:1008219:1008573 [0] NCCL INFO Channel 01/0 : 1[5] -> 2[0] [receive] via NET/IB/0
f18n05:1008219:1008573 [0] NCCL INFO Channel 00/0 : 2[0] -> 3[1] via P2P/IPC
d14n09:567669:568062 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d14n09:567669:568062 [3] NCCL INFO Trees [0] 2/4/-1->1->-1 [1] 2/4/-1->1->-1 [2] 2/-1/-1->1->4 [3] 2/-1/-1->1->4
d14n09:567669:568062 [3] NCCL INFO P2P Chunksize set to 131072
d09n08:1073954:1074323 [0] NCCL INFO Channel 00/0 : 5[5] -> 6[0] [receive] via NET/IB/0
d09n08:1073954:1074323 [0] NCCL INFO Channel 01/0 : 5[5] -> 6[0] [receive] via NET/IB/0
d09n08:1073954:1074323 [0] NCCL INFO Channel 00/0 : 6[0] -> 7[1] via P2P/IPC
d09n07:1063016:1063455 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7
d09n07:1063016:1063455 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7
d09n07:1063016:1063455 [0] NCCL INFO Trees [0] 1/6/-1->0->-1 [1] 1/-1/-1->0->6
d09n07:1063016:1063455 [0] NCCL INFO P2P Chunksize set to 131072
d09n07:1063016:1063455 [0] NCCL INFO Channel 00/0 : 7[1] -> 0[0] [receive] via NET/IB/0
d09n07:1063016:1063455 [0] NCCL INFO Channel 01/0 : 7[1] -> 0[0] [receive] via NET/IB/0
d09n07:1063016:1063455 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/IPC
d14n10:565681:566059 [0] NCCL INFO Trees [0] 5/-1/-1->4->1 [1] 5/-1/-1->4->1 [2] 5/1/-1->4->-1 [3] 5/1/-1->4->-1
d14n10:565681:566059 [0] NCCL INFO P2P Chunksize set to 131072
d14n11:1169360:1169731 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d09n08:1073954:1074323 [0] NCCL INFO Channel 01/0 : 6[0] -> 7[1] via P2P/IPC
d14n11:1169359:1169729 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
d14n09:567670:568063 [4] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1
d14n09:567670:568063 [4] NCCL INFO P2P Chunksize set to 131072
d14n11:1169361:1169732 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d14n10:565683:566056 [2] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5
d14n10:565683:566056 [2] NCCL INFO P2P Chunksize set to 131072
d14n09:567671:568061 [5] NCCL INFO Trees [0] 0/-1/-1->3->2 [1] 0/-1/-1->3->2 [2] 0/-1/-1->3->2 [3] 0/-1/-1->3->2
d14n09:567671:568061 [5] NCCL INFO P2P Chunksize set to 131072
d14n09:567668:568058 [2] NCCL INFO Channel 00/04 :    0   1   2   3   4   5   6   7
d14n09:567668:568058 [2] NCCL INFO Channel 01/04 :    0   7   6   5   4   1   2   3
d14n09:567668:568058 [2] NCCL INFO Channel 02/04 :    0   1   2   3   4   5   6   7
d14n09:567668:568058 [2] NCCL INFO Channel 03/04 :    0   7   6   5   4   1   2   3
d14n09:567668:568058 [2] NCCL INFO Trees [0] -1/-1/-1->0->3 [1] -1/-1/-1->0->3 [2] -1/-1/-1->0->3 [3] -1/-1/-1->0->3
d14n09:567668:568058 [2] NCCL INFO P2P Chunksize set to 131072
d14n09:567668:568058 [2] NCCL INFO Channel 00/0 : 7[3] -> 0[2] [receive] via NET/IB/0
d14n09:567668:568058 [2] NCCL INFO Channel 02/0 : 7[3] -> 0[2] [receive] via NET/IB/0
d14n09:567668:568058 [2] NCCL INFO Channel 00/0 : 0[2] -> 1[3] via P2P/IPC
d14n10:565681:566059 [0] NCCL INFO Channel 00/0 : 3[5] -> 4[0] [receive] via NET/IB/0
d14n10:565681:566059 [0] NCCL INFO Channel 02/0 : 3[5] -> 4[0] [receive] via NET/IB/0
d14n10:565681:566059 [0] NCCL INFO Channel 00/0 : 4[0] -> 5[1] via P2P/IPC
f18n05:1008219:1008573 [0] NCCL INFO Channel 01/0 : 2[0] -> 3[1] via P2P/IPC
d09n07:1063016:1063455 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/IPC
d14n10:565681:566059 [0] NCCL INFO Channel 02/0 : 4[0] -> 5[1] via P2P/IPC
f18n05:1008223:1008575 [4] NCCL INFO Channel 00/0 : 6[4] -> 7[5] via P2P/IPC
f18n05:1008220:1008574 [1] NCCL INFO Channel 00/0 : 3[1] -> 4[2] via P2P/IPC
d09n07:1063021:1063456 [4] NCCL INFO Channel 00/0 : 4[4] -> 5[5] via P2P/IPC
d09n07:1063020:1063457 [3] NCCL INFO Channel 00/0 : 3[3] -> 4[4] via P2P/IPC
f18n05:1008221:1008572 [2] NCCL INFO Channel 00/0 : 4[2] -> 5[3] via P2P/IPC
f18n05:1008222:1008576 [3] NCCL INFO Channel 00/0 : 5[3] -> 6[4] via P2P/IPC
d14n10:565683:566056 [2] NCCL INFO Channel 00/0 : 6[2] -> 7[3] via P2P/IPC
d14n09:567668:568058 [2] NCCL INFO Channel 02/0 : 0[2] -> 1[3] via P2P/IPC
d14n10:565683:566056 [2] NCCL INFO Channel 02/0 : 6[2] -> 7[3] via P2P/IPC
d09n07:1063018:1063459 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/IPC
f18n05:1008220:1008574 [1] NCCL INFO Channel 01/0 : 3[1] -> 4[2] via P2P/IPC
d09n07:1063019:1063460 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/IPC
f18n05:1008221:1008572 [2] NCCL INFO Channel 01/0 : 4[2] -> 5[3] via P2P/IPC
d09n07:1063021:1063456 [4] NCCL INFO Channel 01/0 : 4[4] -> 5[5] via P2P/IPC
d09n08:1073958:1074320 [4] NCCL INFO Connected all rings
f18n05:1008222:1008576 [3] NCCL INFO Channel 01/0 : 5[3] -> 6[4] via P2P/IPC
d09n07:1063020:1063457 [3] NCCL INFO Channel 01/0 : 3[3] -> 4[4] via P2P/IPC
d14n09:567669:568062 [3] NCCL INFO Channel 00/0 : 1[3] -> 2[4] via P2P/IPC
f18n05:1008223:1008575 [4] NCCL INFO Channel 01/0 : 6[4] -> 7[5] via P2P/IPC
d09n07:1063018:1063459 [1] NCCL INFO Channel 01/0 : 1[1] -> 2[2] via P2P/IPC
d09n07:1063019:1063460 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/IPC
d14n10:565684:566060 [3] NCCL INFO Channel 00/0 : 7[3] -> 0[2] [send] via NET/IB/1
d14n10:565684:566060 [3] NCCL INFO Channel 02/0 : 7[3] -> 0[2] [send] via NET/IB/1
d14n10:565684:566060 [3] NCCL INFO Channel 01/0 : 0[2] -> 7[3] [receive] via NET/IB/3
d14n10:565684:566060 [3] NCCL INFO Channel 03/0 : 0[2] -> 7[3] [receive] via NET/IB/3
d14n10:565684:566060 [3] NCCL INFO Channel 01/0 : 7[3] -> 6[2] via P2P/IPC
d14n09:567669:568062 [3] NCCL INFO Channel 01/0 : 1[3] -> 2[4] via P2P/IPC
d14n10:565684:566060 [3] NCCL INFO Channel 03/0 : 7[3] -> 6[2] via P2P/IPC
d14n09:567669:568062 [3] NCCL INFO Channel 02/0 : 1[3] -> 2[4] via P2P/IPC
d14n09:567670:568063 [4] NCCL INFO Channel 00/0 : 2[4] -> 3[5] via P2P/IPC
d14n09:567669:568062 [3] NCCL INFO Channel 03/0 : 1[3] -> 2[4] via P2P/IPC
d14n09:567670:568063 [4] NCCL INFO Channel 01/0 : 2[4] -> 3[5] via P2P/IPC
d09n08:1073958:1074320 [4] NCCL INFO Channel 00/0 : 2[4] -> 1[3] via P2P/IPC
d14n09:567670:568063 [4] NCCL INFO Channel 02/0 : 2[4] -> 3[5] via P2P/IPC
d09n08:1073958:1074320 [4] NCCL INFO Channel 01/0 : 2[4] -> 1[3] via P2P/IPC
d14n09:567670:568063 [4] NCCL INFO Channel 03/0 : 2[4] -> 3[5] via P2P/IPC
d09n08:1073958:1074320 [4] NCCL INFO Channel 02/0 : 2[4] -> 1[3] via P2P/IPC
f18n05:1008220:1008574 [1] NCCL INFO Connected all rings
d09n08:1073958:1074320 [4] NCCL INFO Channel 03/0 : 2[4] -> 1[3] via P2P/IPC
f18n05:1008221:1008572 [2] NCCL INFO Connected all rings
d14n09:567671:568061 [5] NCCL INFO Channel 00/0 : 3[5] -> 4[0] [send] via NET/IB/1
d14n09:567671:568061 [5] NCCL INFO Channel 02/0 : 3[5] -> 4[0] [send] via NET/IB/1
d14n09:567671:568061 [5] NCCL INFO Channel 01/0 : 3[5] -> 0[2] via P2P/IPC
d09n07:1063020:1063457 [3] NCCL INFO Connected all rings
d09n07:1063018:1063459 [1] NCCL INFO Connected all rings
d14n09:567671:568061 [5] NCCL INFO Channel 03/0 : 3[5] -> 0[2] via P2P/IPC
d09n08:1073959:1074322 [5] NCCL INFO Connected all rings
f18n05:1008222:1008576 [3] NCCL INFO Connected all rings
f18n05:1008220:1008574 [1] NCCL INFO Channel 00/0 : 3[1] -> 2[0] via P2P/IPC
f18n05:1008221:1008572 [2] NCCL INFO Channel 00/0 : 4[2] -> 3[1] via P2P/IPC
d09n07:1063019:1063460 [2] NCCL INFO Connected all rings
d11n16:1130268:1130646 [0] NCCL INFO Connected all rings
d11n16:1130268:1130646 [0] NCCL INFO Channel 01/0 : 4[0] -> 5[1] via P2P/IPC
d09n07:1063020:1063457 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/IPC
d09n07:1063018:1063459 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/IPC
d14n09:567668:568058 [2] NCCL INFO Channel 01/0 : 0[2] -> 7[3] [send] via NET/IB/2
d14n09:567668:568058 [2] NCCL INFO Channel 03/0 : 0[2] -> 7[3] [send] via NET/IB/2
f18n05:1008220:1008574 [1] NCCL INFO Channel 01/0 : 3[1] -> 2[0] via P2P/IPC
f18n05:1008221:1008572 [2] NCCL INFO Channel 01/0 : 4[2] -> 3[1] via P2P/IPC
f18n05:1008222:1008576 [3] NCCL INFO Channel 00/0 : 5[3] -> 4[2] via P2P/IPC
d11n16:1130268:1130646 [0] NCCL INFO Channel 03/0 : 4[0] -> 5[1] via P2P/IPC
d09n07:1063020:1063457 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/IPC
f18n05:1008222:1008576 [3] NCCL INFO Channel 01/0 : 5[3] -> 4[2] via P2P/IPC
d09n07:1063018:1063459 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/IPC
d09n07:1063019:1063460 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/IPC
d09n07:1063019:1063460 [2] NCCL INFO Channel 01/0 : 2[2] -> 1[1] via P2P/IPC
d09n08:1073956:1074319 [2] NCCL INFO Connected all rings
d09n08:1073956:1074319 [2] NCCL INFO Channel 00/0 : 0[2] -> 3[5] via P2P/IPC
d09n08:1073956:1074319 [2] NCCL INFO Channel 01/0 : 0[2] -> 3[5] via P2P/IPC
d11n16:1130269:1130644 [1] NCCL INFO Connected all rings
d09n08:1073956:1074319 [2] NCCL INFO Channel 02/0 : 0[2] -> 3[5] via P2P/IPC
f18n05:1008221:1008572 [2] NCCL INFO Connected all trees
f18n05:1008221:1008572 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f18n05:1008221:1008572 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n09:567670:568063 [4] NCCL INFO Connected all rings
d09n08:1073956:1074319 [2] NCCL INFO Channel 03/0 : 0[2] -> 3[5] via P2P/IPC
d09n07:1063019:1063460 [2] NCCL INFO Connected all trees
d09n07:1063019:1063460 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d09n07:1063019:1063460 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n16:1130271:1130647 [3] NCCL INFO Connected all rings
d09n08:1073959:1074322 [5] NCCL INFO Channel 00/0 : 3[5] -> 0[2] via P2P/IPC
d11n16:1130269:1130644 [1] NCCL INFO Channel 01/0 : 5[1] -> 6[2] via P2P/IPC
f17n02:1076279:1076641 [0] NCCL INFO Channel 01/0 : 4[0] -> 1[3] [send] via NET/IB/2
f17n02:1076279:1076641 [0] NCCL INFO Channel 03/0 : 4[0] -> 1[3] [send] via NET/IB/2
f17n01:970281:970639 [5] NCCL INFO Channel 00/0 : 3[5] -> 4[0] [send] via NET/IB/1
f17n01:970281:970639 [5] NCCL INFO Channel 02/0 : 3[5] -> 4[0] [send] via NET/IB/1
f17n01:970281:970639 [5] NCCL INFO Channel 01/0 : 3[5] -> 0[2] via P2P/IPC
d11n16:1130269:1130644 [1] NCCL INFO Channel 03/0 : 5[1] -> 6[2] via P2P/IPC
d09n08:1073959:1074322 [5] NCCL INFO Channel 02/0 : 3[5] -> 0[2] via P2P/IPC
d14n09:567670:568063 [4] NCCL INFO Channel 00/0 : 2[4] -> 1[3] via P2P/IPC
d09n08:1073959:1074322 [5] NCCL INFO Channel 00/0 : 3[5] -> 2[4] via P2P/IPC
d11n16:1130271:1130647 [3] NCCL INFO Channel 00/0 : 7[3] -> 6[2] via P2P/IPC
d14n09:567670:568063 [4] NCCL INFO Channel 01/0 : 2[4] -> 1[3] via P2P/IPC
f17n01:970281:970639 [5] NCCL INFO Channel 03/0 : 3[5] -> 0[2] via P2P/IPC
d14n09:567670:568063 [4] NCCL INFO Channel 02/0 : 2[4] -> 1[3] via P2P/IPC
d11n16:1130268:1130646 [0] NCCL INFO Channel 00/0 : 1[3] -> 4[0] [receive] via NET/IB/0
d11n16:1130268:1130646 [0] NCCL INFO Channel 01/0 : 1[3] -> 4[0] [receive] via NET/IB/3
d11n16:1130268:1130646 [0] NCCL INFO Channel 02/0 : 1[3] -> 4[0] [receive] via NET/IB/0
d11n16:1130268:1130646 [0] NCCL INFO Channel 03/0 : 1[3] -> 4[0] [receive] via NET/IB/3
d11n16:1130268:1130646 [0] NCCL INFO Channel 00/0 : 4[0] -> 1[3] [send] via NET/IB/0
d11n16:1130268:1130646 [0] NCCL INFO Channel 02/0 : 4[0] -> 1[3] [send] via NET/IB/0
d09n08:1073957:1074321 [3] NCCL INFO Connected all rings
d09n08:1073957:1074321 [3] NCCL INFO Channel 00/0 : 1[3] -> 4[0] [send] via NET/IB/3
d09n08:1073957:1074321 [3] NCCL INFO Channel 01/0 : 1[3] -> 4[0] [send] via NET/IB/0
d09n08:1073957:1074321 [3] NCCL INFO Channel 02/0 : 1[3] -> 4[0] [send] via NET/IB/3
d09n08:1073957:1074321 [3] NCCL INFO Channel 03/0 : 1[3] -> 4[0] [send] via NET/IB/0
d09n08:1073957:1074321 [3] NCCL INFO Channel 00/0 : 4[0] -> 1[3] [receive] via NET/IB/3
d09n08:1073957:1074321 [3] NCCL INFO Channel 02/0 : 4[0] -> 1[3] [receive] via NET/IB/3
d09n08:1073959:1074322 [5] NCCL INFO Channel 01/0 : 3[5] -> 2[4] via P2P/IPC
d14n09:567670:568063 [4] NCCL INFO Channel 03/0 : 2[4] -> 1[3] via P2P/IPC
f17n01:970278:970637 [2] NCCL INFO Channel 01/0 : 0[2] -> 7[3] [send] via NET/IB/2
f17n01:970278:970637 [2] NCCL INFO Channel 03/0 : 0[2] -> 7[3] [send] via NET/IB/2
d11n16:1130271:1130647 [3] NCCL INFO Channel 02/0 : 7[3] -> 6[2] via P2P/IPC
d09n08:1073959:1074322 [5] NCCL INFO Channel 02/0 : 3[5] -> 2[4] via P2P/IPC
d11n16:1130270:1130645 [2] NCCL INFO Channel 00/0 : 6[2] -> 5[1] via P2P/IPC
d11n16:1130269:1130644 [1] NCCL INFO Channel 00/0 : 5[1] -> 4[0] via P2P/IPC
d09n08:1073956:1074319 [2] NCCL INFO Connected all trees
d09n08:1073956:1074319 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d09n08:1073956:1074319 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d11n16:1130270:1130645 [2] NCCL INFO Channel 02/0 : 6[2] -> 5[1] via P2P/IPC
d09n08:1073959:1074322 [5] NCCL INFO Channel 03/0 : 3[5] -> 2[4] via P2P/IPC
d11n16:1130269:1130644 [1] NCCL INFO Channel 02/0 : 5[1] -> 4[0] via P2P/IPC
f17n02:1076280:1076639 [1] NCCL INFO Connected all rings
f17n01:970280:970638 [4] NCCL INFO Connected all rings
f17n02:1076280:1076639 [1] NCCL INFO Channel 01/0 : 5[1] -> 6[2] via P2P/IPC
f17n02:1076280:1076639 [1] NCCL INFO Channel 03/0 : 5[1] -> 6[2] via P2P/IPC
d11n16:1130272:1130642 [4] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7
d11n16:1130272:1130642 [4] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7
d11n16:1130272:1130642 [4] NCCL INFO Trees [0] 1/2/-1->0->-1 [1] 1/-1/-1->0->2
d11n16:1130272:1130642 [4] NCCL INFO P2P Chunksize set to 131072
d11n16:1130272:1130642 [4] NCCL INFO Channel 00/0 : 7[5] -> 0[4] [receive] via NET/IB/1
d11n16:1130272:1130642 [4] NCCL INFO Channel 01/0 : 7[5] -> 0[4] [receive] via NET/IB/1
d11n16:1130272:1130642 [4] NCCL INFO Channel 00/0 : 0[4] -> 1[5] via P2P/IPC
d11n17:1142858:1143210 [4] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5
d11n17:1142858:1143210 [4] NCCL INFO P2P Chunksize set to 131072
d11n17:1142855:1143206 [1] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2
d11n17:1142855:1143206 [1] NCCL INFO P2P Chunksize set to 131072
d11n17:1142856:1143207 [2] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3
d11n17:1142856:1143207 [2] NCCL INFO P2P Chunksize set to 131072
f17n01:970280:970638 [4] NCCL INFO Channel 00/0 : 2[4] -> 1[3] via P2P/IPC
d11n17:1142854:1143208 [0] NCCL INFO Trees [0] 3/-1/-1->2->0 [1] 3/0/-1->2->-1
d11n17:1142854:1143208 [0] NCCL INFO P2P Chunksize set to 131072
d11n17:1142854:1143208 [0] NCCL INFO Channel 00/0 : 1[5] -> 2[0] [receive] via NET/IB/0
d11n17:1142854:1143208 [0] NCCL INFO Channel 01/0 : 1[5] -> 2[0] [receive] via NET/IB/0
d11n17:1142854:1143208 [0] NCCL INFO Channel 00/0 : 2[0] -> 3[1] via P2P/IPC
d11n16:1130272:1130642 [4] NCCL INFO Channel 01/0 : 0[4] -> 1[5] via P2P/IPC
f17n01:970280:970638 [4] NCCL INFO Channel 01/0 : 2[4] -> 1[3] via P2P/IPC
f17n01:970280:970638 [4] NCCL INFO Channel 02/0 : 2[4] -> 1[3] via P2P/IPC
d11n17:1142854:1143208 [0] NCCL INFO Channel 01/0 : 2[0] -> 3[1] via P2P/IPC
f17n01:970280:970638 [4] NCCL INFO Channel 03/0 : 2[4] -> 1[3] via P2P/IPC
d11n17:1142855:1143206 [1] NCCL INFO Channel 00/0 : 3[1] -> 4[2] via P2P/IPC
d11n17:1142858:1143210 [4] NCCL INFO Channel 00/0 : 6[4] -> 7[5] via P2P/IPC
d11n17:1142856:1143207 [2] NCCL INFO Channel 00/0 : 4[2] -> 5[3] via P2P/IPC
d11n17:1142855:1143206 [1] NCCL INFO Channel 01/0 : 3[1] -> 4[2] via P2P/IPC
d11n17:1142858:1143210 [4] NCCL INFO Channel 01/0 : 6[4] -> 7[5] via P2P/IPC
d11n17:1142856:1143207 [2] NCCL INFO Channel 01/0 : 4[2] -> 5[3] via P2P/IPC
d11n16:1130270:1130645 [2] NCCL INFO Connected all trees
d11n16:1130270:1130645 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d11n16:1130270:1130645 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d09n08:1073959:1074322 [5] NCCL INFO Connected all trees
d09n08:1073959:1074322 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d09n08:1073959:1074322 [5] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d09n08:1073958:1074320 [4] NCCL INFO Connected all trees
d09n08:1073958:1074320 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d09n08:1073958:1074320 [4] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d11n16:1130271:1130647 [3] NCCL INFO Connected all trees
d11n16:1130271:1130647 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d11n16:1130271:1130647 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f17n02:1076279:1076641 [0] NCCL INFO Connected all rings
f17n02:1076279:1076641 [0] NCCL INFO Channel 01/0 : 4[0] -> 5[1] via P2P/IPC
f17n01:970281:970639 [5] NCCL INFO Connected all rings
f17n02:1076284:1076643 [5] NCCL INFO Channel 00/0 : 1[5] -> 2[0] [send] via NET/IB/1
f17n02:1076284:1076643 [5] NCCL INFO Channel 01/0 : 1[5] -> 2[0] [send] via NET/IB/1
d11n17:1142855:1143206 [1] NCCL INFO Connected all rings
f17n02:1076279:1076641 [0] NCCL INFO Channel 03/0 : 4[0] -> 5[1] via P2P/IPC
d11n17:1142855:1143206 [1] NCCL INFO Channel 00/0 : 3[1] -> 2[0] via P2P/IPC
d14n10:565685:566055 [4] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7
d14n10:565685:566055 [4] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7
d14n10:565685:566055 [4] NCCL INFO Trees [0] 1/2/-1->0->-1 [1] 1/-1/-1->0->2
d14n10:565685:566055 [4] NCCL INFO P2P Chunksize set to 131072
d14n10:565685:566055 [4] NCCL INFO Channel 00/0 : 7[5] -> 0[4] [receive] via NET/IB/1
d14n10:565685:566055 [4] NCCL INFO Channel 01/0 : 7[5] -> 0[4] [receive] via NET/IB/1
d14n10:565685:566055 [4] NCCL INFO Channel 00/0 : 0[4] -> 1[5] via P2P/IPC
f16n16:1079913:1080279 [1] NCCL INFO Channel 00/0 : 5[1] -> 6[2] via P2P/IPC
d11n16:1130269:1130644 [1] NCCL INFO Connected all trees
d11n16:1130269:1130644 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d11n16:1130269:1130644 [1] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f17n01:970278:970637 [2] NCCL INFO Connected all rings
f17n01:970278:970637 [2] NCCL INFO Channel 00/0 : 0[2] -> 3[5] via P2P/IPC
d11n17:1142855:1143206 [1] NCCL INFO Channel 01/0 : 3[1] -> 2[0] via P2P/IPC
d14n10:565685:566055 [4] NCCL INFO Channel 01/0 : 0[4] -> 1[5] via P2P/IPC
f16n16:1079913:1080279 [1] NCCL INFO Channel 02/0 : 5[1] -> 6[2] via P2P/IPC
d14n11:1169360:1169731 [4] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5
d14n11:1169360:1169731 [4] NCCL INFO P2P Chunksize set to 131072
d14n11:1169358:1169730 [2] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3
d14n11:1169358:1169730 [2] NCCL INFO P2P Chunksize set to 131072
d14n11:1169357:1169728 [1] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2
d14n11:1169357:1169728 [1] NCCL INFO P2P Chunksize set to 131072
d14n11:1169356:1169733 [0] NCCL INFO Trees [0] 3/-1/-1->2->0 [1] 3/0/-1->2->-1
d14n11:1169356:1169733 [0] NCCL INFO P2P Chunksize set to 131072
d14n11:1169356:1169733 [0] NCCL INFO Channel 00/0 : 1[5] -> 2[0] [receive] via NET/IB/0
d14n11:1169356:1169733 [0] NCCL INFO Channel 01/0 : 1[5] -> 2[0] [receive] via NET/IB/0
d14n11:1169356:1169733 [0] NCCL INFO Channel 00/0 : 2[0] -> 3[1] via P2P/IPC
f17n01:970278:970637 [2] NCCL INFO Channel 01/0 : 0[2] -> 3[5] via P2P/IPC
f17n01:970279:970640 [3] NCCL INFO Connected all rings
f17n01:970279:970640 [3] NCCL INFO Channel 00/0 : 1[3] -> 4[0] [send] via NET/IB/3
f17n01:970279:970640 [3] NCCL INFO Channel 01/0 : 1[3] -> 4[0] [send] via NET/IB/0
f17n01:970279:970640 [3] NCCL INFO Channel 02/0 : 1[3] -> 4[0] [send] via NET/IB/3
f17n01:970279:970640 [3] NCCL INFO Channel 03/0 : 1[3] -> 4[0] [send] via NET/IB/0
f17n01:970279:970640 [3] NCCL INFO Channel 00/0 : 4[0] -> 1[3] [receive] via NET/IB/3
f17n01:970279:970640 [3] NCCL INFO Channel 02/0 : 4[0] -> 1[3] [receive] via NET/IB/3
f18n05:1008224:1008577 [5] NCCL INFO Channel 00/0 : 7[5] -> 0[4] [send] via NET/IB/1
f18n05:1008224:1008577 [5] NCCL INFO Channel 01/0 : 7[5] -> 0[4] [send] via NET/IB/1
f17n02:1076279:1076641 [0] NCCL INFO Channel 00/0 : 1[3] -> 4[0] [receive] via NET/IB/0
f17n02:1076279:1076641 [0] NCCL INFO Channel 01/0 : 1[3] -> 4[0] [receive] via NET/IB/3
f17n02:1076279:1076641 [0] NCCL INFO Channel 02/0 : 1[3] -> 4[0] [receive] via NET/IB/0
f17n02:1076279:1076641 [0] NCCL INFO Channel 03/0 : 1[3] -> 4[0] [receive] via NET/IB/3
f17n02:1076279:1076641 [0] NCCL INFO Channel 00/0 : 4[0] -> 1[3] [send] via NET/IB/0
f17n02:1076279:1076641 [0] NCCL INFO Channel 02/0 : 4[0] -> 1[3] [send] via NET/IB/0
f16n16:1079912:1080280 [0] NCCL INFO Channel 01/0 : 4[0] -> 1[3] [send] via NET/IB/2
f16n16:1079912:1080280 [0] NCCL INFO Channel 03/0 : 4[0] -> 1[3] [send] via NET/IB/2
f17n01:970278:970637 [2] NCCL INFO Channel 02/0 : 0[2] -> 3[5] via P2P/IPC
d14n11:1169356:1169733 [0] NCCL INFO Channel 01/0 : 2[0] -> 3[1] via P2P/IPC
f17n02:1076282:1076642 [3] NCCL INFO Connected all rings
f17n01:970278:970637 [2] NCCL INFO Channel 03/0 : 0[2] -> 3[5] via P2P/IPC
d14n11:1169360:1169731 [4] NCCL INFO Channel 00/0 : 6[4] -> 7[5] via P2P/IPC
d14n11:1169358:1169730 [2] NCCL INFO Channel 00/0 : 4[2] -> 5[3] via P2P/IPC
d14n11:1169357:1169728 [1] NCCL INFO Channel 00/0 : 3[1] -> 4[2] via P2P/IPC
f17n01:970281:970639 [5] NCCL INFO Channel 00/0 : 3[5] -> 0[2] via P2P/IPC
f17n02:1076280:1076639 [1] NCCL INFO Channel 00/0 : 5[1] -> 4[0] via P2P/IPC
f16n16:1079914:1080281 [2] NCCL INFO Channel 01/0 : 6[2] -> 5[1] via P2P/IPC
f16n16:1079913:1080279 [1] NCCL INFO Channel 01/0 : 5[1] -> 4[0] via P2P/IPC
d14n11:1169360:1169731 [4] NCCL INFO Channel 01/0 : 6[4] -> 7[5] via P2P/IPC
d14n11:1169358:1169730 [2] NCCL INFO Channel 01/0 : 4[2] -> 5[3] via P2P/IPC
d14n11:1169357:1169728 [1] NCCL INFO Channel 01/0 : 3[1] -> 4[2] via P2P/IPC
f16n16:1079914:1080281 [2] NCCL INFO Channel 03/0 : 6[2] -> 5[1] via P2P/IPC
f17n01:970281:970639 [5] NCCL INFO Channel 02/0 : 3[5] -> 0[2] via P2P/IPC
f16n16:1079913:1080279 [1] NCCL INFO Channel 03/0 : 5[1] -> 4[0] via P2P/IPC
f17n02:1076280:1076639 [1] NCCL INFO Channel 02/0 : 5[1] -> 4[0] via P2P/IPC
f17n02:1076282:1076642 [3] NCCL INFO Channel 00/0 : 7[3] -> 6[2] via P2P/IPC
f17n01:970281:970639 [5] NCCL INFO Channel 00/0 : 3[5] -> 2[4] via P2P/IPC
d14n11:1169357:1169728 [1] NCCL INFO Connected all rings
f17n02:1076282:1076642 [3] NCCL INFO Channel 02/0 : 7[3] -> 6[2] via P2P/IPC
f17n01:970281:970639 [5] NCCL INFO Channel 01/0 : 3[5] -> 2[4] via P2P/IPC
d14n11:1169357:1169728 [1] NCCL INFO Channel 00/0 : 3[1] -> 2[0] via P2P/IPC
f17n02:1076284:1076643 [5] NCCL INFO Connected all rings
f17n02:1076284:1076643 [5] NCCL INFO Channel 00/0 : 1[5] -> 0[4] via P2P/IPC
d14n11:1169357:1169728 [1] NCCL INFO Channel 01/0 : 3[1] -> 2[0] via P2P/IPC
d09n08:1073955:1074324 [1] NCCL INFO Channel 00/0 : 7[1] -> 0[0] [send] via NET/IB/0
d09n08:1073955:1074324 [1] NCCL INFO Channel 01/0 : 7[1] -> 0[0] [send] via NET/IB/0
f18n05:1008224:1008577 [5] NCCL INFO Connected all rings
f18n05:1008224:1008577 [5] NCCL INFO Channel 00/0 : 7[5] -> 6[4] via P2P/IPC
f17n01:970281:970639 [5] NCCL INFO Channel 02/0 : 3[5] -> 2[4] via P2P/IPC
f18n05:1008224:1008577 [5] NCCL INFO Channel 01/0 : 7[5] -> 6[4] via P2P/IPC
f17n02:1076281:1076640 [2] NCCL INFO Channel 00/0 : 6[2] -> 5[1] via P2P/IPC
f17n02:1076284:1076643 [5] NCCL INFO Channel 01/0 : 1[5] -> 0[4] via P2P/IPC
f17n01:970281:970639 [5] NCCL INFO Channel 03/0 : 3[5] -> 2[4] via P2P/IPC
f17n01:970278:970637 [2] NCCL INFO Connected all trees
f17n01:970278:970637 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f17n01:970278:970637 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f17n02:1076281:1076640 [2] NCCL INFO Channel 02/0 : 6[2] -> 5[1] via P2P/IPC
f18n05:1008219:1008573 [0] NCCL INFO Connected all rings
f18n05:1008219:1008573 [0] NCCL INFO Channel 00/0 : 0[4] -> 2[0] [receive] via NET/IB/0
f18n05:1008219:1008573 [0] NCCL INFO Channel 01/0 : 0[4] -> 2[0] [receive] via NET/IB/0
f18n05:1008219:1008573 [0] NCCL INFO Channel 00/0 : 2[0] -> 0[4] [send] via NET/IB/0
f18n05:1008219:1008573 [0] NCCL INFO Channel 01/0 : 2[0] -> 0[4] [send] via NET/IB/0
d17n07:1212415:1212804 [5] NCCL INFO Connected all rings
f17n02:1076283:1076638 [4] NCCL INFO Connected all rings
f17n02:1076283:1076638 [4] NCCL INFO Channel 00/0 : 0[4] -> 2[0] [send] via NET/IB/1
f17n02:1076283:1076638 [4] NCCL INFO Channel 01/0 : 0[4] -> 2[0] [send] via NET/IB/1
f17n02:1076283:1076638 [4] NCCL INFO Channel 00/0 : 2[0] -> 0[4] [receive] via NET/IB/1
f17n02:1076283:1076638 [4] NCCL INFO Channel 01/0 : 2[0] -> 0[4] [receive] via NET/IB/1
d11n16:1130268:1130646 [0] NCCL INFO Connected all trees
d11n16:1130268:1130646 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d11n16:1130268:1130646 [0] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f16n16:1079913:1080279 [1] NCCL INFO Connected all rings
d09n08:1073957:1074321 [3] NCCL INFO Connected all trees
d09n08:1073957:1074321 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d09n08:1073957:1074321 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f16n16:1079914:1080281 [2] NCCL INFO Connected all rings
f17n02:1076282:1076642 [3] NCCL INFO Connected all trees
f17n02:1076282:1076642 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f17n02:1076282:1076642 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f18n05:1008220:1008574 [1] NCCL INFO Connected all trees
f18n05:1008220:1008574 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f18n05:1008220:1008574 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n16:1079913:1080279 [1] NCCL INFO Channel 01/0 : 5[1] -> 6[2] via P2P/IPC
f16n16:1079913:1080279 [1] NCCL INFO Channel 03/0 : 5[1] -> 6[2] via P2P/IPC
f16n16:1079914:1080281 [2] NCCL INFO Channel 01/0 : 6[2] -> 7[3] via P2P/IPC
f16n16:1079914:1080281 [2] NCCL INFO Channel 03/0 : 6[2] -> 7[3] via P2P/IPC
f17n01:970280:970638 [4] NCCL INFO Connected all trees
f17n01:970280:970638 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f17n01:970280:970638 [4] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f17n01:970281:970639 [5] NCCL INFO Connected all trees
f17n01:970281:970639 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f17n01:970281:970639 [5] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d09n08:1073956:1074319 [2] NCCL INFO comm 0x161225c40 rank 0 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0xc3dd8166c9a61f34 - Init COMPLETE
d09n08:1073957:1074321 [3] NCCL INFO comm 0x15b80a480 rank 1 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xc3dd8166c9a61f34 - Init COMPLETE
d09n08:1073958:1074320 [4] NCCL INFO comm 0x14fd946c0 rank 2 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xc3dd8166c9a61f34 - Init COMPLETE
d09n08:1073959:1074322 [5] NCCL INFO comm 0x15db7f480 rank 3 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xc3dd8166c9a61f34 - Init COMPLETE
d11n16:1130268:1130646 [0] NCCL INFO comm 0x156bacd40 rank 4 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0xc3dd8166c9a61f34 - Init COMPLETE
f17n02:1076284:1076643 [5] NCCL INFO Connected all trees
f17n02:1076284:1076643 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f17n02:1076284:1076643 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n16:1130269:1130644 [1] NCCL INFO comm 0x138c05090 rank 5 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0xc3dd8166c9a61f34 - Init COMPLETE
d11n16:1130270:1130645 [2] NCCL INFO comm 0x14cf86610 rank 6 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0xc3dd8166c9a61f34 - Init COMPLETE
d11n16:1130271:1130647 [3] NCCL INFO comm 0x16fb767b0 rank 7 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xc3dd8166c9a61f34 - Init COMPLETE
f17n02:1076280:1076639 [1] NCCL INFO Connected all trees
f17n02:1076280:1076639 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f17n02:1076280:1076639 [1] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d17n07:1212412:1212803 [2] NCCL INFO Connected all rings
d17n07:1212412:1212803 [2] NCCL INFO Channel 00/0 : 0[2] -> 3[5] via P2P/IPC
f17n02:1076281:1076640 [2] NCCL INFO Connected all trees
f17n02:1076281:1076640 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f17n02:1076281:1076640 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d17n07:1212412:1212803 [2] NCCL INFO Channel 01/0 : 0[2] -> 3[5] via P2P/IPC
f16n16:1079912:1080280 [0] NCCL INFO Connected all rings
f16n16:1079912:1080280 [0] NCCL INFO Channel 01/0 : 4[0] -> 5[1] via P2P/IPC
d17n07:1212412:1212803 [2] NCCL INFO Channel 02/0 : 0[2] -> 3[5] via P2P/IPC
f16n16:1079915:1080283 [3] NCCL INFO Connected all rings
f16n16:1079912:1080280 [0] NCCL INFO Channel 03/0 : 4[0] -> 5[1] via P2P/IPC
d17n07:1212412:1212803 [2] NCCL INFO Channel 03/0 : 0[2] -> 3[5] via P2P/IPC
d17n07:1212415:1212804 [5] NCCL INFO Channel 00/0 : 3[5] -> 0[2] via P2P/IPC
d17n07:1212413:1212806 [3] NCCL INFO Connected all rings
d17n07:1212413:1212806 [3] NCCL INFO Channel 00/0 : 1[3] -> 4[0] [send] via NET/IB/3
d17n07:1212413:1212806 [3] NCCL INFO Channel 01/0 : 1[3] -> 4[0] [send] via NET/IB/0
d17n07:1212413:1212806 [3] NCCL INFO Channel 02/0 : 1[3] -> 4[0] [send] via NET/IB/3
d17n07:1212413:1212806 [3] NCCL INFO Channel 03/0 : 1[3] -> 4[0] [send] via NET/IB/0
d17n07:1212413:1212806 [3] NCCL INFO Channel 00/0 : 4[0] -> 1[3] [receive] via NET/IB/3
d17n07:1212413:1212806 [3] NCCL INFO Channel 02/0 : 4[0] -> 1[3] [receive] via NET/IB/3
f16n18:1091867:1092250 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
f16n17:1090961:1091324 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
f16n17:1090964:1091329 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
f16n17:1090963:1091328 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
f16n17:1090959:1091326 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d11n16:1130273:1130643 [5] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
d11n16:1130273:1130643 [5] NCCL INFO P2P Chunksize set to 131072
d17n07:1212415:1212804 [5] NCCL INFO Channel 02/0 : 3[5] -> 0[2] via P2P/IPC
f16n17:1090960:1091325 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
f16n16:1079912:1080280 [0] NCCL INFO Channel 00/0 : 1[3] -> 4[0] [receive] via NET/IB/0
f16n16:1079912:1080280 [0] NCCL INFO Channel 01/0 : 1[3] -> 4[0] [receive] via NET/IB/3
f16n16:1079912:1080280 [0] NCCL INFO Channel 02/0 : 1[3] -> 4[0] [receive] via NET/IB/0
f16n16:1079912:1080280 [0] NCCL INFO Channel 03/0 : 1[3] -> 4[0] [receive] via NET/IB/3
f16n16:1079912:1080280 [0] NCCL INFO Channel 00/0 : 4[0] -> 1[3] [send] via NET/IB/0
f16n16:1079912:1080280 [0] NCCL INFO Channel 02/0 : 4[0] -> 1[3] [send] via NET/IB/0
f16n17:1090962:1091327 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
f16n16:1079915:1080283 [3] NCCL INFO Channel 00/0 : 7[3] -> 6[2] via P2P/IPC
d11n17:1142859:1143211 [5] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
d11n17:1142859:1143211 [5] NCCL INFO P2P Chunksize set to 131072
d17n07:1212415:1212804 [5] NCCL INFO Channel 00/0 : 3[5] -> 2[4] via P2P/IPC
d11n17:1142857:1143209 [3] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4
d11n17:1142857:1143209 [3] NCCL INFO P2P Chunksize set to 131072
f16n16:1079913:1080279 [1] NCCL INFO Channel 00/0 : 5[1] -> 4[0] via P2P/IPC
f16n16:1079915:1080283 [3] NCCL INFO Channel 02/0 : 7[3] -> 6[2] via P2P/IPC
f16n16:1079914:1080281 [2] NCCL INFO Channel 00/0 : 6[2] -> 5[1] via P2P/IPC
d17n07:1212415:1212804 [5] NCCL INFO Channel 01/0 : 3[5] -> 2[4] via P2P/IPC
f16n16:1079913:1080279 [1] NCCL INFO Channel 02/0 : 5[1] -> 4[0] via P2P/IPC
d17n07:1212415:1212804 [5] NCCL INFO Channel 02/0 : 3[5] -> 2[4] via P2P/IPC
d14n10:565682:566057 [1] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/-1/-1->5->4 [3] 6/-1/-1->5->4
d14n10:565682:566057 [1] NCCL INFO P2P Chunksize set to 131072
d09n07:1063022:1063458 [5] NCCL INFO Channel 00/0 : 5[5] -> 6[0] [send] via NET/IB/1
d09n07:1063022:1063458 [5] NCCL INFO Channel 01/0 : 5[5] -> 6[0] [send] via NET/IB/1
f16n16:1079914:1080281 [2] NCCL INFO Channel 02/0 : 6[2] -> 5[1] via P2P/IPC
d14n08:1173248:1173633 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d14n10:565686:566058 [5] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
d14n10:565686:566058 [5] NCCL INFO P2P Chunksize set to 131072
d14n08:1173247:1173628 [0] NCCL INFO Setting affinity for GPU 0 to 0f
f18n05:1008219:1008573 [0] NCCL INFO Connected all trees
f18n05:1008219:1008573 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f18n05:1008219:1008573 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n08:1173251:1173631 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d14n08:1173250:1173630 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
f17n02:1076283:1076638 [4] NCCL INFO Connected all trees
f17n02:1076283:1076638 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f17n02:1076283:1076638 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n09:567669:568062 [3] NCCL INFO Channel 01/0 : 4[0] -> 1[3] [receive] via NET/IB/3
d14n09:567669:568062 [3] NCCL INFO Channel 03/0 : 4[0] -> 1[3] [receive] via NET/IB/3
d14n08:1173249:1173632 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d17n07:1212412:1212803 [2] NCCL INFO Connected all trees
d17n07:1212412:1212803 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d17n07:1212412:1212803 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d17n07:1212415:1212804 [5] NCCL INFO Channel 03/0 : 3[5] -> 2[4] via P2P/IPC
d14n11:1169359:1169729 [3] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4
d14n11:1169359:1169729 [3] NCCL INFO P2P Chunksize set to 131072
d14n11:1169361:1169732 [5] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
d14n11:1169361:1169732 [5] NCCL INFO P2P Chunksize set to 131072
d17n06:1216532:1216926 [2] NCCL INFO Setting affinity for GPU 2 to 0f000000,00000000
d17n06:1216530:1216923 [0] NCCL INFO Setting affinity for GPU 0 to 0f
d17n06:1216531:1216928 [1] NCCL INFO Setting affinity for GPU 1 to f0000000
d17n06:1216534:1216925 [4] NCCL INFO Setting affinity for GPU 4 to f00000,00000000,00000000,00000000
d17n06:1216535:1216924 [5] NCCL INFO Setting affinity for GPU 5 to 0f0000,00000000,00000000,00000000,00000000
d17n06:1216533:1216927 [3] NCCL INFO Setting affinity for GPU 3 to 0f000000,00000000,00000000
f17n02:1076279:1076641 [0] NCCL INFO Connected all trees
f17n02:1076279:1076641 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f17n02:1076279:1076641 [0] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d09n08:1073955:1074324 [1] NCCL INFO Connected all rings
d09n08:1073955:1074324 [1] NCCL INFO Channel 00/0 : 7[1] -> 6[0] via P2P/IPC
d09n08:1073955:1074324 [1] NCCL INFO Channel 01/0 : 7[1] -> 6[0] via P2P/IPC
f17n01:970279:970640 [3] NCCL INFO Connected all trees
f17n01:970279:970640 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f17n01:970279:970640 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f17n02:1076283:1076638 [4] NCCL INFO comm 0x15a14b300 rank 0 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x42a519b1adea69c3 - Init COMPLETE
f17n02:1076284:1076643 [5] NCCL INFO comm 0x14e0939c0 rank 1 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x42a519b1adea69c3 - Init COMPLETE
f16n16:1079913:1080279 [1] NCCL INFO Connected all trees
f16n16:1079913:1080279 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n16:1079913:1080279 [1] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f18n05:1008223:1008575 [4] NCCL INFO Connected all rings
d09n07:1063016:1063455 [0] NCCL INFO Connected all rings
d09n07:1063016:1063455 [0] NCCL INFO Channel 00/0 : 6[0] -> 0[0] [receive] via NET/IB/0
d09n07:1063016:1063455 [0] NCCL INFO Channel 01/0 : 6[0] -> 0[0] [receive] via NET/IB/0
f16n16:1079915:1080283 [3] NCCL INFO Connected all trees
f16n16:1079915:1080283 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n16:1079915:1080283 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f18n05:1008223:1008575 [4] NCCL INFO Channel 00/0 : 6[4] -> 5[3] via P2P/IPC
f18n05:1008223:1008575 [4] NCCL INFO Channel 01/0 : 6[4] -> 5[3] via P2P/IPC
f17n01:970276:970641 [0] NCCL INFO Trees [0] 7/-1/-1->6->0 [1] 7/0/-1->6->-1
f17n01:970276:970641 [0] NCCL INFO P2P Chunksize set to 131072
f17n01:970276:970641 [0] NCCL INFO Channel 00/0 : 5[5] -> 6[0] [receive] via NET/IB/0
f17n01:970276:970641 [0] NCCL INFO Channel 01/0 : 5[5] -> 6[0] [receive] via NET/IB/0
f17n01:970276:970641 [0] NCCL INFO Channel 00/0 : 6[0] -> 7[1] via P2P/IPC
f17n01:970276:970641 [0] NCCL INFO Channel 01/0 : 6[0] -> 7[1] via P2P/IPC
f17n01:970278:970637 [2] NCCL INFO comm 0x15a795e10 rank 0 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x3a0bc024a5812684 - Init COMPLETE
f17n01:970280:970638 [4] NCCL INFO comm 0x136191280 rank 2 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x3a0bc024a5812684 - Init COMPLETE
f16n18:1091868:1092251 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
f16n18:1091868:1092251 [2] NCCL INFO P2P Chunksize set to 131072
d14n10:565682:566057 [1] NCCL INFO Channel 00/0 : 5[1] -> 6[2] via P2P/IPC
f16n18:1091867:1092250 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
f16n18:1091867:1092250 [1] NCCL INFO P2P Chunksize set to 131072
f16n18:1091870:1092254 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3
f16n18:1091870:1092254 [4] NCCL INFO P2P Chunksize set to 131072
f16n18:1091866:1092249 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7
f16n18:1091866:1092249 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7
f16n18:1091866:1092249 [0] NCCL INFO Trees [0] 1/6/-1->0->-1 [1] 1/-1/-1->0->6
f16n18:1091866:1092249 [0] NCCL INFO P2P Chunksize set to 131072
f16n18:1091866:1092249 [0] NCCL INFO Channel 00/0 : 7[1] -> 0[0] [receive] via NET/IB/0
f16n18:1091866:1092249 [0] NCCL INFO Channel 01/0 : 7[1] -> 0[0] [receive] via NET/IB/0
f16n18:1091866:1092249 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/IPC
f17n01:970279:970640 [3] NCCL INFO comm 0x143aa6680 rank 1 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x3a0bc024a5812684 - Init COMPLETE
d14n10:565682:566057 [1] NCCL INFO Channel 02/0 : 5[1] -> 6[2] via P2P/IPC
f17n01:970281:970639 [5] NCCL INFO comm 0x14667fb70 rank 3 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x3a0bc024a5812684 - Init COMPLETE
f17n02:1076279:1076641 [0] NCCL INFO comm 0x161aa34c0 rank 4 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x3a0bc024a5812684 - Init COMPLETE
f17n02:1076280:1076639 [1] NCCL INFO comm 0x143931470 rank 5 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x3a0bc024a5812684 - Init COMPLETE
f17n02:1076281:1076640 [2] NCCL INFO comm 0x17e032ad0 rank 6 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x3a0bc024a5812684 - Init COMPLETE
f17n02:1076282:1076642 [3] NCCL INFO comm 0x12aeb4b90 rank 7 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x3a0bc024a5812684 - Init COMPLETE
d17n07:1212414:1212805 [4] NCCL INFO Connected all trees
d17n07:1212414:1212805 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d17n07:1212414:1212805 [4] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n10:565686:566058 [5] NCCL INFO Channel 00/0 : 1[5] -> 2[0] [send] via NET/IB/1
d14n10:565686:566058 [5] NCCL INFO Channel 01/0 : 1[5] -> 2[0] [send] via NET/IB/1
f16n18:1091866:1092249 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/IPC
d17n07:1212415:1212804 [5] NCCL INFO Connected all trees
d17n07:1212415:1212804 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d17n07:1212415:1212804 [5] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f16n18:1091868:1092251 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/IPC
f16n18:1091867:1092250 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/IPC
f18n05:1008224:1008577 [5] NCCL INFO Connected all trees
f18n05:1008224:1008577 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f18n05:1008224:1008577 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n18:1091870:1092254 [4] NCCL INFO Channel 00/0 : 4[4] -> 5[5] via P2P/IPC
d14n10:565681:566059 [0] NCCL INFO Channel 01/0 : 4[0] -> 1[3] [send] via NET/IB/2
d14n10:565681:566059 [0] NCCL INFO Channel 03/0 : 4[0] -> 1[3] [send] via NET/IB/2
f16n18:1091867:1092250 [1] NCCL INFO Channel 01/0 : 1[1] -> 2[2] via P2P/IPC
f16n18:1091870:1092254 [4] NCCL INFO Channel 01/0 : 4[4] -> 5[5] via P2P/IPC
f16n18:1091868:1092251 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/IPC
f18n05:1008223:1008575 [4] NCCL INFO Connected all trees
f18n05:1008223:1008575 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f18n05:1008223:1008575 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d09n07:1063021:1063456 [4] NCCL INFO Connected all rings
d14n10:565683:566056 [2] NCCL INFO Channel 01/0 : 6[2] -> 5[1] via P2P/IPC
d14n10:565682:566057 [1] NCCL INFO Channel 01/0 : 5[1] -> 4[0] via P2P/IPC
d09n07:1063021:1063456 [4] NCCL INFO Channel 00/0 : 4[4] -> 3[3] via P2P/IPC
d14n10:565683:566056 [2] NCCL INFO Channel 03/0 : 6[2] -> 5[1] via P2P/IPC
d14n10:565682:566057 [1] NCCL INFO Channel 03/0 : 5[1] -> 4[0] via P2P/IPC
d09n07:1063021:1063456 [4] NCCL INFO Channel 01/0 : 4[4] -> 3[3] via P2P/IPC
f16n18:1091867:1092250 [1] NCCL INFO Connected all rings
f16n18:1091867:1092250 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/IPC
f16n18:1091867:1092250 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/IPC
d09n07:1063020:1063457 [3] NCCL INFO Connected all trees
d09n07:1063020:1063457 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d09n07:1063020:1063457 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d09n07:1063022:1063458 [5] NCCL INFO Connected all rings
d09n07:1063022:1063458 [5] NCCL INFO Channel 00/0 : 5[5] -> 4[4] via P2P/IPC
d09n07:1063022:1063458 [5] NCCL INFO Channel 01/0 : 5[5] -> 4[4] via P2P/IPC
d09n08:1073954:1074323 [0] NCCL INFO Connected all rings
d09n08:1073954:1074323 [0] NCCL INFO Channel 00/0 : 6[0] -> 0[0] [send] via NET/IB/0
d09n08:1073954:1074323 [0] NCCL INFO Channel 01/0 : 6[0] -> 0[0] [send] via NET/IB/0
d09n08:1073954:1074323 [0] NCCL INFO Channel 00/0 : 0[0] -> 6[0] [receive] via NET/IB/0
d09n08:1073954:1074323 [0] NCCL INFO Channel 01/0 : 0[0] -> 6[0] [receive] via NET/IB/0
d11n17:1142857:1143209 [3] NCCL INFO Channel 00/0 : 5[3] -> 6[4] via P2P/IPC
d11n17:1142857:1143209 [3] NCCL INFO Channel 01/0 : 5[3] -> 6[4] via P2P/IPC
d09n07:1063016:1063455 [0] NCCL INFO Channel 00/0 : 0[0] -> 6[0] [send] via NET/IB/0
d09n07:1063016:1063455 [0] NCCL INFO Channel 01/0 : 0[0] -> 6[0] [send] via NET/IB/0
d11n17:1142859:1143211 [5] NCCL INFO Channel 00/0 : 7[5] -> 0[4] [send] via NET/IB/1
d11n17:1142859:1143211 [5] NCCL INFO Channel 01/0 : 7[5] -> 0[4] [send] via NET/IB/1
d14n10:565686:566058 [5] NCCL INFO Connected all rings
d14n10:565686:566058 [5] NCCL INFO Channel 00/0 : 1[5] -> 0[4] via P2P/IPC
f16n16:1079912:1080280 [0] NCCL INFO Connected all trees
f16n16:1079912:1080280 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n16:1079912:1080280 [0] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d09n07:1063022:1063458 [5] NCCL INFO Connected all trees
d09n07:1063022:1063458 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d09n07:1063022:1063458 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d09n08:1073955:1074324 [1] NCCL INFO Connected all trees
d09n08:1073955:1074324 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d09n08:1073955:1074324 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n07:1212413:1212806 [3] NCCL INFO Connected all trees
d17n07:1212413:1212806 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d17n07:1212413:1212806 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n09:567671:568061 [5] NCCL INFO Connected all rings
d14n10:565686:566058 [5] NCCL INFO Channel 01/0 : 1[5] -> 0[4] via P2P/IPC
d09n07:1063021:1063456 [4] NCCL INFO Connected all trees
d09n07:1063021:1063456 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d09n07:1063021:1063456 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n17:1142858:1143210 [4] NCCL INFO Connected all rings
d11n17:1142857:1143209 [3] NCCL INFO Connected all rings
d17n07:1212413:1212806 [3] NCCL INFO comm 0x139fd6f80 rank 1 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xb4380781c8b9c34c - Init COMPLETE
d11n17:1142856:1143207 [2] NCCL INFO Connected all rings
d17n07:1212414:1212805 [4] NCCL INFO comm 0x17cb3f600 rank 2 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0xb4380781c8b9c34c - Init COMPLETE
d17n07:1212412:1212803 [2] NCCL INFO comm 0x12f86a850 rank 0 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0xb4380781c8b9c34c - Init COMPLETE
d14n10:565683:566056 [2] NCCL INFO Connected all rings
d17n07:1212415:1212804 [5] NCCL INFO comm 0x1512d5af0 rank 3 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0xb4380781c8b9c34c - Init COMPLETE
d14n10:565682:566057 [1] NCCL INFO Connected all rings
d11n17:1142857:1143209 [3] NCCL INFO Channel 00/0 : 5[3] -> 4[2] via P2P/IPC
d11n17:1142858:1143210 [4] NCCL INFO Channel 00/0 : 6[4] -> 5[3] via P2P/IPC
d14n11:1169359:1169729 [3] NCCL INFO Channel 00/0 : 5[3] -> 6[4] via P2P/IPC
d14n09:567667:568059 [1] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
d14n09:567667:568059 [1] NCCL INFO P2P Chunksize set to 131072
d11n17:1142856:1143207 [2] NCCL INFO Channel 00/0 : 4[2] -> 3[1] via P2P/IPC
d14n11:1169359:1169729 [3] NCCL INFO Channel 01/0 : 5[3] -> 6[4] via P2P/IPC
d14n10:565682:566057 [1] NCCL INFO Channel 01/0 : 5[1] -> 6[2] via P2P/IPC
d14n10:565683:566056 [2] NCCL INFO Channel 01/0 : 6[2] -> 7[3] via P2P/IPC
d11n17:1142857:1143209 [3] NCCL INFO Channel 01/0 : 5[3] -> 4[2] via P2P/IPC
d14n08:1173250:1173630 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2
d14n08:1173250:1173630 [3] NCCL INFO P2P Chunksize set to 131072
d11n17:1142858:1143210 [4] NCCL INFO Channel 01/0 : 6[4] -> 5[3] via P2P/IPC
d14n08:1173251:1173631 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3
d14n08:1173251:1173631 [4] NCCL INFO P2P Chunksize set to 131072
d11n17:1142856:1143207 [2] NCCL INFO Channel 01/0 : 4[2] -> 3[1] via P2P/IPC
d14n11:1169361:1169732 [5] NCCL INFO Channel 00/0 : 7[5] -> 0[4] [send] via NET/IB/1
d14n11:1169361:1169732 [5] NCCL INFO Channel 01/0 : 7[5] -> 0[4] [send] via NET/IB/1
d14n09:567666:568060 [0] NCCL INFO Trees [0] 7/-1/-1->6->0 [1] 7/0/-1->6->-1
d14n09:567666:568060 [0] NCCL INFO P2P Chunksize set to 131072
d14n09:567666:568060 [0] NCCL INFO Channel 00/0 : 5[5] -> 6[0] [receive] via NET/IB/0
d14n09:567666:568060 [0] NCCL INFO Channel 01/0 : 5[5] -> 6[0] [receive] via NET/IB/0
d14n09:567666:568060 [0] NCCL INFO Channel 00/0 : 6[0] -> 7[1] via P2P/IPC
d14n10:565683:566056 [2] NCCL INFO Channel 03/0 : 6[2] -> 7[3] via P2P/IPC
d09n07:1063018:1063459 [1] NCCL INFO Connected all trees
d09n07:1063018:1063459 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d09n07:1063018:1063459 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n09:567666:568060 [0] NCCL INFO Channel 01/0 : 6[0] -> 7[1] via P2P/IPC
f16n16:1079917:1080282 [5] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
f16n16:1079917:1080282 [5] NCCL INFO P2P Chunksize set to 131072
d14n08:1173247:1173628 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7
d14n08:1173247:1173628 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7
d14n08:1173247:1173628 [0] NCCL INFO Trees [0] 1/6/-1->0->-1 [1] 1/-1/-1->0->6
d14n08:1173247:1173628 [0] NCCL INFO P2P Chunksize set to 131072
d14n08:1173247:1173628 [0] NCCL INFO Channel 00/0 : 7[1] -> 0[0] [receive] via NET/IB/0
d14n08:1173247:1173628 [0] NCCL INFO Channel 01/0 : 7[1] -> 0[0] [receive] via NET/IB/0
d14n08:1173247:1173628 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/IPC
d14n10:565682:566057 [1] NCCL INFO Channel 03/0 : 5[1] -> 6[2] via P2P/IPC
d14n08:1173252:1173629 [5] NCCL INFO Trees [0] -1/-1/-1->5->4 [1] -1/-1/-1->5->4
d14n08:1173252:1173629 [5] NCCL INFO P2P Chunksize set to 131072
f16n16:1079916:1080278 [4] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7
f16n16:1079916:1080278 [4] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7
f16n16:1079916:1080278 [4] NCCL INFO Trees [0] 1/2/-1->0->-1 [1] 1/-1/-1->0->2
f16n16:1079916:1080278 [4] NCCL INFO P2P Chunksize set to 131072
f16n16:1079916:1080278 [4] NCCL INFO Channel 00/0 : 7[5] -> 0[4] [receive] via NET/IB/1
f16n16:1079916:1080278 [4] NCCL INFO Channel 01/0 : 7[5] -> 0[4] [receive] via NET/IB/1
f16n16:1079916:1080278 [4] NCCL INFO Channel 00/0 : 0[4] -> 1[5] via P2P/IPC
f16n17:1090962:1091327 [3] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4
f16n17:1090962:1091327 [3] NCCL INFO P2P Chunksize set to 131072
f16n17:1090961:1091324 [2] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3
f16n17:1090961:1091324 [2] NCCL INFO P2P Chunksize set to 131072
f16n16:1079916:1080278 [4] NCCL INFO Channel 01/0 : 0[4] -> 1[5] via P2P/IPC
f16n17:1090959:1091326 [0] NCCL INFO Trees [0] 3/-1/-1->2->0 [1] 3/0/-1->2->-1
f16n17:1090959:1091326 [0] NCCL INFO P2P Chunksize set to 131072
f16n17:1090959:1091326 [0] NCCL INFO Channel 00/0 : 1[5] -> 2[0] [receive] via NET/IB/0
f16n17:1090959:1091326 [0] NCCL INFO Channel 01/0 : 1[5] -> 2[0] [receive] via NET/IB/0
f16n17:1090959:1091326 [0] NCCL INFO Channel 00/0 : 2[0] -> 3[1] via P2P/IPC
d14n08:1173249:1173632 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
d14n08:1173249:1173632 [2] NCCL INFO P2P Chunksize set to 131072
d14n08:1173247:1173628 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/IPC
d14n08:1173250:1173630 [3] NCCL INFO Channel 00/0 : 3[3] -> 4[4] via P2P/IPC
d14n08:1173251:1173631 [4] NCCL INFO Channel 00/0 : 4[4] -> 5[5] via P2P/IPC
f16n17:1090963:1091328 [4] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5
f16n17:1090963:1091328 [4] NCCL INFO P2P Chunksize set to 131072
f16n17:1090964:1091329 [5] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
f16n17:1090964:1091329 [5] NCCL INFO P2P Chunksize set to 131072
d11n16:1130273:1130643 [5] NCCL INFO Channel 00/0 : 1[5] -> 2[0] [send] via NET/IB/1
d11n16:1130273:1130643 [5] NCCL INFO Channel 01/0 : 1[5] -> 2[0] [send] via NET/IB/1
d14n09:567667:568059 [1] NCCL INFO Channel 00/0 : 7[1] -> 0[0] [send] via NET/IB/0
d14n09:567667:568059 [1] NCCL INFO Channel 01/0 : 7[1] -> 0[0] [send] via NET/IB/0
f16n17:1090959:1091326 [0] NCCL INFO Channel 01/0 : 2[0] -> 3[1] via P2P/IPC
d11n17:1142857:1143209 [3] NCCL INFO Connected all trees
d11n17:1142857:1143209 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d11n17:1142857:1143209 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n17:1142856:1143207 [2] NCCL INFO Connected all trees
d11n17:1142856:1143207 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d11n17:1142856:1143207 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n08:1173250:1173630 [3] NCCL INFO Channel 01/0 : 3[3] -> 4[4] via P2P/IPC
d14n08:1173251:1173631 [4] NCCL INFO Channel 01/0 : 4[4] -> 5[5] via P2P/IPC
d14n08:1173249:1173632 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/IPC
d14n09:567668:568058 [2] NCCL INFO Connected all rings
d14n09:567668:568058 [2] NCCL INFO Channel 00/0 : 0[2] -> 3[5] via P2P/IPC
f16n16:1079917:1080282 [5] NCCL INFO Channel 00/0 : 1[5] -> 2[0] [send] via NET/IB/1
f16n16:1079917:1080282 [5] NCCL INFO Channel 01/0 : 1[5] -> 2[0] [send] via NET/IB/1
f16n17:1090962:1091327 [3] NCCL INFO Channel 00/0 : 5[3] -> 6[4] via P2P/IPC
d14n08:1173252:1173629 [5] NCCL INFO Channel 00/0 : 5[5] -> 6[0] [send] via NET/IB/1
d14n08:1173252:1173629 [5] NCCL INFO Channel 01/0 : 5[5] -> 6[0] [send] via NET/IB/1
f16n17:1090961:1091324 [2] NCCL INFO Channel 00/0 : 4[2] -> 5[3] via P2P/IPC
d14n10:565681:566059 [0] NCCL INFO Connected all rings
d14n10:565681:566059 [0] NCCL INFO Channel 01/0 : 4[0] -> 5[1] via P2P/IPC
d14n11:1169359:1169729 [3] NCCL INFO Connected all rings
f16n17:1090963:1091328 [4] NCCL INFO Channel 00/0 : 6[4] -> 7[5] via P2P/IPC
f16n17:1090962:1091327 [3] NCCL INFO Channel 01/0 : 5[3] -> 6[4] via P2P/IPC
d14n11:1169358:1169730 [2] NCCL INFO Connected all rings
d14n09:567668:568058 [2] NCCL INFO Channel 01/0 : 0[2] -> 3[5] via P2P/IPC
f16n17:1090961:1091324 [2] NCCL INFO Channel 01/0 : 4[2] -> 5[3] via P2P/IPC
d14n11:1169360:1169731 [4] NCCL INFO Connected all rings
d14n10:565681:566059 [0] NCCL INFO Channel 03/0 : 4[0] -> 5[1] via P2P/IPC
f16n17:1090963:1091328 [4] NCCL INFO Channel 01/0 : 6[4] -> 7[5] via P2P/IPC
d14n10:565684:566060 [3] NCCL INFO Connected all rings
d14n08:1173249:1173632 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/IPC
d14n09:567668:568058 [2] NCCL INFO Channel 02/0 : 0[2] -> 3[5] via P2P/IPC
d14n09:567668:568058 [2] NCCL INFO Channel 03/0 : 0[2] -> 3[5] via P2P/IPC
d14n11:1169359:1169729 [3] NCCL INFO Channel 00/0 : 5[3] -> 4[2] via P2P/IPC
f16n17:1090964:1091329 [5] NCCL INFO Channel 00/0 : 7[5] -> 0[4] [send] via NET/IB/1
f16n17:1090964:1091329 [5] NCCL INFO Channel 01/0 : 7[5] -> 0[4] [send] via NET/IB/1
d14n09:567671:568061 [5] NCCL INFO Channel 00/0 : 3[5] -> 0[2] via P2P/IPC
d14n11:1169358:1169730 [2] NCCL INFO Channel 00/0 : 4[2] -> 3[1] via P2P/IPC
d14n08:1173251:1173631 [4] NCCL INFO Connected all rings
d14n11:1169360:1169731 [4] NCCL INFO Channel 00/0 : 6[4] -> 5[3] via P2P/IPC
d14n11:1169359:1169729 [3] NCCL INFO Channel 01/0 : 5[3] -> 4[2] via P2P/IPC
d14n11:1169361:1169732 [5] NCCL INFO Connected all rings
d14n11:1169361:1169732 [5] NCCL INFO Channel 00/0 : 7[5] -> 6[4] via P2P/IPC
d14n11:1169358:1169730 [2] NCCL INFO Channel 01/0 : 4[2] -> 3[1] via P2P/IPC
d14n09:567669:568062 [3] NCCL INFO Connected all rings
d14n09:567669:568062 [3] NCCL INFO Channel 00/0 : 1[3] -> 4[0] [send] via NET/IB/3
d14n09:567669:568062 [3] NCCL INFO Channel 01/0 : 1[3] -> 4[0] [send] via NET/IB/0
d14n09:567669:568062 [3] NCCL INFO Channel 02/0 : 1[3] -> 4[0] [send] via NET/IB/3
d14n09:567669:568062 [3] NCCL INFO Channel 03/0 : 1[3] -> 4[0] [send] via NET/IB/0
d14n09:567669:568062 [3] NCCL INFO Channel 00/0 : 4[0] -> 1[3] [receive] via NET/IB/3
d14n09:567669:568062 [3] NCCL INFO Channel 02/0 : 4[0] -> 1[3] [receive] via NET/IB/3
d14n11:1169360:1169731 [4] NCCL INFO Channel 01/0 : 6[4] -> 5[3] via P2P/IPC
d09n07:1063016:1063455 [0] NCCL INFO Connected all trees
d09n07:1063016:1063455 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d09n07:1063016:1063455 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n10:565684:566060 [3] NCCL INFO Channel 00/0 : 7[3] -> 6[2] via P2P/IPC
d14n09:567671:568061 [5] NCCL INFO Channel 02/0 : 3[5] -> 0[2] via P2P/IPC
d14n11:1169361:1169732 [5] NCCL INFO Channel 01/0 : 7[5] -> 6[4] via P2P/IPC
d14n10:565681:566059 [0] NCCL INFO Channel 00/0 : 1[3] -> 4[0] [receive] via NET/IB/0
d14n10:565681:566059 [0] NCCL INFO Channel 01/0 : 1[3] -> 4[0] [receive] via NET/IB/3
d14n10:565681:566059 [0] NCCL INFO Channel 02/0 : 1[3] -> 4[0] [receive] via NET/IB/0
d14n10:565681:566059 [0] NCCL INFO Channel 03/0 : 1[3] -> 4[0] [receive] via NET/IB/3
d14n10:565681:566059 [0] NCCL INFO Channel 00/0 : 4[0] -> 1[3] [send] via NET/IB/0
d14n10:565681:566059 [0] NCCL INFO Channel 02/0 : 4[0] -> 1[3] [send] via NET/IB/0
d14n08:1173250:1173630 [3] NCCL INFO Connected all rings
d14n08:1173251:1173631 [4] NCCL INFO Channel 00/0 : 4[4] -> 3[3] via P2P/IPC
d11n16:1130273:1130643 [5] NCCL INFO Connected all rings
d11n16:1130273:1130643 [5] NCCL INFO Channel 00/0 : 1[5] -> 0[4] via P2P/IPC
d09n08:1073954:1074323 [0] NCCL INFO Connected all trees
d09n08:1073954:1074323 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d09n08:1073954:1074323 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n10:565682:566057 [1] NCCL INFO Channel 00/0 : 5[1] -> 4[0] via P2P/IPC
d14n09:567671:568061 [5] NCCL INFO Channel 00/0 : 3[5] -> 2[4] via P2P/IPC
f16n17:1090962:1091327 [3] NCCL INFO Connected all rings
d11n16:1130273:1130643 [5] NCCL INFO Channel 01/0 : 1[5] -> 0[4] via P2P/IPC
d14n10:565684:566060 [3] NCCL INFO Channel 02/0 : 7[3] -> 6[2] via P2P/IPC
d14n08:1173251:1173631 [4] NCCL INFO Channel 01/0 : 4[4] -> 3[3] via P2P/IPC
d11n17:1142859:1143211 [5] NCCL INFO Connected all rings
d11n17:1142859:1143211 [5] NCCL INFO Channel 00/0 : 7[5] -> 6[4] via P2P/IPC
f16n17:1090963:1091328 [4] NCCL INFO Connected all rings
d14n10:565685:566055 [4] NCCL INFO Connected all rings
d14n10:565685:566055 [4] NCCL INFO Channel 00/0 : 0[4] -> 2[0] [send] via NET/IB/1
d14n10:565685:566055 [4] NCCL INFO Channel 01/0 : 0[4] -> 2[0] [send] via NET/IB/1
d14n10:565685:566055 [4] NCCL INFO Channel 00/0 : 2[0] -> 0[4] [receive] via NET/IB/1
d14n10:565685:566055 [4] NCCL INFO Channel 01/0 : 2[0] -> 0[4] [receive] via NET/IB/1
d11n17:1142859:1143211 [5] NCCL INFO Channel 01/0 : 7[5] -> 6[4] via P2P/IPC
d14n09:567671:568061 [5] NCCL INFO Channel 01/0 : 3[5] -> 2[4] via P2P/IPC
d14n08:1173250:1173630 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/IPC
d14n10:565682:566057 [1] NCCL INFO Channel 02/0 : 5[1] -> 4[0] via P2P/IPC
d14n10:565683:566056 [2] NCCL INFO Channel 00/0 : 6[2] -> 5[1] via P2P/IPC
d14n08:1173250:1173630 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/IPC
f16n17:1090962:1091327 [3] NCCL INFO Channel 00/0 : 5[3] -> 4[2] via P2P/IPC
d14n09:567671:568061 [5] NCCL INFO Channel 02/0 : 3[5] -> 2[4] via P2P/IPC
d14n08:1173252:1173629 [5] NCCL INFO Connected all rings
d14n08:1173252:1173629 [5] NCCL INFO Channel 00/0 : 5[5] -> 4[4] via P2P/IPC
f16n17:1090963:1091328 [4] NCCL INFO Channel 00/0 : 6[4] -> 5[3] via P2P/IPC
d14n10:565683:566056 [2] NCCL INFO Channel 02/0 : 6[2] -> 5[1] via P2P/IPC
f16n17:1090962:1091327 [3] NCCL INFO Channel 01/0 : 5[3] -> 4[2] via P2P/IPC
d14n08:1173252:1173629 [5] NCCL INFO Channel 01/0 : 5[5] -> 4[4] via P2P/IPC
d14n11:1169356:1169733 [0] NCCL INFO Connected all rings
d14n11:1169356:1169733 [0] NCCL INFO Channel 00/0 : 0[4] -> 2[0] [receive] via NET/IB/0
d14n11:1169356:1169733 [0] NCCL INFO Channel 01/0 : 0[4] -> 2[0] [receive] via NET/IB/0
d14n11:1169356:1169733 [0] NCCL INFO Channel 00/0 : 2[0] -> 0[4] [send] via NET/IB/0
d14n11:1169356:1169733 [0] NCCL INFO Channel 01/0 : 2[0] -> 0[4] [send] via NET/IB/0
f16n17:1090963:1091328 [4] NCCL INFO Channel 01/0 : 6[4] -> 5[3] via P2P/IPC
d14n11:1169361:1169732 [5] NCCL INFO Connected all trees
d14n11:1169361:1169732 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n11:1169361:1169732 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n09:567671:568061 [5] NCCL INFO Channel 03/0 : 3[5] -> 2[4] via P2P/IPC
d14n09:567668:568058 [2] NCCL INFO Connected all trees
d14n09:567668:568058 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n09:567668:568058 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d09n07:1063018:1063459 [1] NCCL INFO comm 0x12716e210 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x1cb338cf47f3186f - Init COMPLETE
d09n07:1063016:1063455 [0] NCCL INFO comm 0x140efa8a0 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x1cb338cf47f3186f - Init COMPLETE
d09n07:1063020:1063457 [3] NCCL INFO comm 0x120750bb0 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x1cb338cf47f3186f - Init COMPLETE
d09n07:1063021:1063456 [4] NCCL INFO comm 0x179bc6a50 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x1cb338cf47f3186f - Init COMPLETE
d09n07:1063022:1063458 [5] NCCL INFO comm 0x16ad47a60 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x1cb338cf47f3186f - Init COMPLETE
d09n07:1063019:1063460 [2] NCCL INFO comm 0x161a26780 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x1cb338cf47f3186f - Init COMPLETE
d11n17:1142859:1143211 [5] NCCL INFO Connected all trees
d11n17:1142859:1143211 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d11n17:1142859:1143211 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n16:1130272:1130642 [4] NCCL INFO Connected all rings
d11n16:1130272:1130642 [4] NCCL INFO Channel 00/0 : 0[4] -> 2[0] [send] via NET/IB/1
d11n16:1130272:1130642 [4] NCCL INFO Channel 01/0 : 0[4] -> 2[0] [send] via NET/IB/1
d11n16:1130272:1130642 [4] NCCL INFO Channel 00/0 : 2[0] -> 0[4] [receive] via NET/IB/1
d11n16:1130272:1130642 [4] NCCL INFO Channel 01/0 : 2[0] -> 0[4] [receive] via NET/IB/1
f16n17:1090964:1091329 [5] NCCL INFO Connected all rings
f16n17:1090964:1091329 [5] NCCL INFO Channel 00/0 : 7[5] -> 6[4] via P2P/IPC
d14n11:1169359:1169729 [3] NCCL INFO Connected all trees
d14n11:1169359:1169729 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n11:1169359:1169729 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n17:1090964:1091329 [5] NCCL INFO Channel 01/0 : 7[5] -> 6[4] via P2P/IPC
d11n17:1142854:1143208 [0] NCCL INFO Connected all rings
d11n17:1142854:1143208 [0] NCCL INFO Channel 00/0 : 0[4] -> 2[0] [receive] via NET/IB/0
d11n17:1142854:1143208 [0] NCCL INFO Channel 01/0 : 0[4] -> 2[0] [receive] via NET/IB/0
d11n17:1142854:1143208 [0] NCCL INFO Channel 00/0 : 2[0] -> 0[4] [send] via NET/IB/0
d11n17:1142854:1143208 [0] NCCL INFO Channel 01/0 : 2[0] -> 0[4] [send] via NET/IB/0
d09n08:1073954:1074323 [0] NCCL INFO comm 0x14d8a2080 rank 6 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x1cb338cf47f3186f - Init COMPLETE
d09n08:1073955:1074324 [1] NCCL INFO comm 0x15da36520 rank 7 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x1cb338cf47f3186f - Init COMPLETE
d14n08:1173252:1173629 [5] NCCL INFO Connected all trees
d14n08:1173252:1173629 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n08:1173252:1173629 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n17:1142858:1143210 [4] NCCL INFO Connected all trees
d11n17:1142858:1143210 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d11n17:1142858:1143210 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n08:1173251:1173631 [4] NCCL INFO Connected all trees
d14n08:1173251:1173631 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n08:1173251:1173631 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n16:1130273:1130643 [5] NCCL INFO Connected all trees
d11n16:1130273:1130643 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d11n16:1130273:1130643 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n17:1090964:1091329 [5] NCCL INFO Connected all trees
f16n17:1090964:1091329 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n17:1090964:1091329 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n11:1169360:1169731 [4] NCCL INFO Connected all trees
d14n11:1169360:1169731 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n11:1169360:1169731 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n17:1090963:1091328 [4] NCCL INFO Connected all trees
f16n17:1090963:1091328 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n17:1090963:1091328 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n07:1212410:1212807 [0] NCCL INFO Trees [0] 7/-1/-1->6->0 [1] 7/0/-1->6->-1
d17n07:1212410:1212807 [0] NCCL INFO P2P Chunksize set to 131072
d17n07:1212410:1212807 [0] NCCL INFO Channel 00/0 : 5[5] -> 6[0] [receive] via NET/IB/0
d17n07:1212410:1212807 [0] NCCL INFO Channel 01/0 : 5[5] -> 6[0] [receive] via NET/IB/0
d17n07:1212410:1212807 [0] NCCL INFO Channel 00/0 : 6[0] -> 7[1] via P2P/IPC
d14n11:1169358:1169730 [2] NCCL INFO Connected all trees
d14n11:1169358:1169730 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n11:1169358:1169730 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n07:1212410:1212807 [0] NCCL INFO Channel 01/0 : 6[0] -> 7[1] via P2P/IPC
d17n06:1216532:1216926 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
d17n06:1216532:1216926 [2] NCCL INFO P2P Chunksize set to 131072
d17n06:1216531:1216928 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
d17n06:1216531:1216928 [1] NCCL INFO P2P Chunksize set to 131072
f18n05:1008222:1008576 [3] NCCL INFO Connected all trees
f18n05:1008222:1008576 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f18n05:1008222:1008576 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n06:1216534:1216925 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3
d17n06:1216534:1216925 [4] NCCL INFO P2P Chunksize set to 131072
d17n06:1216530:1216923 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7
d17n06:1216530:1216923 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7
d17n06:1216530:1216923 [0] NCCL INFO Trees [0] 1/6/-1->0->-1 [1] 1/-1/-1->0->6
d17n06:1216530:1216923 [0] NCCL INFO P2P Chunksize set to 131072
d17n06:1216530:1216923 [0] NCCL INFO Channel 00/0 : 7[1] -> 0[0] [receive] via NET/IB/0
d17n06:1216530:1216923 [0] NCCL INFO Channel 01/0 : 7[1] -> 0[0] [receive] via NET/IB/0
d17n06:1216530:1216923 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/IPC
d17n06:1216530:1216923 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/IPC
d14n10:565682:566057 [1] NCCL INFO Connected all trees
d14n10:565682:566057 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n10:565682:566057 [1] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n10:565686:566058 [5] NCCL INFO Connected all trees
d14n10:565686:566058 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n10:565686:566058 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n09:567670:568063 [4] NCCL INFO Connected all trees
d14n09:567670:568063 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n09:567670:568063 [4] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d17n06:1216532:1216926 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/IPC
d17n06:1216531:1216928 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/IPC
d17n06:1216534:1216925 [4] NCCL INFO Channel 00/0 : 4[4] -> 5[5] via P2P/IPC
d14n09:567671:568061 [5] NCCL INFO Connected all trees
d14n09:567671:568061 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n09:567671:568061 [5] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n10:565684:566060 [3] NCCL INFO Connected all trees
d14n10:565684:566060 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n10:565684:566060 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d17n06:1216532:1216926 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/IPC
d17n06:1216531:1216928 [1] NCCL INFO Channel 01/0 : 1[1] -> 2[2] via P2P/IPC
d17n06:1216534:1216925 [4] NCCL INFO Channel 01/0 : 4[4] -> 5[5] via P2P/IPC
d17n06:1216531:1216928 [1] NCCL INFO Connected all rings
f18n05:1008221:1008572 [2] NCCL INFO comm 0x1666582c0 rank 4 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x42a519b1adea69c3 - Init COMPLETE
f18n05:1008224:1008577 [5] NCCL INFO comm 0x150aabfd0 rank 7 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x42a519b1adea69c3 - Init COMPLETE
f18n05:1008219:1008573 [0] NCCL INFO comm 0x158e1a8c0 rank 2 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x42a519b1adea69c3 - Init COMPLETE
f18n05:1008222:1008576 [3] NCCL INFO comm 0x152663bc0 rank 5 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x42a519b1adea69c3 - Init COMPLETE
f18n05:1008223:1008575 [4] NCCL INFO comm 0x182732820 rank 6 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x42a519b1adea69c3 - Init COMPLETE
f18n05:1008220:1008574 [1] NCCL INFO comm 0x16bcbf110 rank 3 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x42a519b1adea69c3 - Init COMPLETE
d17n06:1216531:1216928 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/IPC
d17n06:1216531:1216928 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/IPC
f17n01:970277:970642 [1] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
f17n01:970277:970642 [1] NCCL INFO P2P Chunksize set to 131072
d14n11:1169356:1169733 [0] NCCL INFO Connected all trees
d14n11:1169356:1169733 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n11:1169356:1169733 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f17n01:970277:970642 [1] NCCL INFO Channel 00/0 : 7[1] -> 0[0] [send] via NET/IB/0
f17n01:970277:970642 [1] NCCL INFO Channel 01/0 : 7[1] -> 0[0] [send] via NET/IB/0
d17n07:1212411:1212808 [1] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
d17n07:1212411:1212808 [1] NCCL INFO P2P Chunksize set to 131072
d14n10:565685:566055 [4] NCCL INFO Connected all trees
d14n10:565685:566055 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n10:565685:566055 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n17:1090960:1091325 [1] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2
f16n17:1090960:1091325 [1] NCCL INFO P2P Chunksize set to 131072
f16n18:1091869:1092253 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2
f16n18:1091869:1092253 [3] NCCL INFO P2P Chunksize set to 131072
f16n18:1091871:1092252 [5] NCCL INFO Trees [0] -1/-1/-1->5->4 [1] -1/-1/-1->5->4
f16n18:1091871:1092252 [5] NCCL INFO P2P Chunksize set to 131072
d11n17:1142855:1143206 [1] NCCL INFO Connected all trees
d11n17:1142855:1143206 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d11n17:1142855:1143206 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n09:567669:568062 [3] NCCL INFO Connected all trees
d14n09:567669:568062 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n09:567669:568062 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n10:565681:566059 [0] NCCL INFO Connected all trees
d14n10:565681:566059 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n10:565681:566059 [0] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f16n16:1079914:1080281 [2] NCCL INFO Connected all trees
f16n16:1079914:1080281 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n16:1079914:1080281 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
f16n16:1079916:1080278 [4] NCCL INFO Connected all rings
f16n16:1079916:1080278 [4] NCCL INFO Channel 00/0 : 0[4] -> 2[0] [send] via NET/IB/1
f16n16:1079916:1080278 [4] NCCL INFO Channel 01/0 : 0[4] -> 2[0] [send] via NET/IB/1
d14n10:565683:566056 [2] NCCL INFO Connected all trees
d14n10:565683:566056 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n10:565683:566056 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
d14n09:567666:568060 [0] NCCL INFO Connected all rings
d14n09:567666:568060 [0] NCCL INFO Channel 00/0 : 6[0] -> 0[0] [send] via NET/IB/0
d14n09:567666:568060 [0] NCCL INFO Channel 01/0 : 6[0] -> 0[0] [send] via NET/IB/0
d14n08:1173248:1173633 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
d14n08:1173248:1173633 [1] NCCL INFO P2P Chunksize set to 131072
d14n10:565686:566058 [5] NCCL INFO comm 0x11fc6ca10 rank 1 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x66e3f535c9700c0f - Init COMPLETE
d14n10:565685:566055 [4] NCCL INFO comm 0x1642c9590 rank 0 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x66e3f535c9700c0f - Init COMPLETE
d14n11:1169357:1169728 [1] NCCL INFO Connected all trees
d14n11:1169357:1169728 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n11:1169357:1169728 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n06:1216535:1216924 [5] NCCL INFO Trees [0] -1/-1/-1->5->4 [1] -1/-1/-1->5->4
d17n06:1216535:1216924 [5] NCCL INFO P2P Chunksize set to 131072
d17n06:1216533:1216927 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2
d17n06:1216533:1216927 [3] NCCL INFO P2P Chunksize set to 131072
f17n01:970277:970642 [1] NCCL INFO Connected all rings
f17n01:970277:970642 [1] NCCL INFO Channel 00/0 : 7[1] -> 6[0] via P2P/IPC
f17n01:970277:970642 [1] NCCL INFO Channel 01/0 : 7[1] -> 6[0] via P2P/IPC
d14n09:567669:568062 [3] NCCL INFO comm 0x149346280 rank 1 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x2d88817d8ea3a688 - Init COMPLETE
d14n09:567670:568063 [4] NCCL INFO comm 0x164d3cbc0 rank 2 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x2d88817d8ea3a688 - Init COMPLETE
d14n09:567668:568058 [2] NCCL INFO comm 0x12c5b26d0 rank 0 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x2d88817d8ea3a688 - Init COMPLETE
d14n09:567671:568061 [5] NCCL INFO comm 0x13a2d4d90 rank 3 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x2d88817d8ea3a688 - Init COMPLETE
d11n17:1142854:1143208 [0] NCCL INFO Connected all trees
d11n17:1142854:1143208 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d11n17:1142854:1143208 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n16:1130272:1130642 [4] NCCL INFO Connected all trees
d11n16:1130272:1130642 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d11n16:1130272:1130642 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n18:1091869:1092253 [3] NCCL INFO Channel 00/0 : 3[3] -> 4[4] via P2P/IPC
f16n18:1091869:1092253 [3] NCCL INFO Channel 01/0 : 3[3] -> 4[4] via P2P/IPC
f16n18:1091871:1092252 [5] NCCL INFO Channel 00/0 : 5[5] -> 6[0] [send] via NET/IB/1
f16n18:1091871:1092252 [5] NCCL INFO Channel 01/0 : 5[5] -> 6[0] [send] via NET/IB/1
d11n16:1130272:1130642 [4] NCCL INFO comm 0x12700d100 rank 0 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x6a336f573a53dcba - Init COMPLETE
d11n16:1130273:1130643 [5] NCCL INFO comm 0x152baf340 rank 1 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x6a336f573a53dcba - Init COMPLETE
f16n18:1091870:1092254 [4] NCCL INFO Connected all rings
f16n18:1091869:1092253 [3] NCCL INFO Connected all rings
f16n16:1079913:1080279 [1] NCCL INFO comm 0x17ec25cc0 rank 5 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0xb4380781c8b9c34c - Init COMPLETE
f16n16:1079912:1080280 [0] NCCL INFO comm 0x143af5350 rank 4 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0xb4380781c8b9c34c - Init COMPLETE
f16n16:1079914:1080281 [2] NCCL INFO comm 0x165ac6060 rank 6 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0xb4380781c8b9c34c - Init COMPLETE
f16n16:1079915:1080283 [3] NCCL INFO comm 0x1640ed2e0 rank 7 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0xb4380781c8b9c34c - Init COMPLETE
f16n18:1091868:1092251 [2] NCCL INFO Connected all rings
f16n18:1091870:1092254 [4] NCCL INFO Channel 00/0 : 4[4] -> 3[3] via P2P/IPC
f16n18:1091869:1092253 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/IPC
f16n18:1091870:1092254 [4] NCCL INFO Channel 01/0 : 4[4] -> 3[3] via P2P/IPC
f16n18:1091869:1092253 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/IPC
f17n01:970276:970641 [0] NCCL INFO Connected all rings
f17n01:970276:970641 [0] NCCL INFO Channel 00/0 : 6[0] -> 0[0] [send] via NET/IB/0
f17n01:970276:970641 [0] NCCL INFO Channel 01/0 : 6[0] -> 0[0] [send] via NET/IB/0
f17n01:970276:970641 [0] NCCL INFO Channel 00/0 : 0[0] -> 6[0] [receive] via NET/IB/0
f17n01:970276:970641 [0] NCCL INFO Channel 01/0 : 0[0] -> 6[0] [receive] via NET/IB/0
f16n18:1091871:1092252 [5] NCCL INFO Connected all rings
f16n18:1091871:1092252 [5] NCCL INFO Channel 00/0 : 5[5] -> 4[4] via P2P/IPC
f16n18:1091868:1092251 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/IPC
f16n18:1091866:1092249 [0] NCCL INFO Connected all rings
f16n18:1091866:1092249 [0] NCCL INFO Channel 00/0 : 6[0] -> 0[0] [receive] via NET/IB/0
f16n18:1091866:1092249 [0] NCCL INFO Channel 01/0 : 6[0] -> 0[0] [receive] via NET/IB/0
f16n18:1091866:1092249 [0] NCCL INFO Channel 00/0 : 0[0] -> 6[0] [send] via NET/IB/0
f16n18:1091866:1092249 [0] NCCL INFO Channel 01/0 : 0[0] -> 6[0] [send] via NET/IB/0
f16n18:1091871:1092252 [5] NCCL INFO Channel 01/0 : 5[5] -> 4[4] via P2P/IPC
f16n18:1091868:1092251 [2] NCCL INFO Channel 01/0 : 2[2] -> 1[1] via P2P/IPC
f17n01:970277:970642 [1] NCCL INFO Connected all trees
f17n01:970277:970642 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f17n01:970277:970642 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n08:1173248:1173633 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/IPC
d14n08:1173248:1173633 [1] NCCL INFO Channel 01/0 : 1[1] -> 2[2] via P2P/IPC
f16n18:1091871:1092252 [5] NCCL INFO Connected all trees
f16n18:1091871:1092252 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n18:1091871:1092252 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n17:1090960:1091325 [1] NCCL INFO Channel 00/0 : 3[1] -> 4[2] via P2P/IPC
f16n17:1090960:1091325 [1] NCCL INFO Channel 01/0 : 3[1] -> 4[2] via P2P/IPC
f16n18:1091870:1092254 [4] NCCL INFO Connected all trees
f16n18:1091870:1092254 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n18:1091870:1092254 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n10:565681:566059 [0] NCCL INFO comm 0x16eca6d30 rank 4 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x2d88817d8ea3a688 - Init COMPLETE
d14n10:565682:566057 [1] NCCL INFO comm 0x17a9539a0 rank 5 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x2d88817d8ea3a688 - Init COMPLETE
d14n10:565683:566056 [2] NCCL INFO comm 0x12c9d4b80 rank 6 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x2d88817d8ea3a688 - Init COMPLETE
d14n10:565684:566060 [3] NCCL INFO comm 0x12f1e1010 rank 7 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x2d88817d8ea3a688 - Init COMPLETE
d14n08:1173249:1173632 [2] NCCL INFO Connected all rings
d14n08:1173248:1173633 [1] NCCL INFO Connected all rings
f16n18:1091869:1092253 [3] NCCL INFO Connected all trees
f16n18:1091869:1092253 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n18:1091869:1092253 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n06:1216533:1216927 [3] NCCL INFO Channel 00/0 : 3[3] -> 4[4] via P2P/IPC
d17n06:1216533:1216927 [3] NCCL INFO Channel 01/0 : 3[3] -> 4[4] via P2P/IPC
d14n08:1173249:1173632 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/IPC
d14n08:1173248:1173633 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/IPC
f16n17:1090960:1091325 [1] NCCL INFO Connected all rings
f16n17:1090961:1091324 [2] NCCL INFO Connected all rings
d14n08:1173249:1173632 [2] NCCL INFO Channel 01/0 : 2[2] -> 1[1] via P2P/IPC
d14n08:1173248:1173633 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/IPC
f16n18:1091868:1092251 [2] NCCL INFO Connected all trees
f16n18:1091868:1092251 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n18:1091868:1092251 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n09:567667:568059 [1] NCCL INFO Connected all rings
d14n09:567667:568059 [1] NCCL INFO Channel 00/0 : 7[1] -> 6[0] via P2P/IPC
f16n17:1090960:1091325 [1] NCCL INFO Channel 00/0 : 3[1] -> 2[0] via P2P/IPC
d14n09:567667:568059 [1] NCCL INFO Channel 01/0 : 7[1] -> 6[0] via P2P/IPC
f16n17:1090961:1091324 [2] NCCL INFO Channel 00/0 : 4[2] -> 3[1] via P2P/IPC
f16n17:1090960:1091325 [1] NCCL INFO Channel 01/0 : 3[1] -> 2[0] via P2P/IPC
f16n17:1090961:1091324 [2] NCCL INFO Channel 01/0 : 4[2] -> 3[1] via P2P/IPC
d17n06:1216532:1216926 [2] NCCL INFO Connected all rings
d17n06:1216533:1216927 [3] NCCL INFO Connected all rings
d14n11:1169356:1169733 [0] NCCL INFO comm 0x15719da10 rank 2 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x66e3f535c9700c0f - Init COMPLETE
d14n11:1169357:1169728 [1] NCCL INFO comm 0x132cafab0 rank 3 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x66e3f535c9700c0f - Init COMPLETE
d14n11:1169359:1169729 [3] NCCL INFO comm 0x168968a00 rank 5 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x66e3f535c9700c0f - Init COMPLETE
d14n11:1169360:1169731 [4] NCCL INFO comm 0x119bfe460 rank 6 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x66e3f535c9700c0f - Init COMPLETE
f16n16:1079917:1080282 [5] NCCL INFO Connected all rings
f16n16:1079917:1080282 [5] NCCL INFO Channel 00/0 : 1[5] -> 0[4] via P2P/IPC
d14n11:1169358:1169730 [2] NCCL INFO comm 0x142196b00 rank 4 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x66e3f535c9700c0f - Init COMPLETE
d14n08:1173247:1173628 [0] NCCL INFO Connected all rings
d14n08:1173247:1173628 [0] NCCL INFO Channel 00/0 : 6[0] -> 0[0] [receive] via NET/IB/0
d14n08:1173247:1173628 [0] NCCL INFO Channel 01/0 : 6[0] -> 0[0] [receive] via NET/IB/0
d14n08:1173247:1173628 [0] NCCL INFO Channel 00/0 : 0[0] -> 6[0] [send] via NET/IB/0
d14n08:1173247:1173628 [0] NCCL INFO Channel 01/0 : 0[0] -> 6[0] [send] via NET/IB/0
d14n11:1169361:1169732 [5] NCCL INFO comm 0x12c82f150 rank 7 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x66e3f535c9700c0f - Init COMPLETE
d14n09:567666:568060 [0] NCCL INFO Channel 00/0 : 0[0] -> 6[0] [receive] via NET/IB/0
d14n09:567666:568060 [0] NCCL INFO Channel 01/0 : 0[0] -> 6[0] [receive] via NET/IB/0
f16n16:1079917:1080282 [5] NCCL INFO Channel 01/0 : 1[5] -> 0[4] via P2P/IPC
d17n07:1212411:1212808 [1] NCCL INFO Channel 00/0 : 7[1] -> 0[0] [send] via NET/IB/0
d17n07:1212411:1212808 [1] NCCL INFO Channel 01/0 : 7[1] -> 0[0] [send] via NET/IB/0
d17n06:1216532:1216926 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/IPC
d17n06:1216533:1216927 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/IPC
d17n06:1216532:1216926 [2] NCCL INFO Channel 01/0 : 2[2] -> 1[1] via P2P/IPC
d17n06:1216533:1216927 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/IPC
f16n16:1079916:1080278 [4] NCCL INFO Channel 00/0 : 2[0] -> 0[4] [receive] via NET/IB/1
f16n16:1079916:1080278 [4] NCCL INFO Channel 01/0 : 2[0] -> 0[4] [receive] via NET/IB/1
f16n17:1090959:1091326 [0] NCCL INFO Connected all rings
f16n17:1090959:1091326 [0] NCCL INFO Channel 00/0 : 0[4] -> 2[0] [receive] via NET/IB/0
f16n17:1090959:1091326 [0] NCCL INFO Channel 01/0 : 0[4] -> 2[0] [receive] via NET/IB/0
f16n17:1090959:1091326 [0] NCCL INFO Channel 00/0 : 2[0] -> 0[4] [send] via NET/IB/0
f16n17:1090959:1091326 [0] NCCL INFO Channel 01/0 : 2[0] -> 0[4] [send] via NET/IB/0
d14n09:567667:568059 [1] NCCL INFO Connected all trees
d14n09:567667:568059 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n09:567667:568059 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n17:1090962:1091327 [3] NCCL INFO Connected all trees
f16n17:1090962:1091327 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n17:1090962:1091327 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n08:1173250:1173630 [3] NCCL INFO Connected all trees
d14n08:1173250:1173630 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n08:1173250:1173630 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n06:1216532:1216926 [2] NCCL INFO Connected all trees
d17n06:1216532:1216926 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d17n06:1216532:1216926 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n18:1091866:1092249 [0] NCCL INFO Connected all trees
f16n18:1091866:1092249 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n18:1091866:1092249 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n17:1142854:1143208 [0] NCCL INFO comm 0x15c758320 rank 2 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x6a336f573a53dcba - Init COMPLETE
d11n17:1142857:1143209 [3] NCCL INFO comm 0x132a99450 rank 5 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x6a336f573a53dcba - Init COMPLETE
d11n17:1142859:1143211 [5] NCCL INFO comm 0x1371c4ff0 rank 7 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x6a336f573a53dcba - Init COMPLETE
d11n17:1142855:1143206 [1] NCCL INFO comm 0x131a44b10 rank 3 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x6a336f573a53dcba - Init COMPLETE
d11n17:1142858:1143210 [4] NCCL INFO comm 0x134f342e0 rank 6 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x6a336f573a53dcba - Init COMPLETE
f16n16:1079917:1080282 [5] NCCL INFO Connected all trees
f16n16:1079917:1080282 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n16:1079917:1080282 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d11n17:1142856:1143207 [2] NCCL INFO comm 0x13de3a6f0 rank 4 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x6a336f573a53dcba - Init COMPLETE
d17n07:1212411:1212808 [1] NCCL INFO Connected all rings
d17n07:1212411:1212808 [1] NCCL INFO Channel 00/0 : 7[1] -> 6[0] via P2P/IPC
d14n08:1173248:1173633 [1] NCCL INFO Connected all trees
d14n08:1173248:1173633 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n08:1173248:1173633 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n07:1212411:1212808 [1] NCCL INFO Channel 01/0 : 7[1] -> 6[0] via P2P/IPC
f17n01:970276:970641 [0] NCCL INFO Connected all trees
f17n01:970276:970641 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f17n01:970276:970641 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n17:1090960:1091325 [1] NCCL INFO Connected all trees
f16n17:1090960:1091325 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n17:1090960:1091325 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n06:1216535:1216924 [5] NCCL INFO Channel 00/0 : 5[5] -> 6[0] [send] via NET/IB/1
d17n06:1216535:1216924 [5] NCCL INFO Channel 01/0 : 5[5] -> 6[0] [send] via NET/IB/1
d17n06:1216534:1216925 [4] NCCL INFO Connected all rings
d17n06:1216534:1216925 [4] NCCL INFO Channel 00/0 : 4[4] -> 3[3] via P2P/IPC
d17n06:1216534:1216925 [4] NCCL INFO Channel 01/0 : 4[4] -> 3[3] via P2P/IPC
d17n06:1216533:1216927 [3] NCCL INFO Connected all trees
d17n06:1216533:1216927 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d17n06:1216533:1216927 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n06:1216535:1216924 [5] NCCL INFO Connected all rings
d17n06:1216535:1216924 [5] NCCL INFO Channel 00/0 : 5[5] -> 4[4] via P2P/IPC
d14n08:1173247:1173628 [0] NCCL INFO Connected all trees
d14n08:1173247:1173628 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n08:1173247:1173628 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n06:1216535:1216924 [5] NCCL INFO Channel 01/0 : 5[5] -> 4[4] via P2P/IPC
f17n01:970276:970641 [0] NCCL INFO comm 0x15e00e130 rank 6 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x13974c2855421d4b - Init COMPLETE
d14n09:567666:568060 [0] NCCL INFO Connected all trees
d14n09:567666:568060 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n09:567666:568060 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f17n01:970277:970642 [1] NCCL INFO comm 0x149c54d50 rank 7 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x13974c2855421d4b - Init COMPLETE
f16n18:1091867:1092250 [1] NCCL INFO Connected all trees
f16n18:1091867:1092250 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n18:1091867:1092250 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n06:1216535:1216924 [5] NCCL INFO Connected all trees
d17n06:1216535:1216924 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d17n06:1216535:1216924 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n17:1090961:1091324 [2] NCCL INFO Connected all trees
f16n17:1090961:1091324 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n17:1090961:1091324 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n17:1090959:1091326 [0] NCCL INFO Connected all trees
f16n17:1090959:1091326 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n17:1090959:1091326 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n07:1212410:1212807 [0] NCCL INFO Connected all rings
d17n07:1212410:1212807 [0] NCCL INFO Channel 00/0 : 6[0] -> 0[0] [send] via NET/IB/0
d17n07:1212410:1212807 [0] NCCL INFO Channel 01/0 : 6[0] -> 0[0] [send] via NET/IB/0
d17n07:1212410:1212807 [0] NCCL INFO Channel 00/0 : 0[0] -> 6[0] [receive] via NET/IB/0
d17n07:1212410:1212807 [0] NCCL INFO Channel 01/0 : 0[0] -> 6[0] [receive] via NET/IB/0
d17n06:1216530:1216923 [0] NCCL INFO Connected all rings
d17n06:1216530:1216923 [0] NCCL INFO Channel 00/0 : 6[0] -> 0[0] [receive] via NET/IB/0
d17n06:1216530:1216923 [0] NCCL INFO Channel 01/0 : 6[0] -> 0[0] [receive] via NET/IB/0
d17n06:1216530:1216923 [0] NCCL INFO Channel 00/0 : 0[0] -> 6[0] [send] via NET/IB/0
d17n06:1216530:1216923 [0] NCCL INFO Channel 01/0 : 0[0] -> 6[0] [send] via NET/IB/0
f16n16:1079916:1080278 [4] NCCL INFO Connected all trees
f16n16:1079916:1080278 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
f16n16:1079916:1080278 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n06:1216534:1216925 [4] NCCL INFO Connected all trees
d17n06:1216534:1216925 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d17n06:1216534:1216925 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d14n08:1173249:1173632 [2] NCCL INFO Connected all trees
d14n08:1173249:1173632 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d14n08:1173249:1173632 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n07:1212411:1212808 [1] NCCL INFO Connected all trees
d17n07:1212411:1212808 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d17n07:1212411:1212808 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n16:1079916:1080278 [4] NCCL INFO comm 0x150d1de40 rank 0 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x26c01b22882866ea - Init COMPLETE
f16n16:1079917:1080282 [5] NCCL INFO comm 0x171006ac0 rank 1 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x26c01b22882866ea - Init COMPLETE
d14n08:1173247:1173628 [0] NCCL INFO comm 0x139a1aea0 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x1c908ef09309e642 - Init COMPLETE
d14n08:1173251:1173631 [4] NCCL INFO comm 0x16180f260 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x1c908ef09309e642 - Init COMPLETE
d14n08:1173249:1173632 [2] NCCL INFO comm 0x151d4bdc0 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x1c908ef09309e642 - Init COMPLETE
d14n08:1173250:1173630 [3] NCCL INFO comm 0x166da4ff0 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x1c908ef09309e642 - Init COMPLETE
d14n08:1173248:1173633 [1] NCCL INFO comm 0x13b012820 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x1c908ef09309e642 - Init COMPLETE
d14n08:1173252:1173629 [5] NCCL INFO comm 0x1356e14f0 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x1c908ef09309e642 - Init COMPLETE
d14n09:567666:568060 [0] NCCL INFO comm 0x1818e3dc0 rank 6 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x1c908ef09309e642 - Init COMPLETE
d14n09:567667:568059 [1] NCCL INFO comm 0x1522b2b00 rank 7 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x1c908ef09309e642 - Init COMPLETE
f16n17:1090960:1091325 [1] NCCL INFO comm 0x162933540 rank 3 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x26c01b22882866ea - Init COMPLETE
f16n17:1090963:1091328 [4] NCCL INFO comm 0x13fea43d0 rank 6 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x26c01b22882866ea - Init COMPLETE
f16n17:1090962:1091327 [3] NCCL INFO comm 0x13c1790f0 rank 5 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x26c01b22882866ea - Init COMPLETE
f16n17:1090959:1091326 [0] NCCL INFO comm 0x1472aad40 rank 2 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x26c01b22882866ea - Init COMPLETE
f16n17:1090964:1091329 [5] NCCL INFO comm 0x17515e920 rank 7 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x26c01b22882866ea - Init COMPLETE
f16n17:1090961:1091324 [2] NCCL INFO comm 0x122eeff80 rank 4 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x26c01b22882866ea - Init COMPLETE
d17n06:1216530:1216923 [0] NCCL INFO Connected all trees
d17n06:1216530:1216923 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d17n06:1216530:1216923 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n07:1212410:1212807 [0] NCCL INFO Connected all trees
d17n07:1212410:1212807 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d17n07:1212410:1212807 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
f16n18:1091866:1092249 [0] NCCL INFO comm 0x11e2fcf80 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x13974c2855421d4b - Init COMPLETE
f16n18:1091870:1092254 [4] NCCL INFO comm 0x170167300 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x13974c2855421d4b - Init COMPLETE
f16n18:1091868:1092251 [2] NCCL INFO comm 0x17341dfc0 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x13974c2855421d4b - Init COMPLETE
f16n18:1091869:1092253 [3] NCCL INFO comm 0x151a05600 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x13974c2855421d4b - Init COMPLETE
f16n18:1091867:1092250 [1] NCCL INFO comm 0x15caffa60 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x13974c2855421d4b - Init COMPLETE
f16n18:1091871:1092252 [5] NCCL INFO comm 0x14e7194c0 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x13974c2855421d4b - Init COMPLETE
d17n06:1216531:1216928 [1] NCCL INFO Connected all trees
d17n06:1216531:1216928 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
d17n06:1216531:1216928 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
d17n06:1216530:1216923 [0] NCCL INFO comm 0x147f44c70 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x2ed1f251b0bfef39 - Init COMPLETE
d17n06:1216531:1216928 [1] NCCL INFO comm 0x12333ff00 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x2ed1f251b0bfef39 - Init COMPLETE
d17n06:1216532:1216926 [2] NCCL INFO comm 0x130d1c880 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 406000 commId 0x2ed1f251b0bfef39 - Init COMPLETE
d17n06:1216533:1216927 [3] NCCL INFO comm 0x13ee572a0 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 3503000 commId 0x2ed1f251b0bfef39 - Init COMPLETE
d17n06:1216534:1216925 [4] NCCL INFO comm 0x12ae2ac40 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 3504000 commId 0x2ed1f251b0bfef39 - Init COMPLETE
d17n06:1216535:1216924 [5] NCCL INFO comm 0x13d8db700 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId 3505000 commId 0x2ed1f251b0bfef39 - Init COMPLETE
d17n07:1212410:1212807 [0] NCCL INFO comm 0x1741b81d0 rank 6 nranks 8 cudaDev 0 nvmlDev 0 busId 404000 commId 0x2ed1f251b0bfef39 - Init COMPLETE
d17n07:1212411:1212808 [1] NCCL INFO comm 0x17bea82c0 rank 7 nranks 8 cudaDev 1 nvmlDev 1 busId 405000 commId 0x2ed1f251b0bfef39 - Init COMPLETE
[after dataloaders are built] datetime: 2024-03-04 16:46:29 
done with setup ...
training ...
(min, max) time across ranks (ms):
    model-and-optimizer-setup ......................: (5527.33, 5553.38)
    train/valid/test-data-iterators-setup ..........: (1171.79, 1449.81)
[before the start of training step] datetime: 2024-03-04 16:46:29 
[2024-03-04 16:46:30,039] [INFO] [checkpointing.py:529:forward] Activation Checkpointing Information
[2024-03-04 16:46:30,039] [INFO] [checkpointing.py:530:forward] ----Partition Activations False, CPU CHECKPOINTING False
[2024-03-04 16:46:30,039] [INFO] [checkpointing.py:531:forward] ----contiguous Memory Checkpointing False with 32 total layers
[2024-03-04 16:46:30,039] [INFO] [checkpointing.py:533:forward] ----Synchronization False
[2024-03-04 16:46:30,039] [INFO] [checkpointing.py:534:forward] ----Profiling time in checkpointing False
[2024-03-04 16:47:13,892] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[1.4155776e-07, 1.4155776e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
 iteration       10/18310546 | consumed samples:          240 | consumed tokens:       491520 | elapsed time per iteration (ms): 4490.4 | learning rate: 1.416E-07 | global batch size:    24 | lm loss: 1.129544E+01 | loss scale: 2048.0 | grad norm: 61.755 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.345 | tokens per gpu per second (tgs): 114.021 | TFLOPs: 6.51 |
steps: 10 loss: 11.0434 iter time (s): 4.422 samples/sec: 5.427
[Rank 0] (after 10 iterations) memory (MB) | allocated: 2568.96728515625 | max allocated: 5118.70166015625 | reserved: 8468.0 | max reserved: 8468.0
[Rank 4] (after 10 iterations) memory (MB) | allocated: 2568.96728515625 | max allocated: 5118.70166015625 | reserved: 8404.0 | max reserved: 8404.0
[Rank 1] (after 10 iterations) memory (MB) | allocated: 2568.96728515625 | max allocated: 5118.70166015625 | reserved: 8424.0 | max reserved: 8424.0
[Rank 3] (after 10 iterations) memory (MB) | allocated: 2568.96728515625 | max allocated: 5118.70166015625 | reserved: 8424.0 | max reserved: 8424.0
[Rank 5] (after 10 iterations) memory (MB) | allocated: 2568.96728515625 | max allocated: 5118.70166015625 | reserved: 8392.0 | max reserved: 8392.0
[Rank 7] (after 10 iterations) memory (MB) | allocated: 2568.96728515625 | max allocated: 5119.7001953125 | reserved: 8424.0 | max reserved: 8424.0
[Rank 2] (after 10 iterations) memory (MB) | allocated: 2568.96728515625 | max allocated: 5118.70166015625 | reserved: 8408.0 | max reserved: 8408.0
[Rank 6] (after 10 iterations) memory (MB) | allocated: 2568.96728515625 | max allocated: 5119.7001953125 | reserved: 8472.0 | max reserved: 8472.0
[2024-03-04 16:47:56,815] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=0, lr=[2.9884416000000005e-07, 2.9884416000000005e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
 iteration       20/18310546 | consumed samples:          480 | consumed tokens:       983040 | elapsed time per iteration (ms): 4288.2 | learning rate: 2.988E-07 | global batch size:    24 | lm loss: 9.862000E+00 | loss scale: 2048.0 | grad norm: 34.638 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.597 | tokens per gpu per second (tgs): 119.397 | TFLOPs: 6.82 |

------------------------------------------------------------
Sender: LSF System <lsfadmin@batch5>
Subject: Job 3330162: <gpt3-megatron> in cluster <summit> Exited

Job <gpt3-megatron> was submitted from host <login3> by user <sajaldash> in cluster <summit> at Mon Mar  4 16:45:33 2024
Job was executed on host(s) <1*batch5>, in queue <debug>, as user <sajaldash> in cluster <summit> at Mon Mar  4 16:45:44 2024
                            <42*d09n07>
                            <42*d09n08>
                            <42*d11n16>
                            <42*d11n17>
                            <42*d14n08>
                            <42*d14n09>
                            <42*d14n10>
                            <42*d14n11>
                            <42*d17n06>
                            <42*d17n07>
                            <42*f16n16>
                            <42*f16n17>
                            <42*f16n18>
                            <42*f17n01>
                            <42*f17n02>
                            <42*f18n05>
</ccs/home/sajaldash> was used as the home directory.
</gpfs/alpine2/stf218/world-shared/sajal/Megatron-DeepSpeed> was used as the working directory.
Started at Mon Mar  4 16:45:44 2024
Terminated at Mon Mar  4 16:48:22 2024
Results reported at Mon Mar  4 16:48:22 2024

The output (if any) is above this job summary.



PS:

Read file <logs/gpt3-megatron.3330162.e> for stderr output of this job.

